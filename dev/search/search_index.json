{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"zae-limiter","text":"<p>A rate limiting library backed by DynamoDB using the token bucket algorithm.</p>"},{"location":"#overview","title":"Overview","text":"<p>zae-limiter excels at rate limiting scenarios where:</p> <ul> <li>Multiple limits are tracked per call (requests per minute, tokens per minute)</li> <li>Consumption is unknown upfront \u2014 adjust limits after the operation completes</li> <li>Hierarchical limits exist (API key \u2192 project, tenant \u2192 user)</li> <li>Cost matters \u2014 ~$1/1M requests (details)</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Token Bucket Algorithm - Precise rate limiting with configurable burst capacity</li> <li>Multiple Limits - Track requests per minute, tokens per minute, etc. in a single call</li> <li>Hierarchical Entities - Two-level hierarchy (project \u2192 API keys) with cascade mode</li> <li>Atomic Transactions - Multi-key updates via DynamoDB TransactWriteItems</li> <li>Rollback on Exception - Automatic rollback if your code throws</li> <li>Stored Limits - Configure per-entity limits in DynamoDB</li> <li>Usage Analytics - Lambda aggregator for hourly/daily usage snapshots</li> <li>Audit Logging - Track entity and limit changes for compliance</li> <li>Async + Sync APIs - First-class async support with sync wrapper</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from zae_limiter import RateLimiter, Limit, StackOptions\n\n# Async rate limiter with declarative infrastructure\nlimiter = RateLimiter(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Declare desired state - CloudFormation ensures it\n)\n\n# Define default limits (can be overridden per-entity)\ndefault_limits = [\n    Limit.per_minute(\"rpm\", 100),\n    Limit.per_minute(\"tpm\", 10_000, burst=50_000),  # Token bucket with burst\n]\n\nasync with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=default_limits,\n    consume={\"rpm\": 1, \"tpm\": 500},  # Estimate tokens upfront\n) as lease:\n    response = await call_llm()\n    # Reconcile actual usage (can go negative for post-hoc adjustment)\n    await lease.adjust(tpm=response.usage.total_tokens - 500)\n    # On success: committed | On exception: rolled back automatically\n\n# Hierarchical entities: project \u2192 API key\nawait limiter.create_entity(entity_id=\"proj-1\", name=\"Production\")\nawait limiter.set_limits(\"proj-1\", [Limit.per_minute(\"tpm\", 100_000)])\nawait limiter.create_entity(entity_id=\"api-key-456\", parent_id=\"proj-1\")\n\n# cascade=True enforces both key AND project limits\nasync with limiter.acquire(\n    entity_id=\"api-key-456\",\n    resource=\"gpt-4\",\n    limits=default_limits,\n    consume={\"rpm\": 1, \"tpm\": 500},\n    cascade=True,  # Also checks parent's stored limits\n    use_stored_limits=True,  # Uses proj-1's 100k tpm limit\n) as lease:\n    response = await call_llm()\n</code></pre>"},{"location":"#why-dynamodb","title":"Why DynamoDB?","text":"<ul> <li>Serverless - No infrastructure to manage, 99.99% SLA</li> <li>Regional - Deploy independently per region with low latency</li> <li>Scalable - Handles millions of requests per second</li> <li>Cost-effective - Pay per request, no idle costs</li> <li>Atomic - TransactWriteItems for multi-key consistency</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"Guide Description Getting Started Installation and first deployment Basic Usage Rate limiting patterns and error handling Hierarchical Limits Parent/child entities, cascade mode LLM Integration Token estimation and reconciliation Production Guide Security, monitoring, cost CLI Reference Deploy, status, delete commands"},{"location":"cli/","title":"CLI Reference","text":"<p>zae-limiter provides a command-line interface for managing infrastructure and deployments.</p>"},{"location":"cli/#installation","title":"Installation","text":"<p>The CLI is included with the package:</p> <pre><code>pip install zae-limiter\n# or\nconda install -c conda-forge zae-limiter\n</code></pre> <p>Verify installation:</p> <pre><code>zae-limiter --version\n</code></pre>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#deploy","title":"deploy","text":"<p>Deploy the CloudFormation stack with DynamoDB table and Lambda aggregator.</p> <pre><code>zae-limiter deploy [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (creates ZAEL-{name} resources) <code>limiter</code> <code>--region</code> AWS region boto3 default <code>--endpoint-url</code> Custom AWS endpoint (LocalStack) None <code>--snapshot-windows</code> Comma-separated snapshot windows <code>hourly,daily</code> <code>--retention-days</code> Usage snapshot retention (days) <code>90</code> <code>--enable-aggregator/--no-aggregator</code> Deploy Lambda aggregator <code>true</code> <code>--pitr-recovery-days</code> Point-in-time recovery (1-35 days) None (disabled) <code>--log-retention-days</code> CloudWatch log retention (days) <code>30</code> <code>--lambda-timeout</code> Lambda timeout (1-900 seconds) <code>60</code> <code>--lambda-memory</code> Lambda memory (128-3008 MB) <code>256</code> <code>--enable-alarms/--no-alarms</code> Deploy CloudWatch alarms <code>true</code> <code>--alarm-sns-topic</code> SNS topic ARN for notifications None <code>--permission-boundary</code> IAM permission boundary None <code>--role-name-format</code> Lambda role name format None <code>--wait/--no-wait</code> Wait for stack creation <code>true</code> <p>Examples:</p> <pre><code># Basic deployment\nzae-limiter deploy --name limiter --region us-east-1\n\n# With custom settings\nzae-limiter deploy \\\n    --name prod \\\n    --region us-west-2 \\\n    --log-retention-days 90 \\\n    --pitr-recovery-days 7\n\n# Deploy to LocalStack\nzae-limiter deploy \\\n    --name limiter \\\n    --endpoint-url http://localhost:4566 \\\n    --region us-east-1\n\n# Without Lambda aggregator\nzae-limiter deploy \\\n    --name limiter \\\n    --region us-east-1 \\\n    --no-aggregator\n</code></pre>"},{"location":"cli/#status","title":"status","text":"<p>Check the status of a deployed CloudFormation stack.</p> <pre><code>zae-limiter status [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) Required <code>--region</code> AWS region Required <code>--endpoint-url</code> Custom AWS endpoint None <p>Example:</p> <pre><code>zae-limiter status --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>Status: ZAEL-limiter\n==================================================\n\nConnectivity\n  Available:     \u2713 Yes\n  Latency:       42ms\n  Region:        us-east-1\n\nInfrastructure\n  Stack:         CREATE_COMPLETE\n  Table:         ACTIVE\n  Aggregator:    Enabled\n\nVersions\n  Client:        0.2.0\n  Schema:        1.0.0\n  Lambda:        0.2.0\n\nTable Metrics\n  Items:         1,234\n  Size:          128.5 KB\n\n\u2713 Infrastructure is ready\n</code></pre>"},{"location":"cli/#delete","title":"delete","text":"<p>Delete a CloudFormation stack and all its resources.</p> <pre><code>zae-limiter delete [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) Required <code>--region</code> AWS region Required <code>--yes</code> Skip confirmation prompt <code>false</code> <code>--endpoint-url</code> Custom AWS endpoint None <p>Example:</p> <pre><code># With confirmation\nzae-limiter delete --name limiter --region us-east-1\n\n# Skip confirmation\nzae-limiter delete --name limiter --region us-east-1 --yes\n</code></pre> <p>Data Loss</p> <p>Deleting a stack removes the DynamoDB table and all its data. This action cannot be undone.</p>"},{"location":"cli/#cfn-template","title":"cfn-template","text":"<p>Export the CloudFormation template to stdout.</p> <pre><code>zae-limiter cfn-template [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--output</code>, <code>-o</code> Output file path stdout <p>Examples:</p> <pre><code># Export template to stdout\nzae-limiter cfn-template &gt; template.yaml\n\n# Export template to file\nzae-limiter cfn-template --output template.yaml\n\n# View template\nzae-limiter cfn-template | less\n</code></pre>"},{"location":"cli/#lambda-export","title":"lambda-export","text":"<p>Export the Lambda deployment package.</p> <pre><code>zae-limiter lambda-export [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--output</code>, <code>-o</code> Output file path <code>lambda.zip</code> <code>--info</code> Show package info without building <code>false</code> <code>--force</code>, <code>-f</code> Overwrite existing file <code>false</code> <p>Examples:</p> <pre><code># Export Lambda package\nzae-limiter lambda-export --output lambda.zip\n\n# Show package info\nzae-limiter lambda-export --info\n</code></pre> <p>Info output:</p> <pre><code>Lambda Package Info:\n  Handler: zae_limiter.aggregator.handler.lambda_handler\n  Runtime: python3.12\n  Estimated size: ~30KB\n  Dependencies: boto3 (provided by Lambda runtime)\n</code></pre>"},{"location":"cli/#version","title":"version","text":"<p>Show infrastructure version information for a deployed stack.</p> <pre><code>zae-limiter version [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) <code>limiter</code> <code>--region</code> AWS region boto3 default <code>--endpoint-url</code> Custom AWS endpoint None <p>Example:</p> <pre><code>zae-limiter version --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>zae-limiter Infrastructure Version\n====================================\n\nClient Version:     0.1.0\nSchema Version:     1.0.0\n\nInfra Schema:       1.0.0\nLambda Version:     0.1.0\nMin Client Version: 0.0.0\n\nStatus: COMPATIBLE\n</code></pre>"},{"location":"cli/#check","title":"check","text":"<p>Check infrastructure compatibility without modifying.</p> <pre><code>zae-limiter check [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) <code>limiter</code> <code>--region</code> AWS region boto3 default <code>--endpoint-url</code> Custom AWS endpoint None <p>Example:</p> <pre><code>zae-limiter check --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>Compatibility Check\n====================\n\nClient:      0.1.0\nSchema:      1.0.0\nLambda:      0.1.0\n\nResult: COMPATIBLE\n\nClient and infrastructure are fully compatible.\n</code></pre>"},{"location":"cli/#upgrade","title":"upgrade","text":"<p>Upgrade a table schema to the latest version.</p> <pre><code>zae-limiter upgrade [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) <code>limiter</code> <code>--region</code> AWS region boto3 default <code>--endpoint-url</code> Custom AWS endpoint None <code>--lambda-only</code> Only update Lambda code <code>false</code> <code>--force</code> Force update even if version matches <code>false</code> <p>Example:</p> <pre><code># Upgrade infrastructure\nzae-limiter upgrade --name limiter --region us-east-1\n\n# Force Lambda update only\nzae-limiter upgrade --name limiter --region us-east-1 --lambda-only --force\n</code></pre>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects standard AWS environment variables:</p> Variable Description <code>AWS_ACCESS_KEY_ID</code> AWS access key <code>AWS_SECRET_ACCESS_KEY</code> AWS secret key <code>AWS_SESSION_TOKEN</code> AWS session token <code>AWS_DEFAULT_REGION</code> Default AWS region <code>AWS_PROFILE</code> AWS profile name <code>AWS_ENDPOINT_URL</code> Custom endpoint URL"},{"location":"cli/#exit-codes","title":"Exit Codes","text":"Code Description <code>0</code> Success <code>1</code> General error <code>2</code> Invalid arguments <code>3</code> AWS API error <code>4</code> Stack not found"},{"location":"cli/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment - Deployment guide</li> <li>LocalStack - Local development</li> <li>API Reference - Python API documentation</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you install zae-limiter and set up rate limiting in your application.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"pipuvpoetryconda <pre><code>pip install zae-limiter\n</code></pre> <pre><code>uv pip install zae-limiter\n</code></pre> <pre><code>poetry add zae-limiter\n</code></pre> <pre><code>conda install -c conda-forge zae-limiter\n</code></pre>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<p>zae-limiter creates its own infrastructure automatically. Here's a complete example:</p>"},{"location":"getting-started/#async-api-recommended","title":"Async API (Recommended)","text":"<pre><code>from zae_limiter import RateLimiter, Limit, StackOptions, RateLimitExceeded\n\n# Create rate limiter with declarative infrastructure\nlimiter = RateLimiter(\n    name=\"my-app\",           # ZAEL-my-app resources in AWS\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Declare desired state - CloudFormation ensures it\n)\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"requests\", 100)],\n        consume={\"requests\": 1},\n    ) as lease:\n        await do_work()\nexcept RateLimitExceeded as e:\n    print(f\"Rate limited! Retry after {e.retry_after_seconds:.1f}s\")\n</code></pre>"},{"location":"getting-started/#sync-api","title":"Sync API","text":"<pre><code>from zae_limiter import SyncRateLimiter, Limit, StackOptions\n\nlimiter = SyncRateLimiter(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\nwith limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"requests\", 100)],\n    consume={\"requests\": 1},\n) as lease:\n    response = call_api()\n</code></pre>"},{"location":"getting-started/#infrastructure-persistence","title":"Infrastructure Persistence","text":"<p>When you pass <code>stack_options=StackOptions()</code>, zae-limiter creates real AWS infrastructure via CloudFormation:</p> Resource Purpose Persists? DynamoDB Table Rate limit state, entities, usage Yes - until deleted Lambda Function Usage aggregation Yes - until deleted IAM Role Lambda permissions Yes - until deleted CloudWatch Logs Lambda logs Yes - with retention <p>Infrastructure Outlives Your Python Session</p> <p>This infrastructure persists beyond your Python session. Restarting your application reconnects to existing resources. Rate limit state is preserved across restarts. You only pay when the limiter is used (~$1/1M requests).</p>"},{"location":"getting-started/#infrastructure-lifecycle","title":"Infrastructure Lifecycle","text":"<p>Both programmatic API and CLI are fully supported for managing infrastructure.</p>"},{"location":"getting-started/#creating-infrastructure","title":"Creating Infrastructure","text":"ProgrammaticCLI <p>Pass <code>stack_options</code> to declare the desired infrastructure state:</p> <pre><code>limiter = RateLimiter(\n    name=\"my-app\",\n    stack_options=StackOptions(),  # Desired state declaration\n)\n</code></pre> <p>CloudFormation ensures the infrastructure matches your declaration.</p> <pre><code>zae-limiter deploy --name my-app --region us-east-1\n</code></pre> <p>Useful for: CI/CD pipelines, GitOps workflows, infrastructure-as-code.</p>"},{"location":"getting-started/#connecting-to-existing-infrastructure","title":"Connecting to Existing Infrastructure","text":"<p>If you omit <code>stack_options</code>, the limiter connects to existing infrastructure without attempting to create or modify it:</p> <pre><code># Connect only - fails if ZAEL-my-app doesn't exist\nlimiter = RateLimiter(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    # No stack_options = connect only, no create/update\n)\n</code></pre> <p>This is useful when infrastructure is managed separately (e.g., via CLI or Terraform).</p> <p>Declarative State Management</p> <p><code>StackOptions</code> declares the desired infrastructure state. If multiple applications use the same limiter name with different settings, CloudFormation will update the stack to match the most recent declaration\u2014similar to how Terraform applies the last-written configuration.</p> <p>To maintain consistent state:</p> <ul> <li>Use identical <code>StackOptions</code> across all clients sharing a limiter</li> <li>Omit <code>stack_options</code> in application code and manage infrastructure externally</li> <li>Use different limiter names for different configurations</li> </ul>"},{"location":"getting-started/#checking-status","title":"Checking Status","text":"ProgrammaticCLI <pre><code>status = await limiter.get_status()  # Async\n# or\nstatus = limiter.get_status()  # Sync\n\nif not status.available:\n    print(\"DynamoDB not reachable\")\nelif status.stack_status == \"CREATE_COMPLETE\":\n    print(\"Stack is ready\")\n    print(f\"Latency: {status.latency_ms}ms\")\nelif status.stack_status and \"IN_PROGRESS\" in status.stack_status:\n    print(f\"Operation in progress: {status.stack_status}\")\nelif status.stack_status and \"FAILED\" in status.stack_status:\n    print(f\"Stack in failed state: {status.stack_status}\")\n</code></pre> <pre><code>zae-limiter status --name my-app --region us-east-1\n</code></pre>"},{"location":"getting-started/#deleting-infrastructure","title":"Deleting Infrastructure","text":"ProgrammaticCLI <pre><code># After you're done with the limiter\nawait limiter.delete_stack()  # Async\n# or\nlimiter.delete_stack()  # Sync\n</code></pre> <pre><code>zae-limiter delete --name my-app --region us-east-1 --yes\n</code></pre> <p>Data Loss</p> <p>Deleting infrastructure permanently removes all rate limit data, entity configurations, and usage history. This cannot be undone.</p> <p>Deployment Options</p> <p>For organizations requiring strict infrastructure/application separation, see CLI deployment or CloudFormation template export.</p>"},{"location":"getting-started/#understanding-limits","title":"Understanding Limits","text":"<p>Rate limiting in zae-limiter tracks who is making requests, what they're accessing, and how much they can use.</p>"},{"location":"getting-started/#the-core-concepts","title":"The Core Concepts","text":"<p>When you call <code>acquire()</code>, you specify:</p> <ul> <li><code>entity_id</code>: Who is being rate limited (e.g., <code>\"user-123\"</code>, <code>\"api-key-abc\"</code>, <code>\"tenant-xyz\"</code>)</li> <li><code>resource</code>: What they're accessing (e.g., <code>\"gpt-4\"</code>, <code>\"api\"</code>, <code>\"embeddings\"</code>)</li> <li><code>limits</code>: The rate limit rules to apply</li> <li><code>consume</code>: How much capacity this request uses</li> </ul> <p>Each entity has separate buckets per resource. A user rate limited on <code>\"gpt-4\"</code> can still access <code>\"gpt-3.5-turbo\"</code>:</p> <pre><code># User 123 accessing GPT-4 - tracked separately from GPT-3.5\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",        # Bucket: user-123 + gpt-4\n    limits=[Limit.per_minute(\"rpm\", 10)],\n    consume={\"rpm\": 1},\n) as lease:\n    ...\n\n# Same user, different resource - separate bucket\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-3.5-turbo\",  # Bucket: user-123 + gpt-3.5-turbo\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    consume={\"rpm\": 1},\n) as lease:\n    ...\n</code></pre>"},{"location":"getting-started/#defining-limits","title":"Defining Limits","text":"<p>A <code>Limit</code> defines a rate limit using the token bucket algorithm:</p> <pre><code># 100 requests per minute\nLimit.per_minute(\"rpm\", 100)\n\n# 10,000 tokens per minute with 15,000 burst capacity\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n\n# 1,000 requests per hour\nLimit.per_hour(\"rph\", 1_000)\n\n# Custom: 50 requests per 30 seconds\nLimit.custom(\"requests\", capacity=50, refill_period_seconds=30)\n</code></pre> Parameter Description <code>name</code> Unique identifier (e.g., \"rpm\", \"tpm\") <code>capacity</code> Tokens that refill per period (sustained rate) <code>burst</code> Maximum bucket size (defaults to capacity) <p>See Token Bucket Algorithm for details on how capacity, burst, and refill work together.</p>"},{"location":"getting-started/#handling-rate-limit-errors","title":"Handling Rate Limit Errors","text":"<p>When a rate limit is exceeded, <code>RateLimitExceeded</code> is raised with full details:</p> <pre><code>from zae_limiter import RateLimitExceeded\n\ntry:\n    async with limiter.acquire(...):\n        await do_work()\nexcept RateLimitExceeded as e:\n    # Get retry delay\n    print(f\"Retry after: {e.retry_after_seconds}s\")\n\n    # For HTTP responses\n    return JSONResponse(\n        status_code=429,\n        content=e.as_dict(),\n        headers={\"Retry-After\": e.retry_after_header},\n    )\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage - Multiple limits, adjustments, capacity queries</li> <li>Hierarchical Limits - Parent/child entities, cascade mode</li> <li>LLM Integration - Token estimation and reconciliation</li> <li>Deployment Guide - Production deployment options</li> <li>CLI Reference - Full CLI command reference</li> </ul>"},{"location":"migrations/","title":"Migrations","text":"<p>This guide covers managing schema migrations for zae-limiter infrastructure.</p>"},{"location":"migrations/#overview","title":"Overview","text":"<p>Schema migrations handle changes to the DynamoDB table structure when upgrading between major versions of zae-limiter. The migration framework provides:</p> <ul> <li>Version tracking - Infrastructure version stored in DynamoDB</li> <li>Compatibility checking - Automatic client/infrastructure compatibility validation</li> <li>Migration registry - Ordered list of migrations between versions</li> <li>Rollback support - Optional rollback functions for reversible changes</li> </ul>"},{"location":"migrations/#when-migrations-are-needed","title":"When Migrations Are Needed","text":"Change Type Migration Required? Version Bump Add optional attribute No Patch (x.x.1) Add new index (GSI) Yes Minor (x.1.0) Change key structure Yes Major (1.0.0) Remove attribute Yes Major (1.0.0) Change attribute type Yes Major (1.0.0)"},{"location":"migrations/#version-compatibility","title":"Version Compatibility","text":"<p>zae-limiter uses semantic versioning with specific compatibility rules.</p>"},{"location":"migrations/#compatibility-rules","title":"Compatibility Rules","text":"<pre><code>Client 1.x.x + Schema 1.x.x = Compatible\nClient 2.x.x + Schema 1.x.x = Incompatible (migration required)\nClient 1.2.0 + Min Client 1.3.0 = Incompatible (upgrade client)\n</code></pre> <p>Major version mismatch: Always incompatible. Schema migration required before the client can operate.</p> <p>Minor/patch version mismatch: Compatible. Client and infrastructure can operate together.</p> <p>Minimum client version: Infrastructure can require a minimum client version. Older clients are rejected.</p>"},{"location":"migrations/#checking-compatibility","title":"Checking Compatibility","text":"<p>Use the CLI to check compatibility without modifying anything:</p> <pre><code># Check current compatibility status\nzae-limiter check --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>Compatibility Check\n====================\n\nClient:      1.2.0\nSchema:      1.0.0\nLambda:      1.1.0\n\nResult: COMPATIBLE (update available)\n\nLambda update available: 1.1.0 -&gt; 1.2.0\n\nRun 'zae-limiter upgrade' to update.\n</code></pre>"},{"location":"migrations/#viewing-version-information","title":"Viewing Version Information","text":"<pre><code># Show detailed version information\nzae-limiter version --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>zae-limiter Infrastructure Version\n====================================\n\nClient Version:     1.2.0\nSchema Version:     1.0.0\n\nInfra Schema:       1.0.0\nLambda Version:     1.1.0\nMin Client Version: 0.0.0\n\nStatus: COMPATIBLE (Lambda update available)\n\n  Lambda update available: 1.1.0 -&gt; 1.2.0\n\nRun 'zae-limiter upgrade' to update Lambda.\n</code></pre>"},{"location":"migrations/#upgrading-infrastructure","title":"Upgrading Infrastructure","text":"<p>For minor updates (Lambda code, no schema changes):</p> <pre><code># Upgrade Lambda to match client version\nzae-limiter upgrade --name limiter --region us-east-1\n</code></pre> <p>For major version upgrades requiring schema migration, see Sample Migration: v2.0.0.</p>"},{"location":"migrations/#schema-modification-approaches","title":"Schema Modification Approaches","text":"<p>When modifying the DynamoDB schema, prefer solutions that preserve backward compatibility.</p>"},{"location":"migrations/#non-breaking-changes-preferred","title":"Non-Breaking Changes (Preferred)","text":"<p>These changes don't require migrations:</p> <p>Adding optional attributes: <pre><code># Old code works - attribute simply missing\nitem = {\"PK\": \"ENTITY#123\", \"SK\": \"#META\", \"name\": \"test\"}\n\n# New code adds optional attribute\nitem = {\"PK\": \"ENTITY#123\", \"SK\": \"#META\", \"name\": \"test\", \"tags\": [\"prod\"]}\n</code></pre></p> <p>Using <code>if_not_exists()</code> for new nested structures: <pre><code># Initialize nested map only if missing\nupdate_expression = \"SET #data.#metrics = if_not_exists(#data.#metrics, :empty_map)\"\n</code></pre></p> <p>Adding conditional logic for missing attributes: <pre><code># Handle missing attribute gracefully\nmetrics = item.get(\"data\", {}).get(\"metrics\", {})\nrequest_count = metrics.get(\"requests\", 0)\n</code></pre></p>"},{"location":"migrations/#breaking-changes-major-version","title":"Breaking Changes (Major Version)","text":"<p>These changes require migrations and major version bumps:</p> <ul> <li>Changing partition or sort key structure</li> <li>Removing required attributes</li> <li>Changing attribute data types</li> <li>Renaming attributes</li> <li>Restructuring nested data</li> </ul>"},{"location":"migrations/#dynamodb-specific-considerations","title":"DynamoDB-Specific Considerations","text":"<p>GSI Changes:</p> <ul> <li>Adding a GSI: Can be done without migration (CloudFormation update)</li> <li>Removing a GSI: Requires ensuring no code depends on it</li> <li>Changing GSI keys: Requires data migration</li> </ul> <p>Key Pattern Changes:</p> <pre><code># v1.0.0 pattern\nPK = f\"ENTITY#{entity_id}\"\nSK = f\"#BUCKET#{resource}#{limit_name}\"\n\n# v2.0.0 pattern (breaking change!)\nPK = f\"ENT#{entity_id}\"  # Changed prefix\nSK = f\"BKT#{resource}#{limit_name}\"  # Changed prefix\n</code></pre> <p>Key pattern changes require migrating all existing data.</p>"},{"location":"migrations/#creating-a-migration","title":"Creating a Migration","text":""},{"location":"migrations/#migration-file-structure","title":"Migration File Structure","text":"<p>Create a new file in <code>src/zae_limiter/migrations/</code>:</p> <pre><code># src/zae_limiter/migrations/v1_1_0.py\n\"\"\"\nMigration: v1.1.0 (Add metrics tracking)\n\nThis migration adds a metrics attribute to entity metadata\nfor tracking request statistics.\n\nChanges:\n- Add 'metrics' map to entity #META records\n- Initialize with empty counters\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom . import Migration, register_migration\n\nif TYPE_CHECKING:\n    from ..repository import Repository\n\n\nasync def migrate_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Add metrics attribute to all entity metadata records.\n\n    This is a forward-only migration that initializes the\n    metrics structure for existing entities.\n    \"\"\"\n    # Query all entity metadata records\n    # Update each to add metrics if missing\n    # Use conditional updates to be idempotent\n    pass\n\n\nasync def rollback_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Remove metrics attribute from entity metadata.\n\n    Note: This loses all collected metrics data.\n    \"\"\"\n    # Remove metrics attribute from all entities\n    pass\n\n\n# Register the migration\nregister_migration(\n    Migration(\n        version=\"1.1.0\",\n        description=\"Add metrics tracking to entities\",\n        reversible=True,\n        migrate=migrate_v1_1_0,\n        rollback=rollback_v1_1_0,\n    )\n)\n</code></pre>"},{"location":"migrations/#migration-protocol","title":"Migration Protocol","text":"<p>Migration functions must follow this protocol:</p> <pre><code>async def __call__(self, repository: Repository) -&gt; None:\n    \"\"\"Execute the migration.\"\"\"\n    ...\n</code></pre> <p>Key requirements:</p> <ol> <li>Async: All migrations are async functions</li> <li>Repository parameter: Receives a configured Repository instance</li> <li>Idempotent: Safe to run multiple times (use conditional updates)</li> <li>Atomic where possible: Use transactions for related changes</li> </ol>"},{"location":"migrations/#registering-migrations","title":"Registering Migrations","text":"<p>Migrations are auto-registered when imported. Ensure your migration module is imported in <code>migrations/__init__.py</code>:</p> <pre><code># src/zae_limiter/migrations/__init__.py\n\n# ... existing code ...\n\n# Import built-in migrations to register them\nfrom . import v1_0_0 as _v1_0_0  # noqa: F401, E402\nfrom . import v1_1_0 as _v1_1_0  # noqa: F401, E402  # Add new migration\n</code></pre>"},{"location":"migrations/#updating-schema-version","title":"Updating Schema Version","text":"<p>After adding a migration, update the current schema version:</p> <pre><code># src/zae_limiter/version.py\n\n# Current schema version - increment when schema changes\nCURRENT_SCHEMA_VERSION = \"1.1.0\"  # Updated from \"1.0.0\"\n</code></pre>"},{"location":"migrations/#validating-migrations","title":"Validating Migrations","text":""},{"location":"migrations/#unit-testing-with-moto","title":"Unit Testing with Moto","text":"<p>Test migrations using moto for fast, isolated tests:</p> <pre><code># tests/test_migrations.py\nimport pytest\nfrom moto import mock_aws\n\nfrom zae_limiter.migrations import get_migrations_between, apply_migrations\nfrom zae_limiter.repository import Repository\n\n\n@pytest.fixture\ndef mock_dynamodb():\n    with mock_aws():\n        # Create table and seed test data\n        yield\n\n\n@pytest.mark.asyncio\nasync def test_migration_v1_1_0(mock_dynamodb):\n    \"\"\"Test v1.1.0 migration adds metrics to entities.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create test entity without metrics\n    await repo.create_entity(entity_id=\"test-1\", name=\"Test Entity\")\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n\n    assert applied == [\"1.1.0\"]\n\n    # Verify metrics added - use raw DynamoDB query since Entity\n    # dataclass won't have the new 'metrics' field until code is updated\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#test-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert \"metrics\" in item[\"data\"][\"M\"]\n    assert item[\"data\"][\"M\"][\"metrics\"][\"M\"][\"requests\"][\"N\"] == \"0\"\n\n\n@pytest.mark.asyncio\nasync def test_migration_idempotent(mock_dynamodb):\n    \"\"\"Test migration can be safely run multiple times.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create test entity\n    await repo.create_entity(entity_id=\"test-1\", name=\"Test Entity\")\n\n    # Run migration twice\n    await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n    await apply_migrations(repo, \"1.0.0\", \"1.1.0\")  # Should not fail\n\n    # Verify single application via raw DynamoDB query\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#test-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert item[\"data\"][\"M\"][\"metrics\"][\"M\"][\"requests\"][\"N\"] == \"0\"\n</code></pre>"},{"location":"migrations/#integration-testing-with-localstack","title":"Integration Testing with LocalStack","text":"<p>Test migrations against real AWS-compatible infrastructure:</p> <pre><code># tests/test_migrations_integration.py\nimport os\nimport pytest\n\n# Skip if LocalStack not available\npytestmark = pytest.mark.skipif(\n    not os.environ.get(\"AWS_ENDPOINT_URL\"),\n    reason=\"LocalStack not available\"\n)\n\n\n@pytest.mark.integration\n@pytest.mark.asyncio\nasync def test_migration_with_localstack():\n    \"\"\"Test migration against LocalStack.\"\"\"\n    endpoint_url = os.environ[\"AWS_ENDPOINT_URL\"]\n\n    repo = Repository(\n        \"test_migrations\",\n        \"us-east-1\",\n        endpoint_url,\n    )\n\n    # Deploy infrastructure\n    # ... create table with CloudFormation ...\n\n    # Seed test data\n    # ... create entities ...\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n\n    # Verify changes persisted\n    # ... assertions ...\n</code></pre> <p>Run integration tests:</p> <pre><code># Start LocalStack (from project root)\ndocker compose up -d\n\n# Set environment variables and run integration tests\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\npytest -m integration -v\n</code></pre>"},{"location":"migrations/#production-validation-checklist","title":"Production Validation Checklist","text":"<p>Before running migrations in production:</p> <ul> <li>[ ] Backup: Enable Point-in-Time Recovery (PITR) or create on-demand backup</li> <li>[ ] Test: Run migration against production data copy</li> <li>[ ] Monitor: Set up CloudWatch alarms for errors</li> <li>[ ] Rollback plan: Document rollback procedure</li> <li>[ ] Maintenance window: Schedule during low-traffic period</li> <li>[ ] Communication: Notify stakeholders of potential downtime</li> </ul> <pre><code># Create on-demand backup before migration\naws dynamodb create-backup \\\n  --table-name ZAEL-limiter \\\n  --backup-name \"pre-migration-$(date +%Y%m%d)\"\n\n# Verify PITR is enabled\naws dynamodb describe-continuous-backups \\\n  --table-name ZAEL-limiter\n</code></pre>"},{"location":"migrations/#rollback-strategies","title":"Rollback Strategies","text":""},{"location":"migrations/#reversible-migrations","title":"Reversible Migrations","text":"<p>For migrations that can be safely undone:</p> <pre><code>register_migration(\n    Migration(\n        version=\"1.1.0\",\n        description=\"Add metrics tracking\",\n        reversible=True,  # Can be rolled back\n        migrate=migrate_v1_1_0,\n        rollback=rollback_v1_1_0,  # Rollback function\n    )\n)\n</code></pre> <p>Rollback removes or reverts the changes:</p> <pre><code>async def rollback_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"Remove metrics attribute from all entities.\"\"\"\n    # Implementation to remove metrics attribute\n    pass\n</code></pre>"},{"location":"migrations/#forward-only-migrations","title":"Forward-Only Migrations","text":"<p>Some migrations cannot be reversed:</p> <pre><code>register_migration(\n    Migration(\n        version=\"2.0.0\",\n        description=\"Restructure key patterns\",\n        reversible=False,  # Cannot be rolled back\n        migrate=migrate_v2_0_0,\n        rollback=None,  # No rollback function\n    )\n)\n</code></pre> <p>Forward-only migrations typically involve:</p> <ul> <li>Data transformation with information loss</li> <li>Key structure changes</li> <li>Removing deprecated attributes</li> </ul>"},{"location":"migrations/#emergency-rollback-procedures","title":"Emergency Rollback Procedures","text":"<p>If a migration fails or causes issues:</p> <p>1. Stop the bleeding: <pre><code># Revert to previous client version\npip install zae-limiter==1.0.0\n</code></pre></p> <p>2. Restore from backup (if needed): <pre><code># Restore from PITR\naws dynamodb restore-table-to-point-in-time \\\n  --source-table-name ZAEL-limiter \\\n  --target-table-name ZAEL-limiter-restored \\\n  --restore-date-time \"2024-01-15T10:00:00Z\"\n</code></pre></p> <p>3. Run rollback (if reversible): <pre><code>from zae_limiter.migrations import get_migrations\nfrom zae_limiter.repository import Repository\n\nasync def emergency_rollback():\n    repo = Repository(\"ZAEL-limiter\", \"us-east-1\", None)\n\n    migrations = get_migrations()\n    target_migration = next(m for m in migrations if m.version == \"1.1.0\")\n\n    if target_migration.reversible and target_migration.rollback:\n        await target_migration.rollback(repo)\n        print(\"Rollback complete\")\n    else:\n        print(\"Migration is not reversible - restore from backup\")\n</code></pre></p> <p>4. Update version record: <pre><code>await repo.set_version_record(\n    schema_version=\"1.0.0\",  # Reverted version\n    lambda_version=\"1.0.0\",\n    updated_by=\"emergency_rollback\",\n)\n</code></pre></p>"},{"location":"migrations/#sample-migration-v200","title":"Sample Migration: v2.0.0","text":"<p>This example demonstrates a complete migration scenario for a hypothetical v2.0.0 release that adds a new Global Secondary Index for querying entities by creation date.</p>"},{"location":"migrations/#scenario","title":"Scenario","text":"<p>Goal: Add ability to query entities by creation timestamp for audit purposes.</p> <p>Changes: 1. Add <code>created_at</code> attribute to entity metadata 2. Add GSI3 for querying by creation date 3. Backfill <code>created_at</code> for existing entities</p>"},{"location":"migrations/#migration-implementation","title":"Migration Implementation","text":"<pre><code># src/zae_limiter/migrations/v2_0_0.py\n\"\"\"\nMigration: v2.0.0 (Add creation timestamp tracking)\n\nThis migration adds a created_at timestamp to all entities and\ncreates a new GSI for querying entities by creation date.\n\nSchema changes:\n- Add 'created_at' attribute to entity #META records\n- Add GSI3: GSI3PK=CREATED#{YYYY-MM}, GSI3SK=ENTITY#{id}\n\nBreaking changes:\n- Requires CloudFormation stack update for GSI3\n- All queries using GSI3 require v2.0.0+ client\n\nRollback:\n- This migration is NOT reversible (GSI removal loses query capability)\n- Restore from backup if rollback needed\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom datetime import datetime, timezone\nfrom typing import TYPE_CHECKING\n\nfrom . import Migration, register_migration\n\nif TYPE_CHECKING:\n    from ..repository import Repository\n\n\nasync def migrate_v2_0_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Add created_at timestamp to all existing entities.\n\n    Note: GSI3 must be added via CloudFormation update before\n    running this migration. The migration only backfills data.\n\n    Steps:\n    1. Scan all entity metadata records\n    2. Add created_at if missing (set to migration timestamp)\n    3. Add GSI3 keys for index population\n    \"\"\"\n    migration_time = datetime.now(timezone.utc).isoformat()\n    migration_month = datetime.now(timezone.utc).strftime(\"%Y-%m\")\n\n    # Get DynamoDB client\n    client = await repository._get_client()\n\n    # Scan for all entity metadata records\n    paginator = client.get_paginator('scan')\n\n    async for page in paginator.paginate(\n        TableName=repository.table_name,\n        FilterExpression=\"begins_with(SK, :meta)\",\n        ExpressionAttributeValues={\":meta\": {\"S\": \"#META\"}},\n    ):\n        items = page.get(\"Items\", [])\n\n        # Process in batches of 25 (DynamoDB limit)\n        for i in range(0, len(items), 25):\n            batch = items[i:i + 25]\n\n            # Build batch update\n            update_requests = []\n            for item in batch:\n                pk = item[\"PK\"][\"S\"]\n                sk = item[\"SK\"][\"S\"]\n\n                # Use conditional update - only if created_at missing\n                update_requests.append({\n                    \"Update\": {\n                        \"TableName\": repository.table_name,\n                        \"Key\": {\"PK\": {\"S\": pk}, \"SK\": {\"S\": sk}},\n                        \"UpdateExpression\": (\n                            \"SET #created = if_not_exists(#created, :ts), \"\n                            \"GSI3PK = if_not_exists(GSI3PK, :gsi3pk), \"\n                            \"GSI3SK = if_not_exists(GSI3SK, :gsi3sk)\"\n                        ),\n                        \"ExpressionAttributeNames\": {\n                            \"#created\": \"created_at\",\n                        },\n                        \"ExpressionAttributeValues\": {\n                            \":ts\": {\"S\": migration_time},\n                            \":gsi3pk\": {\"S\": f\"CREATED#{migration_month}\"},\n                            \":gsi3sk\": {\"S\": pk},\n                        },\n                    }\n                })\n\n            # Execute batch (transactions limited to 100 items)\n            if update_requests:\n                await client.transact_write_items(\n                    TransactItems=update_requests\n                )\n\n        # Rate limiting to avoid throttling\n        await asyncio.sleep(0.1)\n\n    # Update version record\n    await repository.set_version_record(\n        schema_version=\"2.0.0\",\n        client_min_version=\"2.0.0\",  # Require v2.0.0+ clients\n        updated_by=\"migration:v2.0.0\",\n    )\n\n\n# Register the migration\nregister_migration(\n    Migration(\n        version=\"2.0.0\",\n        description=\"Add creation timestamp tracking with GSI3\",\n        reversible=False,  # GSI changes are not easily reversible\n        migrate=migrate_v2_0_0,\n        rollback=None,\n    )\n)\n</code></pre>"},{"location":"migrations/#cloudformation-update","title":"CloudFormation Update","text":"<p>The GSI must be added before running the migration:</p> <pre><code># Addition to cfn_template.yaml\nResources:\n  RateLimitsTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      # ... existing properties ...\n      GlobalSecondaryIndexes:\n        # ... existing GSIs ...\n        - IndexName: GSI3\n          KeySchema:\n            - AttributeName: GSI3PK\n              KeyType: HASH\n            - AttributeName: GSI3SK\n              KeyType: RANGE\n          Projection:\n            ProjectionType: ALL\n      AttributeDefinitions:\n        # ... existing attributes ...\n        - AttributeName: GSI3PK\n          AttributeType: S\n        - AttributeName: GSI3SK\n          AttributeType: S\n</code></pre>"},{"location":"migrations/#running-the-migration","title":"Running the Migration","text":"<pre><code># 1. Create backup\naws dynamodb create-backup \\\n  --table-name ZAEL-limiter \\\n  --backup-name \"pre-v2-migration-$(date +%Y%m%d)\"\n\n# 2. Update CloudFormation stack (adds GSI3)\naws cloudformation update-stack \\\n  --stack-name ZAEL-limiter \\\n  --template-body file://updated-template.yaml \\\n  --capabilities CAPABILITY_NAMED_IAM\n\n# 3. Wait for GSI to be active\naws dynamodb wait table-exists --table-name ZAEL-limiter\n\n# 4. Install new client version\npip install zae-limiter==2.0.0\n\n# 5. Run migration (via upgrade command or programmatically)\npython -c \"\nimport asyncio\nfrom zae_limiter.migrations import apply_migrations\nfrom zae_limiter.repository import Repository\n\nasync def run():\n    repo = Repository('ZAEL-limiter', 'us-east-1', None)\n    applied = await apply_migrations(repo, '1.0.0', '2.0.0')\n    print(f'Applied migrations: {applied}')\n    await repo.close()\n\nasyncio.run(run())\n\"\n\n# 6. Verify migration\nzae-limiter version --name limiter --region us-east-1\n</code></pre>"},{"location":"migrations/#testing-the-migration","title":"Testing the Migration","text":"<pre><code>@pytest.mark.asyncio\nasync def test_v2_migration_adds_created_at(mock_dynamodb):\n    \"\"\"Test v2.0.0 migration adds created_at to entities.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create entities without created_at (v1 schema)\n    await repo.create_entity(entity_id=\"entity-1\", name=\"Test 1\")\n    await repo.create_entity(entity_id=\"entity-2\", name=\"Test 2\")\n\n    # Verify no created_at before migration\n    entity = await repo.get_entity(\"entity-1\")\n    assert entity.created_at is None\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"2.0.0\")\n    assert applied == [\"2.0.0\"]\n\n    # Verify created_at added - check raw DynamoDB for GSI3 keys\n    # (Entity dataclass has created_at, but GSI3PK/GSI3SK are schema-level)\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#entity-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert \"created_at\" in item\n    assert item[\"created_at\"][\"S\"].startswith(\"20\")  # Valid ISO timestamp\n    assert \"GSI3PK\" in item  # GSI key was added\n    assert item[\"GSI3PK\"][\"S\"].startswith(\"CREATED#\")\n\n\n@pytest.mark.asyncio\nasync def test_v2_migration_idempotent(mock_dynamodb):\n    \"\"\"Test v2.0.0 migration is idempotent.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create entity with created_at already set\n    # (simulating an entity created after v2.0.0 code deployed)\n    original_time = \"2024-01-01T00:00:00Z\"\n    client = await repo._get_client()\n    await client.put_item(\n        TableName=repo.table_name,\n        Item={\n            \"PK\": {\"S\": \"ENTITY#entity-1\"},\n            \"SK\": {\"S\": \"#META\"},\n            \"data\": {\"M\": {\"name\": {\"S\": \"Test\"}}},\n            \"created_at\": {\"S\": original_time},\n            \"GSI3PK\": {\"S\": \"CREATED#2024-01\"},\n            \"GSI3SK\": {\"S\": \"ENTITY#entity-1\"},\n        },\n    )\n\n    # Apply migration - should not overwrite existing values\n    await apply_migrations(repo, \"1.0.0\", \"2.0.0\")\n\n    # Verify original created_at preserved (if_not_exists)\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#entity-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert item[\"created_at\"][\"S\"] == original_time\n</code></pre>"},{"location":"migrations/#reference","title":"Reference","text":""},{"location":"migrations/#version-record-structure","title":"Version Record Structure","text":"<p>The version record is stored in DynamoDB:</p> Attribute Value Description PK <code>SYSTEM#</code> Partition key SK <code>#VERSION</code> Sort key schema_version <code>\"1.0.0\"</code> Current schema version lambda_version <code>\"1.2.0\"</code> Deployed Lambda version client_min_version <code>\"1.0.0\"</code> Minimum client version updated_at ISO timestamp Last update time updated_by <code>\"cli:1.2.0\"</code> What performed the update"},{"location":"migrations/#key-patterns-v100","title":"Key Patterns (v1.0.0)","text":"Pattern Example Description Entity metadata <code>PK=ENTITY#123, SK=#META</code> Entity configuration Bucket state <code>PK=ENTITY#123, SK=#BUCKET#gpt-4#rpm</code> Token bucket state Limit config <code>PK=ENTITY#123, SK=#LIMIT#gpt-4#rpm</code> Stored limit config Usage snapshot <code>PK=ENTITY#123, SK=#USAGE#gpt-4#2024-01-15</code> Usage data Version <code>PK=SYSTEM#, SK=#VERSION</code> Infrastructure version"},{"location":"migrations/#migration-api-reference","title":"Migration API Reference","text":"<pre><code>from zae_limiter.migrations import (\n    Migration,           # Migration dataclass\n    register_migration,  # Register a migration\n    get_migrations,      # Get all registered migrations\n    get_migrations_between,  # Get migrations between versions\n    apply_migrations,    # Apply migrations\n)\n\nfrom zae_limiter.version import (\n    CURRENT_SCHEMA_VERSION,  # Current schema version constant\n    parse_version,           # Parse version string\n    check_compatibility,     # Check client/infra compatibility\n    get_schema_version,      # Get current schema version\n    InfrastructureVersion,   # Version info dataclass\n    CompatibilityResult,     # Compatibility check result\n)\n</code></pre>"},{"location":"migrations/#cli-commands","title":"CLI Commands","text":"<pre><code># Check compatibility\nzae-limiter check --name NAME --region REGION\n\n# Show version information\nzae-limiter version --name NAME --region REGION\n\n# Upgrade infrastructure\nzae-limiter upgrade --name NAME --region REGION [--lambda-only] [--force]\n</code></pre>"},{"location":"monitoring/","title":"Monitoring and Observability","text":"<p>This guide covers monitoring and observability practices for zae-limiter deployments, including structured logging, CloudWatch metrics, alerts, and dashboard templates.</p>"},{"location":"monitoring/#overview","title":"Overview","text":"<p>Effective monitoring of a rate limiter is critical for:</p> <ul> <li>Availability - Detecting service degradation before users are impacted</li> <li>Latency - Ensuring rate limit checks don't become a bottleneck</li> <li>Throughput - Understanding capacity and scaling needs</li> <li>Errors - Identifying and resolving issues quickly</li> </ul> <p>zae-limiter provides built-in observability through:</p> Component Purpose CloudWatch Alarms Proactive alerting on anomalies Structured Logs JSON-formatted logs for analysis Dead Letter Queue Capturing failed events for investigation Usage Snapshots Aggregated consumption metrics Audit Logging Security and compliance tracking <p>Compliance Requirements</p> <p>For tracking who changed what and when, see the Audit Logging Guide.</p>"},{"location":"monitoring/#structured-logging","title":"Structured Logging","text":"<p>The Lambda aggregator uses structured JSON logging compatible with CloudWatch Logs Insights.</p>"},{"location":"monitoring/#log-format","title":"Log Format","text":"<p>All log entries follow this JSON structure:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.000000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter.aggregator.handler\",\n  \"message\": \"Lambda invocation completed\",\n  \"request_id\": \"abc123-def456\",\n  \"processed\": 50,\n  \"snapshots_updated\": 100,\n  \"processing_time_ms\": 45.23\n}\n</code></pre>"},{"location":"monitoring/#log-fields-reference","title":"Log Fields Reference","text":"Field Type Description <code>timestamp</code> string ISO 8601 timestamp (UTC) <code>level</code> string Log level: DEBUG, INFO, WARNING, ERROR <code>logger</code> string Logger name (module path) <code>message</code> string Human-readable message <code>request_id</code> string Lambda request ID for correlation <code>function_name</code> string Lambda function name <code>record_count</code> int DynamoDB stream records in batch <code>processed</code> int Records successfully processed <code>deltas_extracted</code> int Consumption deltas found <code>snapshots_updated</code> int Usage snapshots updated <code>error_count</code> int Processing errors <code>processing_time_ms</code> float Total execution time (ms)"},{"location":"monitoring/#log-levels","title":"Log Levels","text":"Level When Used DEBUG Detailed processing info (snapshot updates) INFO Invocation start/end, batch processing summary WARNING Recoverable errors (single record failures) ERROR Unrecoverable errors (batch failures)"},{"location":"monitoring/#example-log-entries","title":"Example Log Entries","text":"<p>Invocation Start: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.000000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter.aggregator.handler\",\n  \"message\": \"Lambda invocation started\",\n  \"request_id\": \"abc123-def456\",\n  \"function_name\": \"ZAEL-limiter-aggregator\",\n  \"record_count\": 50,\n  \"table_name\": \"ZAEL-limiter\",\n  \"snapshot_windows\": [\"hourly\", \"daily\"]\n}\n</code></pre></p> <p>Batch Complete: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.500000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter.aggregator.processor\",\n  \"message\": \"Batch processing completed\",\n  \"processed_count\": 50,\n  \"deltas_extracted\": 45,\n  \"snapshots_updated\": 90,\n  \"error_count\": 0,\n  \"processing_time_ms\": 423.15\n}\n</code></pre></p> <p>Error with Exception: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:01.000000+00:00\",\n  \"level\": \"ERROR\",\n  \"logger\": \"zae_limiter.aggregator.processor\",\n  \"message\": \"Error processing record\",\n  \"record_index\": 12,\n  \"exception\": \"Traceback (most recent call last):\\n...\"\n}\n</code></pre></p>"},{"location":"monitoring/#cloudwatch-metrics","title":"CloudWatch Metrics","text":""},{"location":"monitoring/#lambda-metrics","title":"Lambda Metrics","text":"<p>Monitor the aggregator Lambda function:</p> Metric Namespace Description Recommended Threshold <code>Invocations</code> AWS/Lambda Total executions Baseline + 50% <code>Errors</code> AWS/Lambda Failed executions &gt; 1 per 5 min <code>Duration</code> AWS/Lambda Execution time (ms) &gt; 80% of timeout <code>Throttles</code> AWS/Lambda Throttled invocations &gt; 0 <code>IteratorAge</code> AWS/Lambda Stream processing lag (ms) &gt; 30,000 ms <code>ConcurrentExecutions</code> AWS/Lambda Parallel executions Account limit"},{"location":"monitoring/#dynamodb-metrics","title":"DynamoDB Metrics","text":"<p>Monitor table performance:</p> Metric Namespace Description Recommended Threshold <code>ConsumedReadCapacityUnits</code> AWS/DynamoDB RCU usage Provisioned capacity <code>ConsumedWriteCapacityUnits</code> AWS/DynamoDB WCU usage Provisioned capacity <code>ReadThrottleEvents</code> AWS/DynamoDB Read throttles &gt; 0 <code>WriteThrottleEvents</code> AWS/DynamoDB Write throttles &gt; 0 <code>SystemErrors</code> AWS/DynamoDB Service errors &gt; 0 <code>SuccessfulRequestLatency</code> AWS/DynamoDB Request latency (ms) p99 &gt; 100ms"},{"location":"monitoring/#sqs-metrics-dead-letter-queue","title":"SQS Metrics (Dead Letter Queue)","text":"<p>Monitor failed event processing:</p> Metric Namespace Description Recommended Threshold <code>ApproximateNumberOfMessagesVisible</code> AWS/SQS Messages in DLQ &gt; 0 <code>ApproximateAgeOfOldestMessage</code> AWS/SQS Oldest message age (s) &gt; 3600"},{"location":"monitoring/#cloudwatch-logs-insights-queries","title":"CloudWatch Logs Insights Queries","text":""},{"location":"monitoring/#batch-processing-performance","title":"Batch Processing Performance","text":"<p>Analyze processing latency over time:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Batch processing completed/\n| parse @message /processing_time_ms\":(?&lt;duration&gt;[\\d.]+)/\n| stats avg(duration) as avg_ms,\n        pct(duration, 50) as p50_ms,\n        pct(duration, 95) as p95_ms,\n        pct(duration, 99) as p99_ms\n  by bin(1h)\n| sort @timestamp desc\n</code></pre>"},{"location":"monitoring/#error-analysis","title":"Error Analysis","text":"<p>Find recent errors and warnings:</p> <pre><code>fields @timestamp, @message, @logStream\n| filter level = \"ERROR\" or level = \"WARNING\"\n| parse @message /message\":\"(?&lt;error_message&gt;[^\"]+)/\n| sort @timestamp desc\n| limit 100\n</code></pre>"},{"location":"monitoring/#invocation-summary","title":"Invocation Summary","text":"<p>Aggregate processing metrics:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Lambda invocation completed/\n| parse @message /processed\":(?&lt;processed&gt;\\d+).*snapshots_updated\":(?&lt;snapshots&gt;\\d+)/\n| stats sum(processed) as total_processed,\n        sum(snapshots) as total_snapshots,\n        count() as invocations\n  by bin(1h)\n| sort @timestamp desc\n</code></pre>"},{"location":"monitoring/#entity-usage-analysis","title":"Entity Usage Analysis","text":"<p>Find highest-usage entities:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Snapshot updated/\n| parse @message /entity_id\":\"(?&lt;entity&gt;[^\"]+)\".*resource\":\"(?&lt;resource&gt;[^\"]+)/\n| stats count() as updates by entity, resource\n| sort updates desc\n| limit 50\n</code></pre>"},{"location":"monitoring/#cold-start-detection","title":"Cold Start Detection","text":"<p>Identify Lambda cold starts:</p> <pre><code>fields @timestamp, @message, @duration\n| filter @type = \"REPORT\"\n| filter @message like /Init Duration/\n| parse @message /Init Duration: (?&lt;init_duration&gt;[\\d.]+) ms/\n| stats count() as cold_starts,\n        avg(init_duration) as avg_init_ms\n  by bin(1h)\n</code></pre>"},{"location":"monitoring/#error-rate-calculation","title":"Error Rate Calculation","text":"<p>Calculate error rate percentage:</p> <pre><code>fields @timestamp\n| filter @message like /Lambda invocation/\n| parse @message /error_count\":(?&lt;errors&gt;\\d+)/\n| stats sum(errors) as total_errors, count() as total_invocations\n| display total_errors, total_invocations,\n         (total_errors * 100.0 / total_invocations) as error_rate_pct\n</code></pre>"},{"location":"monitoring/#x-ray-tracing","title":"X-Ray Tracing","text":"<p>Future Enhancement</p> <p>X-Ray tracing integration is planned for a future release. Track progress in Issue #107.</p> <p>Planned capabilities include:</p> <ul> <li>Lambda Active Tracing - End-to-end request visibility</li> <li>DynamoDB SDK Instrumentation - Database call traces</li> <li>Custom Subsegments - Business logic timing (acquire/release operations)</li> <li>Trace Header Propagation - Cross-service correlation</li> </ul>"},{"location":"monitoring/#dashboard-templates","title":"Dashboard Templates","text":""},{"location":"monitoring/#operations-dashboard","title":"Operations Dashboard","text":"<p>Create a CloudWatch dashboard for day-to-day operations:</p> <pre><code>{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Invocations &amp; Errors\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"Invocations\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Sum\"}],\n          [\".\", \"Errors\", \".\", \".\", {\"stat\": \"Sum\", \"color\": \"#d62728\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Duration (p50/p95/p99)\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"Duration\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"p50\"}],\n          [\"...\", {\"stat\": \"p95\"}],\n          [\"...\", {\"stat\": \"p99\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Stream Iterator Age\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"IteratorAge\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Maximum\"}]\n        ],\n        \"period\": 60,\n        \"view\": \"timeSeries\",\n        \"annotations\": {\n          \"horizontal\": [{\"value\": 30000, \"label\": \"Threshold (30s)\"}]\n        }\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"DynamoDB Capacity\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ConsumedReadCapacityUnits\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\"}],\n          [\".\", \"ConsumedWriteCapacityUnits\", \".\", \".\", {\"stat\": \"Sum\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"DynamoDB Throttles\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ReadThrottleEvents\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\"}],\n          [\".\", \"WriteThrottleEvents\", \".\", \".\", {\"stat\": \"Sum\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Dead Letter Queue\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/SQS\", \"ApproximateNumberOfMessagesVisible\", \"QueueName\", \"${TableName}-aggregator-dlq\"]\n        ],\n        \"period\": 60,\n        \"view\": \"singleValue\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"monitoring/#capacity-planning-dashboard","title":"Capacity Planning Dashboard","text":"<p>Create a dashboard for capacity analysis:</p> <pre><code>{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"RCU/WCU Consumption Trend\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ConsumedReadCapacityUnits\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\", \"period\": 3600}],\n          [\".\", \"ConsumedWriteCapacityUnits\", \".\", \".\", {\"stat\": \"Sum\", \"period\": 3600}]\n        ],\n        \"view\": \"timeSeries\",\n        \"stacked\": false\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Request Latency Distribution\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"SuccessfulRequestLatency\", \"TableName\", \"${TableName}\", \"Operation\", \"GetItem\", {\"stat\": \"p50\"}],\n          [\"...\", {\"stat\": \"p95\"}],\n          [\"...\", {\"stat\": \"p99\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Concurrent Executions\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"ConcurrentExecutions\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Maximum\"}]\n        ],\n        \"period\": 60,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Throttle Events (7 Day)\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ReadThrottleEvents\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\", \"period\": 86400}],\n          [\".\", \"WriteThrottleEvents\", \".\", \".\", {\"stat\": \"Sum\", \"period\": 86400}]\n        ],\n        \"view\": \"bar\"\n      }\n    }\n  ]\n}\n</code></pre> <p>Dashboard Deployment</p> <p>Replace <code>${TableName}</code> with your actual table name (e.g., <code>ZAEL-limiter</code>) and <code>${AWS::Region}</code> with your region before deploying.</p>"},{"location":"monitoring/#alert-configuration","title":"Alert Configuration","text":""},{"location":"monitoring/#default-alarms","title":"Default Alarms","text":"<p>The stack deploys these alarms when <code>--enable-alarms</code> is set:</p> Alarm Metric Threshold Period Evaluation <code>{name}-aggregator-error-rate</code> Lambda Errors &gt; 1 5 min 2 periods <code>{name}-aggregator-duration</code> Lambda Duration &gt; 80% timeout 5 min 2 periods <code>{name}-stream-iterator-age</code> IteratorAge &gt; 30,000 ms 5 min 2 periods <code>{name}-aggregator-dlq-alarm</code> SQS Messages &gt;= 1 5 min 1 period <code>{name}-read-throttle</code> ReadThrottleEvents &gt; 1 5 min 2 periods <code>{name}-write-throttle</code> WriteThrottleEvents &gt; 1 5 min 2 periods"},{"location":"monitoring/#deploying-with-alarms","title":"Deploying with Alarms","text":"<pre><code># Deploy with alarms enabled (default)\nzae-limiter deploy --name limiter --region us-east-1\n\n# Deploy with SNS notifications\nzae-limiter deploy --name limiter --region us-east-1 \\\n    --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts\n\n# Customize duration threshold (70% of timeout)\nzae-limiter deploy --name limiter --region us-east-1 \\\n    --lambda-duration-threshold-pct 70\n\n# Disable alarms (not recommended for production)\nzae-limiter deploy --name limiter --region us-east-1 --no-alarms\n</code></pre>"},{"location":"monitoring/#threshold-tuning-guide","title":"Threshold Tuning Guide","text":"Alarm Default When to Increase When to Decrease Error Rate &gt;1/5min High-volume systems with rare transient errors Critical systems requiring immediate response Duration 80% timeout Batch workloads with variable processing time Latency-sensitive applications Iterator Age 30 seconds Batch-tolerant analytics workloads Real-time processing requirements DLQ Messages &gt;=1 Never (always investigate DLQ messages) N/A Throttles &gt;1/5min During planned traffic spikes Before hitting capacity limits"},{"location":"monitoring/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        enable_alarms=True,\n        alarm_sns_topic=\"arn:aws:sns:us-east-1:123456789012:alerts\",\n        lambda_duration_threshold_pct=75,  # Alert at 75% of timeout\n        log_retention_days=90,\n    ),\n)\n</code></pre>"},{"location":"monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Operations Guide - Troubleshooting and operational procedures</li> <li>Audit Logging - Security and compliance tracking</li> <li>Performance Tuning - Capacity planning and optimization</li> <li>Deployment Guide - Infrastructure setup</li> <li>CloudFormation Reference - Template customization</li> </ul>"},{"location":"performance/","title":"Performance Tuning Guide","text":"<p>This guide provides detailed recommendations for optimizing zae-limiter performance, covering DynamoDB capacity planning, Lambda configuration, and cost optimization strategies.</p>"},{"location":"performance/#1-dynamodb-capacity-planning","title":"1. DynamoDB Capacity Planning","text":""},{"location":"performance/#understanding-rcuwcu-costs","title":"Understanding RCU/WCU Costs","text":"<p>Each zae-limiter operation has specific DynamoDB capacity costs. Use this table for capacity planning:</p> Operation RCUs WCUs Notes <code>acquire()</code> - single limit 1 1 GetItem + TransactWrite <code>acquire()</code> - N limits N N N GetItems + TransactWrite(N items) <code>acquire(cascade=True)</code> 3 2 +GetEntity + parent bucket ops <code>acquire(use_stored_limits=True)</code> +2 0 +2 Query operations for limits <code>available()</code> 1 per limit 0 Read-only, no transaction <code>get_limits()</code> 1 0 Query operation <code>set_limits()</code> 1 N+1 Query + N PutItems <code>delete_entity()</code> 1 batched Query + BatchWrite in 25-item chunks <p>Capacity Validation</p> <p>These costs are validated by automated tests. Run <code>uv run pytest tests/benchmark/test_capacity.py -v</code> to verify.</p>"},{"location":"performance/#capacity-estimation-formula","title":"Capacity Estimation Formula","text":"<p>Use these formulas to estimate hourly capacity requirements:</p> <pre><code>Hourly RCUs = requests/hour \u00d7 limits/request \u00d7 (1 + cascade_pct \u00d7 2 + stored_limits_pct \u00d7 2)\nHourly WCUs = requests/hour \u00d7 limits/request \u00d7 (1 + cascade_pct)\n</code></pre> <p>With the Lambda aggregator enabled (2 windows: hourly, daily): <pre><code>Additional WCUs = requests/hour \u00d7 limits/request \u00d7 2\n</code></pre></p>"},{"location":"performance/#example-calculations","title":"Example Calculations","text":""},{"location":"performance/#scenario-1-simple-api-rate-limiting","title":"Scenario 1: Simple API Rate Limiting","text":"<ul> <li>10,000 requests/hour</li> <li>2 limits per request (rpm, tpm)</li> <li>No cascade, no stored limits</li> </ul> <p>Calculation: <pre><code>RCUs = 10,000 \u00d7 2 \u00d7 1.0 = 20,000 RCUs/hour\nWCUs = 10,000 \u00d7 2 \u00d7 1.0 = 20,000 WCUs/hour\n</code></pre></p>"},{"location":"performance/#scenario-2-hierarchical-llm-limiting","title":"Scenario 2: Hierarchical LLM Limiting","text":"<ul> <li>10,000 requests/hour</li> <li>2 limits per request</li> <li>50% use cascade (API key \u2192 project)</li> <li>20% use stored limits</li> </ul> <p>Calculation: <pre><code>RCUs = 10,000 \u00d7 2 \u00d7 (1 + 0.5\u00d72 + 0.2\u00d72) = 10,000 \u00d7 2 \u00d7 2.4 = 48,000 RCUs/hour\nWCUs = 10,000 \u00d7 2 \u00d7 (1 + 0.5) = 10,000 \u00d7 2 \u00d7 1.5 = 30,000 WCUs/hour\n</code></pre></p>"},{"location":"performance/#billing-mode-selection","title":"Billing Mode Selection","text":"Mode Best For Trade-offs PAY_PER_REQUEST (default) Variable traffic, new deployments Higher per-request cost, no planning needed Provisioned Steady traffic &gt;100 TPS Lower cost at scale, requires planning Provisioned + Reserved High-volume production Lowest cost, 1-year commitment <p>Migration Guidance</p> <p>Start with PAY_PER_REQUEST. Once traffic patterns stabilize (typically 2-4 weeks), analyze CloudWatch metrics to determine optimal provisioned capacity. Switch when monthly on-demand costs exceed provisioned + 20% buffer.</p>"},{"location":"performance/#2-lambda-concurrency-settings","title":"2. Lambda Concurrency Settings","text":"<p>The aggregator Lambda processes DynamoDB Stream events to maintain usage snapshots.</p>"},{"location":"performance/#default-configuration","title":"Default Configuration","text":"Setting Default Range Impact Memory 256 MB 128-3008 MB Higher = faster, more expensive Timeout 60 seconds 1-900 seconds Should be 2\u00d7 typical duration Reserved Concurrency None 1-1000 Limits parallel executions"},{"location":"performance/#memory-tuning","title":"Memory Tuning","text":"<p>Lambda CPU scales linearly with memory allocation:</p> Memory vCPUs Best For 128 MB ~0.08 Minimal workloads (testing only) 256 MB ~0.15 Most workloads (default) 512 MB ~0.30 High-throughput streams 1024 MB ~0.60 Rarely needed <p>Guidance based on batch size:</p> <ul> <li>&lt;50 records/batch: 128-256 MB sufficient</li> <li>50-100 records/batch: 256-512 MB recommended</li> <li>Peak streams: Monitor Lambda duration; increase memory if &gt;50% of timeout</li> </ul>"},{"location":"performance/#concurrency-management","title":"Concurrency Management","text":"<p>DynamoDB Streams creates one shard per 1000 WCU (or ~3000 writes/sec). Each shard invokes one Lambda instance.</p> <p>Recommendations:</p> Volume Reserved Concurrency Notes &lt;1000 writes/sec None Default scaling sufficient 1000-10000/sec 10-50 Prevents runaway scaling &gt;10000/sec Expected shards + 20% Based on table monitoring"},{"location":"performance/#error-handling","title":"Error Handling","text":"<p>Configure error handling for production reliability:</p> <pre><code># Deploy with DLQ and alarms\nzae-limiter deploy --table-name rate_limits \\\n  --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts\n</code></pre> <ul> <li>Retries: Failed records retry 3 times within the same batch</li> <li>DLQ: Persistent failures go to Dead Letter Queue (if configured)</li> <li>Duration Alarm: Triggers at 80% of timeout (48s default)</li> </ul>"},{"location":"performance/#3-batch-operation-patterns","title":"3. Batch Operation Patterns","text":""},{"location":"performance/#transaction-limits","title":"Transaction Limits","text":"<p>DynamoDB enforces these limits:</p> Constraint Limit Impact TransactWriteItems 100 items max Affects multi-limit updates BatchWriteItem 25 items per request Entity deletion is chunked Optimistic locking Entire transaction fails Causes retry on contention"},{"location":"performance/#efficient-patterns","title":"Efficient Patterns","text":""},{"location":"performance/#multi-limit-acquisition","title":"Multi-Limit Acquisition","text":"<pre><code># Efficient: Single lease for multiple limits\nasync with limiter.acquire(\n    \"entity-id\",\n    \"llm-api\",\n    [rpm_limit, tpm_limit],\n    {\"rpm\": 1},  # Initial consumption (1 request)\n) as lease:\n    # 2 GetItems + 1 TransactWrite (2 items)\n    response = await call_llm()\n    lease.adjust({\"tpm\": response.usage.total_tokens})\n\n# Inefficient: Separate acquisitions\nasync with limiter.acquire(\"entity-id\", \"llm-api\", [rpm_limit], {\"rpm\": 1}):\n    async with limiter.acquire(\"entity-id\", \"llm-api\", [tpm_limit], {\"tpm\": 100}):\n        # 2 GetItems + 2 TransactWrites (doubles write cost!)\n        pass\n</code></pre>"},{"location":"performance/#cascade-optimization","title":"Cascade Optimization","text":"<pre><code># Only use cascade when hierarchical limits are actually needed\nasync with limiter.acquire(\n    \"api-key\",\n    \"llm-api\",\n    limits,\n    {\"rpm\": 1},\n    cascade=False,  # Saves 1 GetEntity + parent bucket operations\n):\n    pass\n\n# Use cascade for hierarchical enforcement\nasync with limiter.acquire(\n    \"api-key\",\n    \"llm-api\",\n    limits,\n    {\"rpm\": 1},\n    cascade=True,  # Checks and updates parent limits too\n):\n    pass\n</code></pre>"},{"location":"performance/#stored-limits-optimization","title":"Stored Limits Optimization","text":"<pre><code># Default: No stored limits lookup (saves 2 RCUs per acquire)\nlimiter = RateLimiter(\n    name=\"rate_limits\",\n    region=\"us-east-1\",\n)\n\n# Enable only when limits vary per entity\nlimiter = RateLimiter(\n    name=\"rate_limits\",\n    region=\"us-east-1\",\n    use_stored_limits=True,  # +2 Queries per acquire\n)\n</code></pre>"},{"location":"performance/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Efficient bulk limit setup\nawait limiter.set_limits(\"entity-1\", [rpm_limit, tpm_limit], resource=\"llm-api\")\nawait limiter.set_limits(\"entity-2\", [rpm_limit, tpm_limit], resource=\"llm-api\")\n# Runs 2 Queries + 2\u00d72 PutItems\n\n# Entity deletion (automatically batched in 25-item chunks)\nawait limiter.delete_entity(\"entity-id\")\n# Runs 1 Query + BatchWrite (up to 25 WCUs per chunk)\n</code></pre>"},{"location":"performance/#4-expected-latencies","title":"4. Expected Latencies","text":""},{"location":"performance/#operation-latencies","title":"Operation Latencies","text":"<p>Latencies vary by environment and depend on network conditions, DynamoDB utilization, and operation complexity.</p> Operation Moto p50 LocalStack p50 AWS p50 <code>acquire()</code> - single limit 14ms 36ms 36ms <code>acquire()</code> - two limits 30ms 52ms 43ms <code>acquire(cascade=True)</code> 28ms 57ms 51ms <code>available()</code> check 1ms 9ms 8ms <p>Environment Differences</p> <ul> <li>Moto: In-memory mock, measures code overhead only</li> <li>LocalStack: Docker-based, includes local network latency</li> <li>AWS: Production DynamoDB with real network round-trips</li> </ul>"},{"location":"performance/#latency-breakdown","title":"Latency Breakdown","text":"<p>Typical <code>acquire()</code> latency breakdown for a single limit:</p> <pre><code>acquire() latency breakdown:\n\u251c\u2500\u2500 DynamoDB GetItem (bucket)     ~5-15ms   (network + read)\n\u251c\u2500\u2500 Token bucket calculation      &lt;1ms      (in-memory math)\n\u251c\u2500\u2500 TransactWriteItems            ~10-25ms  (network + write + condition check)\n\u2514\u2500\u2500 Network overhead              variable  (region, instance type)\n</code></pre>"},{"location":"performance/#environment-selection","title":"Environment Selection","text":"Environment Use Case Latency Factor Moto Unit tests, CI/CD 1\u00d7 (baseline) LocalStack Integration tests, local dev 2-3\u00d7 AWS Production, load testing 2-4\u00d7 <p>Run benchmarks to measure your specific environment:</p> <pre><code># Moto benchmarks (fast)\nuv run pytest tests/benchmark/test_latency.py -v --benchmark-json=latency.json\n\n# LocalStack benchmarks (requires Docker)\ndocker compose up -d\nexport AWS_ENDPOINT_URL=http://localhost:4566\nuv run pytest tests/benchmark/test_localstack.py -v --benchmark-json=latency.json\n\n# AWS benchmarks (requires credentials)\nuv run pytest tests/benchmark/test_aws.py --run-aws -v\n</code></pre>"},{"location":"performance/#5-throughput-benchmarks","title":"5. Throughput Benchmarks","text":""},{"location":"performance/#maximum-throughput","title":"Maximum Throughput","text":"<p>Theoretical and practical throughput limits depend on contention patterns:</p> Scenario Expected TPS Bottleneck Sequential, single entity 50-200 Serialized operations Sequential, multiple entities 50-200 Network round-trip Concurrent, separate entities 100-500 Scales with parallelism Concurrent, single entity 20-100 Optimistic locking contention Cascade operations 30-100 Parent bucket contention"},{"location":"performance/#contention-analysis","title":"Contention Analysis","text":"<p>When multiple requests update the same bucket concurrently, DynamoDB's optimistic locking causes transaction retries:</p> <pre><code>Concurrent updates to same bucket:\n\u251c\u2500\u2500 Request A: Read bucket version=1\n\u251c\u2500\u2500 Request B: Read bucket version=1\n\u251c\u2500\u2500 Request A: Write with condition version=1 \u2192 SUCCESS, version=2\n\u251c\u2500\u2500 Request B: Write with condition version=1 \u2192 FAIL (ConditionalCheckFailed)\n\u2514\u2500\u2500 Request B: Retry with version=2 \u2192 SUCCESS\n</code></pre> <p>Each retry adds ~10-30ms latency.</p>"},{"location":"performance/#mitigation-strategies","title":"Mitigation Strategies","text":"<pre><code># Strategy 1: Larger bucket windows (reduces update frequency)\nrpm_limit = Limit.per_minute(\"rpm\", capacity=1000, window_seconds=60)\n\n# Strategy 2: Distribute load across entities\n# Instead of one shared entity, use sharded entities:\nshard = hash(request_id) % 10\nentity_id = f\"api-key-shard-{shard}\"\n\n# Strategy 3: Client-side rate limiting before acquire\n# Reduce concurrent requests to the same entity\n</code></pre>"},{"location":"performance/#running-benchmarks","title":"Running Benchmarks","text":"<p>Use the automated benchmark runner:</p> <pre><code># Run all benchmarks (moto + LocalStack)\npython scripts/run_benchmarks.py\n\n# Include AWS benchmarks\npython scripts/run_benchmarks.py --run-aws\n\n# Skip LocalStack (moto only)\npython scripts/run_benchmarks.py --skip-localstack\n\n# Custom output directory\npython scripts/run_benchmarks.py --output-dir ./results\n</code></pre> <p>Or run individual test suites:</p> <pre><code># Throughput tests\nuv run pytest tests/benchmark/test_throughput.py -v\n\n# Analyze results\npython -c \"import json; print(json.load(open('benchmark.json'))['benchmarks'])\"\n</code></pre>"},{"location":"performance/#6-cost-optimization-strategies","title":"6. Cost Optimization Strategies","text":""},{"location":"performance/#dynamodb-cost-breakdown","title":"DynamoDB Cost Breakdown","text":"<p>Costs vary by region. Using us-east-1 as reference:</p> Component On-Demand Cost Notes Write Request Units $0.625 per million Each WCU = one write Read Request Units $0.125 per million Each RCU = one read Storage $0.25 per GB/month Usually minimal Streams $0.02 per 100K reads Lambda polling Lambda $0.20 per million + duration Aggregator function"},{"location":"performance/#cost-estimation-examples","title":"Cost Estimation Examples","text":""},{"location":"performance/#low-volume-10k-requestsday","title":"Low Volume: 10K requests/day","text":"<pre><code>DynamoDB:\n  Writes: 10K \u00d7 2 limits \u00d7 30 days = 600K WCUs = $0.38\n  Reads:  10K \u00d7 2 limits \u00d7 30 days = 600K RCUs = $0.08\n  Streams: 600K events                         = $0.12\nLambda: 600K invocations                       \u2248 $0.12 + duration\nStorage: ~10 MB                                = negligible\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal: ~$0.70/month\n</code></pre>"},{"location":"performance/#medium-volume-1m-requestsday","title":"Medium Volume: 1M requests/day","text":"<pre><code>DynamoDB:\n  Writes: 1M \u00d7 2 \u00d7 30 = 60M WCUs               = $37.50\n  Reads:  1M \u00d7 2 \u00d7 30 = 60M RCUs               = $7.50\n  Streams: 60M events                          = $12.00\nLambda: 60M invocations                        \u2248 $12.00 + duration\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal (on-demand): ~$70/month\nTotal (provisioned with auto-scaling): ~$45/month\n</code></pre>"},{"location":"performance/#cost-reduction-strategies","title":"Cost Reduction Strategies","text":""},{"location":"performance/#1-disable-unused-features","title":"1. Disable Unused Features","text":"<pre><code># Skip cascade if not needed (saves 1-2 WCUs per request)\nasync with limiter.acquire(\"entity\", \"api\", limits, {\"rpm\": 1}, cascade=False):\n    pass\n\n# Disable stored limits if static (saves 2 RCUs per request)\nlimiter = RateLimiter(name=\"rate_limits\", region=\"us-east-1\")\n</code></pre>"},{"location":"performance/#2-optimize-ttl-settings","title":"2. Optimize TTL Settings","text":"<pre><code># Shorter TTL = faster cleanup = less storage\nlimiter = RateLimiter(\n    name=\"rate_limits\",\n    region=\"us-east-1\",\n    bucket_ttl_seconds=3600,  # 1 hour vs 24 hour default\n)\n</code></pre>"},{"location":"performance/#3-reduce-snapshot-granularity","title":"3. Reduce Snapshot Granularity","text":"<pre><code># Deploy without aggregator if usage tracking not needed\nzae-limiter deploy --table-name rate_limits --no-aggregator\n</code></pre>"},{"location":"performance/#4-switch-to-provisioned-at-scale","title":"4. Switch to Provisioned at Scale","text":"<ul> <li>Break-even: ~5M operations/month</li> <li>Use auto-scaling with 70% target utilization</li> <li>Consider reserved capacity for &gt;20M ops/month</li> </ul>"},{"location":"performance/#5-batch-similar-operations","title":"5. Batch Similar Operations","text":"<pre><code># Combine multiple limits into single acquire\nasync with limiter.acquire(\n    \"entity\",\n    \"api\",\n    [rpm_limit, tpm_limit, daily_limit],\n    {\"rpm\": 1},  # 1 transaction vs 3\n):\n    pass\n</code></pre>"},{"location":"performance/#cost-monitoring","title":"Cost Monitoring","text":"<p>Set up CloudWatch metrics for cost tracking:</p> <p>DynamoDB Metrics:</p> <ul> <li><code>ConsumedReadCapacityUnits</code></li> <li><code>ConsumedWriteCapacityUnits</code></li> <li><code>AccountProvisionedReadCapacityUtilization</code></li> <li><code>AccountProvisionedWriteCapacityUtilization</code></li> </ul> <p>Lambda Metrics:</p> <ul> <li><code>Invocations</code></li> <li><code>Duration</code></li> <li><code>ConcurrentExecutions</code></li> </ul> <p>Recommended Alerts:</p> <pre><code># Deploy with alarms for cost anomalies\nzae-limiter deploy --table-name rate_limits \\\n  --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:billing-alerts\n\n# Set AWS Budgets alert at 80% of expected monthly cost\naws budgets create-budget \\\n  --account-id 123456789012 \\\n  --budget file://budget.json \\\n  --notifications-with-subscribers file://notifications.json\n</code></pre>"},{"location":"performance/#summary","title":"Summary","text":"Optimization Area Key Recommendations Capacity Start with on-demand, switch to provisioned at 5M+ ops/month Latency Expect 30-50ms p50 on AWS; use LocalStack for realistic testing Throughput Distribute load across entities to avoid contention Cost Disable cascade/stored_limits when not needed Monitoring Set up CloudWatch alerts for capacity and cost anomalies <p>For detailed benchmark data, run: <pre><code>python scripts/run_benchmarks.py --run-aws\n</code></pre></p>"},{"location":"api/","title":"API Reference","text":"<p>This section contains the complete API documentation for zae-limiter, auto-generated from source code docstrings.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>The main components of the API are:</p> Component Description <code>RateLimiter</code> Async rate limiter client <code>SyncRateLimiter</code> Synchronous rate limiter client <code>Limit</code> Rate limit configuration <code>RateLimitExceeded</code> Exception when limit is exceeded"},{"location":"api/#quick-reference","title":"Quick Reference","text":""},{"location":"api/#creating-a-limiter","title":"Creating a Limiter","text":"<pre><code>from zae_limiter import RateLimiter, SyncRateLimiter\n\n# Async\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n)\n\n# Sync\nlimiter = SyncRateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n)\n</code></pre>"},{"location":"api/#defining-limits","title":"Defining Limits","text":"<pre><code>from zae_limiter import Limit\n\n# Factory methods\nLimit.per_second(\"rps\", 10)\nLimit.per_minute(\"rpm\", 100)\nLimit.per_hour(\"rph\", 1000)\nLimit.per_day(\"rpd\", 10000)\n\n# With burst capacity\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n\n# Custom period\nLimit.custom(\"requests\", capacity=50, refill_period_seconds=30)\n</code></pre>"},{"location":"api/#acquiring-limits","title":"Acquiring Limits","text":"<pre><code>from zae_limiter import RateLimiter, Limit, RateLimitExceeded\n\nlimiter = RateLimiter(name=\"limiter\")\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ) as lease:\n        # Do work\n        await lease.adjust(rpm=5)  # Adjust if needed\nexcept RateLimitExceeded as e:\n    print(f\"Retry after: {e.retry_after_seconds}s\")\n</code></pre>"},{"location":"api/#handling-exceptions","title":"Handling Exceptions","text":"<pre><code>from zae_limiter import RateLimitExceeded, RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(...):\n        pass\nexcept RateLimitExceeded as e:\n    # Rate limit exceeded\n    print(e.retry_after_seconds)\n    print(e.violations)\n    print(e.as_dict())\nexcept RateLimiterUnavailable as e:\n    # DynamoDB unavailable\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"api/#module-structure","title":"Module Structure","text":"<pre><code>zae_limiter/\n\u251c\u2500\u2500 __init__.py        # Public API exports\n\u251c\u2500\u2500 limiter.py         # RateLimiter, SyncRateLimiter\n\u251c\u2500\u2500 models.py          # Limit, Entity, LimitStatus, BucketState\n\u251c\u2500\u2500 exceptions.py      # RateLimitExceeded, RateLimiterUnavailable\n\u251c\u2500\u2500 lease.py           # Lease context manager\n\u251c\u2500\u2500 bucket.py          # Token bucket algorithm\n\u251c\u2500\u2500 schema.py          # DynamoDB key builders\n\u251c\u2500\u2500 repository.py      # DynamoDB operations\n\u2514\u2500\u2500 cli.py             # CLI commands\n</code></pre>"},{"location":"api/#public-exports","title":"Public Exports","text":"<p>The following are exported from <code>zae_limiter</code>:</p> <pre><code>from zae_limiter import (\n    # Main classes\n    RateLimiter,\n    SyncRateLimiter,\n    Lease,\n    SyncLease,\n\n    # Models\n    Limit,\n    Entity,\n    LimitStatus,\n    BucketState,\n\n    # Enums\n    OnUnavailable,\n\n    # Exceptions - Base\n    ZAELimiterError,\n\n    # Exceptions - Rate Limit\n    RateLimitExceeded,\n\n    # Exceptions - Entity\n    EntityNotFoundError,\n    EntityExistsError,\n\n    # Exceptions - Infrastructure\n    RateLimiterUnavailable,\n    StackCreationError,\n    StackAlreadyExistsError,\n    InfrastructureNotFoundError,\n\n    # Exceptions - Version\n    VersionMismatchError,\n    IncompatibleSchemaError,\n)\n</code></pre>"},{"location":"api/#detailed-documentation","title":"Detailed Documentation","text":"<ul> <li>RateLimiter - Main rate limiter classes</li> <li>Models - Data models and configuration</li> <li>Exceptions - Exception types and handling</li> </ul>"},{"location":"api/exceptions/","title":"Exceptions","text":"<p>Exception types raised by zae-limiter.</p>"},{"location":"api/exceptions/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>ZAELimiterError (base)\n\u251c\u2500\u2500 RateLimitError\n\u2502   \u251c\u2500\u2500 RateLimitExceeded\n\u2502   \u2514\u2500\u2500 RateLimiterUnavailable\n\u251c\u2500\u2500 EntityError\n\u2502   \u251c\u2500\u2500 EntityNotFoundError\n\u2502   \u2514\u2500\u2500 EntityExistsError\n\u251c\u2500\u2500 InfrastructureError\n\u2502   \u251c\u2500\u2500 StackCreationError\n\u2502   \u251c\u2500\u2500 StackAlreadyExistsError\n\u2502   \u2514\u2500\u2500 InfrastructureNotFoundError\n\u2514\u2500\u2500 VersionError\n    \u251c\u2500\u2500 VersionMismatchError\n    \u2514\u2500\u2500 IncompatibleSchemaError\n</code></pre>"},{"location":"api/exceptions/#base-exception","title":"Base Exception","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.ZAELimiterError","title":"ZAELimiterError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all zae-limiter errors.</p> <p>All exceptions raised by this library inherit from this class, allowing callers to catch all library-specific errors with a single except clause.</p>"},{"location":"api/exceptions/#rate-limit-exceptions","title":"Rate Limit Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded","title":"RateLimitExceeded","text":"<pre><code>RateLimitExceeded(statuses)\n</code></pre> <p>               Bases: <code>RateLimitError</code></p> <p>Raised when one or more rate limits would be exceeded.</p> <p>Provides full visibility into ALL limits that were checked, both passed and failed, to help callers understand the full picture.</p> <p>Attributes:</p> Name Type Description <code>statuses</code> <p>Status of ALL limits checked (both passed and failed)</p> <code>violations</code> <p>Only the limits that were exceeded</p> <code>passed</code> <p>Only the limits that passed</p> <code>retry_after_seconds</code> <p>Time until ALL requested capacity is available</p> <code>primary_violation</code> <p>The violation with longest retry time (bottleneck)</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded.retry_after_header","title":"retry_after_header  <code>property</code>","text":"<pre><code>retry_after_header\n</code></pre> <p>Value for HTTP Retry-After header (integer seconds).</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded.as_dict","title":"as_dict","text":"<pre><code>as_dict()\n</code></pre> <p>Serialize for JSON API responses.</p> <p>Returns a dictionary suitable for returning in a 429 response body.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimiterUnavailable","title":"RateLimiterUnavailable","text":"<pre><code>RateLimiterUnavailable(message, cause=None, *, stack_name=None, entity_id=None, resource=None)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when DynamoDB is unavailable and on_unavailable=OnUnavailable.BLOCK.</p> <p>This indicates a transient infrastructure issue, not a rate limit. When using OnUnavailable.BLOCK (the default), your application should be prepared to catch this exception and handle degraded mode gracefully.</p> <p>Attributes:</p> Name Type Description <code>cause</code> <p>The underlying exception that caused the unavailability</p> <code>stack_name</code> <p>The stack/table that was being accessed</p> <code>entity_id</code> <p>The entity being rate limited (if applicable)</p> <code>resource</code> <p>The resource being rate limited (if applicable)</p>"},{"location":"api/exceptions/#entity-exceptions","title":"Entity Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.EntityNotFoundError","title":"EntityNotFoundError","text":"<pre><code>EntityNotFoundError(entity_id)\n</code></pre> <p>               Bases: <code>EntityError</code></p> <p>Raised when an entity is not found.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.EntityExistsError","title":"EntityExistsError","text":"<pre><code>EntityExistsError(entity_id)\n</code></pre> <p>               Bases: <code>EntityError</code></p> <p>Raised when trying to create an entity that already exists.</p>"},{"location":"api/exceptions/#infrastructure-exceptions","title":"Infrastructure Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.StackCreationError","title":"StackCreationError","text":"<pre><code>StackCreationError(stack_name, reason, events=None)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when CloudFormation stack creation fails.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.StackAlreadyExistsError","title":"StackAlreadyExistsError","text":"<pre><code>StackAlreadyExistsError(stack_name, reason, events=None)\n</code></pre> <p>               Bases: <code>StackCreationError</code></p> <p>Raised when stack already exists (informational).</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.InfrastructureNotFoundError","title":"InfrastructureNotFoundError","text":"<pre><code>InfrastructureNotFoundError(stack_name)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when expected infrastructure doesn't exist.</p> <p>This typically means the CloudFormation stack or DynamoDB table hasn't been deployed yet.</p>"},{"location":"api/exceptions/#version-exceptions","title":"Version Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.VersionMismatchError","title":"VersionMismatchError","text":"<pre><code>VersionMismatchError(client_version, schema_version, lambda_version, message, can_auto_update=False)\n</code></pre> <p>               Bases: <code>VersionError</code></p> <p>Raised when client and infrastructure versions are incompatible.</p> <p>This error indicates that the client library version doesn't match the deployed infrastructure and auto-update is disabled or failed.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.IncompatibleSchemaError","title":"IncompatibleSchemaError","text":"<pre><code>IncompatibleSchemaError(client_version, schema_version, message, migration_guide_url=None)\n</code></pre> <p>               Bases: <code>VersionError</code></p> <p>Raised when schema version requires manual migration.</p> <p>This indicates a major version difference that cannot be automatically reconciled.</p>"},{"location":"api/exceptions/#exception-handling-examples","title":"Exception Handling Examples","text":""},{"location":"api/exceptions/#basic-handling","title":"Basic Handling","text":"<pre><code>from zae_limiter import RateLimitExceeded, RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        await do_work()\nexcept RateLimitExceeded as e:\n    # Handle rate limit exceeded\n    print(f\"Rate limited. Retry after {e.retry_after_seconds}s\")\nexcept RateLimiterUnavailable as e:\n    # Handle service unavailable\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"api/exceptions/#http-api-response","title":"HTTP API Response","text":"<pre><code>from fastapi import HTTPException\nfrom fastapi.responses import JSONResponse\n\n@app.post(\"/api/endpoint\")\nasync def endpoint():\n    try:\n        async with limiter.acquire(...):\n            return await process_request()\n    except RateLimitExceeded as e:\n        return JSONResponse(\n            status_code=429,\n            content=e.as_dict(),\n            headers={\"Retry-After\": e.retry_after_header},\n        )\n    except RateLimiterUnavailable:\n        raise HTTPException(status_code=503, detail=\"Service temporarily unavailable\")\n</code></pre>"},{"location":"api/exceptions/#detailed-error-information","title":"Detailed Error Information","text":"<pre><code>try:\n    async with limiter.acquire(...):\n        pass\nexcept RateLimitExceeded as e:\n    # All limit statuses (both passed and failed)\n    for status in e.statuses:\n        print(f\"Limit: {status.limit_name}\")\n        print(f\"  Entity: {status.entity_id}\")\n        print(f\"  Available: {status.available}\")\n        print(f\"  Requested: {status.requested}\")\n        print(f\"  Exceeded: {status.exceeded}\")\n        print(f\"  Retry after: {status.retry_after_seconds}s\")\n\n    # Only the violations\n    print(f\"Violations: {len(e.violations)}\")\n    for v in e.violations:\n        print(f\"  - {v.limit_name}: {v.available} available\")\n\n    # Only the passed limits\n    print(f\"Passed: {len(e.passed)}\")\n\n    # Primary bottleneck (longest wait time)\n    print(f\"Bottleneck: {e.primary_violation.limit_name}\")\n    print(f\"Total retry after: {e.retry_after_seconds}s\")\n</code></pre>"},{"location":"api/exceptions/#as_dict-output","title":"as_dict() Output","text":"<p>The <code>as_dict()</code> method returns a dictionary suitable for API responses:</p> <pre><code>{\n    \"error\": \"rate_limit_exceeded\",\n    \"message\": \"Rate limit exceeded for user-123/api: [rpm]. Retry after 45.2s\",\n    \"retry_after_seconds\": 45.2,\n    \"retry_after_ms\": 45200,\n    \"limits\": [\n        {\n            \"entity_id\": \"user-123\",\n            \"resource\": \"api\",\n            \"limit_name\": \"rpm\",\n            \"capacity\": 100,\n            \"burst\": 100,\n            \"available\": -5,\n            \"requested\": 10,\n            \"exceeded\": True,\n            \"retry_after_seconds\": 45.2,\n        },\n        {\n            \"entity_id\": \"user-123\",\n            \"resource\": \"api\",\n            \"limit_name\": \"tpm\",\n            \"capacity\": 10000,\n            \"burst\": 10000,\n            \"available\": 8500,\n            \"requested\": 500,\n            \"exceeded\": False,\n            \"retry_after_seconds\": 0.0,\n        },\n    ],\n}\n</code></pre> <p>Single <code>limits</code> array</p> <p>All limits (both exceeded and passed) are returned in a single <code>limits</code> array. Use the <code>exceeded</code> field to distinguish between violations and passed limits.</p>"},{"location":"api/limiter/","title":"RateLimiter","text":"<p>The main rate limiter classes for async and sync usage.</p>"},{"location":"api/limiter/#ratelimiter-async","title":"RateLimiter (Async)","text":""},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter","title":"RateLimiter","text":"<pre><code>RateLimiter(name='limiter', region=None, endpoint_url=None, stack_options=None, on_unavailable=BLOCK, auto_update=True, strict_version=True, skip_version_check=False)\n</code></pre> <p>Async rate limiter backed by DynamoDB.</p> <p>Implements token bucket algorithm with support for: - Multiple limits per entity/resource - Two-level hierarchy (parent/child entities) - Cascade mode (consume from entity + parent) - Stored limit configs - Usage analytics</p> Example <p>limiter = RateLimiter(     name=\"my-app\",  # Creates ZAEL-my-app resources     region=\"us-east-1\",     stack_options=StackOptions(), )</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Resource identifier (e.g., 'my-app'). Will be prefixed with 'ZAEL-' automatically. Default: 'limiter' (creates 'ZAEL-limiter' resources)</p> <code>'limiter'</code> <code>region</code> <code>str | None</code> <p>AWS region</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>DynamoDB endpoint URL (for local development)</p> <code>None</code> <code>stack_options</code> <code>StackOptions | None</code> <p>Desired infrastructure state (None = connect only, don't manage)</p> <code>None</code> <code>on_unavailable</code> <code>OnUnavailable</code> <p>Behavior when DynamoDB is unavailable</p> <code>BLOCK</code> <code>auto_update</code> <code>bool</code> <p>Auto-update Lambda when version mismatch detected</p> <code>True</code> <code>strict_version</code> <code>bool</code> <p>Fail if version mismatch (when auto_update is False)</p> <code>True</code> <code>skip_version_check</code> <code>bool</code> <p>Skip all version checks (dangerous)</p> <code>False</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.name","title":"name  <code>property</code>","text":"<pre><code>name\n</code></pre> <p>The resource identifier (with ZAEL- prefix).</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.close","title":"close  <code>async</code>","text":"<pre><code>close()\n</code></pre> <p>Close the underlying connections.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.is_available","title":"is_available  <code>async</code>","text":"<pre><code>is_available(timeout=1.0)\n</code></pre> <p>Check if the rate limiter backend (DynamoDB) is reachable.</p> <p>Performs a lightweight health check without requiring initialization. This method never raises exceptions - it returns False on any error.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>Maximum time in seconds to wait for response (default: 1.0)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if DynamoDB table is reachable, False otherwise.</p> Example <p>limiter = RateLimiter(name=\"my-app\", region=\"us-east-1\") if await limiter.is_available():     async with limiter.acquire(...) as lease:         ... else:     # Handle degraded mode     pass</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.create_entity","title":"create_entity  <code>async</code>","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, metadata=None)\n</code></pre> <p>Create a new entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Unique identifier for the entity</p> required <code>name</code> <code>str | None</code> <p>Human-readable name (defaults to entity_id)</p> <code>None</code> <code>parent_id</code> <code>str | None</code> <p>Parent entity ID (None for root/project entities)</p> <code>None</code> <code>metadata</code> <code>dict[str, str] | None</code> <p>Additional metadata to store</p> <code>None</code> <p>Returns:</p> Type Description <code>Entity</code> <p>The created Entity</p> <p>Raises:</p> Type Description <code>EntityExistsError</code> <p>If entity already exists</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_entity","title":"get_entity  <code>async</code>","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_entity","title":"delete_entity  <code>async</code>","text":"<pre><code>delete_entity(entity_id)\n</code></pre> <p>Delete an entity and all its related data.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_children","title":"get_children  <code>async</code>","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all children of a parent entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.acquire","title":"acquire  <code>async</code>","text":"<pre><code>acquire(entity_id, resource, limits, consume, cascade=False, use_stored_limits=False, on_unavailable=None)\n</code></pre> <p>Acquire rate limit capacity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to acquire capacity for</p> required <code>resource</code> <code>str</code> <p>Resource being accessed (e.g., \"gpt-4\")</p> required <code>limits</code> <code>list[Limit]</code> <p>Default limits to apply</p> required <code>consume</code> <code>dict[str, int]</code> <p>Amounts to consume by limit name</p> required <code>cascade</code> <code>bool</code> <p>If True, also consume from parent entity</p> <code>False</code> <code>use_stored_limits</code> <code>bool</code> <p>If True, use stored limits if available</p> <code>False</code> <code>on_unavailable</code> <code>OnUnavailable | None</code> <p>Override default on_unavailable behavior</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncIterator[Lease]</code> <p>Lease for managing additional consumption</p> <p>Raises:</p> Type Description <code>RateLimitExceeded</code> <p>If any limit would be exceeded</p> <code>RateLimiterUnavailable</code> <p>If DynamoDB unavailable and BLOCK</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.available","title":"available  <code>async</code>","text":"<pre><code>available(entity_id, resource, limits, use_stored_limits=False)\n</code></pre> <p>Check available capacity without consuming.</p> <p>Returns minimum available across entity (and parent if cascade). Can return negative values if bucket is in debt.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>limits</code> <code>list[Limit]</code> <p>Default limits</p> required <code>use_stored_limits</code> <code>bool</code> <p>Use stored limits if available</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping limit_name -&gt; available tokens</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.time_until_available","title":"time_until_available  <code>async</code>","text":"<pre><code>time_until_available(entity_id, resource, limits, needed, use_stored_limits=False)\n</code></pre> <p>Calculate seconds until requested capacity is available.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>limits</code> <code>list[Limit]</code> <p>Default limits</p> required <code>needed</code> <code>dict[str, int]</code> <p>Required amounts by limit name</p> required <code>use_stored_limits</code> <code>bool</code> <p>Use stored limits if available</p> <code>False</code> <p>Returns:</p> Type Description <code>float</code> <p>Seconds until available (0.0 if already available)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.set_limits","title":"set_limits  <code>async</code>","text":"<pre><code>set_limits(entity_id, limits, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Store limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to set limits for</p> required <code>limits</code> <code>list[Limit]</code> <p>Limits to store</p> required <code>resource</code> <code>str</code> <p>Resource these limits apply to (or default)</p> <code>DEFAULT_RESOURCE</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_limits","title":"get_limits  <code>async</code>","text":"<pre><code>get_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Get stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to get limits for</p> required <code>resource</code> <code>str</code> <p>Resource to get limits for</p> <code>DEFAULT_RESOURCE</code> <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of stored limits (empty if none)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_limits","title":"delete_limits  <code>async</code>","text":"<pre><code>delete_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Delete stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to delete limits for</p> required <code>resource</code> <code>str</code> <p>Resource to delete limits for</p> <code>DEFAULT_RESOURCE</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_resource_capacity","title":"get_resource_capacity  <code>async</code>","text":"<pre><code>get_resource_capacity(resource, limit_name, parents_only=False)\n</code></pre> <p>Get aggregated capacity for a resource across all entities.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to query</p> required <code>limit_name</code> <code>str</code> <p>Limit name to query</p> required <code>parents_only</code> <code>bool</code> <p>If True, only include parent entities</p> <code>False</code> <p>Returns:</p> Type Description <code>ResourceCapacity</code> <p>ResourceCapacity with aggregated data</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.create_stack","title":"create_stack  <code>async</code>","text":"<pre><code>create_stack(stack_options=None)\n</code></pre> <p>Create CloudFormation stack for infrastructure.</p> <p>Parameters:</p> Name Type Description Default <code>stack_options</code> <code>StackOptions | None</code> <p>Stack configuration</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with stack_id, stack_name, and status</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If stack creation fails</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_stack","title":"delete_stack  <code>async</code>","text":"<pre><code>delete_stack()\n</code></pre> <p>Delete the CloudFormation stack and all associated resources.</p> <p>This method permanently removes the CloudFormation stack, including:</p> <ul> <li>DynamoDB table and all stored data</li> <li>Lambda aggregator function (if deployed)</li> <li>IAM roles and CloudWatch log groups</li> <li>All other stack resources</li> </ul> <p>The method waits for deletion to complete before returning. If the stack doesn't exist, no error is raised.</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If deletion fails (e.g., permission denied, resources in use, or CloudFormation service error)</p> Example <p>Cleanup after integration testing::</p> <pre><code>limiter = RateLimiter(\n    name=\"test-limits\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\nasync with limiter:\n    # Run tests...\n    pass\n\n# Clean up infrastructure\nawait limiter.delete_stack()\n</code></pre> Warning <p>This operation is irreversible. All rate limit state, entity data, and usage history will be permanently deleted.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_status","title":"get_status  <code>async</code>","text":"<pre><code>get_status()\n</code></pre> <p>Get comprehensive status of the RateLimiter infrastructure.</p> <p>Consolidates connectivity, infrastructure state, version information, and table metrics into a single status object. This method does not raise exceptions for missing infrastructure - it gracefully handles all error cases and returns status information accordingly.</p> <p>Returns:</p> Type Description <code>Status</code> <p>Status object containing:</p> <code>Status</code> <ul> <li>Connectivity: available, latency_ms</li> </ul> <code>Status</code> <ul> <li>Infrastructure: stack_status, table_status, aggregator_enabled</li> </ul> <code>Status</code> <ul> <li>Identity: name, region</li> </ul> <code>Status</code> <ul> <li>Versions: schema_version, lambda_version, client_version</li> </ul> <code>Status</code> <ul> <li>Table metrics: table_item_count, table_size_bytes</li> </ul> Example <p>Check infrastructure health::</p> <pre><code>status = await limiter.get_status()\nif status.available:\n    print(f\"Ready! Latency: {status.latency_ms}ms\")\n    print(f\"Stack: {status.stack_status}\")\n    print(f\"Schema: {status.schema_version}\")\nelse:\n    print(\"DynamoDB is not reachable\")\n</code></pre> Note <p>This method measures actual DynamoDB latency by performing a lightweight operation. The latency_ms value reflects real round-trip time to the DynamoDB endpoint.</p>"},{"location":"api/limiter/#syncratelimiter","title":"SyncRateLimiter","text":""},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter","title":"SyncRateLimiter","text":"<pre><code>SyncRateLimiter(name='limiter', region=None, endpoint_url=None, stack_options=None, on_unavailable=BLOCK, auto_update=True, strict_version=True, skip_version_check=False)\n</code></pre> <p>Synchronous rate limiter backed by DynamoDB.</p> <p>Wraps RateLimiter, running async operations in an event loop.</p> Example <p>limiter = SyncRateLimiter(     name=\"my-app\",  # Creates ZAEL-my-app resources     region=\"us-east-1\",     stack_options=StackOptions(), )</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Close the underlying connections.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.is_available","title":"is_available","text":"<pre><code>is_available(timeout=1.0)\n</code></pre> <p>Check if the rate limiter backend (DynamoDB) is reachable.</p> <p>Performs a lightweight health check without requiring initialization. This method never raises exceptions - it returns False on any error.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>Maximum time in seconds to wait for response (default: 1.0)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if DynamoDB table is reachable, False otherwise.</p> Example <p>limiter = SyncRateLimiter(name=\"my-app\", region=\"us-east-1\") if limiter.is_available():     with limiter.acquire(...) as lease:         ... else:     # Handle degraded mode     pass</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.create_entity","title":"create_entity","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, metadata=None)\n</code></pre> <p>Create a new entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_entity","title":"get_entity","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.delete_entity","title":"delete_entity","text":"<pre><code>delete_entity(entity_id)\n</code></pre> <p>Delete an entity and all its related data.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_children","title":"get_children","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all children of a parent entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.acquire","title":"acquire","text":"<pre><code>acquire(entity_id, resource, limits, consume, cascade=False, use_stored_limits=False, on_unavailable=None)\n</code></pre> <p>Acquire rate limit capacity (synchronous).</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.available","title":"available","text":"<pre><code>available(entity_id, resource, limits, use_stored_limits=False)\n</code></pre> <p>Check available capacity without consuming.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.time_until_available","title":"time_until_available","text":"<pre><code>time_until_available(entity_id, resource, limits, needed, use_stored_limits=False)\n</code></pre> <p>Calculate seconds until requested capacity is available.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.set_limits","title":"set_limits","text":"<pre><code>set_limits(entity_id, limits, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Store limit configs for an entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_limits","title":"get_limits","text":"<pre><code>get_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Get stored limit configs for an entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.delete_limits","title":"delete_limits","text":"<pre><code>delete_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Delete stored limit configs for an entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_resource_capacity","title":"get_resource_capacity","text":"<pre><code>get_resource_capacity(resource, limit_name, parents_only=False)\n</code></pre> <p>Get aggregated capacity for a resource across all entities.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.create_stack","title":"create_stack","text":"<pre><code>create_stack(stack_options=None)\n</code></pre> <p>Create CloudFormation stack for infrastructure.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.delete_stack","title":"delete_stack","text":"<pre><code>delete_stack()\n</code></pre> <p>Delete the CloudFormation stack and all associated resources.</p> <p>Synchronous wrapper for :meth:<code>RateLimiter.delete_stack</code>. See the async version for full documentation.</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If deletion fails</p> Example <p>Cleanup after testing::</p> <pre><code>limiter = SyncRateLimiter(\n    name=\"test-limits\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\nwith limiter:\n    # Run tests...\n    pass\n\n# Clean up infrastructure\nlimiter.delete_stack()\n</code></pre> Warning <p>This operation is irreversible. All data will be permanently deleted.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_status","title":"get_status","text":"<pre><code>get_status()\n</code></pre> <p>Get comprehensive status of the RateLimiter infrastructure.</p> <p>Synchronous wrapper for :meth:<code>RateLimiter.get_status</code>. See the async version for full documentation.</p> <p>Returns:</p> Type Description <code>Status</code> <p>Status object with connectivity, infrastructure, versions, and metrics.</p> Example <p>Check infrastructure health::</p> <pre><code>limiter = SyncRateLimiter(name=\"my-app\", region=\"us-east-1\")\n\nstatus = limiter.get_status()\nif status.available:\n    print(f\"Ready! Latency: {status.latency_ms}ms\")\n    print(f\"Schema: {status.schema_version}\")\nelse:\n    print(\"DynamoDB is not reachable\")\n</code></pre>"},{"location":"api/limiter/#onunavailable","title":"OnUnavailable","text":""},{"location":"api/limiter/#zae_limiter.limiter.OnUnavailable","title":"OnUnavailable","text":"<p>               Bases: <code>Enum</code></p> <p>Behavior when DynamoDB is unavailable.</p>"},{"location":"api/models/","title":"Models","text":"<p>Data models for rate limit configuration and status.</p>"},{"location":"api/models/#limit","title":"Limit","text":""},{"location":"api/models/#zae_limiter.models.Limit","title":"Limit  <code>dataclass</code>","text":"<pre><code>Limit(name, capacity, burst, refill_amount, refill_period_seconds)\n</code></pre> <p>Token bucket rate limit configuration.</p> <p>Refill rate is stored as a fraction (refill_amount / refill_period_seconds) to avoid floating point precision issues.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier for this limit type (e.g., \"rpm\", \"tpm\")</p> <code>capacity</code> <code>int</code> <p>Max tokens that refill over the period (sustained rate)</p> <code>burst</code> <code>int</code> <p>Max tokens in bucket (&gt;= capacity, allows bursting)</p> <code>refill_amount</code> <code>int</code> <p>Numerator of refill rate</p> <code>refill_period_seconds</code> <code>int</code> <p>Denominator of refill rate</p>"},{"location":"api/models/#zae_limiter.models.Limit.refill_rate","title":"refill_rate  <code>property</code>","text":"<pre><code>refill_rate\n</code></pre> <p>Tokens per second (for display/debugging).</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_second","title":"per_second  <code>classmethod</code>","text":"<pre><code>per_second(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per second.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_minute","title":"per_minute  <code>classmethod</code>","text":"<pre><code>per_minute(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per minute.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_hour","title":"per_hour  <code>classmethod</code>","text":"<pre><code>per_hour(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per hour.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_day","title":"per_day  <code>classmethod</code>","text":"<pre><code>per_day(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per day.</p>"},{"location":"api/models/#zae_limiter.models.Limit.custom","title":"custom  <code>classmethod</code>","text":"<pre><code>custom(name, capacity, refill_amount, refill_period_seconds, burst=None)\n</code></pre> <p>Create a custom limit with explicit refill rate.</p> Sustain 100/sec with burst of 1000 <p>Limit.custom(\"requests\", capacity=100, refill_amount=100,             refill_period_seconds=1, burst=1000)</p>"},{"location":"api/models/#zae_limiter.models.Limit.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Serialize to dictionary for storage.</p>"},{"location":"api/models/#zae_limiter.models.Limit.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Deserialize from dictionary.</p>"},{"location":"api/models/#entity","title":"Entity","text":""},{"location":"api/models/#zae_limiter.models.Entity","title":"Entity  <code>dataclass</code>","text":"<pre><code>Entity(id, name=None, parent_id=None, metadata=dict(), created_at=None)\n</code></pre> <p>An entity that can have rate limits applied.</p> <p>Entities can be parents (projects) or children (API keys). Children have a parent_id reference.</p> <p>Note: This model does not validate in post_init to support DynamoDB deserialization and avoid performance overhead. Validation is performed in Repository.create_entity() at the API boundary.</p>"},{"location":"api/models/#zae_limiter.models.Entity.is_parent","title":"is_parent  <code>property</code>","text":"<pre><code>is_parent\n</code></pre> <p>True if this entity has no parent (is a root/project).</p>"},{"location":"api/models/#zae_limiter.models.Entity.is_child","title":"is_child  <code>property</code>","text":"<pre><code>is_child\n</code></pre> <p>True if this entity has a parent.</p>"},{"location":"api/models/#limitstatus","title":"LimitStatus","text":""},{"location":"api/models/#zae_limiter.models.LimitStatus","title":"LimitStatus  <code>dataclass</code>","text":"<pre><code>LimitStatus(entity_id, resource, limit_name, limit, available, requested, exceeded, retry_after_seconds)\n</code></pre> <p>Status of a specific limit check.</p> <p>Returned in RateLimitExceeded to provide full visibility into all limits that were checked.</p> <p>Note: This is an internal model created by the limiter from validated inputs. No validation is performed here to avoid performance overhead.</p>"},{"location":"api/models/#zae_limiter.models.LimitStatus.deficit","title":"deficit  <code>property</code>","text":"<pre><code>deficit\n</code></pre> <p>How many tokens short we are (0 if not exceeded).</p>"},{"location":"api/models/#bucketstate","title":"BucketState","text":""},{"location":"api/models/#zae_limiter.models.BucketState","title":"BucketState  <code>dataclass</code>","text":"<pre><code>BucketState(entity_id, resource, limit_name, tokens_milli, last_refill_ms, capacity_milli, burst_milli, refill_amount_milli, refill_period_ms)\n</code></pre> <p>Internal state of a token bucket.</p> <p>All token values are stored in millitokens (x1000) for precision.</p> <p>Note: This is an internal model. Validation is performed in from_limit() for user-provided inputs, not in post_init to support DynamoDB deserialization and avoid performance overhead on frequent operations.</p>"},{"location":"api/models/#zae_limiter.models.BucketState.tokens","title":"tokens  <code>property</code>","text":"<pre><code>tokens\n</code></pre> <p>Current tokens (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.capacity","title":"capacity  <code>property</code>","text":"<pre><code>capacity\n</code></pre> <p>Capacity (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.burst","title":"burst  <code>property</code>","text":"<pre><code>burst\n</code></pre> <p>Burst (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.from_limit","title":"from_limit  <code>classmethod</code>","text":"<pre><code>from_limit(entity_id, resource, limit, now_ms)\n</code></pre> <p>Create a new bucket at full capacity from a Limit.</p> <p>Note: This is an internal factory method. Validation of entity_id and resource is performed at the API boundary (RateLimiter public methods) before calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier (pre-validated by caller)</p> required <code>resource</code> <code>str</code> <p>Resource name (pre-validated by caller)</p> required <code>limit</code> <code>Limit</code> <p>Limit configuration (validated via post_init)</p> required <code>now_ms</code> <code>int</code> <p>Current time in milliseconds</p> required"},{"location":"api/models/#auditevent","title":"AuditEvent","text":""},{"location":"api/models/#zae_limiter.models.AuditEvent","title":"AuditEvent  <code>dataclass</code>","text":"<pre><code>AuditEvent(event_id, timestamp, action, entity_id, principal=None, resource=None, details=dict())\n</code></pre> <p>Security audit event for tracking modifications.</p> <p>Audit events are logged for security-sensitive operations: - Entity creation and deletion - Limit configuration changes</p> <p>Attributes:</p> Name Type Description <code>event_id</code> <code>str</code> <p>Unique identifier for the event (timestamp-based)</p> <code>timestamp</code> <code>str</code> <p>ISO timestamp when the event occurred</p> <code>action</code> <code>str</code> <p>Type of action (see AuditAction constants)</p> <code>entity_id</code> <code>str</code> <p>ID of the entity affected</p> <code>principal</code> <code>str | None</code> <p>Caller identity who performed the action (optional)</p> <code>resource</code> <code>str | None</code> <p>Resource name for limit-related actions (optional)</p> <code>details</code> <code>dict[str, Any]</code> <p>Additional action-specific details</p>"},{"location":"api/models/#zae_limiter.models.AuditEvent.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Serialize to dictionary for storage.</p>"},{"location":"api/models/#zae_limiter.models.AuditEvent.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Deserialize from dictionary.</p>"},{"location":"api/models/#auditaction","title":"AuditAction","text":""},{"location":"api/models/#zae_limiter.models.AuditAction","title":"AuditAction","text":"<p>Audit action type constants.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to zae-limiter!</p>"},{"location":"contributing/#quick-start","title":"Quick Start","text":"<pre><code>git clone https://github.com/zeroae/zae-limiter.git\ncd zae-limiter\nuv sync --all-extras\npytest\n</code></pre>"},{"location":"contributing/#development-guides","title":"Development Guides","text":"Guide Description Development Setup Environment setup, running tests, code quality LocalStack Local AWS development environment Testing Test organization, pytest fixtures, CI Architecture DynamoDB schema, token bucket algorithm"},{"location":"contributing/#detailed-reference","title":"Detailed Reference","text":"<p>For comprehensive development instructions including:</p> <ul> <li>Build commands and linting</li> <li>Commit message conventions</li> <li>Code review guidelines</li> <li>Release process</li> </ul> <p>See CLAUDE.md in the repository root.</p>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Create a feature branch from <code>main</code></li> <li>Make changes following project conventions</li> <li>Ensure CI passes (lint, type check, tests)</li> <li>Submit PR for review</li> </ol> <p>All changes must go through pull requests. Direct commits to <code>main</code> are not allowed.</p>"},{"location":"contributing/architecture/","title":"Architecture","text":"<p>This guide covers the internal architecture of zae-limiter, including the DynamoDB schema and token bucket implementation.</p>"},{"location":"contributing/architecture/#dynamodb-schema-single-table","title":"DynamoDB Schema (Single Table)","text":"<p>All data is stored in a single DynamoDB table using a composite key pattern:</p> Record Type PK SK Entity metadata <code>ENTITY#{id}</code> <code>#META</code> Bucket <code>ENTITY#{id}</code> <code>#BUCKET#{resource}#{limit_name}</code> Limit config <code>ENTITY#{id}</code> <code>#LIMIT#{resource}#{limit_name}</code> Usage snapshot <code>ENTITY#{id}</code> <code>#USAGE#{resource}#{window_key}</code> System version <code>SYSTEM#</code> <code>#VERSION</code> Audit events <code>AUDIT#{entity_id}</code> <code>#AUDIT#{timestamp}</code>"},{"location":"contributing/architecture/#global-secondary-indexes","title":"Global Secondary Indexes","text":"Index Purpose Key Pattern GSI1 Parent \u2192 Children lookup <code>GSI1PK=PARENT#{id}</code> \u2192 <code>GSI1SK=CHILD#{id}</code> GSI2 Resource aggregation <code>GSI2PK=RESOURCE#{name}</code> \u2192 buckets/usage"},{"location":"contributing/architecture/#access-patterns","title":"Access Patterns","text":"Pattern Query Get entity <code>PK=ENTITY#{id}, SK=#META</code> Get buckets <code>PK=ENTITY#{id}, SK begins_with #BUCKET#</code> Get children GSI1: <code>GSI1PK=PARENT#{id}</code> Resource capacity GSI2: <code>GSI2PK=RESOURCE#{name}, SK begins_with BUCKET#</code> Get version <code>PK=SYSTEM#, SK=#VERSION</code> Get audit events <code>PK=AUDIT#{entity_id}, SK begins_with #AUDIT#</code>"},{"location":"contributing/architecture/#token-bucket-implementation","title":"Token Bucket Implementation","text":"<p>For a conceptual overview of the token bucket algorithm, see the User Guide. This section covers implementation details for contributors.</p>"},{"location":"contributing/architecture/#core-functions","title":"Core Functions","text":"<p>The algorithm is implemented in <code>bucket.py</code>:</p> Function Purpose Lines <code>refill_bucket()</code> Calculate refilled tokens with drift compensation 27-75 <code>try_consume()</code> Atomic check-and-consume operation 78-134 <code>force_consume()</code> Force consume (can go negative) 224-255 <code>calculate_retry_after()</code> Calculate wait time for deficit 137-159"},{"location":"contributing/architecture/#mathematical-formulas","title":"Mathematical Formulas","text":"<p>Refill calculation (lazy, on-demand):</p> <pre><code>tokens_to_add = (elapsed_ms \u00d7 refill_amount_milli) // refill_period_ms\n</code></pre> <p>Drift compensation (prevents accumulated rounding errors):</p> <pre><code>time_used_ms = (tokens_to_add \u00d7 refill_period_ms) // refill_amount_milli\nnew_last_refill = last_refill_ms + time_used_ms\n</code></pre> <p>The inverse calculation ensures we only \"consume\" the time that corresponds to whole tokens, preventing drift over many refill cycles.</p> <p>Retry-after calculation:</p> <pre><code>time_ms = (deficit_milli \u00d7 refill_period_ms) // refill_amount_milli\nretry_seconds = (time_ms + 1) / 1000.0  # +1ms rounds up\n</code></pre>"},{"location":"contributing/architecture/#integer-arithmetic-for-precision","title":"Integer Arithmetic for Precision","text":"<p>All token values are stored as millitokens (\u00d71000) to avoid floating-point precision issues in distributed systems:</p> <pre><code># User sees: 100 tokens/minute\n# Stored as: 100,000 millitokens/minute\ncapacity_milli = 100_000\n</code></pre> <p>Why integers matter in distributed systems:</p> <ul> <li>Floating-point operations can produce different results on different hardware</li> <li>DynamoDB stores numbers as strings, so precision loss can occur during serialization</li> <li>Rate limiting across multiple nodes requires identical calculations</li> </ul>"},{"location":"contributing/architecture/#refill-rate-storage","title":"Refill Rate Storage","text":"<p>Refill rates are stored as a fraction (amount/period) rather than a decimal:</p> <pre><code># 100 tokens per minute stored as:\nrefill_amount_milli = 100_000  # millitokens (numerator)\nrefill_period_ms = 60_000      # milliseconds (denominator)\n</code></pre> <p>This avoids representing <code>1.6667 tokens/second</code> as a float. Instead:</p> <pre><code># 100 tokens/minute = 100,000 millitokens / 60,000 ms\n# Integer division handles the math precisely\n</code></pre>"},{"location":"contributing/architecture/#lazy-refill-with-drift-compensation","title":"Lazy Refill with Drift Compensation","text":"<p>Tokens are calculated on-demand rather than via a background timer. The <code>refill_bucket()</code> function:</p> <ol> <li>Calculates elapsed time since last refill</li> <li>Computes tokens to add using integer division</li> <li>Tracks \"time consumed\" to prevent drift</li> </ol> <pre><code># From bucket.py:refill_bucket()\ntokens_to_add = (elapsed_ms * refill_amount_milli) // refill_period_ms\n\n# Drift compensation: only advance time for tokens actually added\ntime_used_ms = (tokens_to_add * refill_period_ms) // refill_amount_milli\nnew_last_refill = last_refill_ms + time_used_ms\n</code></pre> <p>Without drift compensation, repeated calls with small time intervals would accumulate rounding errors.</p>"},{"location":"contributing/architecture/#negative-buckets-debt","title":"Negative Buckets (Debt)","text":"<p>Buckets can go negative to support post-hoc reconciliation:</p> <pre><code># Estimate 500 tokens, actually used 2000\nasync with limiter.acquire(consume={\"tpm\": 500}) as lease:\n    actual = await call_llm()  # Returns 2000 tokens\n    await lease.adjust(tpm=2000 - 500)  # Bucket at -1500\n</code></pre> <p>The <code>force_consume()</code> function handles this:</p> <pre><code># From bucket.py:force_consume()\n# Consume can go negative - no bounds checking\nnew_tokens_milli = refill.new_tokens_milli - (amount * 1000)\n</code></pre> <p>The debt is repaid as tokens refill over time. A bucket at -1500 millitokens needs 1.5 minutes to reach 0 (at 1000 tokens/minute).</p>"},{"location":"contributing/architecture/#burst-capacity","title":"Burst Capacity","text":"<p>Burst allows temporary exceeding of sustained rate:</p> <pre><code># Sustained: 10k tokens/minute\n# Burst: 15k tokens (one-time)\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n</code></pre> <p>When <code>burst &gt; capacity</code>, users can consume up to <code>burst</code> tokens immediately, then sustain at <code>capacity</code> rate.</p>"},{"location":"contributing/architecture/#design-decisions","title":"Design Decisions","text":"Decision Rationale Integer over float Identical results across distributed nodes; no precision drift Lazy over continuous No background timers; accurate retry_after; efficient Negative allowed Estimate-then-reconcile pattern; operations with unknown cost Fraction over decimal Exact representation of rates like 100/minute"},{"location":"contributing/architecture/#atomicity","title":"Atomicity","text":""},{"location":"contributing/architecture/#transactwriteitems","title":"TransactWriteItems","text":"<p>Multi-entity updates (like cascade mode) use DynamoDB transactions:</p> <pre><code># Single atomic operation:\n# 1. Consume from child entity\n# 2. Consume from parent entity\n# Both succeed or both fail\n</code></pre> <p>Transaction limits: max 100 items per transaction.</p>"},{"location":"contributing/architecture/#optimistic-locking","title":"Optimistic Locking","text":"<p>Entity metadata uses version numbers for optimistic locking:</p> <pre><code># Read entity with version 5\n# Update fails if version changed\ncondition_expression=\"version = :expected_version\"\n</code></pre>"},{"location":"contributing/architecture/#project-structure","title":"Project Structure","text":"<pre><code>src/zae_limiter/\n\u251c\u2500\u2500 __init__.py        # Public API exports\n\u251c\u2500\u2500 models.py          # Limit, Entity, LimitStatus, BucketState, StackOptions\n\u251c\u2500\u2500 exceptions.py      # RateLimitExceeded, RateLimiterUnavailable, etc.\n\u251c\u2500\u2500 naming.py          # Resource name validation and ZAEL- prefix logic\n\u251c\u2500\u2500 bucket.py          # Token bucket math (integer arithmetic)\n\u251c\u2500\u2500 schema.py          # DynamoDB key builders\n\u251c\u2500\u2500 repository.py      # DynamoDB operations\n\u251c\u2500\u2500 lease.py           # Lease context manager\n\u251c\u2500\u2500 limiter.py         # RateLimiter, SyncRateLimiter\n\u251c\u2500\u2500 cli.py             # CLI commands\n\u251c\u2500\u2500 version.py         # Version tracking and compatibility\n\u251c\u2500\u2500 migrations/        # Schema migration framework\n\u2514\u2500\u2500 infra/\n    \u251c\u2500\u2500 stack_manager.py    # CloudFormation stack operations\n    \u251c\u2500\u2500 lambda_builder.py   # Lambda deployment package builder\n    \u2514\u2500\u2500 cfn_template.yaml   # CloudFormation template\n</code></pre>"},{"location":"contributing/architecture/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Lease commits only on success: If any exception occurs in the context, changes are rolled back</li> <li>Bucket can go negative: <code>lease.adjust()</code> never throws, allows debt</li> <li>Cascade is optional: Parent is only checked if <code>cascade=True</code></li> <li>Stored limits override defaults: When <code>use_stored_limits=True</code></li> <li>Transactions are atomic: Multi-entity updates succeed or fail together</li> </ol>"},{"location":"contributing/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup - Setting up your environment</li> <li>Testing - Test organization and fixtures</li> </ul>"},{"location":"contributing/development/","title":"Development Setup","text":"<p>This guide covers setting up a local development environment for zae-limiter.</p>"},{"location":"contributing/development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or 3.12</li> <li>uv (recommended) or conda</li> <li>Docker (for LocalStack integration tests)</li> </ul>"},{"location":"contributing/development/#setup","title":"Setup","text":""},{"location":"contributing/development/#using-uv-recommended","title":"Using uv (Recommended)","text":"<pre><code>git clone --recurse-submodules https://github.com/zeroae/zae-limiter.git\ncd zae-limiter\nuv sync --all-extras\n</code></pre>"},{"location":"contributing/development/#using-conda","title":"Using conda","text":"<pre><code>git clone --recurse-submodules https://github.com/zeroae/zae-limiter.git\ncd zae-limiter\nconda create -n zae-limiter python=3.12\nconda activate zae-limiter\npip install -e \".[dev]\"\n</code></pre> <p>Already cloned?</p> <p>If you cloned without <code>--recurse-submodules</code>, run: <pre><code>git submodule update --init --recursive\n</code></pre></p>"},{"location":"contributing/development/#running-tests","title":"Running Tests","text":"<pre><code># Run all unit tests\npytest tests/unit/ -v\n\n# Run with coverage\npytest --cov=zae_limiter --cov-report=html\n\n# Run specific test file\npytest tests/unit/test_limiter.py -v\n</code></pre> <p>For integration tests with LocalStack, see the Testing Guide.</p>"},{"location":"contributing/development/#code-quality","title":"Code Quality","text":"<pre><code># Format code\nruff format .\n\n# Lint and auto-fix\nruff check --fix .\n\n# Type checking\nmypy src/zae_limiter\n</code></pre>"},{"location":"contributing/development/#commit-messages","title":"Commit Messages","text":"<p>Follow the ZeroAE commit conventions:</p> <pre><code># Examples\nfeat(limiter): add hierarchical rate limiting support\nfix(bucket): prevent integer overflow in refill calculation\ndocs(readme): add CloudFormation deployment guide\nrefactor(schema): simplify DynamoDB key structure\n</code></pre> <p>Project scopes: <code>limiter</code>, <code>bucket</code>, <code>cli</code>, <code>infra</code>, <code>ci</code>, <code>aggregator</code>, <code>models</code>, <code>schema</code>, <code>repository</code>, <code>lease</code>, <code>exceptions</code>, <code>test</code>, <code>benchmark</code></p>"},{"location":"contributing/development/#next-steps","title":"Next Steps","text":"<ul> <li>LocalStack - Local AWS development</li> <li>Testing - Test organization and fixtures</li> <li>Architecture - DynamoDB schema and design decisions</li> </ul>"},{"location":"contributing/localstack/","title":"LocalStack Development","text":"<p>LocalStack provides a local AWS environment for development and testing. This guide covers setting up zae-limiter with LocalStack.</p>"},{"location":"contributing/localstack/#why-localstack","title":"Why LocalStack?","text":"<ul> <li>Free - No AWS costs during development</li> <li>Fast - No network latency</li> <li>Isolated - No risk to production data</li> <li>Full stack - DynamoDB, Lambda, Streams, CloudFormation</li> </ul>"},{"location":"contributing/localstack/#quick-start","title":"Quick Start","text":""},{"location":"contributing/localstack/#1-start-localstack","title":"1. Start LocalStack","text":"Docker Compose (Preferred)DockerLocalStack CLI <p>The project includes a pre-configured <code>docker-compose.yml</code> at the repository root:</p> <pre><code># From the project root\ndocker compose up -d\n</code></pre> <p>This is the preferred method as it includes all required configuration for Lambda execution.</p> <pre><code>docker run -d \\\n  --name localstack \\\n  -p 4566:4566 \\\n  -e SERVICES=dynamodb,dynamodbstreams,lambda,cloudformation,logs,iam,cloudwatch,sqs \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v \"${TMPDIR:-/tmp}/localstack:/var/lib/localstack\" \\\n  localstack/localstack\n</code></pre> <p>Docker Socket Required</p> <p>The Docker socket mount (<code>-v /var/run/docker.sock:/var/run/docker.sock</code>) is required for LocalStack to spawn Lambda functions as Docker containers.</p> <pre><code>pip install localstack\nlocalstack start -d\n</code></pre>"},{"location":"contributing/localstack/#2-deploy-infrastructure","title":"2. Deploy Infrastructure","text":"<pre><code>zae-limiter deploy \\\n    --name limiter \\\n    --endpoint-url http://localhost:4566 \\\n    --region us-east-1\n</code></pre>"},{"location":"contributing/localstack/#3-use-in-code","title":"3. Use in Code","text":"<pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    endpoint_url=\"http://localhost:4566\",\n    region=\"us-east-1\",\n)\n\nasync with limiter.acquire(\n    entity_id=\"test-user\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"requests\", 100)],\n    consume={\"requests\": 1},\n) as lease:\n    print(\"Rate limited request!\")\n</code></pre>"},{"location":"contributing/localstack/#declarative-infrastructure","title":"Declarative Infrastructure","text":"<p>For quick iteration, declare infrastructure in code:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # ZAEL-limiter resources\n    endpoint_url=\"http://localhost:4566\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Declare desired state\n)\n</code></pre>"},{"location":"contributing/localstack/#environment-variables","title":"Environment Variables","text":"<p>Configure via environment variables for easy switching:</p> <pre><code># .env.local\nAWS_ENDPOINT_URL=http://localhost:4566\nAWS_ACCESS_KEY_ID=test\nAWS_SECRET_ACCESS_KEY=test\nAWS_DEFAULT_REGION=us-east-1\n</code></pre> <pre><code>import os\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    endpoint_url=os.getenv(\"AWS_ENDPOINT_URL\"),\n    region=os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\"),\n)\n</code></pre>"},{"location":"contributing/localstack/#debugging","title":"Debugging","text":""},{"location":"contributing/localstack/#check-stack-status","title":"Check Stack Status","text":"<pre><code># List stacks\naws --endpoint-url=http://localhost:4566 cloudformation list-stacks\n\n# Describe stack\naws --endpoint-url=http://localhost:4566 cloudformation describe-stacks \\\n    --stack-name ZAEL-limiter\n</code></pre>"},{"location":"contributing/localstack/#inspect-dynamodb","title":"Inspect DynamoDB","text":"<pre><code># List tables\naws --endpoint-url=http://localhost:4566 dynamodb list-tables\n\n# Scan table\naws --endpoint-url=http://localhost:4566 dynamodb scan \\\n    --table-name ZAEL-limiter\n</code></pre>"},{"location":"contributing/localstack/#view-lambda-logs","title":"View Lambda Logs","text":"<pre><code># List functions\naws --endpoint-url=http://localhost:4566 lambda list-functions\n\n# Get logs\naws --endpoint-url=http://localhost:4566 logs tail \\\n    /aws/lambda/zae-limiter-aggregator\n</code></pre>"},{"location":"contributing/localstack/#localstack-vs-dynamodb-local","title":"LocalStack vs DynamoDB Local","text":"Feature LocalStack DynamoDB Local DynamoDB Yes Yes Streams Yes Limited Lambda Yes No CloudFormation Yes No Cost Free Free Fidelity High Medium <p>Recommendation: Use LocalStack for full integration testing, DynamoDB Local for quick unit tests.</p>"},{"location":"contributing/localstack/#troubleshooting","title":"Troubleshooting","text":""},{"location":"contributing/localstack/#connection-refused","title":"Connection Refused","text":"<pre><code>Cannot connect to http://localhost:4566\n</code></pre> <p>Solution: Ensure LocalStack is running:</p> <pre><code>docker ps | grep localstack\n# or\ncurl http://localhost:4566/_localstack/health\n</code></pre>"},{"location":"contributing/localstack/#lambda-not-executing","title":"Lambda Not Executing","text":"<p>Check Lambda logs:</p> <pre><code>docker logs localstack 2&gt;&amp;1 | grep -i lambda\n</code></pre> <p>Ensure the Lambda service is enabled:</p> <pre><code>docker run -e SERVICES=dynamodb,dynamodbstreams,lambda,...\n</code></pre>"},{"location":"contributing/localstack/#slow-performance","title":"Slow Performance","text":"<p>LocalStack can be slow on first request. Consider:</p> <ul> <li>Pre-warming containers</li> <li>Using persistence for faster restarts</li> <li>Reducing DEBUG level</li> </ul>"},{"location":"contributing/localstack/#next-steps","title":"Next Steps","text":"<ul> <li>Testing - pytest fixtures and CI configuration</li> <li>Development Setup - Local development environment</li> </ul>"},{"location":"contributing/testing/","title":"Testing","text":"<p>This guide covers test organization, pytest fixtures, and CI configuration for zae-limiter.</p>"},{"location":"contributing/testing/#test-organization","title":"Test Organization","text":"<p>Tests are organized by execution environment and scope:</p> <pre><code>tests/\n\u251c\u2500\u2500 conftest.py                  # Shared config (--run-aws flag)\n\u251c\u2500\u2500 unit/                        # Fast tests with mocked AWS (moto)\n\u2502   \u251c\u2500\u2500 test_limiter.py\n\u2502   \u251c\u2500\u2500 test_repository.py\n\u2502   \u2514\u2500\u2500 test_sync_limiter.py\n\u251c\u2500\u2500 integration/                 # LocalStack tests (repository-level)\n\u2502   \u2514\u2500\u2500 test_repository.py\n\u251c\u2500\u2500 e2e/                         # Full workflow tests (LocalStack + AWS)\n\u2502   \u251c\u2500\u2500 test_localstack.py\n\u2502   \u2514\u2500\u2500 test_aws.py\n\u2514\u2500\u2500 benchmark/                   # Performance benchmarks (pytest-benchmark)\n    \u251c\u2500\u2500 test_operations.py       # Mocked benchmarks\n    \u2514\u2500\u2500 test_localstack.py       # LocalStack benchmarks\n</code></pre>"},{"location":"contributing/testing/#test-categories","title":"Test Categories","text":"Category Directory Backend What to Test Speed Unit <code>tests/unit/</code> moto (mocked) Business logic, bucket math, schema, exceptions Fast (~seconds) Integration <code>tests/integration/</code> LocalStack Repository operations, transactions, GSI queries Medium E2E <code>tests/e2e/</code> LocalStack or AWS Full workflows: CLI, rate limiting, hierarchical limits Slow Benchmark <code>tests/benchmark/</code> moto or LocalStack Latency (p50/p95/p99), throughput, cascade overhead Variable"},{"location":"contributing/testing/#pytest-markers","title":"Pytest Markers","text":"Marker Description How to Run (none) Unit tests <code>pytest tests/unit/</code> <code>@pytest.mark.integration</code> Requires LocalStack <code>pytest -m integration</code> <code>@pytest.mark.e2e</code> End-to-end workflows <code>pytest -m e2e</code> <code>@pytest.mark.aws</code> Real AWS (requires <code>--run-aws</code>) <code>pytest -m aws --run-aws</code> <code>@pytest.mark.benchmark</code> Performance benchmarks <code>pytest -m benchmark</code> <code>@pytest.mark.slow</code> Tests with &gt;30s waits Skip with <code>-m \"not slow\"</code>"},{"location":"contributing/testing/#pytest-fixtures","title":"pytest Fixtures","text":""},{"location":"contributing/testing/#localstack-endpoint-fixture","title":"LocalStack Endpoint Fixture","text":"<pre><code>import os\nimport pytest\n\n@pytest.fixture\ndef localstack_endpoint():\n    \"\"\"Get LocalStack endpoint from environment.\"\"\"\n    return os.getenv(\"AWS_ENDPOINT_URL\", \"http://localhost:4566\")\n</code></pre>"},{"location":"contributing/testing/#function-scoped-limiter-isolated","title":"Function-Scoped Limiter (Isolated)","text":"<pre><code>import uuid\nimport pytest\nfrom zae_limiter import RateLimiter, StackOptions\n\n@pytest.fixture(scope=\"function\")\nasync def limiter(localstack_endpoint):\n    \"\"\"\n    Create a rate limiter connected to LocalStack with automatic cleanup.\n\n    This fixture:\n    1. Creates a unique stack for test isolation\n    2. Yields the limiter for test use\n    3. Deletes the stack in teardown\n    \"\"\"\n    # Unique name prevents test interference\n    name = f\"test-{uuid.uuid4().hex[:8]}\"\n\n    limiter = RateLimiter(\n        name=name,  # Creates ZAEL-test-{uuid} resources\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    async with limiter:\n        yield limiter\n\n    # Cleanup: delete the CloudFormation stack\n    await limiter.delete_stack()\n\n\n@pytest.mark.integration\nasync def test_rate_limiting(limiter):\n    async with limiter.acquire(\n        entity_id=\"test-user\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"requests\", 10)],\n        consume={\"requests\": 1},\n    ):\n        pass  # Success\n</code></pre>"},{"location":"contributing/testing/#session-scoped-limiter-faster","title":"Session-Scoped Limiter (Faster)","text":"<p>For test suites where stack creation overhead is significant:</p> <pre><code>@pytest.fixture(scope=\"session\")\nasync def shared_limiter(localstack_endpoint):\n    \"\"\"\n    Session-scoped limiter for faster test execution.\n\n    Trade-off: Tests share state, less isolation.\n    \"\"\"\n    limiter = RateLimiter(\n        name=\"integration-test-shared\",\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    async with limiter:\n        yield limiter\n\n    await limiter.delete_stack()\n</code></pre>"},{"location":"contributing/testing/#sync-fixture-example","title":"Sync Fixture Example","text":"<pre><code>@pytest.fixture(scope=\"function\")\ndef sync_limiter(localstack_endpoint):\n    \"\"\"Synchronous rate limiter with cleanup.\"\"\"\n    from zae_limiter import SyncRateLimiter, StackOptions\n    import uuid\n\n    name = f\"test-sync-{uuid.uuid4().hex[:8]}\"\n\n    limiter = SyncRateLimiter(\n        name=name,\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    with limiter:\n        yield limiter\n\n    limiter.delete_stack()\n</code></pre>"},{"location":"contributing/testing/#running-tests","title":"Running Tests","text":""},{"location":"contributing/testing/#unit-tests-only-no-docker","title":"Unit Tests Only (No Docker)","text":"<pre><code>pytest tests/unit/ -v\n</code></pre>"},{"location":"contributing/testing/#integration-tests-requires-localstack","title":"Integration Tests (Requires LocalStack)","text":"<pre><code># Start LocalStack\ndocker compose up -d\n\n# Set environment variables\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\n\n# Run integration tests\npytest tests/integration/ -v\n\n# Stop LocalStack\ndocker compose down\n</code></pre>"},{"location":"contributing/testing/#e2e-tests","title":"E2E Tests","text":"<pre><code># LocalStack E2E\npytest tests/e2e/test_localstack.py -v\n\n# Real AWS E2E (costs money!)\npytest tests/e2e/test_aws.py --run-aws -v\n</code></pre>"},{"location":"contributing/testing/#benchmarks","title":"Benchmarks","text":"<pre><code># Mocked benchmarks (fast)\npytest tests/benchmark/test_operations.py -v\n\n# LocalStack benchmarks (realistic latency)\npytest tests/benchmark/test_localstack.py -v\n\n# Export results to JSON\npytest tests/benchmark/ -v --benchmark-json=benchmark.json\n</code></pre>"},{"location":"contributing/testing/#ci-configuration","title":"CI Configuration","text":"<p>Example GitHub Actions workflow for integration tests:</p> <pre><code># .github/workflows/ci.yml\njobs:\n  integration:\n    runs-on: ubuntu-latest\n    services:\n      localstack:\n        image: localstack/localstack\n        ports:\n          - 4566:4566\n        env:\n          SERVICES: dynamodb,dynamodbstreams,lambda,cloudformation,logs,iam,cloudwatch,sqs\n        options: &gt;-\n          --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock\n    steps:\n      - uses: actions/checkout@v4\n      - run: pip install -e \".[dev]\"\n      - run: pytest -m integration\n        env:\n          AWS_ENDPOINT_URL: http://localhost:4566\n          AWS_ACCESS_KEY_ID: test\n          AWS_SECRET_ACCESS_KEY: test\n</code></pre>"},{"location":"contributing/testing/#when-to-add-tests","title":"When to Add Tests","text":"<ul> <li>New business logic (bucket calculations, limit validation) \u2192 <code>unit/</code></li> <li>New DynamoDB operations (queries, transactions, GSI) \u2192 <code>integration/</code></li> <li>New user-facing features (CLI commands, rate limiting workflows) \u2192 <code>e2e/</code></li> <li>AWS-specific behavior (alarms, DLQ, CloudWatch metrics) \u2192 <code>e2e/test_aws.py</code></li> <li>Performance-sensitive code (new operations, optimizations) \u2192 <code>benchmark/</code></li> </ul>"},{"location":"contributing/testing/#test-coverage","title":"Test Coverage","text":"<pre><code>pytest --cov=zae_limiter --cov-report=html\nopen htmlcov/index.html\n</code></pre>"},{"location":"contributing/testing/#next-steps","title":"Next Steps","text":"<ul> <li>LocalStack - Local AWS development environment</li> <li>Architecture - Understanding the codebase</li> </ul>"},{"location":"guide/basic-usage/","title":"Basic Usage","text":"<p>This guide covers common rate limiting patterns with zae-limiter.</p>"},{"location":"guide/basic-usage/#the-acquire-context-manager","title":"The Acquire Context Manager","text":"<p>The <code>acquire()</code> method is the primary API for rate limiting:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"user-123\",      # Who is being rate limited\n    resource=\"gpt-4\",          # What resource they're accessing\n    limits=[...],              # Rate limit definitions\n    consume={\"rpm\": 1},        # How much to consume\n) as lease:\n    # Your code here\n    pass\n</code></pre> <p>Behavior:</p> <ul> <li>On entry: Checks limits and consumes tokens</li> <li>On success: Commits the consumption</li> <li>On exception: Rolls back the consumption</li> </ul>"},{"location":"guide/basic-usage/#multiple-limits","title":"Multiple Limits","text":"<p>Track multiple limits in a single call:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),       # 100 requests/minute\n        Limit.per_minute(\"tpm\", 10_000),    # 10,000 tokens/minute\n        Limit.per_hour(\"rph\", 1_000),       # 1,000 requests/hour\n    ],\n    consume={\"rpm\": 1, \"tpm\": 500, \"rph\": 1},\n) as lease:\n    response = await call_llm()\n</code></pre> <p>All limits are checked atomically. If any limit is exceeded, the request is rejected.</p> <p>Performance Tip</p> <p>Combining multiple limits into a single <code>acquire()</code> call is more efficient than separate calls. See Batch Operation Patterns for details.</p>"},{"location":"guide/basic-usage/#burst-capacity","title":"Burst Capacity","text":"<p>Allow temporary bursts above the sustained rate:</p> <pre><code># Sustain 10k tokens/minute, but allow bursts up to 15k\nlimits = [\n    Limit.per_minute(\"tpm\", 10_000, burst=15_000),\n]\n</code></pre> <p>The bucket starts full at <code>burst</code> capacity and refills at <code>capacity</code> tokens per period. See Token Bucket Algorithm for details on how burst and capacity interact.</p>"},{"location":"guide/basic-usage/#adjusting-consumption","title":"Adjusting Consumption","text":"<p>Use <code>lease.adjust()</code> to modify consumption after the fact:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},  # Initial estimate\n) as lease:\n    response = await call_llm()\n\n    # Adjust based on actual usage\n    actual_tokens = response.usage.total_tokens\n    await lease.adjust(tpm=actual_tokens - 500)\n</code></pre> <p>Negative Adjustments</p> <p><code>adjust()</code> can go negative, allowing the bucket to go into debt. This is useful for post-hoc reconciliation when actual usage exceeds estimates. See Token Bucket Algorithm - Negative Buckets for how debt works.</p>"},{"location":"guide/basic-usage/#check-capacity-without-consuming","title":"Check Capacity Without Consuming","text":""},{"location":"guide/basic-usage/#check-available-tokens","title":"Check Available Tokens","text":"<pre><code>available = await limiter.available(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n)\nprint(f\"Available tokens: {available['tpm']}\")\n</code></pre>"},{"location":"guide/basic-usage/#check-time-until-available","title":"Check Time Until Available","text":"<pre><code>wait_seconds = await limiter.time_until_available(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    needed={\"tpm\": 5_000},\n)\n\nif wait_seconds &gt; 0:\n    print(f\"Need to wait {wait_seconds}s for capacity\")\n</code></pre>"},{"location":"guide/basic-usage/#stored-limits","title":"Stored Limits","text":"<p>Configure per-entity limits stored in DynamoDB:</p> <pre><code># Set custom limits for a premium user\nawait limiter.set_limits(\n    entity_id=\"user-premium\",\n    limits=[\n        Limit.per_minute(\"rpm\", 500),        # 5x normal\n        Limit.per_minute(\"tpm\", 50_000),     # 5x normal\n    ],\n)\n\n# Use stored limits (falls back to defaults if not found)\nasync with limiter.acquire(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"rpm\", 100)],  # Default\n    consume={\"rpm\": 1},\n    use_stored_limits=True,  # Use stored if available\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/basic-usage/#entity-management","title":"Entity Management","text":""},{"location":"guide/basic-usage/#create-entities","title":"Create Entities","text":"<pre><code># Create a standalone entity\nawait limiter.create_entity(\n    entity_id=\"user-123\",\n    name=\"John Doe\",\n)\n\n# Create a child entity (API key under a project)\nawait limiter.create_entity(\n    entity_id=\"key-abc\",\n    parent_id=\"project-1\",\n    name=\"Production API Key\",\n)\n</code></pre>"},{"location":"guide/basic-usage/#get-entity-information","title":"Get Entity Information","text":"<pre><code>entity = await limiter.get_entity(\"user-123\")\nprint(f\"Name: {entity.name}\")\nprint(f\"Parent: {entity.parent_id}\")\n</code></pre>"},{"location":"guide/basic-usage/#error-handling","title":"Error Handling","text":""},{"location":"guide/basic-usage/#ratelimitexceeded-details","title":"RateLimitExceeded Details","text":"<pre><code>try:\n    async with limiter.acquire(...):\n        ...\nexcept RateLimitExceeded as e:\n    # All limit statuses\n    for status in e.statuses:\n        print(f\"{status.limit_name}: {status.available}/{status.limit.capacity}\")\n\n    # Only violations\n    for v in e.violations:\n        print(f\"Exceeded: {v.limit_name}\")\n\n    # Primary bottleneck\n    print(f\"Bottleneck: {e.primary_violation.limit_name}\")\n\n    # For API responses\n    return e.as_dict()\n</code></pre>"},{"location":"guide/basic-usage/#service-unavailable","title":"Service Unavailable","text":"<pre><code>from zae_limiter import RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(...):\n        ...\nexcept RateLimiterUnavailable as e:\n    # DynamoDB is unavailable\n    # Behavior depends on on_unavailable setting\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Hierarchical Limits - Parent/child rate limiting</li> <li>LLM Integration - Token estimation patterns</li> <li>Unavailability Handling - Handling service outages</li> </ul>"},{"location":"guide/hierarchical/","title":"Hierarchical Limits","text":"<p>API Changes Planned</p> <p>The cascade API is being redesigned. The <code>cascade</code> parameter will move from <code>acquire()</code> to <code>create_entity()</code>, making cascade behavior a property of the entity rather than each call site. This prevents accidental bypass when multiple libraries share a limiter. See issue #116 for details.</p> <p>zae-limiter supports two-level hierarchies for rate limiting, enabling patterns like:</p> <ul> <li>Project \u2192 API Keys: Limit total project usage while also limiting individual keys</li> <li>Organization \u2192 Users: Organization-wide limits with per-user quotas</li> <li>Tenant \u2192 Services: Multi-tenant limits with service-level controls</li> </ul>"},{"location":"guide/hierarchical/#creating-a-hierarchy","title":"Creating a Hierarchy","text":"<pre><code># Create parent entity (project)\nawait limiter.create_entity(\n    entity_id=\"project-1\",\n    name=\"Production Project\",\n)\n\n# Create child entities (API keys)\nawait limiter.create_entity(\n    entity_id=\"key-abc\",\n    parent_id=\"project-1\",\n    name=\"Web Application Key\",\n)\n\nawait limiter.create_entity(\n    entity_id=\"key-xyz\",\n    parent_id=\"project-1\",\n    name=\"Mobile App Key\",\n)\n</code></pre>"},{"location":"guide/hierarchical/#cascade-mode","title":"Cascade Mode","text":"<p>Use <code>cascade=True</code> to apply rate limits to both the child and parent:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"tpm\", 10_000),  # Per-key limit\n    ],\n    consume={\"tpm\": 500},\n    cascade=True,  # Also applies to parent (project-1)\n) as lease:\n    await call_api()\n</code></pre> <p>Performance Impact</p> <p>Cascade mode adds overhead: +1 GetEntity + parent bucket operations. Only enable when hierarchical enforcement is needed. See Batch Operation Patterns for optimization strategies.</p> <p>What happens:</p> <ol> <li>Check if <code>key-abc</code> has capacity (10k tpm)</li> <li>Check if <code>project-1</code> has capacity (uses same limits)</li> <li>If both pass, consume from both atomically</li> <li>If either fails, reject with details about which limit was exceeded</li> </ol>"},{"location":"guide/hierarchical/#different-limits-per-level","title":"Different Limits Per Level","text":"<p>Set different limits for parents and children:</p> <pre><code># Set project-level limits (higher)\nawait limiter.set_limits(\n    entity_id=\"project-1\",\n    limits=[\n        Limit.per_minute(\"tpm\", 100_000),  # 100k for entire project\n    ],\n)\n\n# Set key-level limits (lower)\nawait limiter.set_limits(\n    entity_id=\"key-abc\",\n    limits=[\n        Limit.per_minute(\"tpm\", 10_000),   # 10k per key\n    ],\n)\n\n# Use stored limits with cascade\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 5_000)],  # Default\n    consume={\"tpm\": 500},\n    cascade=True,\n    use_stored_limits=True,  # Uses stored limits for both levels\n) as lease:\n    await call_api()\n</code></pre>"},{"location":"guide/hierarchical/#understanding-cascade-behavior","title":"Understanding Cascade Behavior","text":""},{"location":"guide/hierarchical/#without-cascade","title":"Without Cascade","text":"<pre><code># Only checks/consumes from key-abc\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},\n    cascade=False,  # Default\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#with-cascade","title":"With Cascade","text":"<pre><code># Checks/consumes from BOTH key-abc AND project-1\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},\n    cascade=True,\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#error-handling-with-hierarchies","title":"Error Handling with Hierarchies","text":"<p>When using cascade mode, <code>RateLimitExceeded</code> includes statuses for all entities:</p> <pre><code>try:\n    async with limiter.acquire(\n        entity_id=\"key-abc\",\n        cascade=True,\n        ...\n    ):\n        ...\nexcept RateLimitExceeded as e:\n    for status in e.statuses:\n        print(f\"Entity: {status.entity_id}\")\n        print(f\"  Limit: {status.limit_name}\")\n        print(f\"  Available: {status.available}\")\n        print(f\"  Exceeded: {status.exceeded}\")\n</code></pre>"},{"location":"guide/hierarchical/#use-cases","title":"Use Cases","text":""},{"location":"guide/hierarchical/#multi-tenant-saas","title":"Multi-Tenant SaaS","text":"<pre><code># Tenant has 1M tokens/day\nawait limiter.set_limits(\n    entity_id=\"tenant-acme\",\n    limits=[Limit.per_day(\"tpd\", 1_000_000)],\n)\n\n# Each user gets 100k tokens/day\nawait limiter.set_limits(\n    entity_id=\"user-123\",\n    limits=[Limit.per_day(\"tpd\", 100_000)],\n)\n\n# Rate limit user, cascade to tenant\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    cascade=True,\n    use_stored_limits=True,\n    ...\n):\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#api-key-management","title":"API Key Management","text":"<pre><code># Project limit: 10k RPM\nawait limiter.set_limits(\n    entity_id=\"project-prod\",\n    limits=[Limit.per_minute(\"rpm\", 10_000)],\n)\n\n# Production key: 5k RPM (half of project)\nawait limiter.set_limits(\n    entity_id=\"key-prod\",\n    limits=[Limit.per_minute(\"rpm\", 5_000)],\n)\n\n# Staging key: 1k RPM\nawait limiter.set_limits(\n    entity_id=\"key-staging\",\n    limits=[Limit.per_minute(\"rpm\", 1_000)],\n)\n</code></pre>"},{"location":"guide/hierarchical/#limitations","title":"Limitations","text":"<ul> <li>Two levels only: Parent \u2192 Child (no grandparents)</li> <li>Single parent: Each entity can have at most one parent</li> <li>Cascade is optional: Must be explicitly enabled per call</li> </ul>"},{"location":"guide/hierarchical/#next-steps","title":"Next Steps","text":"<ul> <li>LLM Integration - Token estimation patterns</li> <li>Unavailability Handling - Handling service outages</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/llm-integration/","title":"LLM Integration","text":"<p>LLM APIs are a natural fit for zae-limiter's estimate-then-reconcile pattern, especially when token counts are unknown until after the call completes. This guide covers patterns for integrating with LLM providers.</p> <p>Understanding the Algorithm</p> <p>This guide assumes familiarity with how rate limiting works. If you're new to token buckets, start with Token Bucket Algorithm to understand concepts like negative buckets (debt) that enable the estimate-then-reconcile pattern.</p>"},{"location":"guide/llm-integration/#the-challenge","title":"The Challenge","text":"<p>LLM APIs present unique rate limiting challenges:</p> <ol> <li>Token counts are unknown upfront - You don't know how many tokens a response will use</li> <li>Multiple limits - Providers often limit both requests and tokens</li> <li>Variable costs - Different models have different token limits</li> <li>Streaming responses - Token count only known after stream completes</li> </ol>"},{"location":"guide/llm-integration/#basic-pattern-estimate-and-reconcile","title":"Basic Pattern: Estimate and Reconcile","text":"<pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),       # Requests per minute\n        Limit.per_minute(\"tpm\", 10_000),    # Tokens per minute\n    ],\n    consume={\"rpm\": 1, \"tpm\": 500},  # Estimate 500 tokens\n) as lease:\n    response = await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    )\n\n    # Reconcile with actual usage\n    actual_tokens = response.usage.total_tokens\n    await lease.adjust(tpm=actual_tokens - 500)\n</code></pre>"},{"location":"guide/llm-integration/#estimation-strategies","title":"Estimation Strategies","text":""},{"location":"guide/llm-integration/#fixed-estimate","title":"Fixed Estimate","text":"<p>Simple but may over/under-estimate:</p> <pre><code>consume={\"tpm\": 500}  # Always estimate 500 tokens\n</code></pre>"},{"location":"guide/llm-integration/#input-based-estimate","title":"Input-Based Estimate","text":"<p>Estimate based on input length:</p> <pre><code>import tiktoken\n\ndef estimate_tokens(messages: list, model: str = \"gpt-4\") -&gt; int:\n    \"\"\"Estimate tokens for input messages.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    total = 0\n    for msg in messages:\n        total += len(encoding.encode(msg[\"content\"]))\n        total += 4  # Message overhead\n    total += 2  # Completion priming\n    return total\n\n# Use in rate limiting\ninput_tokens = estimate_tokens(messages)\nestimated_output = 500  # Rough estimate for output\ntotal_estimate = input_tokens + estimated_output\n\nasync with limiter.acquire(\n    ...\n    consume={\"tpm\": total_estimate},\n) as lease:\n    response = await call_llm()\n    actual = response.usage.total_tokens\n    await lease.adjust(tpm=actual - total_estimate)\n</code></pre>"},{"location":"guide/llm-integration/#max-tokens-estimate","title":"Max Tokens Estimate","text":"<p>Use max_tokens as upper bound:</p> <pre><code>max_tokens = 1000\n\nasync with limiter.acquire(\n    ...\n    consume={\"tpm\": input_tokens + max_tokens},\n) as lease:\n    response = await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        max_tokens=max_tokens,\n    )\n    actual = response.usage.total_tokens\n    await lease.adjust(tpm=actual - (input_tokens + max_tokens))\n</code></pre>"},{"location":"guide/llm-integration/#handling-streaming-responses","title":"Handling Streaming Responses","text":"<p>For streaming responses, token count is only available after the stream completes:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),\n        Limit.per_minute(\"tpm\", 10_000),\n    ],\n    consume={\"rpm\": 1, \"tpm\": estimated_tokens},\n) as lease:\n    chunks = []\n    async for chunk in await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        stream=True,\n    ):\n        chunks.append(chunk)\n        yield chunk  # Stream to client\n\n    # Get final usage from last chunk (OpenAI includes it)\n    if chunks[-1].usage:\n        actual = chunks[-1].usage.total_tokens\n        await lease.adjust(tpm=actual - estimated_tokens)\n</code></pre>"},{"location":"guide/llm-integration/#per-model-rate-limits","title":"Per-Model Rate Limits","text":"<p>Different models have different limits. Use the <code>resource</code> parameter:</p> <pre><code>MODEL_LIMITS = {\n    \"gpt-4\": [\n        Limit.per_minute(\"rpm\", 100),\n        Limit.per_minute(\"tpm\", 10_000),\n    ],\n    \"gpt-4-turbo\": [\n        Limit.per_minute(\"rpm\", 500),\n        Limit.per_minute(\"tpm\", 150_000),\n    ],\n    \"gpt-3.5-turbo\": [\n        Limit.per_minute(\"rpm\", 3500),\n        Limit.per_minute(\"tpm\", 90_000),\n    ],\n}\n\nasync def rate_limited_completion(\n    entity_id: str,\n    model: str,\n    messages: list,\n    estimated_tokens: int,\n):\n    limits = MODEL_LIMITS.get(model, MODEL_LIMITS[\"gpt-3.5-turbo\"])\n\n    async with limiter.acquire(\n        entity_id=entity_id,\n        resource=model,  # Different bucket per model\n        limits=limits,\n        consume={\"rpm\": 1, \"tpm\": estimated_tokens},\n    ) as lease:\n        response = await openai.chat.completions.create(\n            model=model,\n            messages=messages,\n        )\n        actual = response.usage.total_tokens\n        await lease.adjust(tpm=actual - estimated_tokens)\n        return response\n</code></pre>"},{"location":"guide/llm-integration/#negative-buckets-debt","title":"Negative Buckets (Debt)","text":"<p>zae-limiter allows buckets to go negative, which is useful when actual usage exceeds estimates:</p> <pre><code># Estimate: 500 tokens\nasync with limiter.acquire(\n    consume={\"tpm\": 500},\n    ...\n) as lease:\n    response = await call_llm()\n\n    # Actual: 2000 tokens\n    # Adjustment: 2000 - 500 = 1500\n    await lease.adjust(tpm=1500)\n    # Bucket now at -1500 tokens (in debt)\n</code></pre> <p>The debt is repaid as tokens refill over time. This ensures accurate accounting while allowing requests to complete.</p>"},{"location":"guide/llm-integration/#pre-flight-capacity-check","title":"Pre-Flight Capacity Check","text":"<p>Check capacity before making expensive calls:</p> <pre><code>async def call_with_capacity_check(\n    entity_id: str,\n    model: str,\n    messages: list,\n    estimated_tokens: int,\n):\n    limits = MODEL_LIMITS[model]\n\n    # Check available capacity\n    available = await limiter.available(\n        entity_id=entity_id,\n        resource=model,\n        limits=limits,\n    )\n\n    if available[\"tpm\"] &lt; estimated_tokens:\n        # Not enough capacity - check when it will be available\n        wait_time = await limiter.time_until_available(\n            entity_id=entity_id,\n            resource=model,\n            limits=limits,\n            needed={\"tpm\": estimated_tokens},\n        )\n        raise RetryAfter(seconds=wait_time)\n\n    # Proceed with rate-limited call\n    async with limiter.acquire(...):\n        ...\n</code></pre>"},{"location":"guide/llm-integration/#integration-with-retry-libraries","title":"Integration with Retry Libraries","text":"<p>Combine with retry libraries like <code>tenacity</code>:</p> <pre><code>from tenacity import retry, retry_if_exception_type, wait_fixed\n\n@retry(\n    retry=retry_if_exception_type(RateLimitExceeded),\n    wait=wait_fixed(1),\n)\nasync def resilient_llm_call(entity_id: str, messages: list):\n    async with limiter.acquire(\n        entity_id=entity_id,\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        return await openai.chat.completions.create(\n            model=\"gpt-4\",\n            messages=messages,\n        )\n</code></pre> <p>Or use the retry information from the exception:</p> <pre><code>async def smart_retry_llm_call(entity_id: str, messages: list):\n    while True:\n        try:\n            async with limiter.acquire(...):\n                return await call_llm()\n        except RateLimitExceeded as e:\n            await asyncio.sleep(e.retry_after_seconds)\n</code></pre>"},{"location":"guide/llm-integration/#next-steps","title":"Next Steps","text":"<ul> <li>Unavailability Handling - Handling service outages</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/token-bucket/","title":"Token Bucket Algorithm","text":"<p>Understanding how rate limiting works helps you choose the right limits for your application. This page explains the token bucket algorithm and how zae-limiter implements it.</p>"},{"location":"guide/token-bucket/#the-classic-algorithm","title":"The Classic Algorithm","text":"<p>The token bucket algorithm controls request rates using a simple metaphor: imagine a bucket that holds tokens.</p> <ul> <li>Tokens accumulate over time at a fixed rate (the refill rate)</li> <li>Requests consume tokens from the bucket</li> <li>Requests are allowed if enough tokens are available</li> <li>Requests are rejected if the bucket is empty</li> </ul> flowchart LR     subgraph bucket[\"Token Bucket\"]         T[Tokens]     end     Time --&gt;|refill| T     T --&gt;|consume| Request     Request --&gt; Check{Enough tokens?}     Check --&gt;|Yes| Allow[Allow request]     Check --&gt;|No| Reject[Reject + retry_after] <p>This creates a natural rate limit: requests can burst up to the bucket's capacity, but sustained traffic is limited by the refill rate.</p>"},{"location":"guide/token-bucket/#how-zae-limiter-implements-it","title":"How zae-limiter Implements It","text":"<p>zae-limiter uses a modified token bucket optimized for distributed systems. Here's how it differs from the classic algorithm:</p> Aspect Classic Algorithm zae-limiter Token storage Floating-point numbers Integers (millitokens x1000) Refill timing Continuous background process Lazy (calculated on-demand) Minimum tokens 0 (never negative) Can go negative (debt) Precision May drift due to float errors Drift-compensated integers <p>These modifications enable:</p> <ul> <li>Distributed precision: Integer math produces identical results across all nodes</li> <li>Efficiency: No background timers or processes needed</li> <li>Estimate-then-reconcile: Negative buckets allow post-hoc cost adjustment</li> </ul>"},{"location":"guide/token-bucket/#key-concepts","title":"Key Concepts","text":""},{"location":"guide/token-bucket/#capacity-and-burst","title":"Capacity and Burst","text":"<p>Every limit has two key parameters:</p> <ul> <li>Capacity: The sustained rate (tokens that refill per period)</li> <li>Burst: The maximum bucket size (can be larger than capacity)</li> </ul> <pre><code># 10,000 tokens/minute sustained, 15,000 burst\nLimit.per_minute(\"tpm\", capacity=10_000, burst=15_000)\n</code></pre> graph TD     A[\"Bucket starts full at burst (15k)\"]     A --&gt;|\"consume 15k\"| B[\"Bucket empty (0)\"]     B --&gt;|\"wait 1 minute\"| C[\"Refills 10k tokens\"]     C --&gt;|\"wait 30 more seconds\"| D[\"Refills to burst (15k)\"]     D --&gt;|\"steady state\"| E[\"10k tokens/minute\"]      style A fill:#90EE90     style B fill:#FFB6C1     style C fill:#87CEEB     style D fill:#90EE90     style E fill:#87CEEB <p>Key insight: The bucket is larger (15k) but refills at the same rate (10k/minute). After fully depleting the burst, it takes 1.5 minutes to return to full capacity\u2014not 1 minute.</p> <p>When to use burst &gt; capacity:</p> <ul> <li>Startup surge: Handle initial traffic before steady state</li> <li>Bursty workloads: Allow temporary spikes followed by quiet periods</li> <li>User experience: Don't reject the first request just because a minute hasn't passed</li> </ul>"},{"location":"guide/token-bucket/#lazy-refill","title":"Lazy Refill","text":"<p>Unlike traditional implementations that continuously add tokens, zae-limiter calculates refills on-demand:</p> <pre><code>When a request arrives:\n1. Calculate elapsed time since last refill\n2. Add tokens based on elapsed time\n3. Check if enough tokens are available\n4. Consume tokens if allowed\n</code></pre> <p>Why this matters:</p> <ul> <li>Accurate <code>retry_after</code>: Time calculations are exact, not approximations</li> <li>No drift: Integer math with drift compensation prevents accumulated errors</li> <li>Efficient: No background processes consuming resources</li> </ul> <p>The refill formula:</p> <pre><code>tokens_to_add = elapsed_time \u00d7 refill_rate\n             = elapsed_ms \u00d7 refill_amount / refill_period\n</code></pre>"},{"location":"guide/token-bucket/#negative-buckets-debt","title":"Negative Buckets (Debt)","text":"<p>zae-limiter allows buckets to go negative, creating a \"debt\" that must be repaid before more tokens are available. This enables the estimate-then-reconcile pattern for operations with unknown cost.</p> sequenceDiagram     participant App     participant Bucket      Note over Bucket: tokens: 1,000      App-&gt;&gt;Bucket: consume(estimate=500)     Note over Bucket: tokens: 500      App-&gt;&gt;App: execute operation...     Note over App: actual cost: 2,000 units      App-&gt;&gt;Bucket: adjust(+1,500)     Note over Bucket: tokens: -1,000     Note over Bucket: Bucket is now in debt!      Note over Bucket: (time passes, tokens refill)     Note over Bucket: tokens: 0 \u2192 1,000 <p>Why allow negative tokens?</p> <p>Many operations have costs that are unknown until completion:</p> Domain Unknown cost Database queries Rows scanned, data returned File transfers Bytes transferred after compression Batch processing Items processed per batch API calls Metered usage calculated after <p>Negative buckets let you:</p> <ol> <li>Estimate cost upfront (consume)</li> <li>Execute the operation</li> <li>Reconcile based on actual cost (adjust)</li> </ol> <p>The debt is automatically repaid as tokens refill over time.</p> <pre><code>async with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    consume={\"rpm\": 5},  # Estimate 5 units\n) as lease:\n    result = await execute_operation()\n    actual = result.units_consumed  # 12\n    await lease.adjust(rpm=actual - 5)  # Add 7 to debt\n</code></pre> <p>See LLM Integration for a specific application of this pattern.</p>"},{"location":"guide/token-bucket/#practical-implications","title":"Practical Implications","text":""},{"location":"guide/token-bucket/#why-estimates-can-be-wrong","title":"Why estimates can be wrong","text":"<p>Because buckets can go negative, your initial estimate doesn't need to be perfect. Underestimate and adjust later:</p> <ul> <li>Estimate too low? Adjust adds to consumption</li> <li>Estimate too high? Adjust can return tokens (negative adjustment)</li> </ul>"},{"location":"guide/token-bucket/#why-retry_after-is-accurate","title":"Why <code>retry_after</code> is accurate","text":"<p>The lazy refill with drift compensation means <code>retry_after</code> tells you exactly when tokens will be available:</p> <pre><code>try:\n    await limiter.check(entity_id, resource, limits, consume={\"tpm\": 1000})\nexcept RateLimitExceeded as e:\n    # This is the exact time to wait\n    await asyncio.sleep(e.retry_after_seconds)\n    # Now the request will succeed\n</code></pre>"},{"location":"guide/token-bucket/#choosing-the-right-limits","title":"Choosing the right limits","text":"Scenario Capacity Burst Rationale Steady API traffic 100 rpm 100 No bursting needed Bursty batch jobs 100 rpm 500 Allow 5x burst, then sustain LLM tokens 10k tpm 15k Handle variable response sizes Database queries 1k rows/min 5k Allow large result sets occasionally New user onboarding 10 rpm 50 Let users explore, then limit"},{"location":"guide/token-bucket/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage - Common rate limiting patterns</li> <li>LLM Integration - Token estimation strategies</li> <li>Architecture - Implementation details for contributors</li> </ul>"},{"location":"guide/unavailability/","title":"Unavailability Handling","text":"<p>zae-limiter provides configurable behavior when DynamoDB is unavailable. This guide covers the <code>on_unavailable</code> modes and how to choose the right one for your application.</p> <p>Scope</p> <p>This page covers infrastructure unavailability (DynamoDB errors, timeouts, throttling).</p> <p>For handling rate limit violations, see Basic Usage.</p>"},{"location":"guide/unavailability/#available-modes","title":"Available Modes","text":"Mode Behavior Use Case <code>BLOCK</code> Reject requests Security-critical, billing <code>ALLOW</code> Allow requests User experience priority"},{"location":"guide/unavailability/#what-triggers-on_unavailable-logic","title":"What Triggers on_unavailable Logic","text":"<p>The <code>on_unavailable</code> mode only applies to infrastructure errors. These exceptions always propagate regardless of mode:</p> <ul> <li><code>RateLimitExceeded</code> \u2014 Rate limit violated (business logic)</li> <li><code>ValidationError</code> \u2014 Invalid configuration (user error)</li> </ul> <p>Infrastructure errors that trigger on_unavailable:</p> <ul> <li>Connection timeouts</li> <li>DynamoDB throttling</li> <li>Network failures</li> <li>Service unavailable errors</li> </ul>"},{"location":"guide/unavailability/#block-default","title":"BLOCK (Default)","text":"<p>When DynamoDB is unavailable, reject all rate-limited requests by raising <code>RateLimiterUnavailable</code>.</p> <p>Exception Handling Required</p> <p>When using <code>BLOCK</code> mode (the default), your application must catch <code>RateLimiterUnavailable</code> to handle infrastructure failures gracefully. This exception inherits from <code>InfrastructureError</code>, not <code>RateLimitExceeded</code>.</p> <pre><code>from zae_limiter import RateLimiter, OnUnavailable, RateLimiterUnavailable\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    on_unavailable=OnUnavailable.BLOCK,  # Default\n)\n\ntry:\n    async with limiter.acquire(...):\n        await do_work()\nexcept RateLimiterUnavailable as e:\n    # DynamoDB is unavailable - handle degraded mode\n    return JSONResponse(\n        status_code=503,\n        content={\"error\": \"Service temporarily unavailable\"},\n    )\n</code></pre> <p>When to use:</p> <ul> <li>Billing/metering systems where accuracy is critical</li> <li>Security-sensitive operations</li> <li>When over-consumption has significant costs</li> <li>Compliance requirements</li> </ul>"},{"location":"guide/unavailability/#allow","title":"ALLOW","text":"<p>When DynamoDB is unavailable, allow requests to proceed:</p> <pre><code>limiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    on_unavailable=OnUnavailable.ALLOW,\n)\n\n# Requests proceed even if DynamoDB is down\nasync with limiter.acquire(...):\n    await do_work()  # Runs without rate limiting\n</code></pre> <p>When to use:</p> <ul> <li>User experience is the priority</li> <li>Brief outages are acceptable</li> <li>Rate limiting is a soft limit</li> <li>Development/staging environments</li> </ul>"},{"location":"guide/unavailability/#no-op-lease-behavior","title":"No-Op Lease Behavior","text":"<p>When <code>ALLOW</code> activates due to infrastructure failure:</p> <ul> <li>A no-op lease is returned with no bucket entries</li> <li><code>lease.consume()</code>, <code>lease.adjust()</code>, and <code>lease.release()</code> silently do nothing</li> <li>Your code cannot detect degraded mode from the lease itself</li> </ul> <p>To detect and log degraded operations, wrap with custom error handling:</p> <pre><code>async def acquire_with_metrics(limiter, **kwargs):\n    \"\"\"Wrapper that tracks degraded operations.\"\"\"\n    try:\n        async with limiter.acquire(**kwargs) as lease:\n            yield lease\n    except Exception as e:\n        # BLOCK caught the error - we're in degraded mode\n        # This only runs if you use BLOCK and catch manually\n        metrics.increment(\"rate_limiter.degraded\")\n        logger.warning(f\"Rate limiter degraded: {e}\")\n        raise\n</code></pre>"},{"location":"guide/unavailability/#per-request-override","title":"Per-Request Override","text":"<p>Override the default mode for specific requests:</p> <pre><code># Default to BLOCK\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    on_unavailable=OnUnavailable.BLOCK,\n)\n\n# But allow this specific request to proceed\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[...],\n    consume={\"requests\": 1},\n    on_unavailable=OnUnavailable.ALLOW,  # Override for this call\n) as lease:\n    await do_work()\n</code></pre>"},{"location":"guide/unavailability/#handling-unavailable-errors","title":"Handling Unavailable Errors","text":"<p>The <code>RateLimiterUnavailable</code> exception includes details about the failure:</p> <pre><code>from zae_limiter import RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(...):\n        await do_work()\nexcept RateLimiterUnavailable as e:\n    # Log the underlying error\n    logger.error(f\"Rate limiter unavailable: {e}\")\n\n    # Decide how to handle\n    if is_critical_operation:\n        raise HTTPException(status_code=503)\n    else:\n        # Proceed without rate limiting\n        await do_work()\n</code></pre>"},{"location":"guide/unavailability/#best-practices","title":"Best Practices","text":""},{"location":"guide/unavailability/#1-choose-based-on-risk","title":"1. Choose Based on Risk","text":"<pre><code># High-risk: billing, security\nbilling_limiter = RateLimiter(\n    name=\"billing\",  # Connects to ZAEL-billing\n    on_unavailable=OnUnavailable.BLOCK,\n)\n\n# Lower-risk: general API\napi_limiter = RateLimiter(\n    name=\"api\",  # Connects to ZAEL-api\n    on_unavailable=OnUnavailable.ALLOW,\n)\n</code></pre>"},{"location":"guide/unavailability/#2-graceful-degradation","title":"2. Graceful Degradation","text":"<p>Implement fallback behavior:</p> <pre><code>async def resilient_operation(entity_id: str):\n    try:\n        async with limiter.acquire(\n            entity_id=entity_id,\n            on_unavailable=OnUnavailable.BLOCK,\n            ...\n        ):\n            return await premium_operation()\n    except RateLimiterUnavailable:\n        # Fall back to degraded mode\n        logger.warning(\"Rate limiter unavailable, using fallback\")\n        return await basic_operation()\n</code></pre>"},{"location":"guide/unavailability/#3-health-checks","title":"3. Health Checks","text":"<p>Use <code>is_available()</code> to check rate limiter connectivity:</p> <pre><code>async def health_check():\n    checks = {}\n\n    # Check rate limiter connectivity\n    if await limiter.is_available():\n        checks[\"rate_limiter\"] = \"healthy\"\n    else:\n        checks[\"rate_limiter\"] = \"unhealthy\"\n\n    return checks\n</code></pre> <p>The <code>is_available()</code> method:</p> <ul> <li>Returns <code>True</code> if DynamoDB is reachable, <code>False</code> otherwise</li> <li>Never raises exceptions</li> <li>Uses a configurable timeout (default 1 second)</li> <li>Works without requiring initialization</li> </ul> <pre><code># FastAPI health endpoint example\n@app.get(\"/health\")\nasync def health():\n    return {\n        \"status\": \"healthy\" if await limiter.is_available() else \"degraded\",\n    }\n\n# Pre-flight check before operations\nif not await limiter.is_available():\n    logger.warning(\"Rate limiter unavailable, using fallback\")\n</code></pre>"},{"location":"guide/unavailability/#observability","title":"Observability","text":"<p>For monitoring rate limiter health and setting up alerts, see the Monitoring Guide.</p>"},{"location":"guide/unavailability/#next-steps","title":"Next Steps","text":"<ul> <li>Operations Guide - Troubleshooting and operational procedures</li> <li>Deployment - Infrastructure setup</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"infra/auditing/","title":"Audit Logging","text":"<p>zae-limiter provides built-in audit logging for security-sensitive operations, enabling compliance tracking, troubleshooting, and incident investigation.</p>"},{"location":"infra/auditing/#overview","title":"Overview","text":"<p>The audit system automatically logs:</p> Action Trigger Details Captured <code>entity_created</code> Creating an entity name, parent_id, metadata <code>entity_deleted</code> Deleting an entity number of records deleted <code>limits_set</code> Configuring limits all limit configurations <code>limits_deleted</code> Removing limits resource name <p>Each audit event includes:</p> <ul> <li>Unique event ID - ULID (time-sortable, collision-free)</li> <li>Timestamp - ISO 8601 UTC</li> <li>Entity ID - The affected entity</li> <li>Principal - Who performed the action (optional)</li> <li>Details - Action-specific context</li> </ul>"},{"location":"infra/auditing/#audit-event-structure","title":"Audit Event Structure","text":"<pre><code>from zae_limiter import AuditEvent, AuditAction\n\n# Example audit event\nevent = AuditEvent(\n    event_id=\"01HQXYZ123ABC456DEF789GHI\",\n    timestamp=\"2024-01-15T10:30:00.000000+00:00\",\n    action=AuditAction.LIMITS_SET,\n    entity_id=\"api-key-123\",\n    principal=\"admin@example.com\",\n    resource=\"gpt-4\",\n    details={\n        \"limits\": [\n            {\"name\": \"rpm\", \"capacity\": 100, \"burst\": 150}\n        ]\n    }\n)\n</code></pre>"},{"location":"infra/auditing/#auditaction-constants","title":"AuditAction Constants","text":"Constant Value Description <code>ENTITY_CREATED</code> <code>\"entity_created\"</code> New entity was created <code>ENTITY_DELETED</code> <code>\"entity_deleted\"</code> Entity was deleted <code>LIMITS_SET</code> <code>\"limits_set\"</code> Limits were configured <code>LIMITS_DELETED</code> <code>\"limits_deleted\"</code> Limits were removed"},{"location":"infra/auditing/#principal-tracking","title":"Principal Tracking","text":"<p>Track who performed each action by passing the <code>principal</code> parameter:</p> <p>Internal API</p> <p>The <code>Repository</code> class is not part of the public API and may change without notice. See Issue #114 for the planned public interface.</p> <pre><code>from zae_limiter.repository import Repository  # Internal API\n\nrepo = Repository(table_name=\"ZAEL-limiter\", region=\"us-east-1\")\n\n# Track who created the entity\nawait repo.create_entity(\n    entity_id=\"api-key-123\",\n    name=\"Production Key\",\n    principal=\"admin@example.com\",  # Tracks the caller\n)\n\n# Track who configured limits\nawait repo.set_limits(\n    entity_id=\"api-key-123\",\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    principal=\"ops-team@example.com\",\n)\n</code></pre> <p>Valid principal formats:</p> <ul> <li>Email: <code>user@example.com</code></li> <li>Service: <code>auth-service-v2</code></li> <li>Any identifier: alphanumeric start, then alphanumeric/underscore/hyphen/dot/colon/@</li> </ul>"},{"location":"infra/auditing/#querying-audit-events","title":"Querying Audit Events","text":"<p>Retrieve audit events for an entity:</p> <pre><code># Get recent audit events (most recent first)\nevents = await repo.get_audit_events(\n    entity_id=\"api-key-123\",\n    limit=100,\n)\n\nfor event in events:\n    print(f\"{event.timestamp}: {event.action} by {event.principal}\")\n</code></pre>"},{"location":"infra/auditing/#pagination","title":"Pagination","text":"<p>Use <code>start_event_id</code> for pagination through large result sets:</p> <pre><code># First page\nevents = await repo.get_audit_events(\n    entity_id=\"api-key-123\",\n    limit=50,\n)\n\n# Next page (use last event's ID)\nif events:\n    more_events = await repo.get_audit_events(\n        entity_id=\"api-key-123\",\n        limit=50,\n        start_event_id=events[-1].event_id,\n    )\n</code></pre>"},{"location":"infra/auditing/#retention-and-ttl","title":"Retention and TTL","text":"<p>Audit events auto-expire after 90 days by default. This is configurable via the <code>ttl_seconds</code> parameter when logging events.</p> <p>DynamoDB TTL handles deletion automatically:</p> <ul> <li>Events are marked with an expiration timestamp</li> <li>DynamoDB deletes expired items within 48 hours of TTL</li> <li>No manual cleanup required</li> </ul> <p>Long-term Retention</p> <p>For compliance requirements beyond 90 days, see Planned Capabilities for S3 archival.</p>"},{"location":"infra/auditing/#dynamodb-access-patterns","title":"DynamoDB Access Patterns","text":"<p>Audit events are stored in the same DynamoDB table with the following schema:</p> Key Format Description PK <code>AUDIT#{entity_id}</code> Groups events by entity SK <code>#AUDIT#{event_id}</code> Sorts by event ID (chronological)"},{"location":"infra/auditing/#direct-dynamodb-queries","title":"Direct DynamoDB Queries","text":"<p>For advanced use cases, query audit events directly:</p> <pre><code>import boto3\n\ndynamodb = boto3.resource(\"dynamodb\")\ntable = dynamodb.Table(\"ZAEL-limiter\")\n\n# Query all audit events for an entity\nresponse = table.query(\n    KeyConditionExpression=\"PK = :pk AND begins_with(SK, :sk)\",\n    ExpressionAttributeValues={\n        \":pk\": \"AUDIT#api-key-123\",\n        \":sk\": \"#AUDIT#\",\n    },\n    ScanIndexForward=False,  # Most recent first\n    Limit=100,\n)\n\nfor item in response[\"Items\"]:\n    data = item[\"data\"]\n    print(f\"{data['timestamp']}: {data['action']}\")\n</code></pre>"},{"location":"infra/auditing/#use-cases","title":"Use Cases","text":""},{"location":"infra/auditing/#compliance-auditing","title":"Compliance Auditing","text":"<p>Answer \"who changed what, when?\" for SOC2, HIPAA, or internal audits:</p> <pre><code># Find all changes to a specific entity\nevents = await repo.get_audit_events(\"sensitive-api-key\")\n\nfor event in events:\n    print(f\"\"\"\n    Time: {event.timestamp}\n    Action: {event.action}\n    By: {event.principal or 'unknown'}\n    Details: {event.details}\n    \"\"\")\n</code></pre>"},{"location":"infra/auditing/#troubleshooting","title":"Troubleshooting","text":"<p>Investigate when limits were changed:</p> <pre><code># Filter for limit changes\nevents = await repo.get_audit_events(\"api-key-123\")\nlimit_changes = [e for e in events if e.action in (\n    AuditAction.LIMITS_SET,\n    AuditAction.LIMITS_DELETED,\n)]\n\nfor event in limit_changes:\n    print(f\"{event.timestamp}: {event.action}\")\n    if event.details.get(\"limits\"):\n        for limit in event.details[\"limits\"]:\n            print(f\"  - {limit['name']}: {limit['capacity']}\")\n</code></pre>"},{"location":"infra/auditing/#security-incident-response","title":"Security Incident Response","text":"<p>Track entity deletions during an incident window:</p> <pre><code>from datetime import datetime\n\nevents = await repo.get_audit_events(\"compromised-key\")\ndeletions = [\n    e for e in events\n    if e.action == AuditAction.ENTITY_DELETED\n]\n\nfor event in deletions:\n    print(f\"Deleted at {event.timestamp} by {event.principal}\")\n</code></pre>"},{"location":"infra/auditing/#planned-capabilities","title":"Planned Capabilities","text":""},{"location":"infra/auditing/#s3-archival","title":"S3 Archival","text":"<p>Issue #77 - Archive expired audit events to S3 for long-term retention:</p> <ul> <li>Lambda automatically archives TTL-deleted records</li> <li>S3 storage with date partitioning (<code>/audit/year=YYYY/month=MM/</code>)</li> <li>Query with Athena for historical analysis</li> <li>Target: v1.1.0</li> </ul>"},{"location":"infra/auditing/#public-ratelimiter-api","title":"Public RateLimiter API","text":"<p>Issue #114 - Expose audit through the public interface:</p> <pre><code># Proposed API (not yet implemented)\nevents = await limiter.get_audit_events(\"api-key-123\")\n\nawait limiter.create_entity(\n    entity_id=\"api-key-123\",\n    name=\"Production Key\",\n    principal=\"admin@example.com\",  # Track caller\n)\n</code></pre>"},{"location":"infra/auditing/#next-steps","title":"Next Steps","text":"<ul> <li>Production Deployment - Security best practices</li> <li>Monitoring - Observability and alerting</li> <li>API Reference - AuditEvent and AuditAction details</li> </ul>"},{"location":"infra/cloudformation/","title":"CloudFormation Template","text":"<p>This guide covers the CloudFormation template used by zae-limiter and how to customize it.</p>"},{"location":"infra/cloudformation/#template-overview","title":"Template Overview","text":"<p>The template creates:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                CloudFormation Stack                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502  \u2502  DynamoDB   \u2502\u2500\u2500\u2500\u25b6\u2502   Stream    \u2502                 \u2502\n\u2502  \u2502   Table     \u2502    \u2502             \u2502                 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                            \u2502                         \u2502\n\u2502                            \u25bc                         \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502                    \u2502   Lambda    \u2502                  \u2502\n\u2502                    \u2502 Aggregator  \u2502                  \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2502                            \u2502                         \u2502\n\u2502                            \u25bc                         \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502                    \u2502 CloudWatch  \u2502                  \u2502\n\u2502                    \u2502    Logs     \u2502                  \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"infra/cloudformation/#export-template","title":"Export Template","text":"<pre><code># Export to file\nzae-limiter cfn-template &gt; template.yaml\n\n# View template\nzae-limiter cfn-template | less\n</code></pre>"},{"location":"infra/cloudformation/#template-parameters","title":"Template Parameters","text":"<p>The DynamoDB table name is automatically derived from the CloudFormation stack name using the <code>AWS::StackName</code> pseudo-parameter. This ensures consistency between stack and resource names.</p> Parameter Type Default Description <code>SnapshotWindows</code> String <code>hourly,daily</code> Comma-separated list of snapshot windows <code>SnapshotRetentionDays</code> Number <code>90</code> Days to retain usage snapshots (1-3650) <code>LambdaMemorySize</code> Number <code>256</code> Memory for aggregator Lambda (128-3008 MB) <code>LambdaTimeout</code> Number <code>60</code> Timeout for aggregator Lambda (1-900 seconds) <code>EnableAggregator</code> String <code>true</code> Whether to deploy the aggregator Lambda <code>SchemaVersion</code> String <code>1.0.0</code> Schema version for infrastructure <code>PITRRecoveryPeriodDays</code> String (empty) PITR period (1-35 days, empty for AWS default) <code>EnableAlarms</code> String <code>true</code> Whether to deploy CloudWatch alarms <code>AlarmSNSTopicArn</code> String (empty) SNS topic ARN for alarm notifications <code>LogRetentionDays</code> Number <code>30</code> CloudWatch log retention (standard periods)"},{"location":"infra/cloudformation/#dynamodb-table","title":"DynamoDB Table","text":""},{"location":"infra/cloudformation/#schema","title":"Schema","text":"<pre><code>AttributeDefinitions:\n  - AttributeName: PK\n    AttributeType: S\n  - AttributeName: SK\n    AttributeType: S\n  - AttributeName: GSI1PK\n    AttributeType: S\n  - AttributeName: GSI1SK\n    AttributeType: S\n  - AttributeName: GSI2PK\n    AttributeType: S\n  - AttributeName: GSI2SK\n    AttributeType: S\n\nKeySchema:\n  - AttributeName: PK\n    KeyType: HASH\n  - AttributeName: SK\n    KeyType: RANGE\n</code></pre>"},{"location":"infra/cloudformation/#global-secondary-indexes","title":"Global Secondary Indexes","text":"<p>GSI1 - Parent to children lookups:</p> <pre><code>GlobalSecondaryIndexes:\n  - IndexName: GSI1\n    KeySchema:\n      - AttributeName: GSI1PK  # PARENT#{parent_id}\n        KeyType: HASH\n      - AttributeName: GSI1SK  # CHILD#{child_id}\n        KeyType: RANGE\n</code></pre> <p>GSI2 - Resource aggregation:</p> <pre><code>  - IndexName: GSI2\n    KeySchema:\n      - AttributeName: GSI2PK  # RESOURCE#{resource}\n        KeyType: HASH\n      - AttributeName: GSI2SK  # BUCKET#{entity_id}#{limit_name}\n        KeyType: RANGE\n</code></pre>"},{"location":"infra/cloudformation/#stream-configuration","title":"Stream Configuration","text":"<pre><code>StreamSpecification:\n  StreamViewType: NEW_AND_OLD_IMAGES\n</code></pre>"},{"location":"infra/cloudformation/#lambda-aggregator","title":"Lambda Aggregator","text":"<p>The aggregator Lambda processes DynamoDB Stream events to maintain usage snapshots.</p> <p>Performance Tuning</p> <p>For guidance on memory tuning, concurrency management, and error handling configuration, see the Performance Tuning Guide.</p>"},{"location":"infra/cloudformation/#function-configuration","title":"Function Configuration","text":"<pre><code>AggregatorFunction:\n  Type: AWS::Lambda::Function\n  Properties:\n    Runtime: python3.12\n    Handler: zae_limiter.aggregator.handler.lambda_handler\n    MemorySize: 256\n    Timeout: 60\n    Environment:\n      Variables:\n        TABLE_NAME: !Ref AWS::StackName\n        SNAPSHOT_WINDOWS: !Ref SnapshotWindows\n        SNAPSHOT_TTL_DAYS: !Ref SnapshotRetentionDays\n</code></pre>"},{"location":"infra/cloudformation/#event-source-mapping","title":"Event Source Mapping","text":"<pre><code>StreamEventMapping:\n  Type: AWS::Lambda::EventSourceMapping\n  Properties:\n    EventSourceArn: !GetAtt Table.StreamArn\n    FunctionName: !Ref AggregatorFunction\n    StartingPosition: LATEST\n    BatchSize: 100\n    MaximumBatchingWindowInSeconds: 5\n</code></pre>"},{"location":"infra/cloudformation/#iam-permissions","title":"IAM Permissions","text":""},{"location":"infra/cloudformation/#lambda-execution-role","title":"Lambda Execution Role","text":"<pre><code>AggregatorRole:\n  Type: AWS::IAM::Role\n  Properties:\n    AssumeRolePolicyDocument:\n      Statement:\n        - Effect: Allow\n          Principal:\n            Service: lambda.amazonaws.com\n          Action: sts:AssumeRole\n    Policies:\n      - PolicyName: DynamoDBAccess\n        PolicyDocument:\n          Statement:\n            - Effect: Allow\n              Action:\n                - dynamodb:GetItem\n                - dynamodb:PutItem\n                - dynamodb:UpdateItem\n                - dynamodb:Query\n              Resource: !GetAtt Table.Arn\n            - Effect: Allow\n              Action:\n                - dynamodb:GetRecords\n                - dynamodb:GetShardIterator\n                - dynamodb:DescribeStream\n                - dynamodb:ListStreams\n              Resource: !Sub \"${Table.Arn}/stream/*\"\n</code></pre>"},{"location":"infra/cloudformation/#customization","title":"Customization","text":""},{"location":"infra/cloudformation/#add-dead-letter-queue","title":"Add Dead Letter Queue","text":"<pre><code>Parameters:\n  EnableDLQ:\n    Type: String\n    Default: \"false\"\n    AllowedValues: [\"true\", \"false\"]\n\nConditions:\n  CreateDLQ: !Equals [!Ref EnableDLQ, \"true\"]\n\nResources:\n  DeadLetterQueue:\n    Type: AWS::SQS::Queue\n    Condition: CreateDLQ\n    Properties:\n      QueueName: !Sub \"${AWS::StackName}-aggregator-dlq\"\n      MessageRetentionPeriod: 1209600  # 14 days\n\n  StreamEventMapping:\n    Properties:\n      DestinationConfig:\n        OnFailure:\n          Destination: !If\n            - CreateDLQ\n            - !GetAtt DeadLetterQueue.Arn\n            - !Ref AWS::NoValue\n</code></pre>"},{"location":"infra/cloudformation/#add-cloudwatch-alarms","title":"Add CloudWatch Alarms","text":"<pre><code>ReadThrottleAlarm:\n  Type: AWS::CloudWatch::Alarm\n  Properties:\n    AlarmName: !Sub \"${AWS::StackName}-read-throttle\"\n    AlarmDescription: Alert when DynamoDB read requests are throttled\n    MetricName: ReadThrottleEvents\n    Namespace: AWS/DynamoDB\n    Statistic: Sum\n    Period: 300  # 5 minutes\n    EvaluationPeriods: 2\n    Threshold: 1\n    ComparisonOperator: GreaterThanThreshold\n    Dimensions:\n      - Name: TableName\n        Value: !Ref RateLimitsTable\n    TreatMissingData: notBreaching\n    AlarmActions: !If\n      - HasSNSTopic\n      - [!Ref AlarmSNSTopicArn]\n      - !Ref AWS::NoValue\n</code></pre>"},{"location":"infra/cloudformation/#enable-encryption-with-cmk","title":"Enable Encryption with CMK","text":"<pre><code>Parameters:\n  KmsKeyArn:\n    Type: String\n    Default: \"\"\n\nConditions:\n  UseCustomKey: !Not [!Equals [!Ref KmsKeyArn, \"\"]]\n\nResources:\n  Table:\n    Properties:\n      SSESpecification:\n        SSEEnabled: true\n        SSEType: !If [UseCustomKey, \"KMS\", \"AWS_OWNED_KEY\"]\n        KMSMasterKeyId: !If [UseCustomKey, !Ref KmsKeyArn, !Ref AWS::NoValue]\n</code></pre>"},{"location":"infra/cloudformation/#deployment-examples","title":"Deployment Examples","text":""},{"location":"infra/cloudformation/#basic-deployment","title":"Basic Deployment","text":"<pre><code>aws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name zae-limiter \\\n    --capabilities CAPABILITY_NAMED_IAM\n</code></pre>"},{"location":"infra/cloudformation/#with-custom-parameters","title":"With Custom Parameters","text":"<pre><code>aws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name ZAEL-prod \\\n    --parameter-overrides \\\n        PITRRecoveryPeriodDays=35 \\\n        SnapshotRetentionDays=365 \\\n        LogRetentionDays=90 \\\n        EnableAlarms=true \\\n    --capabilities CAPABILITY_NAMED_IAM\n</code></pre> <p>Note: The DynamoDB table name is automatically set to match the stack name (e.g., <code>ZAEL-prod</code>).</p>"},{"location":"infra/cloudformation/#using-sam","title":"Using SAM","text":"<pre><code># samconfig.toml\n[default.deploy.parameters]\nstack_name = \"ZAEL-limiter\"\ncapabilities = \"CAPABILITY_NAMED_IAM\"\n</code></pre> <pre><code>sam deploy --guided\n</code></pre>"},{"location":"infra/cloudformation/#outputs","title":"Outputs","text":"<p>The template exports:</p> Output Description <code>TableArn</code> DynamoDB table ARN <code>StreamArn</code> DynamoDB stream ARN <code>FunctionArn</code> Lambda function ARN <p>Access outputs:</p> <pre><code>aws cloudformation describe-stacks \\\n    --stack-name zae-limiter \\\n    --query \"Stacks[0].Outputs\"\n</code></pre>"},{"location":"infra/cloudformation/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment - Deployment guide</li> <li>LocalStack - Local development</li> </ul>"},{"location":"infra/deployment/","title":"Deployment","text":"<p>This guide covers deploying zae-limiter infrastructure to AWS.</p>"},{"location":"infra/deployment/#overview","title":"Overview","text":"<p>zae-limiter uses CloudFormation to deploy:</p> <ul> <li>DynamoDB Table - Stores rate limit state, entities, and usage data</li> <li>DynamoDB Streams - Captures changes for usage aggregation</li> <li>Lambda Function - Aggregates usage into hourly/daily snapshots</li> <li>IAM Roles - Least-privilege access for Lambda</li> <li>CloudWatch Logs - Lambda function logs</li> </ul>"},{"location":"infra/deployment/#cli-deployment-recommended","title":"CLI Deployment (Recommended)","text":"<p>The simplest way to deploy:</p> <pre><code># Deploy with defaults\nzae-limiter deploy --name limiter --region us-east-1\n\n# Deploy with custom settings\nzae-limiter deploy \\\n    --name limiter \\\n    --region us-east-1 \\\n    --log-retention-days 90 \\\n    --pitr-recovery-days 7\n</code></pre>"},{"location":"infra/deployment/#cli-options","title":"CLI Options","text":"Option Description Default <code>--name</code> Resource identifier (creates ZAEL-{name} resources) <code>limiter</code> <code>--region</code> AWS region boto3 default <code>--endpoint-url</code> Custom endpoint (LocalStack) None <code>--enable-aggregator/--no-aggregator</code> Deploy Lambda aggregator <code>true</code> <code>--log-retention-days</code> CloudWatch log retention <code>30</code> <code>--pitr-recovery-days</code> Point-in-time recovery (1-35 days) None (disabled) <p>For the full list of options, see the CLI Reference.</p>"},{"location":"infra/deployment/#check-stack-status","title":"Check Stack Status","text":"CLIProgrammatic <pre><code>zae-limiter status --name limiter --region us-east-1\n</code></pre> <pre><code>from zae_limiter import RateLimiter\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\nstatus = await limiter.get_status()  # Returns Status dataclass\n\nif not status.available:\n    print(\"DynamoDB not reachable\")\nelif status.stack_status == \"CREATE_COMPLETE\":\n    print(\"Stack is ready\")\n    print(f\"Schema version: {status.schema_version}\")\n    print(f\"Table items: {status.table_item_count}\")\nelif status.stack_status and \"IN_PROGRESS\" in status.stack_status:\n    print(f\"Operation in progress: {status.stack_status}\")\n</code></pre>"},{"location":"infra/deployment/#delete-stack","title":"Delete Stack","text":"<pre><code>zae-limiter delete --name limiter --region us-east-1 --yes\n</code></pre>"},{"location":"infra/deployment/#stack-lifecycle-management","title":"Stack Lifecycle Management","text":""},{"location":"infra/deployment/#programmatic-cleanup","title":"Programmatic Cleanup","text":"<p>In addition to the CLI, you can manage stack lifecycle programmatically using the <code>delete_stack()</code> method:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\n# Create stack\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\n# Use the limiter...\nasync with limiter:\n    # Rate limiting operations here\n    pass\n\n# Delete stack when done\nawait limiter.delete_stack()\n</code></pre>"},{"location":"infra/deployment/#use-case-guidance","title":"Use-Case Guidance","text":""},{"location":"infra/deployment/#development-and-prototyping","title":"Development and Prototyping","text":"<p>For rapid iteration, declare infrastructure with cleanup:</p> <pre><code>async def dev_session():\n    limiter = RateLimiter(\n        name=\"dev\",  # ZAEL-dev resources\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    try:\n        async with limiter:\n            # Development work...\n            pass\n    finally:\n        # Clean up development stack\n        await limiter.delete_stack()\n</code></pre>"},{"location":"infra/deployment/#production","title":"Production","text":"<p>For production deployments, see the Production Guide covering:</p> <ul> <li>Production checklist (PITR, alarms, SNS)</li> <li>Security best practices</li> <li>Multi-region considerations</li> <li>Cost estimation</li> </ul>"},{"location":"infra/deployment/#cloudformation-template","title":"CloudFormation Template","text":"<p>Export and customize the template:</p> <pre><code># Export template\nzae-limiter cfn-template &gt; template.yaml\n\n# Deploy with AWS CLI\naws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name ZAEL-limiter \\\n    --parameter-overrides \\\n        SnapshotRetentionDays=90 \\\n        EnablePITR=true \\\n    --capabilities CAPABILITY_NAMED_IAM\n\n# Deploy Lambda code separately\nzae-limiter lambda-export --output lambda.zip\naws lambda update-function-code \\\n    --function-name zae-limiter-aggregator \\\n    --zip-file fileb://lambda.zip\n</code></pre>"},{"location":"infra/deployment/#template-parameters","title":"Template Parameters","text":"Parameter Description Default <code>SnapshotWindows</code> Aggregation windows <code>hourly,daily</code> <code>SnapshotRetentionDays</code> Usage data retention <code>90</code> <code>EnablePITR</code> Point-in-time recovery <code>false</code> <code>LogRetentionDays</code> CloudWatch log retention <code>14</code>"},{"location":"infra/deployment/#programmatic-creation","title":"Programmatic Creation","text":"<p>Create infrastructure directly from your application:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        snapshot_windows=\"hourly,daily\",\n        retention_days=90,\n    ),\n)\n</code></pre> <p><code>StackOptions</code> declares the desired infrastructure state. CloudFormation ensures the actual infrastructure matches your declaration\u2014creating, updating, or leaving unchanged as needed.</p> <p>Deployment Options</p> <p>For organizations requiring strict infrastructure/application separation, use CLI deployment or CloudFormation template export. See the Production Guide for deployment recommendations.</p>"},{"location":"infra/deployment/#infrastructure-details","title":"Infrastructure Details","text":""},{"location":"infra/deployment/#dynamodb-table","title":"DynamoDB Table","text":"<ul> <li>Billing: Pay-per-request (on-demand)</li> <li>Encryption: AWS-managed keys (default)</li> <li>Streams: NEW_AND_OLD_IMAGES for Lambda trigger</li> </ul>"},{"location":"infra/deployment/#dynamodb-schema","title":"DynamoDB Schema","text":"Key Pattern Purpose PK <code>ENTITY#{id}</code> Partition key SK <code>#META</code>, <code>#BUCKET#...</code>, <code>#LIMIT#...</code> Sort key GSI1PK <code>PARENT#{id}</code> Parent lookups GSI2PK <code>RESOURCE#{name}</code> Resource aggregation"},{"location":"infra/deployment/#lambda-function","title":"Lambda Function","text":"<ul> <li>Runtime: Python 3.12</li> <li>Memory: 256 MB</li> <li>Timeout: 60 seconds</li> <li>Trigger: DynamoDB Streams</li> </ul>"},{"location":"infra/deployment/#iam-permissions","title":"IAM Permissions","text":"<p>The Lambda function has minimal permissions:</p> <pre><code>- dynamodb:GetItem\n- dynamodb:PutItem\n- dynamodb:UpdateItem\n- dynamodb:Query\n</code></pre>"},{"location":"infra/deployment/#next-steps","title":"Next Steps","text":"<ul> <li>Production - Production checklist, security, cost estimation</li> <li>CloudFormation - Template details</li> <li>Monitoring - Dashboards, alerts, Logs Insights</li> <li>LocalStack - Local development setup</li> </ul>"},{"location":"infra/production/","title":"Production Deployment","text":"<p>This guide covers production-readiness for zae-limiter deployments.</p>"},{"location":"infra/production/#production-checklist","title":"Production Checklist","text":"<p>Before deploying to production:</p> Feature CLI Flag Default Recommendation Point-in-Time Recovery <code>--pitr-recovery-days N</code> Disabled Enable (7-35 days) CloudWatch Alarms <code>--enable-alarms</code> Enabled Keep enabled SNS Notifications <code>--alarm-sns-topic ARN</code> None Configure for alerts Log Retention <code>--log-retention-days N</code> 30 90+ for compliance Permission Boundary <code>--permission-boundary ARN</code> None Use in restricted IAM environments"},{"location":"infra/production/#example-production-deployment","title":"Example Production Deployment","text":"<pre><code>zae-limiter deploy \\\n    --name prod-limiter \\\n    --region us-east-1 \\\n    --pitr-recovery-days 7 \\\n    --log-retention-days 90 \\\n    --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts\n</code></pre>"},{"location":"infra/production/#security-best-practices","title":"Security Best Practices","text":""},{"location":"infra/production/#encryption","title":"Encryption","text":"<ul> <li>DynamoDB uses AWS-managed keys (SSE-S3) by default</li> <li>For customer-managed keys (CMK), use CloudFormation template customization</li> </ul>"},{"location":"infra/production/#iam","title":"IAM","text":"<ul> <li>Lambda aggregator uses least-privilege permissions:<ul> <li><code>dynamodb:GetItem</code>, <code>PutItem</code>, <code>UpdateItem</code>, <code>Query</code></li> </ul> </li> <li>Use <code>--permission-boundary</code> for restricted IAM environments</li> <li>Use <code>--role-name-format</code> for organizational naming policies</li> </ul>"},{"location":"infra/production/#network","title":"Network","text":"<ul> <li>No VPC required; uses AWS service endpoints</li> <li>For VPC deployment, configure VPC endpoints for DynamoDB and Lambda</li> </ul>"},{"location":"infra/production/#secrets-management","title":"Secrets Management","text":"<ul> <li>No secrets stored in DynamoDB</li> <li>Use AWS Secrets Manager or Parameter Store for API keys</li> <li>Rate limit entity IDs should not contain sensitive data</li> </ul>"},{"location":"infra/production/#audit-logging","title":"Audit Logging","text":"<ul> <li>All entity and limit changes are automatically logged</li> <li>Track who made changes with optional <code>principal</code> parameter</li> <li>Events auto-expire after 90 days (configurable)</li> <li>For compliance requirements, see Audit Logging Guide</li> </ul>"},{"location":"infra/production/#multi-region-considerations","title":"Multi-Region Considerations","text":"<p>zae-limiter is designed for single-region deployment:</p> Scenario Approach Single region Standard deployment Multi-region (independent) Deploy separate stacks per region Global rate limiting Application-level coordination required"},{"location":"infra/production/#why-not-global-tables","title":"Why Not Global Tables?","text":"<ul> <li>Rate limit state is time-sensitive (token buckets refill continuously)</li> <li>Cross-region replication lag would cause inconsistent limits</li> <li>Each region should enforce its own limits</li> </ul>"},{"location":"infra/production/#cross-region-pattern","title":"Cross-Region Pattern","text":"<pre><code># Deploy separate stacks per region\nus_limiter = RateLimiter(name=\"prod\", region=\"us-east-1\")\neu_limiter = RateLimiter(name=\"prod\", region=\"eu-west-1\")\n\n# Application coordinates between regions if needed\n</code></pre>"},{"location":"infra/production/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":"<p>The stack deploys CloudWatch alarms by default:</p> Alarm Trigger Action Lambda Errors &gt; 1 per 5 min Check logs, verify DynamoDB access Lambda Duration &gt; 80% timeout Increase memory or timeout Iterator Age &gt; 30 seconds Check Lambda concurrency DLQ Messages &gt;= 1 Investigate failed records DynamoDB Throttles &gt; 1 per 5 min Review capacity planning <p>For dashboard templates and Logs Insights queries, see Monitoring Guide.</p>"},{"location":"infra/production/#cost-estimation","title":"Cost Estimation","text":"<p>Costs scale with request volume (us-east-1 pricing):</p> Volume DynamoDB Lambda CloudWatch Total 10K req/day ~$0.50 ~$0.20 ~$0.10 ~$1/month 100K req/day ~$5 ~$2 ~$1 ~$8/month 1M req/day ~$45 ~$12 ~$5 ~$62/month <p>For detailed capacity planning and optimization, see Performance Guide.</p>"},{"location":"infra/production/#next-steps","title":"Next Steps","text":"<ul> <li>Monitoring Guide - Dashboards, alerts, Logs Insights</li> <li>Audit Logging - Compliance tracking and incident investigation</li> <li>Performance Guide - Capacity planning, optimization</li> <li>Operations Guide - Troubleshooting, recovery</li> </ul>"},{"location":"operations/","title":"Operations Guide","text":"<p>This guide consolidates troubleshooting and operational procedures for zae-limiter deployments. Navigate using the interactive map below or jump directly to a topic.</p>"},{"location":"operations/#navigation","title":"Navigation","text":"flowchart LR     OPS[Operations Guide]      subgraph alerts[Alerts &amp; Issues]         LAMBDA[Lambda Aggregator]         DYNAMO[DynamoDB]         STREAMS[Stream Processing]         VERSION[Version Errors]         LIMITS[Rate Limits]     end      subgraph planned[Planned Operations]         UPGRADE[Version Upgrade]         LAMBDA_UPDATE[Lambda Update]         SCALE_LIMITS[Adjust Limits]         SCALE_DYNAMO[Scale DynamoDB]         BACKUP[Backup &amp; Restore]         ROLLBACK[Emergency Rollback]     end      OPS --&gt; alerts     OPS --&gt; planned      click LAMBDA \"lambda/\" \"Lambda troubleshooting\"     click DYNAMO \"dynamodb/\" \"DynamoDB operations\"     click STREAMS \"streams/\" \"Stream processing\"     click VERSION \"version/\" \"Version management\"     click LIMITS \"rate-limits/\" \"Rate limit issues\"     click UPGRADE \"version/#upgrade-procedure\" \"Upgrade procedure\"     click LAMBDA_UPDATE \"lambda/#lambda-redeployment\" \"Redeploy Lambda\"     click SCALE_LIMITS \"rate-limits/#adjust-limits-at-runtime\" \"Adjust limits\"     click SCALE_DYNAMO \"dynamodb/#scaling-procedures\" \"Scale capacity\"     click BACKUP \"recovery/#dynamodb-backup-and-restore\" \"Backup &amp; restore\"     click ROLLBACK \"recovery/#emergency-rollback-decision-matrix\" \"Emergency rollback\""},{"location":"operations/#alerts-issues","title":"Alerts &amp; Issues","text":"Component Common Issues Lambda Error rate, Duration/timeout, DLQ messages DynamoDB Throttling, Capacity Streams Iterator age, Processing lag Version VersionMismatchError, IncompatibleSchemaError Rate Limits Unexpected RateLimitExceeded, Limits not enforcing"},{"location":"operations/#planned-operations","title":"Planned Operations","text":"Operation Guides Upgrades Version upgrade, Lambda update Scaling Adjust rate limits, DynamoDB capacity Recovery Emergency rollback, Backup/restore, PITR"},{"location":"operations/#quick-reference","title":"Quick Reference","text":"Symptom Go To <code>RateLimitExceeded</code> unexpected Rate Limits <code>ProvisionedThroughputExceededException</code> DynamoDB DLQ messages accumulating Lambda <code>VersionMismatchError</code> Version High <code>IteratorAge</code> Streams Need to rollback Recovery"},{"location":"operations/#cli-diagnostic-commands","title":"CLI Diagnostic Commands","text":"Command Description <code>zae-limiter status --name &lt;name&gt;</code> Check stack status and resources <code>zae-limiter version --name &lt;name&gt;</code> Show version information <code>zae-limiter check --name &lt;name&gt;</code> Check client/infrastructure compatibility"},{"location":"operations/#cloudwatch-metrics-overview","title":"CloudWatch Metrics Overview","text":"Metric Namespace Threshold Guide <code>Errors</code> AWS/Lambda &gt; 1/5min Lambda <code>Duration</code> AWS/Lambda &gt; 80% timeout Lambda <code>IteratorAge</code> AWS/Lambda &gt; 30,000ms Streams <code>ReadThrottleEvents</code> AWS/DynamoDB &gt; 0 DynamoDB <code>WriteThrottleEvents</code> AWS/DynamoDB &gt; 0 DynamoDB <code>ApproximateNumberOfMessagesVisible</code> AWS/SQS &gt; 0 Lambda"},{"location":"operations/#exception-reference","title":"Exception Reference","text":"Exception Cause Guide <code>RateLimitExceeded</code> Rate limit violated Rate Limits <code>RateLimiterUnavailable</code> DynamoDB unavailable DynamoDB <code>EntityNotFoundError</code> Entity doesn't exist Rate Limits <code>VersionMismatchError</code> Client/Lambda version mismatch Version <code>IncompatibleSchemaError</code> Major version difference Version <code>StackCreationError</code> CloudFormation failed Recovery"},{"location":"operations/#related-documentation","title":"Related Documentation","text":"<ul> <li>Monitoring Guide - CloudWatch metrics, dashboards, and alerts</li> <li>Performance Tuning - Capacity planning and optimization</li> <li>Migration Guide - Schema versioning and upgrades</li> <li>Unavailability Handling - Configure behavior when DynamoDB is unavailable</li> </ul>"},{"location":"operations/dynamodb/","title":"DynamoDB Operations","text":"<p>This guide covers troubleshooting and operational procedures for DynamoDB capacity management and throttling issues.</p>"},{"location":"operations/dynamodb/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([DynamoDB Issue]) --&gt; Q1{What's the symptom?}      Q1 --&gt;|ReadThrottleEvents| A1[Check read patterns]     Q1 --&gt;|WriteThrottleEvents| A2[Check write patterns]     Q1 --&gt;|High latency| A3[Check capacity utilization]     Q1 --&gt;|Planning scale| A4[Capacity planning]      A1 --&gt; FIX1{Emergency?}     A2 --&gt; FIX1     FIX1 --&gt;|Yes| EMERGENCY[Switch to on-demand]     FIX1 --&gt;|No| PLAN[Increase provisioned capacity]      A3 --&gt; CHECK[Check CloudWatch metrics]     CHECK --&gt; FIX1      A4 --&gt; LINK([\u2192 Performance Guide])      click A1 \"#throttling\" \"Diagnose throttling\"     click A2 \"#throttling\" \"Diagnose throttling\"     click A3 \"#capacity-planning\" \"Check capacity\"     click EMERGENCY \"#emergency-on-demand\" \"Switch to on-demand\"     click PLAN \"#scaling-procedures\" \"Scale capacity\"     click CHECK \"#diagnostic-queries\" \"View metrics\"     click LINK \"../performance/\" \"Capacity planning guide\""},{"location":"operations/dynamodb/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/dynamodb/#symptoms","title":"Symptoms","text":"<ul> <li><code>ProvisionedThroughputExceededException</code> errors</li> <li>Increased latency on rate limit checks</li> <li>CloudWatch throttle alarms triggered</li> <li><code>RateLimiterUnavailable</code> with <code>OnUnavailable.BLOCK</code> mode</li> </ul>"},{"location":"operations/dynamodb/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check CloudWatch metrics:</p> <pre><code># View throttle events (last hour)\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ReadThrottleEvents \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Check capacity utilization:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedReadCapacityUnits \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Identify hot partitions (if Contributor Insights enabled):</p> <pre><code>aws dynamodb describe-contributor-insights \\\n  --table-name ZAEL-&lt;name&gt;\n</code></pre>"},{"location":"operations/dynamodb/#throttling","title":"Throttling","text":""},{"location":"operations/dynamodb/#common-causes-and-solutions","title":"Common Causes and Solutions","text":"Cause Solution Provisioned capacity too low Increase RCU/WCU or switch to on-demand Hot partition Distribute entity IDs more evenly Burst traffic Enable auto-scaling or use on-demand GSI throttling Check GSI capacity separately"},{"location":"operations/dynamodb/#read-throttling","title":"Read Throttling","text":"<p>Check which operations are throttling:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ThrottledRequests \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; Name=Operation,Value=GetItem \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre>"},{"location":"operations/dynamodb/#write-throttling","title":"Write Throttling","text":"<p>Write throttling typically occurs during high-volume rate limiting or when the aggregator Lambda is processing many stream events.</p> <p>Check write patterns:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedWriteCapacityUnits \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Sum\n</code></pre>"},{"location":"operations/dynamodb/#capacity-planning","title":"Capacity Planning","text":"<p>For detailed capacity calculations, see the Performance Tuning Guide.</p> <p>Quick estimates:</p> Operation RCU WCU <code>acquire()</code> ~2 ~4 <code>acquire()</code> with cascade ~4 ~8 <code>available()</code> ~2 ~0 Aggregator (per record) ~1 ~2"},{"location":"operations/dynamodb/#procedures","title":"Procedures","text":""},{"location":"operations/dynamodb/#emergency-capacity-increase","title":"Emergency Capacity Increase","text":"<p>Switch to on-demand capacity (immediate relief):</p> <p>Billing Impact</p> <p>On-demand pricing is typically 5-7x more expensive than provisioned capacity at steady state, but has no throttling.</p> <pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --billing-mode PAY_PER_REQUEST\n</code></pre> <p>Increase provisioned capacity:</p> <pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --provisioned-throughput ReadCapacityUnits=1000,WriteCapacityUnits=500\n</code></pre>"},{"location":"operations/dynamodb/#scaling-procedures","title":"Scaling Procedures","text":""},{"location":"operations/dynamodb/#planned-capacity-scaling","title":"Planned Capacity Scaling","text":"<p>Step 1: Analyze current usage</p> <pre><code># Get average consumption over last 24 hours\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedReadCapacityUnits \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; \\\n  --start-time $(date -u -d '24 hours ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 3600 \\\n  --statistics Average\n</code></pre> <p>Step 2: Calculate required capacity</p> <p>Use the formulas from Performance Tuning:</p> <ul> <li><code>RCU = (requests_per_second \u00d7 2) + (cascade_requests \u00d7 2)</code></li> <li><code>WCU = (requests_per_second \u00d7 4) + (cascade_requests \u00d7 4)</code></li> </ul> <p>Add 20% headroom for bursts.</p> <p>Step 3: Apply changes</p> <pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --provisioned-throughput ReadCapacityUnits=&lt;new_rcu&gt;,WriteCapacityUnits=&lt;new_wcu&gt;\n</code></pre> <p>Step 4: Verify</p> <pre><code>aws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n  --query 'Table.ProvisionedThroughput'\n</code></pre>"},{"location":"operations/dynamodb/#enable-auto-scaling","title":"Enable Auto-Scaling","text":"<p>Create scaling targets:</p> <pre><code># Register read capacity target\naws application-autoscaling register-scalable-target \\\n  --service-namespace dynamodb \\\n  --resource-id \"table/ZAEL-&lt;name&gt;\" \\\n  --scalable-dimension \"dynamodb:table:ReadCapacityUnits\" \\\n  --min-capacity 5 \\\n  --max-capacity 1000\n\n# Register write capacity target\naws application-autoscaling register-scalable-target \\\n  --service-namespace dynamodb \\\n  --resource-id \"table/ZAEL-&lt;name&gt;\" \\\n  --scalable-dimension \"dynamodb:table:WriteCapacityUnits\" \\\n  --min-capacity 5 \\\n  --max-capacity 500\n</code></pre> <p>Create scaling policies:</p> <pre><code># Read capacity policy (target 70% utilization)\naws application-autoscaling put-scaling-policy \\\n  --service-namespace dynamodb \\\n  --resource-id \"table/ZAEL-&lt;name&gt;\" \\\n  --scalable-dimension \"dynamodb:table:ReadCapacityUnits\" \\\n  --policy-name \"ZAEL-&lt;name&gt;-read-scaling\" \\\n  --policy-type \"TargetTrackingScaling\" \\\n  --target-tracking-scaling-policy-configuration '{\n    \"TargetValue\": 70.0,\n    \"PredefinedMetricSpecification\": {\n      \"PredefinedMetricType\": \"DynamoDBReadCapacityUtilization\"\n    }\n  }'\n</code></pre>"},{"location":"operations/dynamodb/#switch-to-on-demand","title":"Switch to On-Demand","text":"<p>When to use on-demand:</p> <ul> <li>Unpredictable traffic patterns</li> <li>New deployments without baseline data</li> <li>Cost is less important than avoiding throttling</li> </ul> <p>Switch from provisioned to on-demand:</p> <pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --billing-mode PAY_PER_REQUEST\n</code></pre> <p>Switch back to provisioned:</p> <p>Cooldown Period</p> <p>You can only switch billing modes once per 24 hours.</p> <pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --billing-mode PROVISIONED \\\n  --provisioned-throughput ReadCapacityUnits=100,WriteCapacityUnits=50\n</code></pre>"},{"location":"operations/dynamodb/#verification","title":"Verification","text":"<p>After capacity changes, monitor for 15-30 minutes:</p> <pre><code># Watch throttle events\nwatch -n 30 \"aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ReadThrottleEvents \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; \\\n  --start-time \\$(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time \\$(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Sum\"\n</code></pre>"},{"location":"operations/dynamodb/#related","title":"Related","text":"<ul> <li>Performance Tuning - Capacity planning formulas and optimization</li> <li>Lambda Operations - Aggregator throttling due to DynamoDB</li> <li>Stream Processing - Stream processing affected by DynamoDB capacity</li> </ul>"},{"location":"operations/lambda/","title":"Lambda Aggregator Operations","text":"<p>This guide covers troubleshooting and operational procedures for the Lambda aggregator function that processes DynamoDB stream events and maintains usage snapshots.</p>"},{"location":"operations/lambda/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Lambda Issue]) --&gt; Q1{What's the symptom?}      Q1 --&gt;|Error rate alarm| CHECK1[Check CloudWatch Logs]     Q1 --&gt;|Duration alarm| CHECK2[Check processing time]     Q1 --&gt;|DLQ messages| CHECK3[Inspect DLQ]     Q1 --&gt;|Cold starts| CHECK4[Check init duration]      CHECK1 --&gt; DIAG{Error type?}     DIAG --&gt;|Permission denied| FIX1[Check IAM role]     DIAG --&gt;|Timeout| FIX2[Increase memory/timeout]     DIAG --&gt;|DynamoDB error| LINK1([\u2192 DynamoDB])     DIAG --&gt;|Code error| FIX3[Check logs, deploy fix]      CHECK2 --&gt; FIX2     CHECK3 --&gt; DLQ[DLQ Processing]     CHECK4 --&gt; FIX4[Increase memory]      click CHECK1 \"#error-rate-issues\" \"View error diagnostics\"     click FIX1 \"#error-rate-issues\" \"IAM troubleshooting\"     click FIX2 \"#high-lambda-duration\" \"Increase resources\"     click LINK1 \"dynamodb/\" \"DynamoDB operations\"     click FIX3 \"#lambda-redeployment\" \"Redeploy Lambda\"     click DLQ \"#messages-in-dead-letter-queue\" \"DLQ processing\"     click FIX4 \"#cold-start-issues\" \"Cold start fixes\""},{"location":"operations/lambda/#health-indicators","title":"Health Indicators","text":"<p>Monitor these metrics for Lambda health. See Monitoring Guide for dashboard templates.</p> Metric Healthy Warning Critical Error Rate 0% &lt; 1% &gt; 1% Duration &lt; 50% timeout &lt; 80% timeout &gt; 80% timeout Iterator Age &lt; 1s &lt; 30s &gt; 30s DLQ Depth 0 1-10 &gt; 10"},{"location":"operations/lambda/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/lambda/#symptoms","title":"Symptoms","text":"<ul> <li>Usage snapshots not updating</li> <li>Messages accumulating in Dead Letter Queue (DLQ)</li> <li>Lambda duration alarm triggered</li> <li>CloudWatch Logs showing errors</li> </ul>"},{"location":"operations/lambda/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check Lambda errors:</p> <pre><code># View recent Lambda invocations\naws logs filter-log-events \\\n  --log-group-name /aws/lambda/ZAEL-&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%s)000 \\\n  --filter-pattern \"ERROR\"\n</code></pre> <p>Check DLQ message count:</p> <pre><code>aws sqs get-queue-attributes \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/ZAEL-&lt;name&gt;-aggregator-dlq \\\n  --attribute-names ApproximateNumberOfMessagesVisible\n</code></pre> <p>Inspect DLQ messages:</p> <pre><code>aws sqs receive-message \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/ZAEL-&lt;name&gt;-aggregator-dlq \\\n  --max-number-of-messages 10 \\\n  --visibility-timeout 0\n</code></pre>"},{"location":"operations/lambda/#error-rate-issues","title":"Error Rate Issues","text":"<p>CloudWatch Logs Insights query for errors:</p> <pre><code>fields @timestamp, @message\n| filter @message like /ERROR/\n| sort @timestamp desc\n| limit 50\n</code></pre> <p>Common errors and solutions:</p> Error Cause Solution <code>AccessDeniedException</code> IAM role missing permissions Check role has DynamoDB and SQS permissions <code>ValidationException</code> Invalid DynamoDB operation Check for schema changes <code>ResourceNotFoundException</code> Table or stream doesn't exist Verify table name, redeploy stack <code>ProvisionedThroughputExceededException</code> DynamoDB throttling See DynamoDB Operations"},{"location":"operations/lambda/#high-lambda-duration","title":"High Lambda Duration","text":"<p>Symptoms: Duration alarm triggered, <code>processing_time_ms</code> &gt; 80% of timeout</p> <p>Diagnostic query:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Batch processing completed/\n| parse @message /processing_time_ms\":(?&lt;duration&gt;[\\d.]+)/\n| stats avg(duration) as avg_ms,\n        pct(duration, 50) as p50_ms,\n        pct(duration, 95) as p95_ms,\n        pct(duration, 99) as p99_ms\n  by bin(1h)\n| sort @timestamp desc\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Increase Lambda memory (CPU scales with memory):    <pre><code>aws lambda update-function-configuration \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --memory-size 512\n</code></pre></p> </li> <li> <p>Reduce batch size in event source mapping:    <pre><code>MAPPING_UUID=$(aws lambda list-event-source-mappings \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --query 'EventSourceMappings[0].UUID' \\\n  --output text)\n\naws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --batch-size 50\n</code></pre></p> </li> <li> <p>Check DynamoDB latency - see DynamoDB Operations</p> </li> </ol>"},{"location":"operations/lambda/#messages-in-dead-letter-queue","title":"Messages in Dead Letter Queue","text":"<p>Symptoms: DLQ alarm triggered, messages accumulating</p> <p>Investigation:</p> <ol> <li>Check Lambda logs for the error that caused the failure</li> <li>Identify if it's a transient error or persistent issue</li> <li>Fix the root cause before reprocessing</li> </ol> <p>Reprocess DLQ messages after fix:</p> <pre><code>import boto3\nimport json\n\nsqs = boto3.client('sqs')\nlambda_client = boto3.client('lambda')\n\ndlq_url = \"https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/ZAEL-&lt;name&gt;-aggregator-dlq\"\n\nwhile True:\n    response = sqs.receive_message(\n        QueueUrl=dlq_url,\n        MaxNumberOfMessages=10,\n        WaitTimeSeconds=5,\n    )\n\n    messages = response.get('Messages', [])\n    if not messages:\n        break\n\n    for msg in messages:\n        # Reprocess the failed event\n        body = json.loads(msg['Body'])\n\n        # Invoke Lambda directly with the failed records\n        lambda_client.invoke(\n            FunctionName='ZAEL-&lt;name&gt;-aggregator',\n            InvocationType='Event',\n            Payload=json.dumps(body),\n        )\n\n        # Delete from DLQ after successful reprocessing\n        sqs.delete_message(\n            QueueUrl=dlq_url,\n            ReceiptHandle=msg['ReceiptHandle'],\n        )\n\n        print(f\"Reprocessed message: {msg['MessageId']}\")\n</code></pre> <p>Purge DLQ (discard all messages):</p> <p>Data Loss</p> <p>This permanently discards failed events. Only use after confirming data is not needed.</p> <pre><code>aws sqs purge-queue \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/ZAEL-&lt;name&gt;-aggregator-dlq\n</code></pre>"},{"location":"operations/lambda/#cold-start-issues","title":"Cold Start Issues","text":"<p>Diagnostic query:</p> <pre><code>fields @timestamp, @message, @duration\n| filter @type = \"REPORT\"\n| filter @message like /Init Duration/\n| parse @message /Init Duration: (?&lt;init_duration&gt;[\\d.]+) ms/\n| stats count() as cold_starts,\n        avg(init_duration) as avg_init_ms\n  by bin(1h)\n</code></pre> <p>Solutions:</p> <ol> <li>Increase Lambda memory (faster initialization)</li> <li>Enable provisioned concurrency for consistent latency:    <pre><code># Publish a new version first (provisioned concurrency requires a version or alias)\nVERSION=$(aws lambda publish-version \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --query 'Version' --output text)\n\n# Configure provisioned concurrency on the published version\naws lambda put-provisioned-concurrency-config \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --qualifier $VERSION \\\n  --provisioned-concurrent-executions 2\n</code></pre></li> </ol>"},{"location":"operations/lambda/#procedures","title":"Procedures","text":""},{"location":"operations/lambda/#lambda-redeployment","title":"Lambda Redeployment","text":"<p>Update Lambda code only:</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre> <p>Full stack update:</p> <pre><code>zae-limiter deploy --name &lt;name&gt; --region &lt;region&gt;\n</code></pre>"},{"location":"operations/lambda/#memorytimeout-adjustment","title":"Memory/Timeout Adjustment","text":"<p>Via CLI (recommended):</p> <pre><code># Redeploy with new settings\nzae-limiter deploy --name &lt;name&gt; --region &lt;region&gt; \\\n  --lambda-memory 512 \\\n  --lambda-timeout 120\n</code></pre> <p>Direct Lambda update:</p> <pre><code>aws lambda update-function-configuration \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --memory-size 512 \\\n  --timeout 120\n</code></pre>"},{"location":"operations/lambda/#verification","title":"Verification","text":"<p>After any Lambda changes, verify health:</p> <pre><code># Check function configuration\naws lambda get-function-configuration \\\n  --function-name ZAEL-&lt;name&gt;-aggregator\n\n# Watch for errors in real-time\naws logs tail /aws/lambda/ZAEL-&lt;name&gt;-aggregator --follow\n</code></pre>"},{"location":"operations/lambda/#related","title":"Related","text":"<ul> <li>Stream Processing - Iterator age and stream lag issues</li> <li>DynamoDB Operations - Throttling and capacity issues</li> <li>Monitoring Guide - CloudWatch dashboards and alerts</li> </ul>"},{"location":"operations/rate-limits/","title":"Rate Limit Operations","text":"<p>This guide covers troubleshooting rate limit enforcement issues and procedures for adjusting limits at runtime.</p>"},{"location":"operations/rate-limits/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Rate Limit Issue]) --&gt; Q1{What's happening?}      Q1 --&gt;|Unexpected RateLimitExceeded| A1[Check bucket state]     Q1 --&gt;|Limits not enforcing| A2[Check entity exists]     Q1 --&gt;|Cascade not working| A3[Check parent entity]     Q1 --&gt;|Need to adjust limits| A4[Runtime adjustment]      A1 --&gt; CHECK1[Query bucket in DynamoDB]     A2 --&gt; CHECK2[Query entity metadata]     A3 --&gt; CHECK3[Verify parent_id and cascade=True]      CHECK1 --&gt; FIX1{Bucket state?}     FIX1 --&gt;|Depleted| WAIT[Wait for refill or reset]     FIX1 --&gt;|Has capacity| CONFIG[Check limit configuration]      CHECK2 --&gt; FIX2{Entity exists?}     FIX2 --&gt;|No| CREATE[Create entity first]     FIX2 --&gt;|Yes| LIMITS[Check use_stored_limits]      click A1 \"#unexpected-ratelimitexceeded\" \"Diagnose unexpected limits\"     click A2 \"#limits-not-enforcing\" \"Check entity setup\"     click A3 \"#cascade-not-working\" \"Check parent setup\"     click A4 \"#adjust-limits-at-runtime\" \"Adjust limits\"     click WAIT \"#reset-bucket-state\" \"Reset bucket\"     click CHECK1 \"#debug-bucket-state\" \"Query bucket state\""},{"location":"operations/rate-limits/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/rate-limits/#symptoms","title":"Symptoms","text":"<ul> <li>Requests succeed when they should be rate limited</li> <li><code>RateLimitExceeded</code> raised unexpectedly</li> <li>Cascade to parent entity not working</li> <li>Bucket state appears incorrect</li> </ul>"},{"location":"operations/rate-limits/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check entity and bucket state:</p> <pre><code># Query entity metadata\naws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n\n# Query bucket state for a specific limit\naws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre> <p>Verify stored limits (if using <code>use_stored_limits=True</code>):</p> <pre><code>aws dynamodb query --table-name ZAEL-&lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#LIMIT#\"}}'\n</code></pre>"},{"location":"operations/rate-limits/#unexpected-ratelimitexceeded","title":"Unexpected RateLimitExceeded","text":"<p>Possible causes:</p> Cause Diagnosis Solution Bucket depleted Check bucket <code>tokens</code> value Wait for refill or increase limit Limit too restrictive Compare limit capacity vs usage Increase capacity Cascade triggered Check <code>violations</code> array Increase parent limit Clock skew Compare server time with bucket <code>last_update</code> Sync NTP <p>Check bucket state:</p> <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}' \\\n  --projection-expression \"tokens, last_update, capacity\"\n</code></pre> <p>Interpret the response:</p> <ul> <li><code>tokens</code>: Current token count (in millitokens, divide by 1000)</li> <li><code>last_update</code>: Unix timestamp of last access</li> <li><code>capacity</code>: Maximum bucket capacity (in millitokens)</li> </ul>"},{"location":"operations/rate-limits/#limits-not-enforcing","title":"Limits Not Enforcing","text":"<p>Common causes:</p> Cause Solution Entity not created Create entity before rate limiting: <code>await limiter.create_entity(...)</code> Wrong <code>use_stored_limits</code> setting Set <code>use_stored_limits=True</code> if limits are in DynamoDB Stale bucket state Bucket refills over time; tokens may have refilled Limit configuration mismatch Verify limit <code>capacity</code>, <code>burst</code>, and <code>refill_rate</code> match expectations <p>Verify entity exists:</p> <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n</code></pre>"},{"location":"operations/rate-limits/#cascade-not-working","title":"Cascade Not Working","text":"<p>If cascade to parent is not enforced:</p> <p>Step 1: Verify parent entity exists:</p> <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;parent_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n</code></pre> <p>Step 2: Verify child has <code>parent_id</code> set:</p> <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;child_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n# Check the \"parent_id\" attribute in response\n</code></pre> <p>Step 3: Ensure <code>cascade=True</code> in acquire call:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"child-id\",\n    cascade=True,  # Must be True to check parent\n    ...\n):\n</code></pre>"},{"location":"operations/rate-limits/#verification","title":"Verification","text":"<p>Test that rate limiting is working correctly:</p> <pre><code>from zae_limiter import RateLimiter, Limit, RateLimitExceeded\n\nlimiter = RateLimiter(name=\"&lt;name&gt;\", region=\"&lt;region&gt;\")\n\n# Consume all capacity\nfor i in range(100):\n    try:\n        async with limiter.acquire(\n            entity_id=\"test-entity\",\n            resource=\"test\",\n            limits=[Limit.per_minute(\"rpm\", 100)],\n            consume={\"rpm\": 1},\n        ):\n            pass\n    except RateLimitExceeded as e:\n        print(f\"Rate limited after {i} requests, retry_after={e.retry_after_seconds}s\")\n        break\n</code></pre>"},{"location":"operations/rate-limits/#procedures","title":"Procedures","text":""},{"location":"operations/rate-limits/#adjust-limits-at-runtime","title":"Adjust Limits at Runtime","text":""},{"location":"operations/rate-limits/#programmatic-adjustment","title":"Programmatic Adjustment","text":"<p>Update stored limits for an entity without redeployment:</p> <pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(name=\"&lt;name&gt;\", region=\"&lt;region&gt;\")\n\n# Update limits for an entity\nawait limiter.set_limits(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",  # Resource these limits apply to\n    limits=[\n        Limit.per_minute(\"rpm\", 1000),      # Requests per minute\n        Limit.per_minute(\"tpm\", 100_000),   # Tokens per minute\n    ],\n)\n\nprint(\"Limits updated successfully\")\n</code></pre>"},{"location":"operations/rate-limits/#direct-dynamodb-update","title":"Direct DynamoDB Update","text":"<p>Advanced</p> <p>Direct DynamoDB updates bypass validation. Use programmatic API when possible.</p> <pre><code># Update a stored limit\naws dynamodb put-item --table-name ZAEL-&lt;name&gt; \\\n  --item '{\n    \"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"},\n    \"SK\": {\"S\": \"#LIMIT#&lt;resource&gt;#&lt;limit_name&gt;\"},\n    \"capacity\": {\"N\": \"1000000\"},\n    \"burst\": {\"N\": \"1000000\"},\n    \"refill_amount\": {\"N\": \"1000000\"},\n    \"refill_period\": {\"N\": \"60\"}\n  }'\n</code></pre>"},{"location":"operations/rate-limits/#reset-bucket-state","title":"Reset Bucket State","text":"<p>Reset a bucket to restore full capacity:</p> <pre><code># Delete the bucket (will be recreated on next acquire with full capacity)\naws dynamodb delete-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre>"},{"location":"operations/rate-limits/#debug-bucket-state","title":"Debug Bucket State","text":"<p>Query all buckets for an entity:</p> <pre><code>aws dynamodb query --table-name ZAEL-&lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#BUCKET#\"}}' \\\n  --projection-expression \"SK, tokens, capacity, last_update\"\n</code></pre> <p>Interpret bucket values:</p> <p>All token values are stored as millitokens (multiply by 1000):</p> Field Description Example <code>tokens</code> Current available tokens \u00d7 1000 <code>50000</code> = 50 tokens <code>capacity</code> Maximum bucket size \u00d7 1000 <code>100000</code> = 100 tokens <code>last_update</code> Unix timestamp <code>1705312800</code>"},{"location":"operations/rate-limits/#verification-after-changes","title":"Verification After Changes","text":"<p>After adjusting limits, verify:</p> <pre><code># Check available capacity\navailable = await limiter.available(\n    entity_id=\"&lt;entity_id&gt;\",\n    resource=\"&lt;resource&gt;\",\n    limits=[Limit.per_minute(\"&lt;limit_name&gt;\", &lt;capacity&gt;)],\n)\n\nprint(f\"Available: {available}\")\n# Output: {'&lt;limit_name&gt;': &lt;available_tokens&gt;}\n</code></pre>"},{"location":"operations/rate-limits/#dynamodb-key-patterns","title":"DynamoDB Key Patterns","text":"Pattern Key Description Entity metadata <code>PK=ENTITY#&lt;id&gt;, SK=#META</code> Entity configuration Bucket state <code>PK=ENTITY#&lt;id&gt;, SK=#BUCKET#&lt;resource&gt;#&lt;limit&gt;</code> Token bucket Stored limit <code>PK=ENTITY#&lt;id&gt;, SK=#LIMIT#&lt;resource&gt;#&lt;limit&gt;</code> Limit configuration"},{"location":"operations/rate-limits/#related","title":"Related","text":"<ul> <li>Recovery &amp; Rollback - Reset corrupted buckets</li> <li>Performance Tuning - Capacity planning for rate limits</li> <li>Hierarchical Limits - Cascade configuration</li> </ul>"},{"location":"operations/recovery/","title":"Recovery &amp; Rollback","text":"<p>This guide covers backup, restore, and rollback procedures for zae-limiter deployments.</p>"},{"location":"operations/recovery/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([What went wrong?]) --&gt; Q1{Issue type?}      Q1 --&gt;|Bad deployment| DEP{Deployment issue?}     Q1 --&gt;|Bad migration| MIG{Reversible?}     Q1 --&gt;|Data corruption| DATA{How recent?}     Q1 --&gt;|Complete failure| FAIL{Table exists?}      DEP --&gt;|CloudFormation failed| STACK_ROLL[Stack Rollback]     DEP --&gt;|Lambda broken| LAMBDA_FIX[Lambda Redeployment]     DEP --&gt;|Config wrong| STACK_UPDATE[Stack Redeployment]      MIG --&gt;|Yes| MIG_ROLL[Migration Rollback]     MIG --&gt;|No| BACKUP_RESTORE[Restore from Backup]      DATA --&gt;|&lt; 35 days| PITR[PITR Recovery]     DATA --&gt;|Older| BACKUP_RESTORE      FAIL --&gt;|Yes| STACK_UPDATE     FAIL --&gt;|No| FULL[Full Recovery]      click STACK_ROLL \"#stack-rollback\" \"CloudFormation auto-rollback\"     click LAMBDA_FIX \"#lambda-redeployment\" \"Redeploy Lambda code\"     click STACK_UPDATE \"#stack-redeployment\" \"Delete and recreate stack\"     click MIG_ROLL \"#migration-rollback\" \"Rollback reversible migration\"     click BACKUP_RESTORE \"#dynamodb-backup-and-restore\" \"Restore from on-demand backup\"     click PITR \"#point-in-time-recovery-pitr\" \"Point-in-time recovery\"     click FULL \"#full-recovery\" \"Complete recovery procedure\""},{"location":"operations/recovery/#emergency-rollback-decision-matrix","title":"Emergency Rollback Decision Matrix","text":"Situation Action Time to Recovery Data Loss Risk Lambda errors after upgrade <code>zae-limiter upgrade --lambda-only</code> with previous version ~2 min None Schema migration failed Restore from pre-migration backup ~10-30 min Changes since backup Stack update failed CloudFormation auto-rollback ~5 min None Data corruption (recent) PITR restore ~15-30 min None (point-in-time) Data corruption (old) On-demand backup restore ~15-30 min Changes since backup Complete stack failure Delete + redeploy (if deletion protection on) ~10 min None (table retained)"},{"location":"operations/recovery/#dynamodb-backup-and-restore","title":"DynamoDB Backup and Restore","text":""},{"location":"operations/recovery/#create-on-demand-backup","title":"Create On-Demand Backup","text":"<p>Before any risky operation:</p> <pre><code>aws dynamodb create-backup \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --backup-name \"manual-backup-$(date +%Y%m%d-%H%M%S)\"\n</code></pre> <p>Verify backup created:</p> <pre><code>aws dynamodb list-backups \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --time-range-lower-bound $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ)\n</code></pre>"},{"location":"operations/recovery/#list-available-backups","title":"List Available Backups","text":"<pre><code>aws dynamodb list-backups \\\n  --table-name ZAEL-&lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#restore-from-backup","title":"Restore from Backup","text":"<p>New Table Name</p> <p>Restore creates a new table. You must update your application to use the new table name or rename after restore.</p> <pre><code>aws dynamodb restore-table-from-backup \\\n  --target-table-name ZAEL-&lt;name&gt;-restored \\\n  --backup-arn &lt;backup-arn&gt;\n</code></pre> <p>Wait for restore to complete:</p> <pre><code>aws dynamodb describe-table --table-name ZAEL-&lt;name&gt;-restored \\\n  --query 'Table.TableStatus'\n</code></pre>"},{"location":"operations/recovery/#point-in-time-recovery-pitr","title":"Point-in-Time Recovery (PITR)","text":"<p>PITR allows restore to any point in the last 35 days.</p> <p>Check if PITR is enabled:</p> <pre><code>aws dynamodb describe-continuous-backups \\\n  --table-name ZAEL-&lt;name&gt;\n</code></pre> <p>Enable PITR (if not enabled):</p> <pre><code>aws dynamodb update-continuous-backups \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true\n</code></pre> <p>Restore to specific point in time:</p> <pre><code>aws dynamodb restore-table-to-point-in-time \\\n  --source-table-name ZAEL-&lt;name&gt; \\\n  --target-table-name ZAEL-&lt;name&gt;-restored \\\n  --restore-date-time \"2024-01-15T10:00:00Z\"\n</code></pre> <p>Restore to latest restorable time:</p> <pre><code>aws dynamodb restore-table-to-point-in-time \\\n  --source-table-name ZAEL-&lt;name&gt; \\\n  --target-table-name ZAEL-&lt;name&gt;-restored \\\n  --use-latest-restorable-time\n</code></pre>"},{"location":"operations/recovery/#migration-rollback","title":"Migration Rollback","text":""},{"location":"operations/recovery/#reversible-migrations","title":"Reversible Migrations","text":"<p>For migrations that support rollback:</p> <pre><code>from zae_limiter.migrations import get_migrations\nfrom zae_limiter.repository import Repository\n\nasync def rollback_migration(name: str, region: str, target_version: str):\n    \"\"\"Rollback a reversible migration.\"\"\"\n    repo = Repository(f\"ZAEL-{name}\", region, None)\n\n    try:\n        migrations = get_migrations()\n        target = next((m for m in migrations if m.version == target_version), None)\n\n        if target and target.reversible and target.rollback:\n            await target.rollback(repo)\n            print(f\"Rolled back migration {target_version}\")\n\n            # Update version record\n            await repo.set_version_record(\n                schema_version=\"&lt;previous_version&gt;\",\n                updated_by=\"manual_rollback\",\n            )\n        else:\n            print(\"Migration is not reversible - restore from backup\")\n    finally:\n        await repo.close()\n</code></pre>"},{"location":"operations/recovery/#non-reversible-migrations","title":"Non-Reversible Migrations","text":"<p>For migrations without rollback support:</p> <ol> <li>Restore from backup taken before migration</li> <li>Update stack to match restored schema version</li> <li>Downgrade client to compatible version</li> </ol>"},{"location":"operations/recovery/#stack-operations","title":"Stack Operations","text":""},{"location":"operations/recovery/#stack-rollback","title":"Stack Rollback","text":"<p>CloudFormation automatically rolls back failed updates. If a stack is stuck:</p> <p>Check stack status:</p> <pre><code>aws cloudformation describe-stacks \\\n  --stack-name ZAEL-&lt;name&gt; \\\n  --query 'Stacks[0].StackStatus'\n</code></pre> <p>View rollback events:</p> <pre><code>aws cloudformation describe-stack-events \\\n  --stack-name ZAEL-&lt;name&gt; \\\n  --query 'StackEvents[?ResourceStatus==`UPDATE_ROLLBACK_IN_PROGRESS` || ResourceStatus==`UPDATE_ROLLBACK_COMPLETE`]'\n</code></pre> <p>Continue rollback (if stuck):</p> <pre><code>aws cloudformation continue-update-rollback \\\n  --stack-name ZAEL-&lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#stack-redeployment","title":"Stack Redeployment","text":"<p>Delete and recreate stack (preserves DynamoDB data with deletion protection):</p> <pre><code># Step 1: Verify deletion protection is enabled\naws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n  --query 'Table.DeletionProtectionEnabled'\n\n# Step 2: Delete stack (table retained if deletion protection enabled)\nzae-limiter delete --name &lt;name&gt; --region &lt;region&gt; --yes\n\n# Step 3: Wait for deletion\naws cloudformation wait stack-delete-complete --stack-name ZAEL-&lt;name&gt;\n\n# Step 4: Redeploy\nzae-limiter deploy --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Update existing stack:</p> <pre><code># Export current template\nzae-limiter cfn-template &gt; updated-template.yaml\n\n# Update via CloudFormation\naws cloudformation update-stack \\\n  --stack-name ZAEL-&lt;name&gt; \\\n  --template-body file://updated-template.yaml \\\n  --capabilities CAPABILITY_NAMED_IAM\n\n# Wait for update\naws cloudformation wait stack-update-complete --stack-name ZAEL-&lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#lambda-redeployment","title":"Lambda Redeployment","text":"<p>Redeploy Lambda with current code:</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre> <p>Redeploy with specific version:</p> <pre><code># First, install the specific version\npip install zae-limiter==&lt;version&gt;\n\n# Then upgrade Lambda\nzae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre>"},{"location":"operations/recovery/#data-reconciliation","title":"Data Reconciliation","text":""},{"location":"operations/recovery/#reset-corrupted-bucket","title":"Reset Corrupted Bucket","text":"<p>Delete a specific bucket (will be recreated on next acquire):</p> <pre><code>aws dynamodb delete-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre>"},{"location":"operations/recovery/#reset-all-buckets-for-entity","title":"Reset All Buckets for Entity","text":"<pre><code># Query all buckets\nBUCKETS=$(aws dynamodb query --table-name ZAEL-&lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#BUCKET#\"}}' \\\n  --projection-expression \"PK, SK\" \\\n  --output json)\n\n# Delete each bucket\necho $BUCKETS | jq -r '.Items[] | @base64' | while read item; do\n  PK=$(echo $item | base64 -d | jq -r '.PK.S')\n  SK=$(echo $item | base64 -d | jq -r '.SK.S')\n\n  aws dynamodb delete-item --table-name ZAEL-&lt;name&gt; \\\n    --key \"{\\\"PK\\\": {\\\"S\\\": \\\"$PK\\\"}, \\\"SK\\\": {\\\"S\\\": \\\"$SK\\\"}}\"\n\n  echo \"Deleted: $SK\"\ndone\n</code></pre>"},{"location":"operations/recovery/#verify-entity-integrity","title":"Verify Entity Integrity","text":"<pre><code>async def verify_entity(limiter, entity_id: str) -&gt; bool:\n    \"\"\"Verify entity can perform rate limiting operations.\"\"\"\n    from zae_limiter import Limit\n\n    try:\n        # Check entity exists\n        entity = await limiter.get_entity(entity_id)\n        print(f\"Entity: {entity.entity_id}, parent: {entity.parent_id}\")\n\n        # Check rate limiting works\n        available = await limiter.available(\n            entity_id=entity_id,\n            resource=\"health-check\",\n            limits=[Limit.per_minute(\"test\", 1000)],\n        )\n        print(f\"Available capacity: {available}\")\n\n        return True\n    except Exception as e:\n        print(f\"Entity verification failed: {e}\")\n        return False\n</code></pre>"},{"location":"operations/recovery/#full-recovery","title":"Full Recovery","text":"<p>Complete recovery from total failure:</p>"},{"location":"operations/recovery/#step-1-assess-situation","title":"Step 1: Assess Situation","text":"<pre><code># Check if table exists\naws dynamodb describe-table --table-name ZAEL-&lt;name&gt; 2&gt;/dev/null &amp;&amp; echo \"Table exists\" || echo \"Table missing\"\n\n# Check if stack exists\naws cloudformation describe-stacks --stack-name ZAEL-&lt;name&gt; 2&gt;/dev/null &amp;&amp; echo \"Stack exists\" || echo \"Stack missing\"\n</code></pre>"},{"location":"operations/recovery/#step-2-restore-table-if-needed","title":"Step 2: Restore Table (if needed)","text":"<pre><code># List available backups\naws dynamodb list-backups --table-name ZAEL-&lt;name&gt;\n\n# Restore from backup\naws dynamodb restore-table-from-backup \\\n  --target-table-name ZAEL-&lt;name&gt; \\\n  --backup-arn &lt;backup-arn&gt;\n\n# Wait for restore\naws dynamodb wait table-exists --table-name ZAEL-&lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#step-3-redeploy-stack","title":"Step 3: Redeploy Stack","text":"<pre><code>zae-limiter deploy --name &lt;name&gt; --region &lt;region&gt;\n</code></pre>"},{"location":"operations/recovery/#step-4-verify","title":"Step 4: Verify","text":"<pre><code># Check stack status\nzae-limiter status --name &lt;name&gt; --region &lt;region&gt;\n\n# Check version\nzae-limiter version --name &lt;name&gt; --region &lt;region&gt;\n\n# Check compatibility\nzae-limiter check --name &lt;name&gt; --region &lt;region&gt;\n</code></pre>"},{"location":"operations/recovery/#prevention","title":"Prevention","text":""},{"location":"operations/recovery/#enable-deletion-protection","title":"Enable Deletion Protection","text":"<pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --deletion-protection-enabled\n</code></pre>"},{"location":"operations/recovery/#enable-pitr","title":"Enable PITR","text":"<pre><code>aws dynamodb update-continuous-backups \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true\n</code></pre>"},{"location":"operations/recovery/#schedule-regular-backups","title":"Schedule Regular Backups","text":"<p>Create a CloudWatch Events rule to backup daily:</p> <pre><code># Create backup Lambda or use AWS Backup service\naws backup create-backup-plan \\\n  --backup-plan '{\"BackupPlanName\": \"zae-limiter-daily\", \"Rules\": [{\"RuleName\": \"daily\", \"TargetBackupVaultName\": \"Default\", \"ScheduleExpression\": \"cron(0 5 * * ? *)\", \"Lifecycle\": {\"DeleteAfterDays\": 30}}]}'\n</code></pre>"},{"location":"operations/recovery/#related","title":"Related","text":"<ul> <li>Version Management - Version upgrade and rollback</li> <li>DynamoDB Operations - Capacity and throttling issues</li> <li>Migration Guide - Schema migration procedures</li> </ul>"},{"location":"operations/streams/","title":"Stream Processing Operations","text":"<p>This guide covers troubleshooting and operational procedures for DynamoDB Streams processing, which powers the usage aggregation feature.</p>"},{"location":"operations/streams/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Stream Issue]) --&gt; Q1{What's the symptom?}      Q1 --&gt;|High IteratorAge| A1[Check processing lag]     Q1 --&gt;|Lambda throttling| A2[Check concurrency]     Q1 --&gt;|Missing snapshots| A3[Check Lambda errors]     Q1 --&gt;|Planning optimization| A4[Tune configuration]      A1 --&gt; CHECK1{Lambda healthy?}     CHECK1 --&gt;|No| LINK1([\u2192 Lambda])     CHECK1 --&gt;|Yes| SCALE[Increase concurrency]      A2 --&gt; SCALE     A3 --&gt; LINK1     A4 --&gt; TUNE[Adjust batch size / concurrency]      click A1 \"#high-iterator-age\" \"Diagnose lag\"     click LINK1 \"lambda/\" \"Lambda troubleshooting\"     click SCALE \"#scaling-stream-processing\" \"Scale concurrency\"     click A3 \"lambda/#error-rate-issues\" \"Check Lambda errors\"     click TUNE \"#tuning-stream-processing\" \"Configuration tuning\""},{"location":"operations/streams/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/streams/#symptoms","title":"Symptoms","text":"<ul> <li><code>IteratorAge</code> metric growing</li> <li>Usage snapshots delayed</li> <li>Stream iterator age alarm triggered</li> <li>Lambda throttling</li> </ul>"},{"location":"operations/streams/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check IteratorAge metric:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name IteratorAge \\\n  --dimensions Name=FunctionName,Value=ZAEL-&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum\n</code></pre> <p>Check stream status:</p> <pre><code>aws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n  --query 'Table.StreamSpecification'\n</code></pre> <p>Check Lambda event source mapping:</p> <pre><code>aws lambda list-event-source-mappings \\\n  --function-name ZAEL-&lt;name&gt;-aggregator\n</code></pre> <p>Check Lambda concurrent executions:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name ConcurrentExecutions \\\n  --dimensions Name=FunctionName,Value=ZAEL-&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum\n</code></pre>"},{"location":"operations/streams/#high-iterator-age","title":"High Iterator Age","text":"<p>Common causes and solutions:</p> Cause Solution Lambda errors Fix errors (check DLQ and logs) - see Lambda Operations Lambda throttling Increase reserved concurrency Low Lambda concurrency Match concurrency to shard count DynamoDB throttling Increase table capacity - see DynamoDB Operations Large batch sizes Reduce batch size in event source mapping <p>Understanding IteratorAge:</p> <ul> <li><code>IteratorAge</code> measures the delay between when a record is written to the stream and when Lambda processes it</li> <li>Healthy: &lt; 1 second</li> <li>Warning: &lt; 30 seconds</li> <li>Critical: &gt; 30 seconds (default alarm threshold)</li> </ul>"},{"location":"operations/streams/#lambda-throttling","title":"Lambda Throttling","text":"<p>Check if Lambda is being throttled:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name Throttles \\\n  --dimensions Name=FunctionName,Value=ZAEL-&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Solution: Increase reserved concurrency (see procedures below).</p>"},{"location":"operations/streams/#procedures","title":"Procedures","text":""},{"location":"operations/streams/#increase-lambda-concurrency","title":"Increase Lambda Concurrency","text":"<p>Set reserved concurrency:</p> <pre><code>aws lambda put-function-concurrency \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --reserved-concurrent-executions 10\n</code></pre> <p>Check current concurrency:</p> <pre><code>aws lambda get-function-concurrency \\\n  --function-name ZAEL-&lt;name&gt;-aggregator\n</code></pre> <p>Remove concurrency limit (use account default):</p> <pre><code>aws lambda delete-function-concurrency \\\n  --function-name ZAEL-&lt;name&gt;-aggregator\n</code></pre>"},{"location":"operations/streams/#adjust-batch-size","title":"Adjust Batch Size","text":"<p>Get current mapping UUID:</p> <pre><code>MAPPING_UUID=$(aws lambda list-event-source-mappings \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --query 'EventSourceMappings[0].UUID' \\\n  --output text)\n\necho \"Mapping UUID: $MAPPING_UUID\"\n</code></pre> <p>Reduce batch size (process fewer records per invocation):</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --batch-size 50\n</code></pre> <p>Increase batch size (higher throughput, higher latency):</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --batch-size 100\n</code></pre> <p>Adjust batch window (wait for more records):</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --maximum-batching-window-in-seconds 5\n</code></pre>"},{"location":"operations/streams/#shard-scaling","title":"Shard Scaling","text":"<p>DynamoDB Streams automatically scales shards based on table throughput.</p> <p>Check shard count:</p> <pre><code>aws dynamodbstreams describe-stream \\\n  --stream-arn $(aws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n    --query 'Table.LatestStreamArn' --output text) \\\n  --query 'StreamDescription.Shards | length(@)'\n</code></pre> <p>Rule of thumb: Lambda concurrency should be &gt;= shard count for optimal processing.</p> <p>If you have 10 shards but only 5 concurrent Lambda executions, processing will lag.</p>"},{"location":"operations/streams/#enable-parallelization-factor","title":"Enable Parallelization Factor","text":"<p>Process multiple batches from the same shard concurrently:</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --parallelization-factor 2\n</code></pre> <p>Valid values: 1-10 (default: 1)</p> <p>Ordering</p> <p>Increasing parallelization factor may result in out-of-order processing within a shard. This is acceptable for usage aggregation but may not be suitable for all use cases.</p>"},{"location":"operations/streams/#verify-stream-health","title":"Verify Stream Health","text":"<p>Check stream is enabled:</p> <pre><code>aws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n  --query 'Table.StreamSpecification'\n</code></pre> <p>Expected output: <pre><code>{\n    \"StreamEnabled\": true,\n    \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n}\n</code></pre></p> <p>Check event source mapping is active:</p> <pre><code>aws lambda list-event-source-mappings \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --query 'EventSourceMappings[0].State'\n</code></pre> <p>Expected output: <code>\"Enabled\"</code></p>"},{"location":"operations/streams/#monitor-after-changes","title":"Monitor After Changes","text":"<p>After tuning, monitor for 15-30 minutes:</p> <pre><code># Watch IteratorAge\nwatch -n 30 \"aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name IteratorAge \\\n  --dimensions Name=FunctionName,Value=ZAEL-&lt;name&gt;-aggregator \\\n  --start-time \\$(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time \\$(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum \\\n  --query 'Datapoints | sort_by(@, &amp;Timestamp) | [-1].Maximum'\"\n</code></pre>"},{"location":"operations/streams/#tuning-guidelines","title":"Tuning Guidelines","text":"Scenario Batch Size Concurrency Parallelization Low volume (&lt; 100 req/s) 100 2 1 Medium volume (100-1000 req/s) 100 5-10 1 High volume (&gt; 1000 req/s) 50-100 10+ 2 Real-time requirements 10-50 10+ 2-5"},{"location":"operations/streams/#related","title":"Related","text":"<ul> <li>Lambda Operations - Lambda errors and duration issues</li> <li>DynamoDB Operations - Throttling affecting stream processing</li> <li>Monitoring Guide - CloudWatch dashboards for streams</li> </ul>"},{"location":"operations/version/","title":"Version Management","text":"<p>This guide covers version compatibility issues and upgrade procedures for zae-limiter.</p>"},{"location":"operations/version/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Version Issue]) --&gt; Q1{What's happening?}      Q1 --&gt;|VersionMismatchError| A1[Lambda needs update]     Q1 --&gt;|IncompatibleSchemaError| A2[Schema migration required]     Q1 --&gt;|Minimum client error| A3[Upgrade pip package]     Q1 --&gt;|Planning upgrade| A4[Follow upgrade procedure]      A1 --&gt; CMD1[\"zae-limiter upgrade --name X\"]     A2 --&gt; CMD2[Follow migrations guide]     A3 --&gt; CMD3[\"pip install --upgrade zae-limiter\"]     A4 --&gt; PROC[Pre-upgrade checklist]      CMD1 --&gt; VERIFY     CMD2 --&gt; VERIFY     CMD3 --&gt; VERIFY     VERIFY([Verify: zae-limiter check])      click A1 \"#versionmismatcherror\" \"Version mismatch details\"     click A2 \"#incompatibleschemaerror\" \"Schema error details\"     click CMD1 \"#upgrade-procedure\" \"Upgrade steps\"     click CMD2 \"../migrations/\" \"Migration guide\"     click A4 \"#upgrade-procedure\" \"Upgrade checklist\"     click VERIFY \"#verification\" \"Verify upgrade\""},{"location":"operations/version/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/version/#symptoms","title":"Symptoms","text":"<ul> <li><code>VersionMismatchError</code> exception raised</li> <li><code>IncompatibleSchemaError</code> exception raised</li> <li>CLI commands fail with version errors</li> <li>Rate limiter initialization fails</li> </ul>"},{"location":"operations/version/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check compatibility with CLI:</p> <pre><code>zae-limiter check --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>View detailed version information:</p> <pre><code>zae-limiter version --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Query version record directly:</p> <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"SYSTEM#\"}, \"SK\": {\"S\": \"#VERSION\"}}'\n</code></pre>"},{"location":"operations/version/#versionmismatcherror","title":"VersionMismatchError","text":"<p>Cause: Client library version differs from deployed Lambda version.</p> <p>Example error: <pre><code>VersionMismatchError: Version mismatch: client=1.2.0, schema=1.0.0, lambda=1.0.0.\nLambda update available.\n</code></pre></p> <p>Solution: Upgrade Lambda to match client:</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Or programmatically:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\n# Auto-update Lambda on initialization\nlimiter = RateLimiter(\n    name=\"&lt;name&gt;\",\n    region=\"&lt;region&gt;\",\n    stack_options=StackOptions(),  # Enables auto-update\n)\n</code></pre>"},{"location":"operations/version/#incompatibleschemaerror","title":"IncompatibleSchemaError","text":"<p>Cause: Major version difference requiring schema migration.</p> <p>Example error: <pre><code>IncompatibleSchemaError: Incompatible schema: client 2.0.0 is not compatible\nwith schema 1.0.0. Migration required.\n</code></pre></p> <p>Solution: Follow the Migration Guide to upgrade the schema:</p> <ol> <li>Create a backup</li> <li>Run migration</li> <li>Update client</li> </ol> <pre><code># Create backup before migration\naws dynamodb create-backup \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --backup-name \"pre-migration-$(date +%Y%m%d)\"\n</code></pre> <p>Then follow the migration procedures in the Migration Guide.</p>"},{"location":"operations/version/#minimum-client-version-error","title":"Minimum Client Version Error","text":"<p>Cause: Infrastructure requires a newer client version.</p> <p>Solution: Upgrade the client library:</p> <pre><code>pip install --upgrade zae-limiter\n</code></pre>"},{"location":"operations/version/#upgrade-procedure","title":"Upgrade Procedure","text":""},{"location":"operations/version/#pre-upgrade-checklist","title":"Pre-upgrade Checklist","text":"<p>Before upgrading, verify the following:</p> <ul> <li>[ ] Check current version: <code>zae-limiter version --name &lt;name&gt;</code></li> <li>[ ] Check compatibility: <code>zae-limiter check --name &lt;name&gt;</code></li> <li>[ ] Review release notes for breaking changes</li> <li>[ ] Verify PITR is enabled for rollback capability</li> <li>[ ] Schedule maintenance window (if major upgrade)</li> <li>[ ] Notify stakeholders</li> </ul>"},{"location":"operations/version/#upgrade-execution","title":"Upgrade Execution","text":"<p>Standard upgrade (Lambda + client):</p> <pre><code># Step 1: Upgrade client library\npip install --upgrade zae-limiter\n\n# Step 2: Update infrastructure\nzae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt;\n\n# Step 3: Verify\nzae-limiter check --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Lambda-only upgrade:</p> <pre><code># Update Lambda without schema changes\nzae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre> <p>Force upgrade (skip compatibility check):</p> <p>Use with caution</p> <p>Only use <code>--force</code> when you understand the implications.</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --force\n</code></pre>"},{"location":"operations/version/#post-upgrade-verification","title":"Post-upgrade Verification","text":"<p>After upgrading, verify the system is healthy:</p> <ol> <li> <p>Check version alignment: <pre><code>zae-limiter version --name &lt;name&gt;\n</code></pre></p> </li> <li> <p>Run smoke tests: <pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(name=\"&lt;name&gt;\", region=\"&lt;region&gt;\")\n\n# Test basic operation\nasync with limiter.acquire(\n    entity_id=\"test-entity\",\n    resource=\"test\",\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    consume={\"rpm\": 1},\n):\n    print(\"Rate limiting working\")\n</code></pre></p> </li> <li> <p>Monitor for 15 minutes:</p> </li> <li>Check Lambda error rate in CloudWatch</li> <li>Verify usage snapshots are updating</li> <li>Watch for unexpected exceptions in application logs</li> </ol>"},{"location":"operations/version/#rollback","title":"Rollback","text":"<p>If issues occur after upgrade, see Recovery &amp; Rollback.</p>"},{"location":"operations/version/#related","title":"Related","text":"<ul> <li>Migration Guide - Schema versioning and migration procedures</li> <li>Recovery &amp; Rollback - Emergency rollback procedures</li> <li>CLI Reference - Full CLI command documentation</li> </ul>"}]}