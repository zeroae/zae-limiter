{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"","text":"<p>A rate limiting library backed by DynamoDB using the token bucket algorithm.</p>"},{"location":"#overview","title":"Overview","text":"<p>zae-limiter excels at rate limiting scenarios where:</p> <ul> <li>Multiple limits are tracked per call (requests per minute, tokens per minute)</li> <li>Consumption is unknown upfront \u2014 adjust limits after the operation completes</li> <li>Hierarchical limits exist (API key \u2192 project, tenant \u2192 user)</li> <li>Cost matters \u2014 ~$0.75/1M requests (details)</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Token Bucket Algorithm - Precise rate limiting with configurable burst capacity</li> <li>Multiple Limits - Track requests per minute, tokens per minute, etc. in a single call</li> <li>Hierarchical Entities - Two-level hierarchy (project \u2192 API keys) with cascade mode</li> <li>Atomic Transactions - Multi-key updates via DynamoDB TransactWriteItems</li> <li>Write-on-Enter with Rollback - Tokens consumed immediately on acquire; compensating writes on exception</li> <li>Stored Limits - Configure per-entity limits in DynamoDB</li> <li>Usage Analytics - Lambda aggregator for hourly/daily usage snapshots</li> <li>Audit Logging - Track entity and limit changes for compliance</li> <li>Async + Sync APIs - First-class async support with sync wrapper</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from zae_limiter import RateLimiter, Limit, StackOptions\n\n# Async rate limiter with declarative infrastructure\nlimiter = RateLimiter(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Declare desired state - CloudFormation ensures it\n)\n\n# Define default limits (can be overridden per-entity)\ndefault_limits = [\n    Limit.per_minute(\"rpm\", 100),\n    Limit.per_minute(\"tpm\", 10_000, burst=50_000),  # Token bucket with burst\n]\n\nasync with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=default_limits,\n    consume={\"rpm\": 1, \"tpm\": 500},  # Estimate tokens upfront\n) as lease:\n    response = await call_llm()\n    # Reconcile actual usage (can go negative for post-hoc adjustment)\n    await lease.adjust(tpm=response.usage.total_tokens - 500)\n    # Tokens written to DynamoDB on enter | Rolled back on exception\n\n# Hierarchical entities: project \u2192 API key\nawait limiter.create_entity(entity_id=\"proj-1\", name=\"Production\")\nawait limiter.set_limits(\"proj-1\", [Limit.per_minute(\"tpm\", 100_000)])\nawait limiter.create_entity(entity_id=\"api-key-456\", parent_id=\"proj-1\", cascade=True)\n\n# cascade is an entity property \u2014 acquire() auto-cascades to parent\n# limits=None auto-resolves from stored config (Entity &gt; Resource &gt; System)\nasync with limiter.acquire(\n    entity_id=\"api-key-456\",\n    resource=\"gpt-4\",\n    limits=None,\n    consume={\"rpm\": 1, \"tpm\": 500},\n) as lease:\n    response = await call_llm()\n</code></pre>"},{"location":"#why-dynamodb","title":"Why DynamoDB?","text":"<ul> <li>Serverless - No infrastructure to manage, 99.99% SLA</li> <li>Regional - Deploy independently per region with low latency</li> <li>Scalable - Handles millions of requests per second</li> <li>Cost-effective - Pay per request, no idle costs</li> <li>Atomic - TransactWriteItems for multi-key consistency</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"Guide Description Getting Started Installation and first deployment Basic Usage Rate limiting patterns and error handling Hierarchical Limits Parent/child entities, cascade mode LLM Integration Token estimation and reconciliation Production Guide Security, monitoring, cost CLI Reference Deploy, status, delete commands"},{"location":"benchmarks/","title":"Benchmark Results","text":"<p>This document tracks benchmark results for performance-sensitive operations in zae-limiter.</p>"},{"location":"benchmarks/#baseline-results","title":"Baseline Results","text":"<p>Baseline benchmarks capture performance before optimization work. Compare new results against baselines to detect performance regressions.</p>"},{"location":"benchmarks/#moto-benchmarks-mocked-dynamodb","title":"Moto Benchmarks (Mocked DynamoDB)","text":"<p>Moto benchmarks run against mocked DynamoDB and measure operation latency without network overhead.</p> <pre><code>Run with:\npytest tests/benchmark/test_operations.py -v --benchmark-json=benchmark-moto.json\n</code></pre> <p>Key Metrics: - <code>acquire_release_single_limit</code>: Single limit acquire/release (baseline) - <code>acquire_release_multiple_limits</code>: Multi-limit overhead (rpm + tpm) - <code>cascade_optimized</code>: BatchGetItem optimization impact - <code>config_lookup_cached</code>: Config cache hit performance - <code>config_lookup_cold</code>: Config cache miss performance</p>"},{"location":"benchmarks/#localstack-benchmarks-realistic-dynamodb","title":"LocalStack Benchmarks (Realistic DynamoDB)","text":"<p>LocalStack benchmarks run against an emulated DynamoDB including realistic network latency.</p> <pre><code>Run with:\ndocker compose up -d\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\npytest tests/benchmark/test_localstack.py -v --benchmark-json=benchmark-localstack.json\n</code></pre> <p>Key Metrics: - <code>acquire_release_localstack</code>: Basic acquire with realistic latency - <code>cascade_with_batchgetitem_optimization</code>: Cascade using optimized pattern - <code>cascade_with_config_cache_optimization</code>: Combined optimizations</p>"},{"location":"benchmarks/#performance-targets","title":"Performance Targets","text":"Scenario Metric Target Single limit acquire p50 latency No regression Single limit acquire p95 latency No regression Single limit acquire p99 latency &lt; 2x baseline Cascade (BatchGetItem) p50 latency 10-20% reduction vs sequential Config lookup (cached) p50 latency &lt; 5ms overhead Config lookup (cold) p50 latency &lt; 20ms overhead"},{"location":"benchmarks/#historical-comparison","title":"Historical Comparison","text":"<p>Benchmark JSON files are stored alongside this document for version-to-version comparison:</p> <ul> <li><code>benchmark-v0.11.0.json</code> - Baseline before config caching and cascade optimization</li> <li><code>benchmark-v0.12.0.json</code> - After centralized config implementation (v0.5.0 feature)</li> <li><code>benchmark-v0.12.1.json</code> - After cascade BatchGetItem optimization (issue #133)</li> </ul>"},{"location":"benchmarks/#benchmark-organization","title":"Benchmark Organization","text":"<pre><code>tests/benchmark/\n\u251c\u2500\u2500 conftest.py           # Shared fixtures (CapacityCounter, benchmark_entities)\n\u251c\u2500\u2500 test_operations.py    # Moto benchmarks (fast, no Docker)\n\u251c\u2500\u2500 test_localstack.py    # LocalStack benchmarks (realistic latency)\n\u251c\u2500\u2500 test_latency.py       # p50/p95/p99 latency breakdown\n\u251c\u2500\u2500 test_throughput.py    # Sequential/concurrent throughput\n\u251c\u2500\u2500 test_capacity.py      # DynamoDB RCU/WCU tracking\n\u2514\u2500\u2500 test_aws.py           # Real AWS benchmarks (production metrics)\n</code></pre>"},{"location":"benchmarks/#running-benchmarks","title":"Running Benchmarks","text":""},{"location":"benchmarks/#unitmoto-benchmarks-fast","title":"Unit/Moto Benchmarks (Fast)","text":"<pre><code># All moto benchmarks\nuv run pytest tests/benchmark/test_operations.py -v --benchmark-json=bench.json\n\n# Specific benchmark class\nuv run pytest tests/benchmark/test_operations.py::TestConfigLookupBenchmarks -v\n\n# Compare against baseline\nuv run pytest tests/benchmark/test_operations.py --benchmark-compare=bench-baseline.json\n</code></pre>"},{"location":"benchmarks/#localstack-benchmarks-requires-docker","title":"LocalStack Benchmarks (Requires Docker)","text":"<pre><code># Start LocalStack\ndocker compose up -d\n\n# Run LocalStack benchmarks\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\nuv run pytest tests/benchmark/test_localstack.py -v --benchmark-json=bench-ls.json\n\n# Stop LocalStack\ndocker compose down\n</code></pre>"},{"location":"benchmarks/#real-aws-benchmarks-optional","title":"Real AWS Benchmarks (Optional)","text":"<pre><code># Run against real AWS (costs money!)\nAWS_PROFILE=zeroae-code/AWSPowerUserAccess \\\n  uv run pytest tests/benchmark/test_aws.py --run-aws -v --benchmark-json=bench-aws.json\n</code></pre>"},{"location":"benchmarks/#interpreting-results","title":"Interpreting Results","text":""},{"location":"benchmarks/#pytest-benchmark-output","title":"Pytest-Benchmark Output","text":"<pre><code>benchmark: 5 tests\n\ntest_operations.py::TestAcquireReleaseBenchmarks::test_acquire_release_single_limit\n  mean \u00b1 std dev: 1.23 \u00b1 0.15 ms [min: 0.98 ms, max: 1.65 ms]\n  \"... 1000 rounds\"\n</code></pre> <p>Columns: - <code>mean</code>: Average latency - <code>std dev</code>: Standard deviation (consistency) - <code>min/max</code>: Range of observed values - Rounds: Number of iterations</p>"},{"location":"benchmarks/#comparing-baselines","title":"Comparing Baselines","text":"<pre><code># Generate JSON from new run\npytest tests/benchmark/test_operations.py -v --benchmark-json=new.json\n\n# Compare against saved baseline\npytest tests/benchmark/test_operations.py -v --benchmark-compare=baseline.json\n</code></pre> <p>Output interpretation: - <code>PASS</code>: Performance stable (no regression) - <code>FAIL</code>: Performance degraded (potential issue) - <code>5.50%</code> or <code>+5.50%</code>: Performance improved by 5.5% - <code>-5.50%</code>: Performance degraded by 5.5%</p>"},{"location":"benchmarks/#adding-new-benchmarks","title":"Adding New Benchmarks","text":"<p>When adding new benchmarks:</p> <ol> <li>Create test in appropriate file (<code>test_operations.py</code>, <code>test_localstack.py</code>, etc.)</li> <li>Use <code>@pytest.mark.benchmark</code> marker</li> <li>Include clear docstring explaining what's measured</li> <li>Compare against related baseline test</li> <li>Run benchmark locally: <code>pytest tests/benchmark/test_*.py -v --benchmark-json=bench.json</code></li> <li>Commit JSON baseline for future comparison</li> <li>Update this document with new metrics and targets</li> </ol>"},{"location":"benchmarks/#markers-and-filters","title":"Markers and Filters","text":"Marker Purpose Filter <code>@pytest.mark.benchmark</code> Benchmark test <code>pytest -m benchmark</code> <code>@pytest.mark.integration</code> Requires LocalStack <code>pytest -m integration</code> <code>@pytest.mark.slow</code> &gt; 30s runtime <code>pytest -m \"not slow\"</code>"},{"location":"benchmarks/#ci-integration","title":"CI Integration","text":"<p>Benchmarks can be integrated into CI/CD:</p> <pre><code># .github/workflows/benchmark.yml (optional)\n- name: Run benchmarks\n  run: |\n    docker compose up -d\n    pytest tests/benchmark/ -v --benchmark-json=results.json\n    docker compose down\n</code></pre> <p>Note: Consider benchmark flakiness before enabling in CI (network latency varies).</p>"},{"location":"cli/","title":"CLI Reference","text":""},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#zae-limiter","title":"zae-limiter","text":"<p>zae-limiter infrastructure management CLI.</p> <p>Usage:</p> <pre><code>zae-limiter [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--version</code> boolean Show the version and exit. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>audit: Audit log commands.</li> <li>cfn-template: Export CloudFormation template for custom deployment.</li> <li>check: Check infrastructure compatibility without modifying.</li> <li>delete: Delete CloudFormation stack and all resources.</li> <li>deploy: Deploy CloudFormation stack with DynamoDB table and Lambda aggregator.</li> <li>entity: Entity-level limit configuration.</li> <li>lambda-export: Export Lambda deployment package for custom deployment.</li> <li>list: List all deployed rate limiter instances in the region.</li> <li>loadtest: Load testing commands for zae-limiter.</li> <li>local: Local development with LocalStack.</li> <li>namespace: Namespace management commands.</li> <li>resource: Resource-level default limit configuration.</li> <li>status: Get comprehensive status of rate limiter infrastructure.</li> <li>system: System-level default limit configuration.</li> <li>upgrade: Upgrade infrastructure to match client version.</li> <li>usage: Usage snapshot commands.</li> <li>version: Show infrastructure version information.</li> </ul>"},{"location":"cli/#zae-limiter-audit","title":"zae-limiter audit","text":"<p>Audit log commands.</p> <p>Query audit events for entities. Events track configuration changes like limits_set, entity_created, and entity_deleted.</p> <p>Usage:</p> <pre><code>zae-limiter audit [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>list: List audit events for an entity.</li> </ul>"},{"location":"cli/#zae-limiter-audit-list","title":"zae-limiter audit list","text":"<p>List audit events for an entity.</p> <p>Shows configuration changes like limits_set, entity_created, entity_deleted. Results are ordered by timestamp (newest first).</p> <p>Examples: <pre><code>zae-limiter audit list --entity-id user-123\nzae-limiter audit list --entity-id user-123 --limit 10\n</code></pre></p> <p>Sample Output: <pre><code>Audit Events for: user-123\n\nTimestamp                Action         Principal   Resource\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n2026-01-15T10:30:00Z     limits_set     admin       gpt-4\n2026-01-15T10:25:00Z     entity_created admin       -\n\nTotal: 2 events\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter audit list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--entity-id</code>, <code>-e</code> text Entity ID to query audit events for <code>Sentinel.UNSET</code> <code>--limit</code>, <code>-l</code> integer Maximum number of events to return (default: 100) <code>100</code> <code>--start-event-id</code> text Event ID to start after (for pagination) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-cfn-template","title":"zae-limiter cfn-template","text":"<p>Export CloudFormation template for custom deployment.</p> <p>Outputs the raw CloudFormation YAML template for manual deployment, integration with CDK/Terraform, or customization.</p> <p>Examples: <pre><code># Export to file\nzae-limiter cfn-template --output template.yaml\n\n# Pipe to stdout\nzae-limiter cfn-template &gt; template.yaml\n\n# View in pager\nzae-limiter cfn-template | less\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter cfn-template [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--output</code>, <code>-o</code> path Output file (default: stdout) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-check","title":"zae-limiter check","text":"<p>Check infrastructure compatibility without modifying.</p> <p>Verifies that the client version is compatible with the deployed infrastructure. Read-only operation - does not change anything.</p> <p>Examples: <pre><code>zae-limiter check --name my-app --region us-east-1\nzae-limiter check --endpoint-url http://localhost:4566\n</code></pre></p> <p>Sample Output: <pre><code>Compatibility Check\n====================\n\nClient:      0.6.0\nSchema:      0.6.0\nLambda:      0.6.0\n\nResult: COMPATIBLE\n\nClient and infrastructure are fully compatible.\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter check [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-delete","title":"zae-limiter delete","text":"<p>Delete CloudFormation stack and all resources.</p> <p>Removes the DynamoDB table, Lambda function, IAM roles, and all associated resources. This action cannot be undone - all data will be permanently lost.</p> <p>Examples: <pre><code># Delete with confirmation prompt\nzae-limiter delete --name my-app --region us-east-1\n\n# Skip confirmation (for scripts)\nzae-limiter delete --name my-app --yes\n\n# Delete without waiting\nzae-limiter delete --name my-app --no-wait\n</code></pre></p> <p>Data Loss</p> <p>Deleting a stack removes the DynamoDB table and all its data. This action cannot be undone.</p> <p>Usage:</p> <pre><code>zae-limiter delete [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name <code>Sentinel.UNSET</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--wait</code> / <code>--no-wait</code> boolean Wait for stack deletion to complete <code>True</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-deploy","title":"zae-limiter deploy","text":"<p>Deploy CloudFormation stack with DynamoDB table and Lambda aggregator.</p> <p>Creates or updates infrastructure including DynamoDB table, Lambda aggregator for usage snapshots, CloudWatch alarms, and IAM roles. The stack is idempotent - running deploy again updates existing resources.</p> <p>Examples: <pre><code># Basic deployment\nzae-limiter deploy --name my-app --region us-east-1\n\n# Production with deletion protection and tracing\nzae-limiter deploy --name prod --region us-east-1 \\\n    --enable-deletion-protection --enable-tracing\n\n# Without Lambda aggregator (table only)\nzae-limiter deploy --name simple --no-aggregator\n\n# LocalStack development\nzae-limiter deploy --name dev \\\n    --endpoint-url http://localhost:4566\n\n# Enterprise with permission boundary\nzae-limiter deploy --name prod \\\n    --permission-boundary arn:aws:iam::aws:policy/PowerUserAccess \\\n    --role-name-format \"pb-{}-PowerUser\"\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter deploy [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--snapshot-windows</code> text Comma-separated list of snapshot windows <code>hourly,daily</code> <code>--usage-retention-days</code> integer Number of days to retain usage snapshots <code>90</code> <code>--audit-retention-days</code> integer Number of days to retain audit records (default: 90) <code>90</code> <code>--enable-aggregator</code> / <code>--no-aggregator</code> boolean Deploy Lambda aggregator for usage snapshots <code>True</code> <code>--pitr-recovery-days</code> integer Point-in-Time Recovery period in days (1-35, default: AWS default of 35) <code>Sentinel.UNSET</code> <code>--log-retention-days</code> choice (<code>1</code> | <code>3</code> | <code>5</code> | <code>7</code> | <code>14</code> | <code>30</code> | <code>60</code> | <code>90</code> | <code>120</code> | <code>150</code> | <code>180</code> | <code>365</code> | <code>400</code> | <code>545</code> | <code>731</code> | <code>1096</code> | <code>1827</code> | <code>2192</code> | <code>2557</code> | <code>2922</code> | <code>3288</code> | <code>3653</code>) Number of days to retain Lambda logs (CloudWatch standard retention periods) <code>30</code> <code>--lambda-timeout</code> integer range (between <code>1</code> and <code>900</code>) Lambda timeout in seconds (1-900, default: 60) <code>60</code> <code>--lambda-memory</code> integer range (between <code>128</code> and <code>3008</code>) Lambda memory size in MB (128-3008, default: 256) <code>256</code> <code>--enable-alarms</code> / <code>--no-alarms</code> boolean Deploy CloudWatch alarms for monitoring (default: enabled) <code>True</code> <code>--alarm-sns-topic</code> text SNS topic ARN for alarm notifications (optional) None <code>--lambda-duration-threshold-pct</code> integer range (between <code>1</code> and <code>100</code>) Lambda duration alarm threshold as percentage of timeout (1-100, default: 80) <code>80</code> <code>--wait</code> / <code>--no-wait</code> boolean Wait for stack creation to complete <code>True</code> <code>--permission-boundary</code> text IAM permission boundary for Lambda role (policy name or full ARN) None <code>--role-name-format</code> text Format template for role name. Use {} as placeholder for default name. Example: 'pb-{}' produces 'pb-mystack-aggr'. None <code>--policy-name-format</code> text Format template for managed policy name. Use {} as placeholder for default name. Example: 'pb-{}' produces 'pb-mystack-app'. None <code>--enable-audit-archival</code> / <code>--no-audit-archival</code> boolean Archive expired audit events to S3 (default: enabled) <code>True</code> <code>--audit-archive-glacier-days</code> integer range (between <code>1</code> and <code>3650</code>) Days before transitioning audit archives to Glacier Instant Retrieval (default: 90) <code>90</code> <code>--enable-tracing</code> / <code>--no-tracing</code> boolean Enable AWS X-Ray tracing for Lambda aggregator (default: disabled) <code>False</code> <code>--create-iam-roles</code> / <code>--no-create-iam-roles</code> boolean Create App/Admin/ReadOnly IAM roles (default: disabled). Policies always created. <code>False</code> <code>--iam</code> / <code>--no-iam</code> boolean Create IAM resources (policies, roles). --no-iam skips all IAM. <code>True</code> <code>--aggregator-role-arn</code> text Use existing IAM role ARN for Lambda aggregator (enables aggregator with --no-iam). None <code>--enable-deletion-protection</code> / <code>--no-deletion-protection</code> boolean Enable DynamoDB table deletion protection (default: disabled) <code>False</code> <code>--tag</code>, <code>-t</code> text User-defined tag in KEY=VALUE format. Can be specified multiple times. <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-entity","title":"zae-limiter entity","text":"<p>Entity-level limit configuration.</p> <p>Manage entities (users, API keys, projects) and their custom limits. Entity limits have highest priority, overriding resource and system defaults.</p> <p>Usage:</p> <pre><code>zae-limiter entity [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>create: Create a new entity.</li> <li>delete-limits: Delete limits for a specific entity and resource.</li> <li>get-limits: Get limits for a specific entity and resource.</li> <li>list: List entities with custom limit configurations.</li> <li>list-resources: List resources with entity-level custom limit configurations.</li> <li>set-limits: Set limits for a specific entity and resource.</li> <li>show: Show details for an entity.</li> </ul>"},{"location":"cli/#zae-limiter-entity-create","title":"zae-limiter entity create","text":"<p>Create a new entity.</p> <p>ENTITY_ID is the unique identifier for the entity (e.g., 'user-123', 'api-key-abc').</p> <p>Examples: <pre><code># Create a standalone entity\nzae-limiter entity create user-123\n\n# Create with display name\nzae-limiter entity create api-key-abc --display-name \"Production API\"\n\n# Create with parent and cascade\nzae-limiter entity create user-123 --parent org-456 --cascade\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter entity create [OPTIONS] ENTITY_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--display-name</code> text Human-readable name (defaults to entity_id) None <code>--parent</code> text Parent entity ID (for hierarchical limits) None <code>--cascade</code> / <code>--no-cascade</code> boolean Enable cascade: acquire() also consumes from parent entity <code>False</code> <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-entity-delete-limits","title":"zae-limiter entity delete-limits","text":"<p>Delete limits for a specific entity and resource.</p> <p>ENTITY_ID is the entity to delete limits from (e.g., 'user-123', 'api-key-abc').</p> <p>Examples: <pre><code># Delete with confirmation\nzae-limiter entity delete-limits user-premium --resource gpt-4\n\n# Skip confirmation\nzae-limiter entity delete-limits user-premium -r gpt-4 --yes\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter entity delete-limits [OPTIONS] ENTITY_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--resource</code>, <code>-r</code> text Resource name (e.g., 'gpt-4', 'default' for all resources). Default: default <code>_default_</code> <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-entity-get-limits","title":"zae-limiter entity get-limits","text":"<p>Get limits for a specific entity and resource.</p> <p>ENTITY_ID is the entity to query (e.g., 'user-123', 'api-key-abc').</p> <p>Examples: <pre><code>zae-limiter entity get-limits user-premium --resource gpt-4\nzae-limiter entity get-limits api-key-123 -r claude-3\n</code></pre></p> <p>Sample Output: <pre><code>Limits for entity 'user-premium' on resource 'gpt-4':\n  rpm: 1000/min (burst: 1000)\n  tpm: 100000/min (burst: 100000)\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter entity get-limits [OPTIONS] ENTITY_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--resource</code>, <code>-r</code> text Resource name (e.g., 'gpt-4', 'default' for all resources). Default: default <code>_default_</code> <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-entity-list","title":"zae-limiter entity list","text":"<p>List entities with custom limit configurations.</p> <p>Uses GSI3 sparse index for efficient queries.</p> <p>Examples: <pre><code># List entities with custom limits for gpt-4\nzae-limiter entity list --with-custom-limits gpt-4\n\n# List with a maximum of 10 results\nzae-limiter entity list --with-custom-limits claude-3 --limit 10\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter entity list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--with-custom-limits</code> text List entities with custom limits for this resource <code>Sentinel.UNSET</code> <code>--limit</code> integer Maximum number of entities to return None <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-entity-list-resources","title":"zae-limiter entity list-resources","text":"<p>List resources with entity-level custom limit configurations.</p> <p>Shows which resources have at least one entity with custom limits. Uses the entity config resources registry for fast O(1) lookup.</p> <p>Examples: <pre><code>zae-limiter entity list-resources\nzae-limiter entity list-resources --name prod\n</code></pre></p> <p>Sample Output: <pre><code>Resources with entity-level custom limits:\n  gpt-4\n  claude-3\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter entity list-resources [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-entity-set-limits","title":"zae-limiter entity set-limits","text":"<p>Set limits for a specific entity and resource.</p> <p>ENTITY_ID is the entity to configure (e.g., 'user-123', 'api-key-abc'). Entity limits override resource and system defaults.</p> <p>Examples: <pre><code># Set premium user limits for gpt-4\nzae-limiter entity set-limits user-premium -r gpt-4 -l tpm:100000 -l rpm:1000\n\n# Set limits with burst\nzae-limiter entity set-limits api-key-123 -r claude-3 -l tpm:50000:75000\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter entity set-limits [OPTIONS] ENTITY_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--resource</code>, <code>-r</code> text Resource name (e.g., 'gpt-4', 'default' for all resources). Default: default <code>_default_</code> <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--limit</code>, <code>-l</code> text Limit: 'name:capacity[:burst]' (repeatable). Example: -l tpm:10000 -l rpm:500 <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-entity-show","title":"zae-limiter entity show","text":"<p>Show details for an entity.</p> <p>ENTITY_ID is the entity to query (e.g., 'user-123', 'api-key-abc').</p> <p>Examples: <pre><code>zae-limiter entity show user-123\nzae-limiter entity show api-key-abc --name prod\n</code></pre></p> <p>Sample Output: <pre><code>Entity: user-123\n  Name:       Alice Smith\n  Parent:     org-456\n  Cascade:    True\n  Created:    2026-01-15T10:30:00Z\n  Metadata:   {'tier': 'premium'}\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter entity show [OPTIONS] ENTITY_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-lambda-export","title":"zae-limiter lambda-export","text":"<p>Export Lambda deployment package for custom deployment.</p> <p>Creates a ZIP file containing the Lambda aggregator code for manual deployment or inspection. Useful for custom deployment pipelines.</p> <p>Examples: <pre><code># Export Lambda package\nzae-limiter lambda-export --output lambda.zip\n\n# Show package info without building\nzae-limiter lambda-export --info\n\n# Overwrite existing file\nzae-limiter lambda-export --force\n</code></pre></p> <p>Sample Output (--info): <pre><code>Lambda Package Information\n==========================\n\nPackage path:      /path/to/zae_limiter_aggregator\nPython files:      4\nUncompressed size: 24.5 KB\nHandler:           zae_limiter_aggregator.handler.handler\nDependencies:      1\n  - aws-lambda-powertools\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter lambda-export [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--output</code>, <code>-o</code> path Output file path (default: lambda.zip) <code>lambda.zip</code> <code>--info</code> boolean Show package information without building <code>False</code> <code>--force</code>, <code>-f</code> boolean Overwrite existing file without prompting <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-list","title":"zae-limiter list","text":"<p>List all deployed rate limiter instances in the region.</p> <p>Discovers stacks by CloudFormation tags. Shows name, status, version, and creation date for each instance.</p> <p>Examples: <pre><code>zae-limiter list --region us-east-1\nzae-limiter list --endpoint-url http://localhost:4566\n</code></pre></p> <p>Sample Output: <pre><code>Rate Limiter Instances (us-east-1)\n\nName        Status             Version   Created\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nmy-app      CREATE_COMPLETE    0.6.0     2026-01-15\nprod-api    UPDATE_COMPLETE    0.6.0     2026-01-10\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-loadtest","title":"zae-limiter loadtest","text":"<p>Load testing commands for zae-limiter.</p> <p>Usage:</p> <pre><code>zae-limiter loadtest [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>delete: Delete load test infrastructure.</li> <li>deploy: Deploy load test infrastructure.</li> <li>list: List deployed load test stacks.</li> <li>push: Rebuild and push locustfiles and Lambda code.</li> <li>run: Run a single load test execution.</li> <li>tune: Find optimal per-worker user count via binary search.</li> <li>ui: Open Locust web UI via SSM tunnel.</li> </ul>"},{"location":"cli/#zae-limiter-loadtest-delete","title":"zae-limiter loadtest delete","text":"<p>Delete load test infrastructure.</p> <p>Usage:</p> <pre><code>zae-limiter loadtest delete [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text zae-limiter name <code>Sentinel.UNSET</code> <code>--region</code> text AWS region None <code>--yes</code> boolean Skip confirmation <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-loadtest-deploy","title":"zae-limiter loadtest deploy","text":"<p>Deploy load test infrastructure.</p> <p>Usage:</p> <pre><code>zae-limiter loadtest deploy [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text zae-limiter name None <code>--region</code> text AWS region None <code>--vpc-id</code> text VPC ID for load test resources None <code>--subnet-ids</code> text Comma-separated private subnet IDs None <code>--max-workers</code> integer Maximum Lambda workers (auto-scaling cap) <code>100</code> <code>--users-per-worker</code> integer Max users per Lambda worker for auto-scaling (default: 10) <code>10</code> <code>--min-workers</code> integer Minimum workers to maintain (default: 1) <code>1</code> <code>--startup-lead-time</code> integer Seconds to predict ahead for proactive scaling (default: 20) <code>20</code> <code>--lambda-timeout</code> integer Lambda worker timeout in minutes (default: 5) <code>5</code> <code>--lambda-memory</code> integer Lambda worker memory in MB (CPU scales with memory; 1769 MB = 1 vCPU, default: 1769) <code>1769</code> <code>--capacity-provider</code> choice (<code>FARGATE_SPOT</code> | <code>FARGATE</code>) ECS capacity provider (default: FARGATE_SPOT) <code>FARGATE_SPOT</code> <code>--ssm-endpoint</code> / <code>--no-ssm-endpoint</code> boolean Create VPC endpoints for SSM (not needed if VPC has NAT gateway) <code>False</code> <code>--dynamodb-endpoint</code> / <code>--no-dynamodb-endpoint</code> boolean Create DynamoDB gateway endpoint (auto-discovers route tables) <code>True</code> <code>-C</code> directory Directory containing locustfiles (default: current directory) <code>.</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-loadtest-list","title":"zae-limiter loadtest list","text":"<p>List deployed load test stacks.</p> <p>Usage:</p> <pre><code>zae-limiter loadtest list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--region</code> text AWS region None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-loadtest-push","title":"zae-limiter loadtest push","text":"<p>Rebuild and push locustfiles and Lambda code.</p> <p>Usage:</p> <pre><code>zae-limiter loadtest push [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text zae-limiter name None <code>--region</code> text AWS region None <code>-C</code> directory Directory containing locustfiles (default: current directory) <code>.</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-loadtest-run","title":"zae-limiter loadtest run","text":"<p>Run a single load test execution.</p> <p>Lambda mode (default): Invokes a single Lambda worker in headless mode. Use --workers N to run distributed (Fargate master + Lambda workers).</p> <p>Optionally pass User class names to run specific classes (default: all).</p> <p>Usage:</p> <pre><code>zae-limiter loadtest run [OPTIONS] [USER_CLASSES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text zae-limiter name <code>Sentinel.UNSET</code> <code>--region</code> text AWS region None <code>--users</code> integer Number of simulated users (default: 20) <code>20</code> <code>--duration</code> integer Test duration in seconds (default: 60) <code>60</code> <code>--spawn-rate</code> integer User spawn rate per second (default: 10) <code>10</code> <code>-f</code>, <code>--locustfile</code> text Locustfile path (e.g. locustfiles/max_rps.py) <code>Sentinel.UNSET</code> <code>--cpu</code> integer Override Fargate task CPU units (default from task def) None <code>--memory</code> integer Override Fargate task memory in MB (default from task def) None <code>--port</code> integer Local port for SSM tunnel (Fargate mode) <code>8089</code> <code>--workers</code> integer Number of Lambda workers (implies distributed mode) None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-loadtest-tune","title":"zae-limiter loadtest tune","text":"<p>Find optimal per-worker user count via binary search.</p> <p>Uses Little's Law to binary-search for the optimal per-worker user count by measuring efficiency (baseline_p50 / observed_p50) at different concurrency levels. Lambda-only.</p> <p>Optionally pass User class names to run specific classes (default: all).</p> <p>Usage:</p> <pre><code>zae-limiter loadtest tune [OPTIONS] [USER_CLASSES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text zae-limiter name <code>Sentinel.UNSET</code> <code>--region</code> text AWS region None <code>-f</code>, <code>--locustfile</code> text Locustfile path (e.g. locustfiles/max_rps.py) <code>Sentinel.UNSET</code> <code>--max-users</code> integer Upper bound for binary search (default: 40) <code>40</code> <code>--threshold</code> float Target efficiency ratio (default: 0.80) <code>0.8</code> <code>--step-duration</code> integer Seconds per tuning step (default: 30) <code>30</code> <code>--baseline-duration</code> integer Seconds for baseline phase (default: 60) <code>60</code> <code>--spawn-rate</code> integer User spawn rate per second (default: 10) <code>10</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-loadtest-ui","title":"zae-limiter loadtest ui","text":"<p>Open Locust web UI via SSM tunnel.</p> <p>Usage:</p> <pre><code>zae-limiter loadtest ui [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text zae-limiter name <code>Sentinel.UNSET</code> <code>--region</code> text AWS region None <code>--port</code> integer Local port for Locust UI <code>8089</code> <code>--destroy</code> boolean Stop Fargate on disconnect even if already running <code>False</code> <code>--force</code> boolean Stop existing task and restart with new config <code>False</code> <code>-f</code>, <code>--locustfile</code> text Locustfile path (relative to -C directory used in deploy) <code>Sentinel.UNSET</code> <code>--max-workers</code> integer Override max Lambda workers None <code>--min-workers</code> integer Override minimum workers None <code>--users-per-worker</code> integer Override users per worker ratio None <code>--startup-lead-time</code> integer Override predictive scaling lookahead None <code>--cpu</code> integer Override task CPU units (256, 512, 1024, 2048, 4096) None <code>--memory</code> integer Override task memory in MB None <code>--pool-connections</code> integer Override boto3 connection pool size (default: 1000) None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-local","title":"zae-limiter local","text":"<p>Local development with LocalStack.</p> <p>Requires the [local] extra:</p> <pre><code>pip install 'zae-limiter[local]'\n</code></pre> <p>Usage:</p> <pre><code>zae-limiter local [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>down: Stop LocalStack.</li> <li>env: Output LocalStack environment variables.</li> <li>logs: Show LocalStack container logs.</li> <li>status: Show LocalStack container status.</li> <li>up: Start LocalStack for local development.</li> </ul>"},{"location":"cli/#zae-limiter-local-down","title":"zae-limiter local down","text":"<p>Stop LocalStack.</p> <p>Examples:</p> <pre><code>zae-limiter local down\n</code></pre> <p>Usage:</p> <pre><code>zae-limiter local down [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--docker-host</code> text Docker daemon URL (e.g., unix:///path/to/docker.sock) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-local-env","title":"zae-limiter local env","text":"<p>Output LocalStack environment variables.</p> <p>Prints the environment variables needed to connect to LocalStack. Does not require Docker or a running container.</p> <p>Examples:</p> <pre><code>eval \"$(zae-limiter local env)\"                 # bash/zsh\nzae-limiter local env --format direnv &gt; .envrc  # direnv\nzae-limiter local env --format powershell       # PowerShell\n</code></pre> <p>Usage:</p> <pre><code>zae-limiter local env [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--format</code>, <code>-f</code> choice (<code>eval</code> | <code>direnv</code> | <code>powershell</code>) Output format <code>eval</code> <code>--port</code> integer Host port for LocalStack endpoint <code>4566</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-local-logs","title":"zae-limiter local logs","text":"<p>Show LocalStack container logs.</p> <p>Examples:</p> <pre><code># Show recent logs\nzae-limiter local logs\n\n# Follow logs\nzae-limiter local logs --follow\n\n# Show last 50 lines\nzae-limiter local logs --tail 50\n</code></pre> <p>Usage:</p> <pre><code>zae-limiter local logs [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--docker-host</code> text Docker daemon URL (e.g., unix:///path/to/docker.sock) <code>Sentinel.UNSET</code> <code>--follow</code>, <code>-f</code> boolean Follow log output <code>False</code> <code>--tail</code> integer Number of lines to show from end of logs <code>100</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-local-status","title":"zae-limiter local status","text":"<p>Show LocalStack container status.</p> <p>Examples:</p> <pre><code>zae-limiter local status\n</code></pre> <p>Sample Output:</p> <pre><code>LocalStack: running\nEndpoint:   http://localhost:4566\nHealth:     healthy\nImage:      localstack/localstack:4\nServices:   dynamodb,dynamodbstreams,lambda,cloudformation,...\n\nTo configure your shell:\n  eval \"$(zae-limiter local env)\"                 # bash/zsh\n  zae-limiter local env --format direnv &gt; .envrc  # direnv\n  zae-limiter local env --format powershell       # PowerShell\n</code></pre> <p>Usage:</p> <pre><code>zae-limiter local status [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--docker-host</code> text Docker daemon URL (e.g., unix:///path/to/docker.sock) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-local-up","title":"zae-limiter local up","text":"<p>Start LocalStack for local development.</p> <p>Examples:</p> <pre><code># Start LocalStack\nzae-limiter local up\n\n# Start with deploy instructions\nzae-limiter local up --name my-app\n\n# Use a different port\nzae-limiter local up --port 4567\n</code></pre> <p>Usage:</p> <pre><code>zae-limiter local up [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--docker-host</code> text Docker daemon URL (e.g., unix:///path/to/docker.sock) <code>Sentinel.UNSET</code> <code>--image</code> text LocalStack Docker image <code>localstack/localstack:4</code> <code>--name</code>, <code>-n</code> text Stack name to include in deploy instructions None <code>--port</code> integer Host port to bind LocalStack to <code>4566</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-namespace","title":"zae-limiter namespace","text":"<p>Namespace management commands.</p> <p>Manage multi-tenant namespaces for isolated rate limiting. Each namespace has its own entities, buckets, and configurations.</p> <p>Usage:</p> <pre><code>zae-limiter namespace [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>delete: Soft-delete a namespace (recoverable).</li> <li>list: List all active namespaces with IDs.</li> <li>orphans: List deleted namespaces with orphaned data.</li> <li>purge: Permanently delete all data for a namespace (IRREVERSIBLE).</li> <li>recover: Recover a deleted namespace by its ID.</li> <li>register: Register one or more namespaces.</li> <li>show: Show details for a specific namespace.</li> </ul>"},{"location":"cli/#zae-limiter-namespace-delete","title":"zae-limiter namespace delete","text":"<p>Soft-delete a namespace (recoverable).</p> <p>NAMESPACE_NAME is the namespace to delete (e.g., 'tenant-alpha'). Data items are NOT deleted \u2014 they remain orphaned and can be recovered.</p> <p>Examples: <pre><code>zae-limiter namespace delete tenant-alpha --name my-app --yes\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter namespace delete [OPTIONS] NAMESPACE_NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-namespace-list","title":"zae-limiter namespace list","text":"<p>List all active namespaces with IDs.</p> <p>Examples: <pre><code>zae-limiter namespace list --name my-app\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter namespace list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-namespace-orphans","title":"zae-limiter namespace orphans","text":"<p>List deleted namespaces with orphaned data.</p> <p>Examples: <pre><code>zae-limiter namespace orphans --name my-app\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter namespace orphans [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-namespace-purge","title":"zae-limiter namespace purge","text":"<p>Permanently delete all data for a namespace (IRREVERSIBLE).</p> <p>NAMESPACE_ID is the opaque namespace ID (e.g., 'aB3x_9Qw'). Use 'namespace orphans' to find deleted namespace IDs.</p> <p>Examples: <pre><code>zae-limiter namespace purge aB3x_9Qw --name my-app --yes\n</code></pre></p> <p>Data Loss</p> <p>Purging permanently deletes all entities, buckets, configs, and audit logs in the namespace. This cannot be undone.</p> <p>Usage:</p> <pre><code>zae-limiter namespace purge [OPTIONS] NAMESPACE_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-namespace-recover","title":"zae-limiter namespace recover","text":"<p>Recover a deleted namespace by its ID.</p> <p>NAMESPACE_ID is the opaque namespace ID (e.g., 'aB3x_9Qw'). Use 'namespace orphans' to find deleted namespace IDs.</p> <p>Examples: <pre><code>zae-limiter namespace recover aB3x_9Qw --name my-app\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter namespace recover [OPTIONS] NAMESPACE_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-namespace-register","title":"zae-limiter namespace register","text":"<p>Register one or more namespaces.</p> <p>NAMESPACES are the namespace names to register (e.g., 'tenant-alpha'). Multiple names can be provided for bulk registration.</p> <p>Examples: <pre><code>zae-limiter namespace register tenant-alpha --name my-app\nzae-limiter namespace register tenant-alpha tenant-beta --name my-app\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter namespace register [OPTIONS] NAMESPACES...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-namespace-show","title":"zae-limiter namespace show","text":"<p>Show details for a specific namespace.</p> <p>NAMESPACE_NAME is the namespace to look up (e.g., 'tenant-alpha').</p> <p>Examples: <pre><code>zae-limiter namespace show tenant-alpha --name my-app\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter namespace show [OPTIONS] NAMESPACE_NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-resource","title":"zae-limiter resource","text":"<p>Resource-level default limit configuration.</p> <p>Configure default limits for specific resources (e.g., gpt-4, claude-3). Resource defaults override system defaults but are overridden by entity limits.</p> <p>Usage:</p> <pre><code>zae-limiter resource [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>delete-defaults: Delete default limits for a resource.</li> <li>get-defaults: Get default limits for a resource.</li> <li>list: List all resources with configured defaults.</li> <li>set-defaults: Set default limits for a resource.</li> </ul>"},{"location":"cli/#zae-limiter-resource-delete-defaults","title":"zae-limiter resource delete-defaults","text":"<p>Delete default limits for a resource.</p> <p>RESOURCE_NAME is the resource to delete defaults from (e.g., 'gpt-4', 'claude-3').</p> <p>Examples: <pre><code># Delete with confirmation prompt\nzae-limiter resource delete-defaults gpt-4\n\n# Skip confirmation\nzae-limiter resource delete-defaults gpt-4 --yes\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter resource delete-defaults [OPTIONS] RESOURCE_NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-resource-get-defaults","title":"zae-limiter resource get-defaults","text":"<p>Get default limits for a resource.</p> <p>RESOURCE_NAME is the resource to query (e.g., 'gpt-4', 'claude-3').</p> <p>Examples: <pre><code>zae-limiter resource get-defaults gpt-4\nzae-limiter resource get-defaults claude-3 --name prod\n</code></pre></p> <p>Sample Output: <pre><code>Defaults for resource 'gpt-4':\n  rpm: 500/min (burst: 500)\n  tpm: 50000/min (burst: 50000)\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter resource get-defaults [OPTIONS] RESOURCE_NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-resource-list","title":"zae-limiter resource list","text":"<p>List all resources with configured defaults.</p> <p>Examples: <pre><code>zae-limiter resource list\nzae-limiter resource list --name prod\n</code></pre></p> <p>Sample Output: <pre><code>Resources with configured defaults:\n  gpt-4\n  gpt-3.5-turbo\n  claude-3\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter resource list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-resource-set-defaults","title":"zae-limiter resource set-defaults","text":"<p>Set default limits for a resource.</p> <p>RESOURCE_NAME is the resource to configure (e.g., 'gpt-4', 'claude-3'). Resource defaults override system defaults for this specific resource.</p> <p>Examples: <pre><code># Set TPM and RPM defaults for gpt-4\nzae-limiter resource set-defaults gpt-4 -l tpm:100000 -l rpm:1000\n\n# Set limits with burst capacity\nzae-limiter resource set-defaults claude-3 -l tpm:50000:75000\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter resource set-defaults [OPTIONS] RESOURCE_NAME\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--limit</code>, <code>-l</code> text Limit: 'name:capacity[:burst]' (repeatable). Example: -l tpm:10000 -l rpm:500 <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-status","title":"zae-limiter status","text":"<p>Get comprehensive status of rate limiter infrastructure.</p> <p>Shows connectivity, stack status, version compatibility, table metrics, and IAM role ARNs. Read-only operation - does not modify any resources.</p> <p>Examples: <pre><code>zae-limiter status --name my-app --region us-east-1\nzae-limiter status --name dev --endpoint-url http://localhost:4566\n</code></pre></p> <p>Sample Output: <pre><code>Status: my-app\n==================================================\n\nConnectivity\n  Available:     \u2713 Yes\n  Latency:       42ms\n  Region:        us-east-1\n\nInfrastructure\n  Stack:         CREATE_COMPLETE\n  Table:         ACTIVE\n  Aggregator:    Enabled\n\nVersions\n  Client:        0.6.0\n  Schema:        0.6.0\n  Lambda:        0.6.0\n\nTable Metrics\n  Items:         1,234\n  Size:          256 KB\n\n\u2713 Infrastructure is ready\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter status [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name <code>Sentinel.UNSET</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-system","title":"zae-limiter system","text":"<p>System-level default limit configuration.</p> <p>Configure global defaults that apply to ALL resources unless overridden. System defaults are the lowest priority in the hierarchy.</p> <p>Usage:</p> <pre><code>zae-limiter system [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>delete-defaults: Delete all system-wide default limits and config.</li> <li>get-defaults: Get system-wide default limits and config.</li> <li>set-defaults: Set system-wide default limits.</li> </ul>"},{"location":"cli/#zae-limiter-system-delete-defaults","title":"zae-limiter system delete-defaults","text":"<p>Delete all system-wide default limits and config.</p> <p>Examples: <pre><code># Delete with confirmation prompt\nzae-limiter system delete-defaults\n\n# Skip confirmation\nzae-limiter system delete-defaults --yes\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter system delete-defaults [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-system-get-defaults","title":"zae-limiter system get-defaults","text":"<p>Get system-wide default limits and config.</p> <p>Examples: <pre><code>zae-limiter system get-defaults\nzae-limiter system get-defaults --name prod\n</code></pre></p> <p>Sample Output: <pre><code>System-wide defaults:\n  Limits:\n    rpm: 1000/min (burst: 1000)\n    tpm: 100000/min (burst: 100000)\n  on_unavailable: allow\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter system get-defaults [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-system-set-defaults","title":"zae-limiter system set-defaults","text":"<p>Set system-wide default limits.</p> <p>System defaults apply to ALL resources unless overridden at resource or entity level.</p> <p>Examples: <pre><code># Set global defaults\nzae-limiter system set-defaults -l tpm:10000 -l rpm:100\n\n# Set defaults with unavailability behavior\nzae-limiter system set-defaults -l tpm:10000 --on-unavailable allow\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter system set-defaults [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Stack identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack) <code>Sentinel.UNSET</code> <code>--limit</code>, <code>-l</code> text Limit: 'name:capacity[:burst]' (repeatable). Example: -l tpm:10000 -l rpm:500 <code>Sentinel.UNSET</code> <code>--on-unavailable</code> choice (<code>allow</code> | <code>block</code>) Behavior when DynamoDB is unavailable <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-upgrade","title":"zae-limiter upgrade","text":"<p>Upgrade infrastructure to match client version.</p> <p>Updates Lambda code and version records to match the current client. Use --force to update even when versions already match.</p> <p>Examples: <pre><code># Standard upgrade\nzae-limiter upgrade --name my-app --region us-east-1\n\n# Force Lambda update\nzae-limiter upgrade --name my-app --force\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter upgrade [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--lambda-only</code> boolean Only update Lambda code <code>False</code> <code>--force</code> boolean Force update even if version matches <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-usage","title":"zae-limiter usage","text":"<p>Usage snapshot commands.</p> <p>Query historical usage data aggregated by the Lambda aggregator. Snapshots track token consumption per entity/resource in hourly and daily windows.</p> <p>Usage:</p> <pre><code>zae-limiter usage [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>list: List usage snapshots.</li> <li>summary: Show aggregated usage summary.</li> </ul>"},{"location":"cli/#zae-limiter-usage-list","title":"zae-limiter usage list","text":"<p>List usage snapshots.</p> <p>Query historical token consumption data. Requires either --entity-id or --resource. Use --plot for ASCII chart visualization.</p> <p>Examples: <pre><code>zae-limiter usage list --entity-id user-123\nzae-limiter usage list --resource gpt-4 --window hourly\nzae-limiter usage list --entity-id user-123 --plot\n</code></pre></p> <p>Note</p> <p>Either <code>--entity-id</code> or <code>--resource</code> must be provided.</p> <p>ASCII Charts</p> <p>The <code>--plot</code> flag requires the optional <code>plot</code> extra: <code>pip install 'zae-limiter[plot]'</code></p> <p>Sample Output: <pre><code>Usage Snapshots\n\nWindow Start          Type    Resource  Entity    Events  Counters\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n2026-01-15T10:00:00Z  hourly  gpt-4     user-123  42      tpm=15,000\n2026-01-15T09:00:00Z  hourly  gpt-4     user-123  38      tpm=12,500\n\nTotal: 2 snapshots\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter usage list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--entity-id</code>, <code>-e</code> text Entity ID to query (required unless --resource is provided) <code>Sentinel.UNSET</code> <code>--resource</code>, <code>-r</code> text Resource name filter (required if --entity-id is not provided) <code>Sentinel.UNSET</code> <code>--window</code>, <code>-w</code> choice (<code>hourly</code> | <code>daily</code>) Filter by window type <code>Sentinel.UNSET</code> <code>--start</code> text Start time (ISO format, e.g., 2024-01-01T00:00:00Z) <code>Sentinel.UNSET</code> <code>--end</code> text End time (ISO format, e.g., 2024-01-31T23:59:59Z) <code>Sentinel.UNSET</code> <code>--limit</code>, <code>-l</code> integer Maximum number of snapshots to return (default: 100) <code>100</code> <code>--plot</code>, <code>-p</code> boolean Display as ASCII charts instead of table (requires: pip install 'zae-limiter[plot]') <code>False</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-usage-summary","title":"zae-limiter usage summary","text":"<p>Show aggregated usage summary.</p> <p>Computes total and average consumption across matching snapshots. Useful for billing, reporting, and capacity planning.</p> <p>Examples: <pre><code>zae-limiter usage summary --entity-id user-123\nzae-limiter usage summary --resource gpt-4 --window daily\n</code></pre></p> <p>Note</p> <p>Either <code>--entity-id</code> or <code>--resource</code> must be provided.</p> <p>Sample Output: <pre><code>Usage Summary\n\nEntity:     user-123\nResource:   gpt-4\nSnapshots:  24\nTime Range: 2026-01-14T00:00:00Z to 2026-01-15T23:00:00Z\n\nLimit  Total     Average\n\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nrpm        950      39.58\ntpm    450,000  18,750.00\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter usage summary [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--entity-id</code>, <code>-e</code> text Entity ID to query (required unless --resource is provided) <code>Sentinel.UNSET</code> <code>--resource</code>, <code>-r</code> text Resource name filter (required if --entity-id is not provided) <code>Sentinel.UNSET</code> <code>--window</code>, <code>-w</code> choice (<code>hourly</code> | <code>daily</code>) Filter by window type <code>Sentinel.UNSET</code> <code>--start</code> text Start time (ISO format, e.g., 2024-01-01T00:00:00Z) <code>Sentinel.UNSET</code> <code>--end</code> text End time (ISO format, e.g., 2024-01-31T23:59:59Z) <code>Sentinel.UNSET</code> <code>--namespace</code>, <code>-N</code> text Namespace within the table (default: \"default\") <code>default</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#zae-limiter-version","title":"zae-limiter version","text":"<p>Show infrastructure version information.</p> <p>Displays client version, schema version, and deployed infrastructure versions. Checks compatibility between client and infrastructure.</p> <p>Examples: <pre><code>zae-limiter version --name my-app --region us-east-1\nzae-limiter version --endpoint-url http://localhost:4566\n</code></pre></p> <p>Sample Output: <pre><code>zae-limiter Infrastructure Version\n====================================\n\nClient Version:     0.6.0\nSchema Version:     0.6.0\n\nInfra Schema:       0.6.0\nLambda Version:     0.6.0\nMin Client Version: 0.5.0\n\nStatus: COMPATIBLE\n</code></pre></p> <p>Usage:</p> <pre><code>zae-limiter version [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code>, <code>-n</code> text Resource identifier used as the CloudFormation stack name. Default: limiter <code>limiter</code> <code>--region</code> text AWS region (default: use boto3 defaults) <code>Sentinel.UNSET</code> <code>--endpoint-url</code> text AWS endpoint URL (e.g., http://localhost:4566 for LocalStack, or other AWS-compatible services) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects standard AWS environment variables:</p> Variable Description <code>AWS_ACCESS_KEY_ID</code> AWS access key <code>AWS_SECRET_ACCESS_KEY</code> AWS secret key <code>AWS_SESSION_TOKEN</code> AWS session token <code>AWS_DEFAULT_REGION</code> Default AWS region <code>AWS_PROFILE</code> AWS profile name <code>AWS_ENDPOINT_URL</code> Custom endpoint URL"},{"location":"cli/#exit-codes","title":"Exit Codes","text":"Code Description <code>0</code> Success <code>1</code> General error <code>2</code> Invalid arguments <code>3</code> AWS API error <code>4</code> Stack not found"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you install zae-limiter and set up rate limiting in your application.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"pipuvpoetryconda <pre><code>pip install zae-limiter\n</code></pre> <pre><code>uv pip install zae-limiter\n</code></pre> <pre><code>poetry add zae-limiter\n</code></pre> <pre><code>conda install -c conda-forge zae-limiter\n</code></pre>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<p>zae-limiter creates its own infrastructure automatically.</p>"},{"location":"getting-started/#minimalist","title":"Minimalist","text":"<p>For scripts and quick demos, pass limits inline:</p> <pre><code>from zae_limiter import Repository, RateLimiter, Limit, StackOptions, RateLimitExceeded\n\nrepo = Repository(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Creates infrastructure if needed\n)\nawait repo.ensure_infrastructure()\nlimiter = RateLimiter(repository=repo)\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        consume={\"requests\": 1},\n        limits=[Limit.per_minute(\"requests\", 100)],\n    ) as lease:\n        await do_work()\nexcept RateLimitExceeded as e:\n    print(f\"Rate limited! Retry after {e.retry_after_seconds:.1f}s\")\n\n# Clean up when done\nawait repo.delete_stack()\n</code></pre>"},{"location":"getting-started/#stored-config-recommended","title":"Stored Config (Recommended)","text":"<p>For production, configure limits once and keep application code simple.</p> <p>Step 1: Deploy and configure</p> CLIPython <pre><code># Deploy infrastructure\nzae-limiter deploy --name my-app --region us-east-1\n\n# Configure limits (apply to all entities)\nzae-limiter system set-defaults --name my-app -l rpm:1000 -l tpm:100000\n</code></pre> <pre><code>from zae_limiter import RateLimiter, Limit, StackOptions\n\nlimiter = RateLimiter(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\nawait limiter.set_system_defaults(limits=[\n    Limit.per_minute(\"rpm\", 1000),\n    Limit.per_minute(\"tpm\", 100000),\n])\n</code></pre> <p>Step 2: Use in your application</p> <pre><code>from zae_limiter import Repository, RateLimiter, RateLimitExceeded\n\nrepo = Repository(name=\"my-app\", region=\"us-east-1\")\nlimiter = RateLimiter(repository=repo)\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        consume={\"rpm\": 1, \"tpm\": 500},  # Limits resolved automatically\n    ) as lease:\n        await do_work()\nexcept RateLimitExceeded as e:\n    print(f\"Rate limited! Retry after {e.retry_after_seconds:.1f}s\")\n</code></pre>"},{"location":"getting-started/#infrastructure-persistence","title":"Infrastructure Persistence","text":"<p>When you pass <code>stack_options=StackOptions()</code>, zae-limiter creates real AWS infrastructure via CloudFormation:</p> Resource Purpose Persists? DynamoDB Table Rate limit state, entities, usage Yes - until deleted Lambda Function Usage aggregation Yes - until deleted IAM Role Lambda permissions Yes - until deleted CloudWatch Logs Lambda logs Yes - with retention <p>Infrastructure Outlives Your Python Session</p> <p>This infrastructure persists beyond your Python session. Restarting your application reconnects to existing resources. Rate limit state is preserved across restarts. You only pay when the limiter is used (~$0.75/1M requests).</p>"},{"location":"getting-started/#infrastructure-lifecycle","title":"Infrastructure Lifecycle","text":"<p>Both programmatic API and CLI are fully supported for managing infrastructure.</p>"},{"location":"getting-started/#creating-infrastructure","title":"Creating Infrastructure","text":"ProgrammaticCLI <p>Pass <code>stack_options</code> to declare the desired infrastructure state:</p> <pre><code>limiter = RateLimiter(\n    name=\"my-app\",\n    stack_options=StackOptions(),  # Desired state declaration\n)\n</code></pre> <p>CloudFormation ensures the infrastructure matches your declaration.</p> <pre><code>zae-limiter deploy --name my-app --region us-east-1\n</code></pre> <p>Useful for: CI/CD pipelines, GitOps workflows, infrastructure-as-code.</p>"},{"location":"getting-started/#connecting-to-existing-infrastructure","title":"Connecting to Existing Infrastructure","text":"<p>If you omit <code>stack_options</code>, the limiter connects to existing infrastructure without attempting to create or modify it:</p> <pre><code># Connect only - fails if my-app stack doesn't exist\nlimiter = RateLimiter(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    # No stack_options = connect only, no create/update\n)\n</code></pre> <p>This is useful when infrastructure is managed separately (e.g., via CLI or Terraform).</p> <p>Declarative State Management</p> <p><code>StackOptions</code> declares the desired infrastructure state. If multiple applications use the same limiter name with different settings, CloudFormation will update the stack to match the most recent declaration\u2014similar to how Terraform applies the last-written configuration.</p> <p>To maintain consistent state:</p> <ul> <li>Use identical <code>StackOptions</code> across all clients sharing a limiter</li> <li>Omit <code>stack_options</code> in application code and manage infrastructure externally</li> <li>Use different limiter names for different configurations</li> </ul>"},{"location":"getting-started/#checking-status","title":"Checking Status","text":"ProgrammaticCLI <pre><code>available = await repo.ping()  # Async\n# or\navailable = repo.ping()  # Sync\n\nif available:\n    print(\"Stack is ready\")\nelse:\n    print(\"DynamoDB not reachable\")\n</code></pre> <p>For comprehensive status including CloudFormation details, use the CLI command.</p> <pre><code>zae-limiter status --name my-app --region us-east-1\n</code></pre>"},{"location":"getting-started/#deleting-infrastructure","title":"Deleting Infrastructure","text":"ProgrammaticCLI <pre><code># After you're done with the limiter\nawait repo.delete_stack()  # Async\n# or\nrepo.delete_stack()  # Sync\n</code></pre> <pre><code>zae-limiter delete --name my-app --region us-east-1 --yes\n</code></pre> <p>Data Loss</p> <p>Deleting infrastructure permanently removes all rate limit data, entity configurations, and usage history. This cannot be undone.</p> <p>Deployment Options</p> <p>For organizations requiring strict infrastructure/application separation, see CLI deployment or CloudFormation template export.</p>"},{"location":"getting-started/#understanding-limits","title":"Understanding Limits","text":"<p>Rate limiting in zae-limiter tracks who is making requests, what they're accessing, and how much they can use.</p>"},{"location":"getting-started/#the-core-concepts","title":"The Core Concepts","text":"<p>When you call <code>acquire()</code>, you specify:</p> <ul> <li><code>entity_id</code>: Who is being rate limited (e.g., <code>\"user-123\"</code>, <code>\"api-key-abc\"</code>, <code>\"tenant-xyz\"</code>)</li> <li><code>resource</code>: What they're accessing (e.g., <code>\"gpt-4\"</code>, <code>\"api\"</code>, <code>\"embeddings\"</code>)</li> <li><code>consume</code>: How much capacity this request uses</li> <li><code>limits</code>: The rate limit rules to apply (optional if using stored config)</li> </ul> <p>Each entity has separate buckets per resource. A user rate limited on <code>\"gpt-4\"</code> can still access <code>\"gpt-3.5-turbo\"</code>:</p> <pre><code># User 123 accessing GPT-4 - tracked separately from GPT-3.5\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",        # Bucket: user-123 + gpt-4\n    consume={\"rpm\": 1},\n    limits=[Limit.per_minute(\"rpm\", 10)],\n) as lease:\n    ...\n\n# Same user, different resource - separate bucket\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-3.5-turbo\",  # Bucket: user-123 + gpt-3.5-turbo\n    consume={\"rpm\": 1},\n    limits=[Limit.per_minute(\"rpm\", 100)],\n) as lease:\n    ...\n</code></pre>"},{"location":"getting-started/#defining-limits","title":"Defining Limits","text":"<p>A <code>Limit</code> defines a rate limit using the token bucket algorithm:</p> <pre><code># 100 requests per minute\nLimit.per_minute(\"rpm\", 100)\n\n# 10,000 tokens per minute with 15,000 burst capacity\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n\n# 1,000 requests per hour\nLimit.per_hour(\"rph\", 1_000)\n\n# Custom: 50 requests per 30 seconds\nLimit.custom(\"requests\", capacity=50, refill_amount=50, refill_period_seconds=30)\n</code></pre> Parameter Description <code>name</code> Unique identifier (e.g., \"rpm\", \"tpm\") <code>capacity</code> Tokens that refill per period (sustained rate) <code>burst</code> Maximum bucket size (defaults to capacity) <p>See Token Bucket Algorithm for details on how capacity, burst, and refill work together.</p>"},{"location":"getting-started/#handling-rate-limit-errors","title":"Handling Rate Limit Errors","text":"<p>When a rate limit is exceeded, <code>RateLimitExceeded</code> is raised with full details:</p> <pre><code>from zae_limiter import RateLimitExceeded\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"gpt-4\",\n        consume={\"rpm\": 2},  # Exceeds capacity to trigger error\n        limits=[Limit.per_minute(\"rpm\", 1)],\n    ):\n        await do_work()\nexcept RateLimitExceeded as e:\n    # Get retry delay\n    print(f\"Retry after: {e.retry_after_seconds}s\")\n\n    # For HTTP responses\n    response = JSONResponse(\n        status_code=429,\n        content=e.as_dict(),\n        headers={\"Retry-After\": e.retry_after_header},\n    )\n</code></pre>"},{"location":"getting-started/#centralized-configuration-v050","title":"Centralized Configuration (v0.5.0+)","text":"<p>zae-limiter supports storing rate limit configurations in DynamoDB, eliminating the need to hardcode limits in application code.</p>"},{"location":"getting-started/#setting-up-defaults","title":"Setting Up Defaults","text":"<p>Configure limits at system and resource levels (typically done by admins during deployment):</p> <pre><code># Set system-wide defaults (applies to ALL resources)\nzae-limiter system set-defaults -l rpm:100 -l tpm:10000\n\n# Set resource-specific defaults (override system for this resource)\nzae-limiter resource set-defaults gpt-4 -l rpm:50 -l tpm:100000\nzae-limiter resource set-defaults gpt-3.5-turbo -l rpm:200 -l tpm:500000\n\n# Set entity-specific limits (premium users)\nzae-limiter entity set-limits user-premium --resource gpt-4 -l rpm:500 -l tpm:500000\n</code></pre>"},{"location":"getting-started/#automatic-resolution","title":"Automatic Resolution","text":"<p>With limits configured, application code becomes simpler\u2014no need to pass limits:</p> <pre><code># Limits are resolved automatically from stored config\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    consume={\"rpm\": 1},  # No limits parameter needed\n) as lease:\n    await call_api()\n</code></pre> <p>Resolution order (highest to lowest precedence):</p> <ol> <li>Entity level - Specific limits for entity+resource</li> <li>Resource level - Default limits for a resource</li> <li>System level - Global defaults for all resources</li> <li>Override parameter - Fallback if no stored config</li> </ol> <p>See Configuration Hierarchy for full details.</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage - Multiple limits, adjustments, capacity queries</li> <li>Configuration Hierarchy - Three-tier limit resolution</li> <li>Hierarchical Limits - Parent/child entities, cascade mode</li> <li>LLM Integration - Token estimation and reconciliation</li> <li>Deployment Guide - Production deployment options</li> <li>CLI Reference - Full CLI command reference</li> </ul>"},{"location":"migrations/","title":"Migrations","text":"<p>This guide covers managing schema migrations for zae-limiter infrastructure.</p>"},{"location":"migrations/#overview","title":"Overview","text":"<p>Schema migrations handle changes to the DynamoDB table structure when upgrading between major versions of zae-limiter. The migration framework provides:</p> <ul> <li>Version tracking - Infrastructure version stored in DynamoDB</li> <li>Compatibility checking - Automatic client/infrastructure compatibility validation</li> <li>Migration registry - Ordered list of migrations between versions</li> <li>Rollback support - Optional rollback functions for reversible changes</li> </ul>"},{"location":"migrations/#when-migrations-are-needed","title":"When Migrations Are Needed","text":"Change Type Migration Required? Version Bump Add optional attribute No Patch (x.x.1) Add new index (GSI) Yes Minor (x.1.0) Change key structure Yes Major (1.0.0) Remove attribute Yes Major (1.0.0) Change attribute type Yes Major (1.0.0)"},{"location":"migrations/#version-compatibility","title":"Version Compatibility","text":"<p>zae-limiter uses semantic versioning with specific compatibility rules.</p>"},{"location":"migrations/#compatibility-rules","title":"Compatibility Rules","text":"<pre><code>Client 1.x.x + Schema 1.x.x = Compatible\nClient 2.x.x + Schema 1.x.x = Incompatible (migration required)\nClient 1.2.0 + Min Client 1.3.0 = Incompatible (upgrade client)\n</code></pre> <p>Major version mismatch: Always incompatible. Schema migration required before the client can operate.</p> <p>Minor/patch version mismatch: Compatible. Client and infrastructure can operate together.</p> <p>Minimum client version: Infrastructure can require a minimum client version. Older clients are rejected.</p>"},{"location":"migrations/#checking-compatibility","title":"Checking Compatibility","text":"<p>Use the CLI to check compatibility without modifying anything:</p> <pre><code># Check current compatibility status\nzae-limiter check --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>Compatibility Check\n====================\n\nClient:      1.2.0\nSchema:      1.0.0\nLambda:      1.1.0\n\nResult: COMPATIBLE (update available)\n\nLambda update available: 1.1.0 -&gt; 1.2.0\n\nRun 'zae-limiter upgrade' to update.\n</code></pre>"},{"location":"migrations/#viewing-version-information","title":"Viewing Version Information","text":"<pre><code># Show detailed version information\nzae-limiter version --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>zae-limiter Infrastructure Version\n====================================\n\nClient Version:     1.2.0\nSchema Version:     1.0.0\n\nInfra Schema:       1.0.0\nLambda Version:     1.1.0\nMin Client Version: 0.0.0\n\nStatus: COMPATIBLE (Lambda update available)\n\n  Lambda update available: 1.1.0 -&gt; 1.2.0\n\nRun 'zae-limiter upgrade' to update Lambda.\n</code></pre>"},{"location":"migrations/#upgrading-infrastructure","title":"Upgrading Infrastructure","text":"<p>For minor updates (Lambda code, no schema changes):</p> <pre><code># Upgrade Lambda to match client version\nzae-limiter upgrade --name limiter --region us-east-1\n</code></pre> <p>For major version upgrades requiring schema migration, see Sample Migration: v2.0.0.</p>"},{"location":"migrations/#schema-modification-approaches","title":"Schema Modification Approaches","text":"<p>When modifying the DynamoDB schema, prefer solutions that preserve backward compatibility.</p>"},{"location":"migrations/#non-breaking-changes-preferred","title":"Non-Breaking Changes (Preferred)","text":"<p>These changes don't require migrations:</p> <p>Adding optional attributes: <pre><code># Old code works - attribute simply missing\nitem = {\"PK\": \"ENTITY#123\", \"SK\": \"#META\", \"name\": \"test\"}\n\n# New code adds optional attribute\nitem = {\"PK\": \"ENTITY#123\", \"SK\": \"#META\", \"name\": \"test\", \"tags\": [\"prod\"]}\n</code></pre></p> <p>Using <code>if_not_exists()</code> for new nested structures: <pre><code># Initialize nested map only if missing\nupdate_expression = \"SET #data.#metrics = if_not_exists(#data.#metrics, :empty_map)\"\n</code></pre></p> <p>Adding conditional logic for missing attributes: <pre><code># Handle missing attribute gracefully\nmetrics = item.get(\"data\", {}).get(\"metrics\", {})\nrequest_count = metrics.get(\"requests\", 0)\n</code></pre></p>"},{"location":"migrations/#breaking-changes-major-version","title":"Breaking Changes (Major Version)","text":"<p>These changes require migrations and major version bumps:</p> <ul> <li>Changing partition or sort key structure</li> <li>Removing required attributes</li> <li>Changing attribute data types</li> <li>Renaming attributes</li> <li>Restructuring nested data</li> </ul>"},{"location":"migrations/#dynamodb-specific-considerations","title":"DynamoDB-Specific Considerations","text":"<p>GSI Changes:</p> <ul> <li>Adding a GSI: Can be done without migration (CloudFormation update)</li> <li>Removing a GSI: Requires ensuring no code depends on it</li> <li>Changing GSI keys: Requires data migration</li> </ul> <p>Key Pattern Changes:</p> <pre><code># v1.0.0 pattern\nPK = f\"ENTITY#{entity_id}\"\nSK = f\"#BUCKET#{resource}#{limit_name}\"\n\n# v2.0.0 pattern (breaking change!)\nPK = f\"ENT#{entity_id}\"  # Changed prefix\nSK = f\"BKT#{resource}#{limit_name}\"  # Changed prefix\n</code></pre> <p>Key pattern changes require migrating all existing data.</p>"},{"location":"migrations/#creating-a-migration","title":"Creating a Migration","text":""},{"location":"migrations/#migration-file-structure","title":"Migration File Structure","text":"<p>Create a new file in <code>src/zae_limiter/migrations/</code>:</p> <pre><code># src/zae_limiter/migrations/v1_1_0.py\n\"\"\"\nMigration: v1.1.0 (Add metrics tracking)\n\nThis migration adds a metrics attribute to entity metadata\nfor tracking request statistics.\n\nChanges:\n- Add 'metrics' map to entity #META records\n- Initialize with empty counters\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom . import Migration, register_migration\n\nif TYPE_CHECKING:\n    from ..repository import Repository\n\n\nasync def migrate_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Add metrics attribute to all entity metadata records.\n\n    This is a forward-only migration that initializes the\n    metrics structure for existing entities.\n    \"\"\"\n    # Query all entity metadata records\n    # Update each to add metrics if missing\n    # Use conditional updates to be idempotent\n    pass\n\n\nasync def rollback_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Remove metrics attribute from entity metadata.\n\n    Note: This loses all collected metrics data.\n    \"\"\"\n    # Remove metrics attribute from all entities\n    pass\n\n\n# Register the migration\nregister_migration(\n    Migration(\n        version=\"1.1.0\",\n        description=\"Add metrics tracking to entities\",\n        reversible=True,\n        migrate=migrate_v1_1_0,\n        rollback=rollback_v1_1_0,\n    )\n)\n</code></pre>"},{"location":"migrations/#migration-protocol","title":"Migration Protocol","text":"<p>Migration functions must follow this protocol:</p> <pre><code>async def __call__(self, repository: Repository) -&gt; None:\n    \"\"\"Execute the migration.\"\"\"\n    ...\n</code></pre> <p>Key requirements:</p> <ol> <li>Async: All migrations are async functions</li> <li>Repository parameter: Receives a configured Repository instance</li> <li>Idempotent: Safe to run multiple times (use conditional updates)</li> <li>Atomic where possible: Use transactions for related changes</li> </ol>"},{"location":"migrations/#registering-migrations","title":"Registering Migrations","text":"<p>Migrations are auto-registered when imported. Ensure your migration module is imported in <code>migrations/__init__.py</code>:</p> <pre><code># src/zae_limiter/migrations/__init__.py\n\n# ... existing code ...\n\n# Import built-in migrations to register them\nfrom . import v1_0_0 as _v1_0_0  # noqa: F401, E402\nfrom . import v1_1_0 as _v1_1_0  # noqa: F401, E402  # Add new migration\n</code></pre>"},{"location":"migrations/#updating-schema-version","title":"Updating Schema Version","text":"<p>After adding a migration, update the current schema version:</p> <pre><code># src/zae_limiter/version.py\n\n# Current schema version - increment when schema changes\nCURRENT_SCHEMA_VERSION = \"1.1.0\"  # Updated from \"1.0.0\"\n</code></pre>"},{"location":"migrations/#validating-migrations","title":"Validating Migrations","text":""},{"location":"migrations/#unit-testing-with-moto","title":"Unit Testing with Moto","text":"<p>Test migrations using moto for fast, isolated tests:</p> <pre><code># tests/test_migrations.py\nimport pytest\nfrom moto import mock_aws\n\nfrom zae_limiter.migrations import get_migrations_between, apply_migrations\nfrom zae_limiter.repository import Repository\n\n\n@pytest.fixture\ndef mock_dynamodb():\n    with mock_aws():\n        # Create table and seed test data\n        yield\n\n\n@pytest.mark.asyncio\nasync def test_migration_v1_1_0(mock_dynamodb):\n    \"\"\"Test v1.1.0 migration adds metrics to entities.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create test entity without metrics\n    await repo.create_entity(entity_id=\"test-1\", name=\"Test Entity\")\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n\n    assert applied == [\"1.1.0\"]\n\n    # Verify metrics added - use raw DynamoDB query since Entity\n    # dataclass won't have the new 'metrics' field until code is updated\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#test-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert \"metrics\" in item[\"data\"][\"M\"]\n    assert item[\"data\"][\"M\"][\"metrics\"][\"M\"][\"requests\"][\"N\"] == \"0\"\n\n\n@pytest.mark.asyncio\nasync def test_migration_idempotent(mock_dynamodb):\n    \"\"\"Test migration can be safely run multiple times.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create test entity\n    await repo.create_entity(entity_id=\"test-1\", name=\"Test Entity\")\n\n    # Run migration twice\n    await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n    await apply_migrations(repo, \"1.0.0\", \"1.1.0\")  # Should not fail\n\n    # Verify single application via raw DynamoDB query\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#test-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert item[\"data\"][\"M\"][\"metrics\"][\"M\"][\"requests\"][\"N\"] == \"0\"\n</code></pre>"},{"location":"migrations/#integration-testing-with-localstack","title":"Integration Testing with LocalStack","text":"<p>Test migrations against real AWS-compatible infrastructure:</p> <pre><code># tests/test_migrations_integration.py\nimport os\nimport pytest\n\n# Skip if LocalStack not available\npytestmark = pytest.mark.skipif(\n    not os.environ.get(\"AWS_ENDPOINT_URL\"),\n    reason=\"LocalStack not available\"\n)\n\n\n@pytest.mark.integration\n@pytest.mark.asyncio\nasync def test_migration_with_localstack():\n    \"\"\"Test migration against LocalStack.\"\"\"\n    endpoint_url = os.environ[\"AWS_ENDPOINT_URL\"]\n\n    repo = Repository(\n        \"test_migrations\",\n        \"us-east-1\",\n        endpoint_url,\n    )\n\n    # Deploy infrastructure\n    # ... create table with CloudFormation ...\n\n    # Seed test data\n    # ... create entities ...\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n\n    # Verify changes persisted\n    # ... assertions ...\n</code></pre> <p>Run integration tests:</p> <pre><code># Start LocalStack (from project root)\ndocker compose up -d\n\n# Set environment variables and run integration tests\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\npytest -m integration -v\n</code></pre>"},{"location":"migrations/#production-validation-checklist","title":"Production Validation Checklist","text":"<p>Before running migrations in production:</p> <ul> <li> Backup: Enable Point-in-Time Recovery (PITR) or create on-demand backup</li> <li> Test: Run migration against production data copy</li> <li> Monitor: Set up CloudWatch alarms for errors</li> <li> Rollback plan: Document rollback procedure</li> <li> Maintenance window: Schedule during low-traffic period</li> <li> Communication: Notify stakeholders of potential downtime</li> </ul> <pre><code># Create on-demand backup before migration\naws dynamodb create-backup \\\n  --table-name limiter \\\n  --backup-name \"pre-migration-$(date +%Y%m%d)\"\n\n# Verify PITR is enabled\naws dynamodb describe-continuous-backups \\\n  --table-name limiter\n</code></pre>"},{"location":"migrations/#rollback-strategies","title":"Rollback Strategies","text":""},{"location":"migrations/#reversible-migrations","title":"Reversible Migrations","text":"<p>For migrations that can be safely undone:</p> <pre><code>register_migration(\n    Migration(\n        version=\"1.1.0\",\n        description=\"Add metrics tracking\",\n        reversible=True,  # Can be rolled back\n        migrate=migrate_v1_1_0,\n        rollback=rollback_v1_1_0,  # Rollback function\n    )\n)\n</code></pre> <p>Rollback removes or reverts the changes:</p> <pre><code>async def rollback_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"Remove metrics attribute from all entities.\"\"\"\n    # Implementation to remove metrics attribute\n    pass\n</code></pre>"},{"location":"migrations/#forward-only-migrations","title":"Forward-Only Migrations","text":"<p>Some migrations cannot be reversed:</p> <pre><code>register_migration(\n    Migration(\n        version=\"2.0.0\",\n        description=\"Restructure key patterns\",\n        reversible=False,  # Cannot be rolled back\n        migrate=migrate_v2_0_0,\n        rollback=None,  # No rollback function\n    )\n)\n</code></pre> <p>Forward-only migrations typically involve:</p> <ul> <li>Data transformation with information loss</li> <li>Key structure changes</li> <li>Removing deprecated attributes</li> </ul>"},{"location":"migrations/#emergency-rollback-procedures","title":"Emergency Rollback Procedures","text":"<p>If a migration fails or causes issues:</p> <p>1. Stop the bleeding: <pre><code># Revert to previous client version\npip install zae-limiter==1.0.0\n</code></pre></p> <p>2. Restore from backup (if needed): <pre><code># Restore from PITR\naws dynamodb restore-table-to-point-in-time \\\n  --source-table-name limiter \\\n  --target-table-name limiter-restored \\\n  --restore-date-time \"2024-01-15T10:00:00Z\"\n</code></pre></p> <p>3. Run rollback (if reversible): <pre><code>from zae_limiter.migrations import get_migrations\nfrom zae_limiter.repository import Repository\n\nasync def emergency_rollback():\n    repo = Repository(\"limiter\", \"us-east-1\", None)\n\n    migrations = get_migrations()\n    target_migration = next(m for m in migrations if m.version == \"1.1.0\")\n\n    if target_migration.reversible and target_migration.rollback:\n        await target_migration.rollback(repo)\n        print(\"Rollback complete\")\n    else:\n        print(\"Migration is not reversible - restore from backup\")\n</code></pre></p> <p>4. Update version record: <pre><code>await repo.set_version_record(\n    schema_version=\"1.0.0\",  # Reverted version\n    lambda_version=\"1.0.0\",\n    updated_by=\"emergency_rollback\",\n)\n</code></pre></p>"},{"location":"migrations/#sample-migration-v200","title":"Sample Migration: v2.0.0","text":"<p>This example demonstrates a complete migration scenario for a hypothetical v2.0.0 release that adds a new Global Secondary Index for querying entities by creation date.</p>"},{"location":"migrations/#scenario","title":"Scenario","text":"<p>Goal: Add ability to query entities by creation timestamp for audit purposes.</p> <p>Changes: 1. Add <code>created_at</code> attribute to entity metadata 2. Add GSI3 for querying by creation date 3. Backfill <code>created_at</code> for existing entities</p>"},{"location":"migrations/#migration-implementation","title":"Migration Implementation","text":"<pre><code># src/zae_limiter/migrations/v2_0_0.py\n\"\"\"\nMigration: v2.0.0 (Add creation timestamp tracking)\n\nThis migration adds a created_at timestamp to all entities and\ncreates a new GSI for querying entities by creation date.\n\nSchema changes:\n- Add 'created_at' attribute to entity #META records\n- Add GSI3: GSI3PK=CREATED#{YYYY-MM}, GSI3SK=ENTITY#{id}\n\nBreaking changes:\n- Requires CloudFormation stack update for GSI3\n- All queries using GSI3 require v2.0.0+ client\n\nRollback:\n- This migration is NOT reversible (GSI removal loses query capability)\n- Restore from backup if rollback needed\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom datetime import UTC, datetime\nfrom typing import TYPE_CHECKING\n\nfrom . import Migration, register_migration\n\nif TYPE_CHECKING:\n    from ..repository import Repository\n\n\nasync def migrate_v2_0_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Add created_at timestamp to all existing entities.\n\n    Note: GSI3 must be added via CloudFormation update before\n    running this migration. The migration only backfills data.\n\n    Steps:\n    1. Scan all entity metadata records\n    2. Add created_at if missing (set to migration timestamp)\n    3. Add GSI3 keys for index population\n    \"\"\"\n    migration_time = datetime.now(UTC).isoformat()\n    migration_month = datetime.now(UTC).strftime(\"%Y-%m\")\n\n    # Get DynamoDB client\n    client = await repository._get_client()\n\n    # Scan for all entity metadata records\n    paginator = client.get_paginator('scan')\n\n    async for page in paginator.paginate(\n        TableName=repository.table_name,\n        FilterExpression=\"begins_with(SK, :meta)\",\n        ExpressionAttributeValues={\":meta\": {\"S\": \"#META\"}},\n    ):\n        items = page.get(\"Items\", [])\n\n        # Process in batches of 25 (DynamoDB limit)\n        for i in range(0, len(items), 25):\n            batch = items[i:i + 25]\n\n            # Build batch update\n            update_requests = []\n            for item in batch:\n                pk = item[\"PK\"][\"S\"]\n                sk = item[\"SK\"][\"S\"]\n\n                # Use conditional update - only if created_at missing\n                update_requests.append({\n                    \"Update\": {\n                        \"TableName\": repository.table_name,\n                        \"Key\": {\"PK\": {\"S\": pk}, \"SK\": {\"S\": sk}},\n                        \"UpdateExpression\": (\n                            \"SET #created = if_not_exists(#created, :ts), \"\n                            \"GSI3PK = if_not_exists(GSI3PK, :gsi3pk), \"\n                            \"GSI3SK = if_not_exists(GSI3SK, :gsi3sk)\"\n                        ),\n                        \"ExpressionAttributeNames\": {\n                            \"#created\": \"created_at\",\n                        },\n                        \"ExpressionAttributeValues\": {\n                            \":ts\": {\"S\": migration_time},\n                            \":gsi3pk\": {\"S\": f\"CREATED#{migration_month}\"},\n                            \":gsi3sk\": {\"S\": pk},\n                        },\n                    }\n                })\n\n            # Execute batch (transactions limited to 100 items)\n            if update_requests:\n                await client.transact_write_items(\n                    TransactItems=update_requests\n                )\n\n        # Rate limiting to avoid throttling\n        await asyncio.sleep(0.1)\n\n    # Update version record\n    await repository.set_version_record(\n        schema_version=\"2.0.0\",\n        client_min_version=\"2.0.0\",  # Require v2.0.0+ clients\n        updated_by=\"migration:v2.0.0\",\n    )\n\n\n# Register the migration\nregister_migration(\n    Migration(\n        version=\"2.0.0\",\n        description=\"Add creation timestamp tracking with GSI3\",\n        reversible=False,  # GSI changes are not easily reversible\n        migrate=migrate_v2_0_0,\n        rollback=None,\n    )\n)\n</code></pre>"},{"location":"migrations/#cloudformation-update","title":"CloudFormation Update","text":"<p>The GSI must be added before running the migration:</p> <pre><code># Addition to cfn_template.yaml\nResources:\n  RateLimitsTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      # ... existing properties ...\n      GlobalSecondaryIndexes:\n        # ... existing GSIs ...\n        - IndexName: GSI3\n          KeySchema:\n            - AttributeName: GSI3PK\n              KeyType: HASH\n            - AttributeName: GSI3SK\n              KeyType: RANGE\n          Projection:\n            ProjectionType: ALL\n      AttributeDefinitions:\n        # ... existing attributes ...\n        - AttributeName: GSI3PK\n          AttributeType: S\n        - AttributeName: GSI3SK\n          AttributeType: S\n</code></pre>"},{"location":"migrations/#running-the-migration","title":"Running the Migration","text":"<pre><code># 1. Create backup\naws dynamodb create-backup \\\n  --table-name limiter \\\n  --backup-name \"pre-v2-migration-$(date +%Y%m%d)\"\n\n# 2. Update CloudFormation stack (adds GSI3)\naws cloudformation update-stack \\\n  --stack-name limiter \\\n  --template-body file://updated-template.yaml \\\n  --capabilities CAPABILITY_NAMED_IAM\n\n# 3. Wait for GSI to be active\naws dynamodb wait table-exists --table-name limiter\n\n# 4. Install new client version\npip install zae-limiter==2.0.0\n\n# 5. Run migration (via upgrade command or programmatically)\npython -c \"\nimport asyncio\nfrom zae_limiter.migrations import apply_migrations\nfrom zae_limiter.repository import Repository\n\nasync def run():\n    repo = Repository('limiter', 'us-east-1', None)\n    applied = await apply_migrations(repo, '1.0.0', '2.0.0')\n    print(f'Applied migrations: {applied}')\n    await repo.close()\n\nasyncio.run(run())\n\"\n\n# 6. Verify migration\nzae-limiter version --name limiter --region us-east-1\n</code></pre>"},{"location":"migrations/#testing-the-migration","title":"Testing the Migration","text":"<pre><code>@pytest.mark.asyncio\nasync def test_v2_migration_adds_created_at(mock_dynamodb):\n    \"\"\"Test v2.0.0 migration adds created_at to entities.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create entities without created_at (v1 schema)\n    await repo.create_entity(entity_id=\"entity-1\", name=\"Test 1\")\n    await repo.create_entity(entity_id=\"entity-2\", name=\"Test 2\")\n\n    # Verify no created_at before migration\n    entity = await repo.get_entity(\"entity-1\")\n    assert entity.created_at is None\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"2.0.0\")\n    assert applied == [\"2.0.0\"]\n\n    # Verify created_at added - check raw DynamoDB for GSI3 keys\n    # (Entity dataclass has created_at, but GSI3PK/GSI3SK are schema-level)\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#entity-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert \"created_at\" in item\n    assert item[\"created_at\"][\"S\"].startswith(\"20\")  # Valid ISO timestamp\n    assert \"GSI3PK\" in item  # GSI key was added\n    assert item[\"GSI3PK\"][\"S\"].startswith(\"CREATED#\")\n\n\n@pytest.mark.asyncio\nasync def test_v2_migration_idempotent(mock_dynamodb):\n    \"\"\"Test v2.0.0 migration is idempotent.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create entity with created_at already set\n    # (simulating an entity created after v2.0.0 code deployed)\n    original_time = \"2024-01-01T00:00:00Z\"\n    client = await repo._get_client()\n    await client.put_item(\n        TableName=repo.table_name,\n        Item={\n            \"PK\": {\"S\": \"ENTITY#entity-1\"},\n            \"SK\": {\"S\": \"#META\"},\n            \"data\": {\"M\": {\"name\": {\"S\": \"Test\"}}},\n            \"created_at\": {\"S\": original_time},\n            \"GSI3PK\": {\"S\": \"CREATED#2024-01\"},\n            \"GSI3SK\": {\"S\": \"ENTITY#entity-1\"},\n        },\n    )\n\n    # Apply migration - should not overwrite existing values\n    await apply_migrations(repo, \"1.0.0\", \"2.0.0\")\n\n    # Verify original created_at preserved (if_not_exists)\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#entity-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert item[\"created_at\"][\"S\"] == original_time\n</code></pre>"},{"location":"migrations/#reference","title":"Reference","text":""},{"location":"migrations/#version-record-structure","title":"Version Record Structure","text":"<p>The version record is stored in DynamoDB:</p> Attribute Value Description PK <code>SYSTEM#</code> Partition key SK <code>#VERSION</code> Sort key schema_version <code>\"1.0.0\"</code> Current schema version lambda_version <code>\"1.2.0\"</code> Deployed Lambda version client_min_version <code>\"1.0.0\"</code> Minimum client version updated_at ISO timestamp Last update time updated_by <code>\"cli:1.2.0\"</code> What performed the update"},{"location":"migrations/#key-patterns-v100","title":"Key Patterns (v1.0.0)","text":"Pattern Example Description Entity metadata <code>PK=ENTITY#123, SK=#META</code> Entity configuration Bucket state <code>PK=ENTITY#123, SK=#BUCKET#gpt-4#rpm</code> Token bucket state Limit config <code>PK=ENTITY#123, SK=#LIMIT#gpt-4#rpm</code> Stored limit config Usage snapshot <code>PK=ENTITY#123, SK=#USAGE#gpt-4#2024-01-15</code> Usage data Version <code>PK=SYSTEM#, SK=#VERSION</code> Infrastructure version"},{"location":"migrations/#migration-api-reference","title":"Migration API Reference","text":"<pre><code>from zae_limiter.migrations import (\n    Migration,           # Migration dataclass\n    register_migration,  # Register a migration\n    get_migrations,      # Get all registered migrations\n    get_migrations_between,  # Get migrations between versions\n    apply_migrations,    # Apply migrations\n)\n\nfrom zae_limiter.version import (\n    CURRENT_SCHEMA_VERSION,  # Current schema version constant\n    parse_version,           # Parse version string\n    check_compatibility,     # Check client/infra compatibility\n    get_schema_version,      # Get current schema version\n    InfrastructureVersion,   # Version info dataclass\n    CompatibilityResult,     # Compatibility check result\n)\n</code></pre>"},{"location":"migrations/#cli-commands","title":"CLI Commands","text":"<pre><code># Check compatibility\nzae-limiter check --name NAME --region REGION\n\n# Show version information\nzae-limiter version --name NAME --region REGION\n\n# Upgrade infrastructure\nzae-limiter upgrade --name NAME --region REGION [--lambda-only] [--force]\n</code></pre>"},{"location":"migrations/#version-specific-migration-guides","title":"Version-Specific Migration Guides","text":"<ul> <li>Namespace-Prefixed Keys (v0.10.0) -- Migrate from bare DynamoDB keys to namespace-prefixed keys for multi-tenant isolation</li> </ul>"},{"location":"monitoring/","title":"Monitoring and Observability","text":"<p>This guide covers monitoring and observability practices for zae-limiter deployments, including structured logging, CloudWatch metrics, alerts, and dashboard templates.</p>"},{"location":"monitoring/#overview","title":"Overview","text":"<p>Effective monitoring of a rate limiter is critical for:</p> <ul> <li>Availability - Detecting service degradation before users are impacted</li> <li>Latency - Ensuring rate limit checks don't become a bottleneck</li> <li>Throughput - Understanding capacity and scaling needs</li> <li>Errors - Identifying and resolving issues quickly</li> </ul> <p>zae-limiter provides built-in observability through:</p> Component Purpose CloudWatch Alarms Proactive alerting on anomalies Structured Logs JSON-formatted logs for analysis Dead Letter Queue Capturing failed events for investigation Usage Snapshots Aggregated consumption metrics Audit Logging Security and compliance tracking <p>Compliance Requirements</p> <p>For tracking who changed what and when, see the Audit Logging Guide.</p> <p>Usage Data</p> <p>For querying historical consumption data (billing, capacity planning), see the Usage Snapshots Guide.</p>"},{"location":"monitoring/#structured-logging","title":"Structured Logging","text":"<p>The Lambda aggregator uses structured JSON logging compatible with CloudWatch Logs Insights.</p>"},{"location":"monitoring/#log-format","title":"Log Format","text":"<p>All log entries follow this JSON structure:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.000000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter_aggregator.handler\",\n  \"message\": \"Lambda invocation completed\",\n  \"request_id\": \"abc123-def456\",\n  \"processed\": 50,\n  \"snapshots_updated\": 100,\n  \"processing_time_ms\": 45.23\n}\n</code></pre>"},{"location":"monitoring/#log-fields-reference","title":"Log Fields Reference","text":"Field Type Description <code>timestamp</code> string ISO 8601 timestamp (UTC) <code>level</code> string Log level: DEBUG, INFO, WARNING, ERROR <code>logger</code> string Logger name (module path) <code>message</code> string Human-readable message <code>request_id</code> string Lambda request ID for correlation <code>function_name</code> string Lambda function name <code>record_count</code> int DynamoDB stream records in batch <code>processed</code> int Records successfully processed <code>deltas_extracted</code> int Consumption deltas found <code>snapshots_updated</code> int Usage snapshots updated <code>error_count</code> int Processing errors <code>processing_time_ms</code> float Total execution time (ms)"},{"location":"monitoring/#log-levels","title":"Log Levels","text":"Level When Used DEBUG Detailed processing info (snapshot updates) INFO Invocation start/end, batch processing summary WARNING Recoverable errors (single record failures) ERROR Unrecoverable errors (batch failures)"},{"location":"monitoring/#example-log-entries","title":"Example Log Entries","text":"<p>Invocation Start: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.000000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter_aggregator.handler\",\n  \"message\": \"Lambda invocation started\",\n  \"request_id\": \"abc123-def456\",\n  \"function_name\": \"limiter-aggregator\",\n  \"record_count\": 50,\n  \"table_name\": \"limiter\",\n  \"snapshot_windows\": [\"hourly\", \"daily\"]\n}\n</code></pre></p> <p>Batch Complete: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.500000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter_aggregator.processor\",\n  \"message\": \"Batch processing completed\",\n  \"processed_count\": 50,\n  \"deltas_extracted\": 45,\n  \"snapshots_updated\": 90,\n  \"error_count\": 0,\n  \"processing_time_ms\": 423.15\n}\n</code></pre></p> <p>Error with Exception: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:01.000000+00:00\",\n  \"level\": \"ERROR\",\n  \"logger\": \"zae_limiter_aggregator.processor\",\n  \"message\": \"Error processing record\",\n  \"record_index\": 12,\n  \"exception\": \"Traceback (most recent call last):\\n...\"\n}\n</code></pre></p>"},{"location":"monitoring/#cloudwatch-metrics","title":"CloudWatch Metrics","text":""},{"location":"monitoring/#lambda-metrics","title":"Lambda Metrics","text":"<p>Monitor the aggregator Lambda function:</p> Metric Namespace Description Recommended Threshold <code>Invocations</code> AWS/Lambda Total executions Baseline + 50% <code>Errors</code> AWS/Lambda Failed executions &gt; 1 per 5 min <code>Duration</code> AWS/Lambda Execution time (ms) &gt; 80% of timeout <code>Throttles</code> AWS/Lambda Throttled invocations &gt; 0 <code>IteratorAge</code> AWS/Lambda Stream processing lag (ms) &gt; 30,000 ms <code>ConcurrentExecutions</code> AWS/Lambda Parallel executions Account limit"},{"location":"monitoring/#dynamodb-metrics","title":"DynamoDB Metrics","text":"<p>Monitor table performance:</p> Metric Namespace Description Recommended Threshold <code>ConsumedReadCapacityUnits</code> AWS/DynamoDB RCU usage Provisioned capacity <code>ConsumedWriteCapacityUnits</code> AWS/DynamoDB WCU usage Provisioned capacity <code>ReadThrottleEvents</code> AWS/DynamoDB Read throttles &gt; 0 <code>WriteThrottleEvents</code> AWS/DynamoDB Write throttles &gt; 0 <code>SystemErrors</code> AWS/DynamoDB Service errors &gt; 0 <code>SuccessfulRequestLatency</code> AWS/DynamoDB Request latency (ms) p99 &gt; 100ms"},{"location":"monitoring/#sqs-metrics-dead-letter-queue","title":"SQS Metrics (Dead Letter Queue)","text":"<p>Monitor failed event processing:</p> Metric Namespace Description Recommended Threshold <code>ApproximateNumberOfMessagesVisible</code> AWS/SQS Messages in DLQ &gt; 0 <code>ApproximateAgeOfOldestMessage</code> AWS/SQS Oldest message age (s) &gt; 3600"},{"location":"monitoring/#cloudwatch-logs-insights-queries","title":"CloudWatch Logs Insights Queries","text":""},{"location":"monitoring/#batch-processing-performance","title":"Batch Processing Performance","text":"<p>Analyze processing latency over time:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Batch processing completed/\n| parse @message /processing_time_ms\":(?&lt;duration&gt;[\\d.]+)/\n| stats avg(duration) as avg_ms,\n        pct(duration, 50) as p50_ms,\n        pct(duration, 95) as p95_ms,\n        pct(duration, 99) as p99_ms\n  by bin(1h)\n| sort @timestamp desc\n</code></pre>"},{"location":"monitoring/#error-analysis","title":"Error Analysis","text":"<p>Find recent errors and warnings:</p> <pre><code>fields @timestamp, @message, @logStream\n| filter level = \"ERROR\" or level = \"WARNING\"\n| parse @message /message\":\"(?&lt;error_message&gt;[^\"]+)/\n| sort @timestamp desc\n| limit 100\n</code></pre>"},{"location":"monitoring/#invocation-summary","title":"Invocation Summary","text":"<p>Aggregate processing metrics:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Lambda invocation completed/\n| parse @message /processed\":(?&lt;processed&gt;\\d+).*snapshots_updated\":(?&lt;snapshots&gt;\\d+)/\n| stats sum(processed) as total_processed,\n        sum(snapshots) as total_snapshots,\n        count() as invocations\n  by bin(1h)\n| sort @timestamp desc\n</code></pre>"},{"location":"monitoring/#entity-usage-analysis","title":"Entity Usage Analysis","text":"<p>Find highest-usage entities:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Snapshot updated/\n| parse @message /entity_id\":\"(?&lt;entity&gt;[^\"]+)\".*resource\":\"(?&lt;resource&gt;[^\"]+)/\n| stats count() as updates by entity, resource\n| sort updates desc\n| limit 50\n</code></pre>"},{"location":"monitoring/#cold-start-detection","title":"Cold Start Detection","text":"<p>Identify Lambda cold starts:</p> <pre><code>fields @timestamp, @message, @duration\n| filter @type = \"REPORT\"\n| filter @message like /Init Duration/\n| parse @message /Init Duration: (?&lt;init_duration&gt;[\\d.]+) ms/\n| stats count() as cold_starts,\n        avg(init_duration) as avg_init_ms\n  by bin(1h)\n</code></pre>"},{"location":"monitoring/#error-rate-calculation","title":"Error Rate Calculation","text":"<p>Calculate error rate percentage:</p> <pre><code>fields @timestamp\n| filter @message like /Lambda invocation/\n| parse @message /error_count\":(?&lt;errors&gt;\\d+)/\n| stats sum(errors) as total_errors, count() as total_invocations\n| display total_errors, total_invocations,\n         (total_errors * 100.0 / total_invocations) as error_rate_pct\n</code></pre>"},{"location":"monitoring/#x-ray-tracing","title":"X-Ray Tracing","text":"<p>AWS X-Ray tracing is available for the Lambda aggregator function. When enabled, traces are automatically captured for Lambda invocations, providing visibility into stream processing performance.</p>"},{"location":"monitoring/#enabling-x-ray","title":"Enabling X-Ray","text":"<p>X-Ray tracing is opt-in to avoid unexpected costs:</p> <pre><code># Enable tracing via CLI\nzae-limiter deploy --name my-app --enable-tracing\n\n# Or programmatically\nfrom zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        enable_tracing=True,\n    ),\n)\n</code></pre>"},{"location":"monitoring/#whats-traced-phase-1","title":"What's Traced (Phase 1)","text":"<ul> <li>Lambda Active Tracing - End-to-end request visibility for aggregator invocations</li> <li>Automatic segments - AWS SDK calls (DynamoDB, S3) are automatically instrumented</li> </ul>"},{"location":"monitoring/#future-enhancements","title":"Future Enhancements","text":"<p>Track progress on additional X-Ray features in Issue #107:</p> <ul> <li>DynamoDB SDK instrumentation for client-side operations</li> <li>Custom subsegments for acquire/release operations</li> <li>Trace header propagation for cross-service correlation</li> </ul>"},{"location":"monitoring/#dashboard-templates","title":"Dashboard Templates","text":""},{"location":"monitoring/#operations-dashboard","title":"Operations Dashboard","text":"<p>Create a CloudWatch dashboard for day-to-day operations:</p> <pre><code>{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Invocations &amp; Errors\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"Invocations\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Sum\"}],\n          [\".\", \"Errors\", \".\", \".\", {\"stat\": \"Sum\", \"color\": \"#d62728\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Duration (p50/p95/p99)\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"Duration\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"p50\"}],\n          [\"...\", {\"stat\": \"p95\"}],\n          [\"...\", {\"stat\": \"p99\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Stream Iterator Age\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"IteratorAge\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Maximum\"}]\n        ],\n        \"period\": 60,\n        \"view\": \"timeSeries\",\n        \"annotations\": {\n          \"horizontal\": [{\"value\": 30000, \"label\": \"Threshold (30s)\"}]\n        }\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"DynamoDB Capacity\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ConsumedReadCapacityUnits\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\"}],\n          [\".\", \"ConsumedWriteCapacityUnits\", \".\", \".\", {\"stat\": \"Sum\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"DynamoDB Throttles\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ReadThrottleEvents\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\"}],\n          [\".\", \"WriteThrottleEvents\", \".\", \".\", {\"stat\": \"Sum\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Dead Letter Queue\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/SQS\", \"ApproximateNumberOfMessagesVisible\", \"QueueName\", \"${TableName}-aggregator-dlq\"]\n        ],\n        \"period\": 60,\n        \"view\": \"singleValue\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"monitoring/#capacity-planning-dashboard","title":"Capacity Planning Dashboard","text":"<p>Create a dashboard for capacity analysis:</p> <pre><code>{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"RCU/WCU Consumption Trend\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ConsumedReadCapacityUnits\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\", \"period\": 3600}],\n          [\".\", \"ConsumedWriteCapacityUnits\", \".\", \".\", {\"stat\": \"Sum\", \"period\": 3600}]\n        ],\n        \"view\": \"timeSeries\",\n        \"stacked\": false\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Request Latency Distribution\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"SuccessfulRequestLatency\", \"TableName\", \"${TableName}\", \"Operation\", \"GetItem\", {\"stat\": \"p50\"}],\n          [\"...\", {\"stat\": \"p95\"}],\n          [\"...\", {\"stat\": \"p99\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Concurrent Executions\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"ConcurrentExecutions\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Maximum\"}]\n        ],\n        \"period\": 60,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Throttle Events (7 Day)\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ReadThrottleEvents\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\", \"period\": 86400}],\n          [\".\", \"WriteThrottleEvents\", \".\", \".\", {\"stat\": \"Sum\", \"period\": 86400}]\n        ],\n        \"view\": \"bar\"\n      }\n    }\n  ]\n}\n</code></pre> <p>Dashboard Deployment</p> <p>Replace <code>${TableName}</code> with your actual table name (e.g., <code>limiter</code>) and <code>${AWS::Region}</code> with your region before deploying.</p>"},{"location":"monitoring/#alert-configuration","title":"Alert Configuration","text":""},{"location":"monitoring/#default-alarms","title":"Default Alarms","text":"<p>The stack deploys these alarms when <code>--enable-alarms</code> is set:</p> Alarm Metric Threshold Period Evaluation <code>{name}-aggregator-error-rate</code> Lambda Errors &gt; 1 5 min 2 periods <code>{name}-aggregator-duration</code> Lambda Duration &gt; 80% timeout 5 min 2 periods <code>{name}-stream-iterator-age</code> IteratorAge &gt; 30,000 ms 5 min 2 periods <code>{name}-aggregator-dlq-alarm</code> SQS Messages &gt;= 1 5 min 1 period <code>{name}-read-throttle</code> ReadThrottleEvents &gt; 1 5 min 2 periods <code>{name}-write-throttle</code> WriteThrottleEvents &gt; 1 5 min 2 periods"},{"location":"monitoring/#deploying-with-alarms","title":"Deploying with Alarms","text":"<pre><code># Deploy with alarms enabled (default)\nzae-limiter deploy --name limiter --region us-east-1\n\n# Deploy with SNS notifications\nzae-limiter deploy --name limiter --region us-east-1 \\\n    --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts\n\n# Customize duration threshold (70% of timeout)\nzae-limiter deploy --name limiter --region us-east-1 \\\n    --lambda-duration-threshold-pct 70\n\n# Disable alarms (not recommended for production)\nzae-limiter deploy --name limiter --region us-east-1 --no-alarms\n</code></pre>"},{"location":"monitoring/#threshold-tuning-guide","title":"Threshold Tuning Guide","text":"Alarm Default When to Increase When to Decrease Error Rate &gt;1/5min High-volume systems with rare transient errors Critical systems requiring immediate response Duration 80% timeout Batch workloads with variable processing time Latency-sensitive applications Iterator Age 30 seconds Batch-tolerant analytics workloads Real-time processing requirements DLQ Messages &gt;=1 Never (always investigate DLQ messages) N/A Throttles &gt;1/5min During planned traffic spikes Before hitting capacity limits"},{"location":"monitoring/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        enable_alarms=True,\n        alarm_sns_topic=\"arn:aws:sns:us-east-1:123456789012:alerts\",\n        lambda_duration_threshold_pct=75,  # Alert at 75% of timeout\n        log_retention_days=90,\n    ),\n)\n</code></pre>"},{"location":"monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Operations Guide - Troubleshooting and operational procedures</li> <li>Audit Logging - Security and compliance tracking</li> <li>Performance Tuning - Capacity planning and optimization</li> <li>Deployment Guide - Infrastructure setup</li> <li>CloudFormation Reference - Template customization</li> </ul>"},{"location":"performance/","title":"Performance Tuning Guide","text":"<p>This guide provides detailed recommendations for optimizing zae-limiter performance, covering DynamoDB capacity planning, Lambda configuration, and cost optimization strategies.</p>"},{"location":"performance/#1-dynamodb-capacity-planning","title":"1. DynamoDB Capacity Planning","text":""},{"location":"performance/#understanding-rcuwcu-costs","title":"Understanding RCU/WCU Costs","text":"<p>Each zae-limiter operation has specific DynamoDB capacity costs. Use this table for capacity planning:</p> Operation RCUs WCUs Notes <code>acquire()</code> 1 1 O(1) regardless of limit count (composite bucket items) <code>acquire()</code> with cascade 2 4 Entity + parent bucket reads and writes (TransactWriteItems, 2 WCU per item) <code>acquire()</code> speculative success 0 1 Skips read; conditional UpdateItem (issue #315) <code>acquire()</code> speculative success + cascade (sequential) 0 2 Child then parent speculative UpdateItem <code>acquire()</code> speculative success + cascade (parallel) 0 2 Concurrent child + parent via entity cache (issue #318) <code>acquire()</code> speculative fast rejection 0 0 Exhausted bucket; rejected from ALL_OLD without write <code>acquire()</code> speculative fallback (non-cascade) 1 2 Failed speculative (1 WCU) + normal path (1 RCU + 1 WCU) <code>acquire()</code> speculative cascade fallback (parent refill helps) 0.5 3 Child stays consumed; parent-only read (0.5 RCU) + single-item write (1 WCU) <code>acquire()</code> retry (contention) 0 1 ADD-based writes don't require re-read <code>acquire()</code> with adjustments 0 +1 per entity Independent writes via <code>write_each()</code> (1 WCU each) <code>acquire()</code> rollback (on exception) 0 +1 per entity Independent compensating writes (1 WCU each) Aggregator bucket refill (per active bucket) 0 1 Proactive refill via Lambda; 0 WCU if lock lost <code>acquire(limits=None)</code> with config cache miss +3 0 +3 GetItem operations for config hierarchy <code>available()</code> 1 0 Read-only, single composite bucket item <code>get_limits()</code> 1 0 Query operation <code>set_limits()</code> 1 N+1 Query + N PutItems <code>delete_entity()</code> 1 batched Query + BatchWrite in 25-item chunks <p>O(1) Cost Optimization (v0.7.0)</p> <p>ADR-114 (Composite Bucket Items) and ADR-115 (ADD-Based Writes) reduced <code>acquire()</code> costs from O(N) to O(1) where N is the number of limits. All limits for an entity+resource are stored in a single DynamoDB item, and ADD operations eliminate the need for read-modify-write cycles on contention retries.</p> <p>Capacity Validation</p> <p>These costs are validated by automated tests. Run <code>uv run pytest tests/benchmark/test_capacity.py -v</code> to verify.</p>"},{"location":"performance/#capacity-estimation-formula","title":"Capacity Estimation Formula","text":"<p>Use these formulas to estimate hourly capacity requirements:</p> <pre><code>Hourly RCUs = requests/hour \u00d7 (1 + cascade_pct + config_cache_miss_pct \u00d7 3)\nHourly WCUs = requests/hour \u00d7 (1 + cascade_pct \u00d7 3)\n</code></pre> <p>With speculative writes enabled (<code>speculative_writes=True</code>), the steady-state formula changes: <pre><code>Hourly RCUs = requests/hour \u00d7 (fallback_pct + cascade_pct \u00d7 0.5 + config_cache_miss_pct \u00d7 3)\nHourly WCUs = requests/hour \u00d7 (1 + cascade_pct)\n</code></pre></p> <p>Where <code>fallback_pct</code> is the fraction of requests that fall back to the slow path (typically &lt;5% for pre-warmed buckets).</p> <p>O(1) Scaling (v0.7.0+)</p> <p>Costs no longer scale with the number of limits per request. Composite bucket items store all limits in a single DynamoDB item, so 1 limit and 10 limits cost the same.</p> <p>With the Lambda aggregator enabled (2 windows: hourly, daily): <pre><code>Additional WCUs = requests/hour \u00d7 2\n</code></pre></p>"},{"location":"performance/#example-calculations","title":"Example Calculations","text":""},{"location":"performance/#scenario-1-simple-api-rate-limiting","title":"Scenario 1: Simple API Rate Limiting","text":"<ul> <li>10,000 requests/hour</li> <li>2 limits per request (rpm, tpm)</li> <li>No cascade, config cached</li> </ul> <p>Calculation: <pre><code>RCUs = 10,000 \u00d7 1.0 = 10,000 RCUs/hour\nWCUs = 10,000 \u00d7 1.0 = 10,000 WCUs/hour\n</code></pre></p> <p>Limit count doesn't affect cost</p> <p>With composite bucket items (v0.7.0+), whether you track 1 limit or 10 limits, the DynamoDB cost is identical\u2014all limits are stored in a single item.</p>"},{"location":"performance/#scenario-2-hierarchical-llm-limiting","title":"Scenario 2: Hierarchical LLM Limiting","text":"<ul> <li>10,000 requests/hour</li> <li>2 limits per request</li> <li>50% use cascade (API key \u2192 project)</li> <li>2% config cache miss rate</li> </ul> <p>Calculation: <pre><code>RCUs = 10,000 \u00d7 (1 + 0.5 + 0.02\u00d73) = 10,000 \u00d7 1.56 = 15,600 RCUs/hour\nWCUs = 10,000 \u00d7 (1 + 0.5\u00d73) = 10,000 \u00d7 2.5 = 25,000 WCUs/hour\n</code></pre></p>"},{"location":"performance/#billing-mode-selection","title":"Billing Mode Selection","text":"Mode Best For Trade-offs PAY_PER_REQUEST (default) Variable traffic, new deployments Higher per-request cost, no planning needed Provisioned Steady traffic &gt;100 TPS Lower cost at scale, requires planning Provisioned + Reserved High-volume production Lowest cost, 1-year commitment <p>Migration Guidance</p> <p>Start with PAY_PER_REQUEST. Once traffic patterns stabilize (typically 2-4 weeks), analyze CloudWatch metrics to determine optimal provisioned capacity. Switch when monthly on-demand costs exceed provisioned + 20% buffer.</p>"},{"location":"performance/#2-lambda-concurrency-settings","title":"2. Lambda Concurrency Settings","text":"<p>The aggregator Lambda processes DynamoDB Stream events to maintain usage snapshots.</p>"},{"location":"performance/#default-configuration","title":"Default Configuration","text":"Setting Default Range Impact Memory 256 MB 128-3008 MB Higher = faster, more expensive Timeout 60 seconds 1-900 seconds Should be 2\u00d7 typical duration Reserved Concurrency None 1-1000 Limits parallel executions"},{"location":"performance/#memory-tuning","title":"Memory Tuning","text":"<p>Lambda CPU scales linearly with memory allocation:</p> Memory vCPUs Best For 128 MB ~0.08 Minimal workloads (testing only) 256 MB ~0.15 Most workloads (default) 512 MB ~0.30 High-throughput streams 1024 MB ~0.60 Rarely needed <p>Guidance based on batch size:</p> <ul> <li>&lt;50 records/batch: 128-256 MB sufficient</li> <li>50-100 records/batch: 256-512 MB recommended</li> <li>Peak streams: Monitor Lambda duration; increase memory if &gt;50% of timeout</li> </ul>"},{"location":"performance/#concurrency-management","title":"Concurrency Management","text":"<p>DynamoDB Streams creates one shard per 1000 WCU (or ~3000 writes/sec). Each shard invokes one Lambda instance.</p> <p>Recommendations:</p> Volume Reserved Concurrency Notes &lt;1000 writes/sec None Default scaling sufficient 1000-10000/sec 10-50 Prevents runaway scaling &gt;10000/sec Expected shards + 20% Based on table monitoring"},{"location":"performance/#error-handling","title":"Error Handling","text":"<p>Configure error handling for production reliability:</p> <pre><code># Deploy with DLQ and alarms\nzae-limiter deploy --table-name rate_limits \\\n  --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts\n</code></pre> <ul> <li>Retries: Failed records retry 3 times within the same batch</li> <li>DLQ: Persistent failures go to Dead Letter Queue (if configured)</li> <li>Duration Alarm: Triggers at 80% of timeout (48s default)</li> </ul>"},{"location":"performance/#3-batch-operation-patterns","title":"3. Batch Operation Patterns","text":""},{"location":"performance/#transaction-limits","title":"Transaction Limits","text":"<p>DynamoDB enforces these limits:</p> Constraint Limit Impact TransactWriteItems 100 items max Affects multi-limit updates BatchWriteItem 25 items per request Entity deletion is chunked Optimistic locking Entire transaction fails Causes retry on contention"},{"location":"performance/#efficient-patterns","title":"Efficient Patterns","text":""},{"location":"performance/#multi-limit-acquisition","title":"Multi-Limit Acquisition","text":"<pre><code># Efficient: Single lease for multiple limits\nasync with limiter.acquire(\n    \"entity-id\",\n    \"llm-api\",\n    {\"rpm\": 1},  # Initial consumption (1 request)\n    limits=[rpm_limit, tpm_limit],\n) as lease:\n    # 1 BatchGetItem + 1 UpdateItem (1 WCU, single composite bucket)\n    response = await call_llm()\n    await lease.adjust(tpm=response.usage.total_tokens)\n    # Adjustment: +1 UpdateItem via write_each (1 WCU)\n\n# Inefficient: Separate acquisitions\nasync with limiter.acquire(\"entity-id\", \"llm-api\", {\"rpm\": 1}, limits=[rpm_limit]):\n    async with limiter.acquire(\"entity-id\", \"llm-api\", {\"tpm\": 100}, limits=[tpm_limit]):\n        # 2 reads + 2 writes (doubles cost!)\n        pass\n</code></pre>"},{"location":"performance/#cascade-optimization","title":"Cascade Optimization","text":"<pre><code># Entity without cascade (default) \u2014 saves 1 GetEntity + parent bucket operations\nawait limiter.create_entity(entity_id=\"api-key\", parent_id=\"project-1\")\n\nasync with limiter.acquire(\"api-key\", \"llm-api\", {\"rpm\": 1}, limits=limits):\n    pass  # Only checks api-key's limits\n\n# Entity with cascade \u2014 checks and updates parent limits too\nawait limiter.create_entity(entity_id=\"api-key\", parent_id=\"project-1\", cascade=True)\n\nasync with limiter.acquire(\"api-key\", \"llm-api\", {\"rpm\": 1}, limits=limits):\n    pass  # Checks both api-key AND project-1 limits\n</code></pre>"},{"location":"performance/#write-sharding-for-high-fanout-parents","title":"Write Sharding for High-Fanout Parents","text":"<p>When a parent entity has many children (1000+) with <code>cascade=True</code>, the parent partition may experience write throttling. DynamoDB limits throughput per partition to ~1,000 WCU (or ~3,000 RCU).</p> <p>Manual Write Sharding Solution:</p> <p>Instead of one parent, distribute ownership across multiple sharded parent entities:</p> <pre><code># OLD: Single parent becomes a hotspot\n# \u251c\u2500\u2500 project-1 (parent)\n# \u2502   \u251c\u2500\u2500 api-key-1 (child, cascade=True)\n# \u2502   \u251c\u2500\u2500 api-key-2 (child, cascade=True)\n# \u2502   \u2514\u2500\u2500 ... (1000+ children)\n\n# NEW: Distribute across shards (e.g., 10 shards = 10x capacity)\nnum_shards = 10\napi_key_id = \"api-key-12345\"\nshard_id = hash(api_key_id) % num_shards\nparent_id = f\"project-1-shard-{shard_id}\"\n\n# Create shard parents once during setup\nfor shard in range(num_shards):\n    parent_id = f\"project-1-shard-{shard}\"\n    await limiter.create_entity(entity_id=parent_id, parent_id=\"project-1\")\n    # Set the same limits on all shards\n    await limiter.set_limits(\n        parent_id,\n        [\n            Limit.per_minute(\"rpm\", capacity=10000),\n            Limit.per_minute(\"tpm\", capacity=100000),\n        ],\n        resource=\"llm-api\"\n    )\n\n# For each child, assign to a random shard\nshard_id = hash(api_key_id) % num_shards\nsharded_parent = f\"project-1-shard-{shard_id}\"\nawait limiter.create_entity(\n    entity_id=api_key_id,\n    parent_id=sharded_parent,\n    cascade=True\n)\n\n# On acquire, use the same sharding logic\nshard_id = hash(api_key_id) % num_shards\nsharded_parent = f\"project-1-shard-{shard_id}\"\nasync with limiter.acquire(api_key_id, \"llm-api\", {\"rpm\": 1}, limits=limits):\n    pass  # Cascades to sharded parent instead of single hotspot\n</code></pre> <p>Benefits: - Distributes parent write traffic across N partitions - With 10 shards: ~10x capacity improvement - Only requires application-level sharding logic</p> <p>Drawbacks: - More parent entities to manage - Limits checked per shard (not globally across all shards) - Requires hash consistency in sharding logic</p> <p>When to use: - Parent has &gt;500 API keys with <code>cascade=True</code> and hitting throttling - Cost-effective alternative to on-demand billing - Temporary solution before implementing more sophisticated load distribution</p>"},{"location":"performance/#stored-limits-optimization","title":"Stored Limits Optimization","text":"<pre><code># Config caching reduces RCUs (60s TTL by default)\nrepo = Repository(\n    name=\"rate-limits\",\n    region=\"us-east-1\",\n    config_cache_ttl=60,  # seconds (0 to disable)\n)\nlimiter = RateLimiter(repository=repo)\n\n# Pass explicit limits to skip config resolution entirely\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"rpm\", 100)],  # No config lookup\n    consume={\"rpm\": 1},\n) as lease:\n    ...\n</code></pre>"},{"location":"performance/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Efficient bulk limit setup\nawait limiter.set_limits(\"entity-1\", [rpm_limit, tpm_limit], resource=\"llm-api\")\nawait limiter.set_limits(\"entity-2\", [rpm_limit, tpm_limit], resource=\"llm-api\")\n# Runs 2 Queries + 2\u00d72 PutItems\n\n# Entity deletion (automatically batched in 25-item chunks)\nawait limiter.delete_entity(\"entity-2\")\n# Runs 1 Query + BatchWrite (up to 25 WCUs per chunk)\n</code></pre>"},{"location":"performance/#4-expected-latencies","title":"4. Expected Latencies","text":""},{"location":"performance/#operation-latencies","title":"Operation Latencies","text":"<p>Latencies vary by environment and depend on network conditions, DynamoDB utilization, and operation complexity.</p> Operation Moto p50 LocalStack p50 AWS (external) p50 AWS (in-region) p50 <code>acquire()</code> - single limit 9ms 43ms 38ms 15-20ms <code>acquire()</code> - two limits 11ms 43ms 36ms 15-20ms <code>acquire()</code> with cascade 22ms 47ms 48ms 25-35ms <code>available()</code> check 1ms 7ms 10ms 1-3ms <p>Environment Differences</p> <ul> <li>Moto: In-memory mock, measures code overhead only</li> <li>LocalStack: Docker-based, includes local network latency (varies by host)</li> <li>AWS (external): From outside AWS, includes internet latency (~8-14ms per round-trip)</li> <li>AWS (in-region): From EC2/Lambda in same region (~0.5-1ms per round-trip)</li> </ul> <p>In-Region Performance</p> <p>When running inside AWS (same region as DynamoDB), latency drops significantly because network round-trips take &lt;1ms instead of 8-14ms. For a typical LLM API call, rate limit overhead is ~4% (20ms / 500ms) vs ~7% when calling from external networks.</p>"},{"location":"performance/#latency-breakdown","title":"Latency Breakdown","text":"<p>Typical <code>acquire()</code> latency breakdown for a single limit (non-cascade):</p> <pre><code>acquire() latency breakdown (external client):\n\u251c\u2500\u2500 Network to AWS               ~8-10ms   (internet latency)\n\u251c\u2500\u2500 DynamoDB GetItem             ~3-5ms    (server-side processing)\n\u251c\u2500\u2500 Network back                 ~8-10ms\n\u251c\u2500\u2500 UpdateItem                   ~3-5ms    (single-item API, 1 WCU)\n\u2514\u2500\u2500 Network back                 ~8-10ms\n                                 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                         Total:  ~30-40ms\n\nacquire() latency breakdown (in-region):\n\u251c\u2500\u2500 Network to DynamoDB          ~0.5-1ms  (VPC internal)\n\u251c\u2500\u2500 DynamoDB GetItem             ~3-5ms\n\u251c\u2500\u2500 Network back                 ~0.5-1ms\n\u251c\u2500\u2500 UpdateItem                   ~3-5ms    (single-item API, 1 WCU)\n\u2514\u2500\u2500 Network back                 ~0.5-1ms\n                                 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                         Total:  ~10-15ms\n</code></pre> <p>With speculative writes enabled (<code>speculative_writes=True</code>), the read round trip is eliminated on success:</p> <pre><code>speculative acquire() latency breakdown (in-region, success):\n\u251c\u2500\u2500 Network to DynamoDB          ~0.5-1ms  (VPC internal)\n\u251c\u2500\u2500 Conditional UpdateItem       ~3-5ms    (1 WCU, skips read)\n\u2514\u2500\u2500 Network back                 ~0.5-1ms\n                                 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                         Total:  ~5-8ms\n</code></pre> <p>Single-item vs Transaction writes</p> <p>Non-cascade <code>acquire()</code> writes a single composite bucket item, so <code>transact_write()</code> dispatches it as a plain UpdateItem (1 WCU). Cascade mode with 2 items uses TransactWriteItems (2 WCU per item). Adjustments and rollbacks always use independent single-item writes via <code>write_each()</code> (1 WCU each).</p>"},{"location":"performance/#environment-selection","title":"Environment Selection","text":"Environment Use Case Latency Factor Moto Unit tests, CI/CD 1\u00d7 (baseline) LocalStack Integration tests, local dev 4-5\u00d7 AWS (external) Development, testing 4\u00d7 AWS (in-region) Production 2\u00d7 <p>Run benchmarks to measure your specific environment:</p> <pre><code># Moto benchmarks (fast)\nuv run pytest tests/benchmark/test_latency.py -v --benchmark-json=latency.json\n\n# LocalStack benchmarks (requires Docker)\ndocker compose up -d\nexport AWS_ENDPOINT_URL=http://localhost:4566\nuv run pytest tests/benchmark/test_localstack.py -v --benchmark-json=latency.json\n\n# AWS benchmarks (requires credentials)\nuv run pytest tests/benchmark/test_aws.py --run-aws -v\n</code></pre>"},{"location":"performance/#5-throughput-benchmarks","title":"5. Throughput Benchmarks","text":""},{"location":"performance/#maximum-throughput","title":"Maximum Throughput","text":"<p>Theoretical and practical throughput limits depend on contention patterns:</p> Scenario Moto TPS AWS TPS Bottleneck Sequential, single entity 95 28 Network round-trip Sequential, multiple entities 76 26 Network round-trip Concurrent, separate entities 85 176 Scales with parallelism Concurrent, single entity 88 \u2014 Optimistic locking contention Cascade sequential 27 19 Parent bucket operations Cascade concurrent 28 91 Parent bucket contention <p>AWS Concurrent Performance</p> <p>AWS concurrent throughput (176 TPS) exceeds sequential (28 TPS) because parallel requests to separate entities eliminate serialization. In-region performance would be ~2\u00d7 higher due to reduced network latency.</p>"},{"location":"performance/#contention-analysis","title":"Contention Analysis","text":"<p>When multiple requests update the same bucket concurrently, DynamoDB's optimistic locking causes transaction retries:</p> <pre><code>Concurrent updates to same bucket:\n\u251c\u2500\u2500 Request A: Read bucket version=1\n\u251c\u2500\u2500 Request B: Read bucket version=1\n\u251c\u2500\u2500 Request A: Write with condition version=1 \u2192 SUCCESS, version=2\n\u251c\u2500\u2500 Request B: Write with condition version=1 \u2192 FAIL (ConditionalCheckFailed)\n\u2514\u2500\u2500 Request B: Retry with version=2 \u2192 SUCCESS\n</code></pre> <p>Each retry adds ~10-30ms latency.</p>"},{"location":"performance/#mitigation-strategies","title":"Mitigation Strategies","text":"<pre><code># Strategy 1: Higher capacity (reduces contention per request)\nrpm_limit = Limit.per_minute(\"rpm\", capacity=1000)\n\n# Strategy 2: Distribute load across entities\n# Instead of one shared entity, use sharded entities:\nshard = hash(request_id) % 10\nentity_id = f\"api-key-shard-{shard}\"\n\n# Strategy 3: Client-side rate limiting before acquire\n# Reduce concurrent requests to the same entity\n</code></pre>"},{"location":"performance/#running-benchmarks","title":"Running Benchmarks","text":"<p>Use the automated benchmark runner:</p> <pre><code># Run all benchmarks (moto + LocalStack)\npython scripts/run_benchmarks.py\n\n# Include AWS benchmarks\npython scripts/run_benchmarks.py --run-aws\n\n# Skip LocalStack (moto only)\npython scripts/run_benchmarks.py --skip-localstack\n\n# Custom output directory\npython scripts/run_benchmarks.py --output-dir ./results\n</code></pre> <p>Or run individual test suites:</p> <pre><code># Throughput tests\nuv run pytest tests/benchmark/test_throughput.py -v\n\n# Analyze results\npython -c \"import json; print(json.load(open('benchmark.json'))['benchmarks'])\"\n</code></pre>"},{"location":"performance/#6-cost-optimization-strategies","title":"6. Cost Optimization Strategies","text":""},{"location":"performance/#dynamodb-cost-breakdown","title":"DynamoDB Cost Breakdown","text":"<p>Costs vary by region. Using us-east-1 as reference:</p> Component On-Demand Cost Notes Write Request Units $0.625 per million Each WCU = one write Read Request Units $0.125 per million Each RCU = one read Storage $0.25 per GB/month Usually minimal Streams $0.02 per 100K reads Lambda polling Lambda $0.20 per million + duration Aggregator function"},{"location":"performance/#cost-estimation-examples","title":"Cost Estimation Examples","text":"<p>O(1) Costs (v0.7.0+)</p> <p>With composite bucket items, costs no longer multiply by number of limits. Whether you track 2 limits or 10 limits per request, DynamoDB costs are the same.</p>"},{"location":"performance/#low-volume-10k-requestsday","title":"Low Volume: 10K requests/day","text":"<pre><code>DynamoDB:\n  Writes: 10K \u00d7 30 days = 300K WCUs            = $0.19\n  Reads:  10K \u00d7 30 days = 300K RCUs            = $0.04\n  Streams: 300K events                         = $0.06\nLambda: 300K invocations                       \u2248 $0.06 + duration\nStorage: ~10 MB                                = negligible\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal: ~$0.35/month\n</code></pre>"},{"location":"performance/#medium-volume-1m-requestsday","title":"Medium Volume: 1M requests/day","text":"<pre><code>DynamoDB:\n  Writes: 1M \u00d7 30 = 30M WCUs                   = $18.75\n  Reads:  1M \u00d7 30 = 30M RCUs                   = $3.75\n  Streams: 30M events                          = $6.00\nLambda: 30M invocations                        \u2248 $6.00 + duration\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal (on-demand): ~$35/month\nTotal (provisioned with auto-scaling): ~$22/month\n</code></pre>"},{"location":"performance/#cost-reduction-strategies","title":"Cost Reduction Strategies","text":""},{"location":"performance/#1-disable-unused-features","title":"1. Disable Unused Features","text":"<pre><code># Create entity without cascade if not needed (saves 1-2 WCUs per request)\nawait limiter.create_entity(entity_id=\"entity\", parent_id=\"project-1\")  # cascade=False by default\nasync with limiter.acquire(\"entity\", \"api\", limits, {\"rpm\": 1}):\n    pass\n\n# Disable stored limits if static (saves 2 RCUs per request)\nlimiter = RateLimiter(name=\"rate-limits\", region=\"us-east-1\")\n</code></pre>"},{"location":"performance/#2-optimize-ttl-settings","title":"2. Optimize TTL Settings","text":"<pre><code># Shorter TTL = faster cleanup = less storage\n# bucket_ttl_seconds is configured via StackOptions or CloudFormation\nlimiter = RateLimiter(name=\"rate-limits\", region=\"us-east-1\")\n</code></pre>"},{"location":"performance/#3-reduce-snapshot-granularity","title":"3. Reduce Snapshot Granularity","text":"<pre><code># Deploy without aggregator if usage tracking not needed\nzae-limiter deploy --table-name rate_limits --no-aggregator\n</code></pre>"},{"location":"performance/#4-switch-to-provisioned-at-scale","title":"4. Switch to Provisioned at Scale","text":"<ul> <li>Break-even: ~5M operations/month</li> <li>Use auto-scaling with 70% target utilization</li> <li>Consider reserved capacity for &gt;20M ops/month</li> </ul>"},{"location":"performance/#5-batch-similar-operations","title":"5. Batch Similar Operations","text":"<pre><code># Combine multiple limits into single acquire\nasync with limiter.acquire(\n    entity_id=\"entity\",\n    resource=\"api\",\n    consume={\"rpm\": 1},  # 1 transaction vs 3\n    limits=[rpm_limit, tpm_limit, daily_limit],\n):\n    pass\n</code></pre>"},{"location":"performance/#cost-monitoring","title":"Cost Monitoring","text":"<p>Set up CloudWatch metrics for cost tracking:</p> <p>DynamoDB Metrics:</p> <ul> <li><code>ConsumedReadCapacityUnits</code></li> <li><code>ConsumedWriteCapacityUnits</code></li> <li><code>AccountProvisionedReadCapacityUtilization</code></li> <li><code>AccountProvisionedWriteCapacityUtilization</code></li> </ul> <p>Lambda Metrics:</p> <ul> <li><code>Invocations</code></li> <li><code>Duration</code></li> <li><code>ConcurrentExecutions</code></li> </ul> <p>Recommended Alerts:</p> <pre><code># Deploy with alarms for cost anomalies\nzae-limiter deploy --table-name rate_limits \\\n  --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:billing-alerts\n\n# Set AWS Budgets alert at 80% of expected monthly cost\naws budgets create-budget \\\n  --account-id 123456789012 \\\n  --budget file://budget.json \\\n  --notifications-with-subscribers file://notifications.json\n</code></pre>"},{"location":"performance/#7-config-cache-tuning","title":"7. Config Cache Tuning","text":"<p>The config cache reduces DynamoDB reads by caching system defaults, resource defaults, and entity limits. This section covers tuning the cache for your workload.</p>"},{"location":"performance/#cache-configuration","title":"Cache Configuration","text":"<pre><code>from zae_limiter import RateLimiter, Repository\n\n# Default: 60-second TTL (recommended for most workloads)\nrepo = Repository(name=\"my-app\", region=\"us-east-1\", config_cache_ttl=60)\nlimiter = RateLimiter(repository=repo)\n\n# High-frequency updates: Shorter TTL for faster propagation\nrepo = Repository(name=\"my-app\", region=\"us-east-1\", config_cache_ttl=10)\nlimiter = RateLimiter(repository=repo)\n\n# Disable caching: For testing or when config changes must be immediate\nrepo = Repository(name=\"my-app\", region=\"us-east-1\", config_cache_ttl=0)\nlimiter = RateLimiter(repository=repo)\n</code></pre>"},{"location":"performance/#cost-impact","title":"Cost Impact","text":"<p>Without caching, each <code>acquire()</code> call performs 3 DynamoDB reads to resolve limits:</p> <ol> <li>Entity-level config lookup (1 RCU)</li> <li>Resource-level config lookup (1 RCU)</li> <li>System-level config lookup (1 RCU)</li> </ol> <p>With caching (default):</p> Traffic Rate Cache Hit Rate Amortized RCU/request 1 req/sec 98.3% 0.05 RCU 10 req/sec 99.8% 0.005 RCU 100 req/sec 99.98% 0.0005 RCU <p>Negative caching also helps: When an entity has no custom config (95%+ of entities typically), the cache remembers this to avoid repeated lookups.</p>"},{"location":"performance/#automatic-cache-eviction","title":"Automatic Cache Eviction","text":"<p>Config-modifying methods (<code>set_limits()</code>, <code>delete_limits()</code>) automatically evict relevant cache entries. Manual invalidation is only needed after external changes (e.g., direct DynamoDB writes or changes from another process).</p>"},{"location":"performance/#manual-invalidation","title":"Manual Invalidation","text":"<p>After external config changes, force immediate refresh:</p> <pre><code>await repo.invalidate_config_cache()\n</code></pre> <p>Without manual invalidation, changes propagate within the TTL period (max 60 seconds by default).</p>"},{"location":"performance/#monitoring-cache-performance","title":"Monitoring Cache Performance","text":"<pre><code># Get cache statistics\nstats = repo.get_cache_stats()\ntotal = stats.hits + stats.misses\nprint(f\"Cache hit rate: {stats.hits / total:.1%}\" if total else \"No requests yet\")\nprint(f\"Cache entries: {stats.size}\")\nprint(f\"TTL: {stats.ttl_seconds}s\")\n</code></pre>"},{"location":"performance/#ttl-selection-guidelines","title":"TTL Selection Guidelines","text":"Scenario Recommended TTL Rationale Production (stable config) 60s (default) Best cost/latency trade-off Development/testing 10-30s Faster config iteration Compliance-critical 10-30s Minimizes staleness Testing with frequent changes 0 (disabled) Immediate visibility High-traffic APIs (&gt;100 req/s) 60-120s Maximize cache hits"},{"location":"performance/#8-speculative-writes","title":"8. Speculative Writes","text":"<p>Speculative writes (issue #315) enable a fast path for <code>acquire()</code> that skips the read round trip by issuing a conditional <code>UpdateItem</code> directly. This is most effective for pre-warmed buckets with sufficient capacity.</p>"},{"location":"performance/#configuring-speculative-writes","title":"Configuring Speculative Writes","text":"<pre><code>from zae_limiter import RateLimiter, Repository\n\nlimiter = RateLimiter(\n    repository=Repository(name=\"my-app\", region=\"us-east-1\"),\n    speculative_writes=True,  # Default\n)\n</code></pre>"},{"location":"performance/#how-it-works","title":"How It Works","text":"<p>Instead of the normal read-then-write flow (BatchGetItem + UpdateItem), the speculative path attempts a conditional UpdateItem first.</p> <p>First acquire (sequential, populates entity cache):</p> <pre><code>acquire(entity_id, resource, consume)\n|\n+- Speculative UpdateItem (condition: bucket exists AND has enough tokens)\n   |\n   +- SUCCEEDS -&gt; read cascade/parent_id from ALL_NEW, populate entity cache\n   |  +- cascade=False -&gt; DONE (1 RT, 0 RCU, 1 WCU)\n   |  +- cascade=True -&gt; Parent speculative UpdateItem (sequential)\n   |     +- SUCCEEDS -&gt; DONE (2 RT, 0 RCU, 2 WCU)\n   |     +- FAILS -&gt; [parent failure handling, see below]\n   |\n   +- FAILS (ConditionalCheckFailedException)\n      +- No ALL_OLD (bucket missing) -&gt; SLOW PATH (creates bucket)\n      +- Missing limit in ALL_OLD -&gt; SLOW PATH\n      +- Refill would help -&gt; SLOW PATH\n      +- Refill won't help -&gt; RateLimitExceeded (0 RCU, 0 WCU)\n</code></pre> <p>Subsequent acquires (parallel, issue #318):</p> <p>When the entity cache contains <code>(cascade=True, parent_id)</code> from a prior acquire, child and parent speculative writes are issued concurrently:</p> <pre><code>acquire(entity_id, resource, consume)   [cache hit: cascade=True, parent_id known]\n|\n+- asyncio.gather(child_speculative, parent_speculative)\n   |\n   +- BOTH SUCCEED -&gt; DONE (1 RT, 0 RCU, 2 WCU)\n   +- CHILD FAILS, PARENT SUCCEEDS -&gt; Compensate parent, check child ALL_OLD\n   |  +- [same child failure handling as sequential path]\n   +- CHILD SUCCEEDS, PARENT FAILS -&gt; Check parent ALL_OLD (child stays consumed)\n   |  +- No ALL_OLD (missing) -&gt; Compensate child, SLOW PATH\n   |  +- Missing limit -&gt; Compensate child, SLOW PATH\n   |  +- Refill won't help -&gt; Compensate child, RateLimitExceeded\n   |  +- Refill would help -&gt; Parent-only slow path (keep child)\n   |     +- Parent acquire succeeds -&gt; DONE (2 RT, 0.5 RCU, 3 WCU)\n   |     +- Parent acquire fails -&gt; Compensate child, SLOW PATH\n   +- BOTH FAIL -&gt; Check child ALL_OLD, fall back or fast-reject\n</code></pre> <p>The <code>ReturnValuesOnConditionCheckFailure=ALL_OLD</code> response provides the current bucket state on failure, allowing the limiter to determine whether refill would help without an additional read.</p> <p>Deferred cascade compensation: When the child speculative write succeeds but the parent fails with \"refill would help\", the child's consumption is kept in place while a parent-only slow path is attempted. This avoids compensating the child (1 WCU), re-reading it (0.5 RCU), and using TransactWriteItems for the full cascade write (4 WCU). Instead, only the parent is read (0.5 RCU) and written via a single-item UpdateItem (1 WCU). Compensation only happens when the parent-only path also fails.</p> <p>Entity metadata cache (issue #318): <code>Repository._entity_cache</code> stores <code>{entity_id: (cascade, parent_id)}</code> as immutable metadata with no TTL. After the first acquire populates the cache (from <code>ALL_NEW</code> on speculative success or from the entity META record on slow path), subsequent cascade acquires fire child and parent speculative writes concurrently via <code>asyncio.gather</code> inside <code>speculative_consume()</code>. This reduces cascade latency from 2 sequential round trips to 1 parallel round trip while maintaining the same WCU cost. In sync mode, <code>asyncio.gather</code> is transformed to <code>self._run_in_executor(lambda: a, lambda: b)</code> using a lazy <code>ThreadPoolExecutor(max_workers=2)</code> for true parallel execution.</p>"},{"location":"performance/#cost-comparison","title":"Cost Comparison","text":"Scenario Round Trips RCU WCU Cost per 1M Normal path (non-cascade) 2 1 1 $0.75 Speculative success (non-cascade) 1 0 1 $0.625 Speculative fast rejection (exhausted) 1 0 0 $0.00 Speculative fallback (refill helps) 3 1 2 $1.375 Normal path (cascade) 3 2 4 $1.75 Speculative success (cascade, sequential) 2 0 2 $1.25 Speculative success (cascade, parallel) 1 0 2 $1.25 Speculative cascade fallback (parent refill helps) 2+ 0.5 3 $2.00 Speculative cascade fast rejection (parent exhausted) 1 0 2 $1.25 <p>When speculative writes save money</p> <p>The speculative path is cheaper than the normal path when most requests succeed without needing refill. If a high percentage of requests fall back to the slow path (new entities, near-capacity buckets, frequent config changes), the extra WCU from the failed speculative write makes it more expensive.</p>"},{"location":"performance/#latency-comparison","title":"Latency Comparison","text":"Scenario Round Trips Expected Latency (in-region) Normal path (non-cascade) 2 10-15ms Speculative success (non-cascade) 1 5-8ms Speculative fast rejection (exhausted) 1 5-8ms Speculative fallback (refill helps) 3 15-22ms Normal path (cascade) 3 15-22ms Speculative success (cascade, sequential) 2 8-12ms Speculative success (cascade, parallel) 1 5-8ms Speculative cascade fallback (parent refill helps) 2+ 12-20ms Speculative cascade fast rejection (parent exhausted) 1 5-8ms"},{"location":"performance/#aggregator-assisted-refill-issue-317","title":"Aggregator-Assisted Refill (Issue #317)","text":"<p>When the Lambda aggregator is enabled, it proactively refills token buckets for active entities between client requests. This keeps speculative writes on the fast path (1 RT, 0 RCU, 1 WCU) by ensuring buckets have sufficient tokens, reducing fallback to the slow path (3 RT, 1 RCU, 2 WCU).</p> <p>How it works:</p> <ol> <li>The aggregator processes DynamoDB Stream events for bucket modifications</li> <li>For each active (entity, resource) bucket, it aggregates consumption deltas from the batch</li> <li>If projected tokens after natural refill are insufficient to cover the observed consumption rate, it writes a proactive refill</li> <li>The refill uses <code>ADD</code> (commutative with concurrent speculative writes) and an optimistic lock on <code>rf</code> to prevent double-refill</li> </ol> <p>Cost: 1 WCU per refill written (0 WCU if another writer updated <code>rf</code> first). The cost is amortized across all stream records in a batch, so high-throughput workloads see fewer refills per request.</p> <p>Aggregator refill + speculative writes</p> <p>The combination of aggregator-assisted refill and speculative writes provides the best latency and cost profile: the aggregator keeps buckets warm so speculative writes rarely fall back, achieving ~5-8ms p50 latency at $0.625/M requests (non-cascade).</p>"},{"location":"performance/#when-to-use-speculative-writes","title":"When to Use Speculative Writes","text":"<p>Good fit:</p> <ul> <li>High-throughput workloads with pre-warmed buckets</li> <li>Buckets that rarely exhaust capacity (high capacity relative to request rate)</li> <li>Latency-sensitive applications where saving one round trip matters</li> <li>Cascade entities with repeated acquires (entity cache enables parallel writes after first acquire)</li> <li>Deployments with the Lambda aggregator enabled (aggregator keeps buckets warm for speculative success)</li> </ul> <p>Poor fit:</p> <ul> <li>New entities that have never been seen before (first acquire always falls back)</li> <li>Near-capacity buckets that frequently exhaust (high fallback rate)</li> <li>Workloads with frequent config changes (missing limits trigger fallback)</li> <li>One-shot entities that are only acquired once (entity cache provides no benefit)</li> </ul>"},{"location":"performance/#monitoring-speculative-effectiveness","title":"Monitoring Speculative Effectiveness","text":"<p>Track the ratio of speculative successes to fallbacks to determine if speculative writes are beneficial for your workload:</p> <pre><code># Speculative writes work transparently with acquire()\n# Monitor DynamoDB ConsumedWriteCapacityUnits to observe:\n# - Lower WCU = more speculative successes\n# - Higher WCU = more fallbacks (consider disabling)\n</code></pre> <p>Disabling speculative writes</p> <p>If most requests are from new entities or near-capacity buckets, disable with <code>speculative_writes=False</code> to avoid the extra WCU from failed speculative attempts.</p>"},{"location":"performance/#9-load-testing-with-locust","title":"9. Load Testing with Locust","text":"<p>For realistic, multi-user load testing against a live DynamoDB stack, zae-limiter provides a Locust integration module (<code>zae_limiter.locust</code>). It exposes <code>RateLimiterUser</code> and <code>RateLimiterSession</code>, analogous to Locust's built-in <code>HttpUser</code> and <code>HttpSession</code>, so that every <code>acquire()</code>, <code>available()</code>, and management call fires Locust request events with timing.</p>"},{"location":"performance/#installation","title":"Installation","text":"<p>Install the <code>[bench]</code> extra to pull in Locust and its dependencies:</p> <pre><code># pip install zae-limiter[bench]\n</code></pre>"},{"location":"performance/#quick-start","title":"Quick Start","text":"<pre><code>from locust import task\nfrom zae_limiter.locust import RateLimiterUser\n\nclass MyUser(RateLimiterUser):\n    stack_name = \"my-limiter\"\n\n    @task\n    def do_acquire(self):\n        with self.client.acquire(\n            entity_id=\"user-123\",\n            resource=\"gpt-4\",\n            consume={\"rpm\": 1, \"tpm\": 500},\n            name=\"gpt-4/baseline\",\n        ):\n            pass  # simulate work\n</code></pre> <p>Run with:</p> <pre><code>locust -f locustfile.py --host &lt;stack-name&gt;\n</code></pre>"},{"location":"performance/#key-design-points","title":"Key Design Points","text":"<ul> <li>Shared limiter: A single <code>SyncRateLimiter</code> instance is shared across all Locust user greenlets (thread-safe via boto3).</li> <li>Connection pool: <code>_configure_boto3_pool()</code> automatically enlarges the boto3 connection pool (default 1000, override with <code>BOTO3_MAX_POOL</code> env var) to prevent pool exhaustion under high concurrency.</li> <li>Event types: <code>ACQUIRE</code>, <code>COMMIT</code>, <code>RATE_LIMITED</code>, <code>AVAILABLE</code>, and management operations (<code>SET_SYSTEM_DEFAULTS</code>, <code>CREATE_ENTITY</code>, etc.) appear as distinct request types in the Locust UI.</li> <li>Rate limit handling: <code>RateLimitExceeded</code> is tracked as <code>RATE_LIMITED</code> (not counted as a failure), so Locust statistics cleanly separate infrastructure errors from expected rate limiting.</li> </ul>"},{"location":"performance/#example-scenarios","title":"Example Scenarios","text":"<p>Pre-built locustfiles are available in <code>examples/locust/locustfiles/</code>:</p> Scenario File Description Simple <code>simple.py</code> Single resource, single limit, basic <code>acquire</code> Max RPS <code>max_rps.py</code> Zero-wait back-to-back <code>acquire</code> for throughput ceiling LLM Gateway <code>llm_gateway.py</code> 8 LLM models with RPM + TPM and lease adjustments LLM Production <code>llm_production.py</code> Weighted tasks with custom daily/spike load shapes Stress <code>stress.py</code> 16K entities with whale/spike/power-law traffic patterns <p>See <code>examples/locust/README.md</code> for full usage instructions including distributed execution on AWS.</p>"},{"location":"performance/#summary","title":"Summary","text":"Optimization Area Key Recommendations Capacity Start with on-demand, switch to provisioned at 5M+ ops/month Latency Expect 15-20ms p50 in-region, 35-45ms external; network is the dominant factor Throughput Distribute load across entities to avoid contention Cost Disable cascade/stored_limits when not needed Config Cache Use default 60s TTL; invalidate manually for immediate changes Speculative Writes Enable for pre-warmed high-throughput workloads; saves 1 round trip on success; cascade entities get parallel writes after first acquire Load Testing Use <code>zae_limiter.locust</code> with <code>RateLimiterUser</code> for realistic multi-user load tests; see <code>examples/locust/</code> Monitoring Set up CloudWatch alerts for capacity and cost anomalies <p>For detailed benchmark data, run: <pre><code>python scripts/run_benchmarks.py --run-aws\n</code></pre></p>"},{"location":"adr/000-adr-format-standard/","title":"ADR-000: ADR Format Standard","text":"<p>Status: Accepted Date: 2026-01-19</p>"},{"location":"adr/000-adr-format-standard/#context","title":"Context","text":"<p>Architecture Decision Records help teams understand why past decisions were made. Without consistent formatting, ADRs become hard to scan, compare, and maintain. Some ADRs balloon into design documents with code examples and implementation checklists, while others lack essential sections like alternatives considered.</p> <p>The team needs a standard format that keeps ADRs focused on the \"why\" while ensuring they remain concise and actionable.</p>"},{"location":"adr/000-adr-format-standard/#decision","title":"Decision","text":"<p>All ADRs must follow this format:</p> <ol> <li>Maximum 100 lines - If longer, split into multiple ADRs or move details to issues</li> <li>One decision per ADR - Each ADR documents exactly one architectural choice</li> <li>Required sections:</li> <li>Context (2-3 paragraphs max)</li> <li>Decision (1-2 sentences)</li> <li>Consequences (positive and negative bullet lists)</li> <li>Alternatives Considered (1 sentence rejection reason each)</li> <li>Excluded content (belongs in issues or design docs):</li> <li>Code examples or API signatures</li> <li>Implementation checklists</li> <li>Test cases</li> <li>Phased rollout plans</li> <li>Detailed cost calculations</li> <li>Enforceable decisions - Write decisions that can be deterministically verified:</li> <li>Use explicit prose requirements (\"must use X\", \"Y owns Z\")</li> <li>Avoid vague language (\"should\", \"ideally\", \"consider\")</li> <li>Link to issues for implementation details and examples</li> </ol>"},{"location":"adr/000-adr-format-standard/#consequences","title":"Consequences","text":"<p>Positive: - ADRs are quick to read and compare - Reviewers can focus on architectural reasoning, not implementation details - Consistent structure makes it easy to find information</p> <p>Negative: - Some decisions require linking to external design documents - Contributors must learn the format before writing ADRs</p>"},{"location":"adr/000-adr-format-standard/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/000-adr-format-standard/#free-form-documentation","title":"Free-form documentation","text":"<p>Rejected because: Inconsistent formats make ADRs hard to scan and maintain over time.</p>"},{"location":"adr/000-adr-format-standard/#detailed-design-documents","title":"Detailed design documents","text":"<p>Rejected because: Design docs focus on \"how\" rather than \"why\", and become stale after implementation.</p>"},{"location":"adr/001-single-table-dynamodb/","title":"ADR-001: Single-Table DynamoDB Design","text":"<p>Status: Accepted Date: 2026-01-09 Commit: 3902c8c Milestone: v0.1.0</p>"},{"location":"adr/001-single-table-dynamodb/#context","title":"Context","text":"<p>zae-limiter needs to store multiple entity types: entities (users/API keys), token buckets, limits, audit events, usage snapshots, and version metadata. Traditional relational design would use separate tables, but DynamoDB pricing and access patterns favor different approaches.</p> <p>Key requirements: - Atomic multi-item transactions (entity + buckets in single transaction) - Efficient parent-child lookups (hierarchical entities) - Resource-level aggregation (capacity across all entities) - Pay-per-request pricing optimization</p>"},{"location":"adr/001-single-table-dynamodb/#decision","title":"Decision","text":"<p>Use single-table design with composite keys and GSIs for all access patterns.</p> <p>Key structure: - <code>PK</code>: Entity/resource identifier (e.g., <code>ENTITY#user-1</code>, <code>RESOURCE#gpt-4</code>, <code>SYSTEM#</code>) - <code>SK</code>: Record type and identifiers (e.g., <code>#META</code>, <code>#BUCKET#gpt-4#tpm</code>, <code>#AUDIT#2026-01-01T00:00:00Z</code>)</p> <p>Global Secondary Indexes: - <code>GSI1</code>: Parent \u2192 Children lookups (<code>GSI1PK=PARENT#{id}</code>) - <code>GSI2</code>: Resource aggregation (<code>GSI2PK=RESOURCE#{name}</code>)</p>"},{"location":"adr/001-single-table-dynamodb/#consequences","title":"Consequences","text":"<p>Positive: - Single table = single provisioning decision, simpler cost management - TransactWriteItems works across all record types (max 100 items) - Efficient queries: entity + all buckets in single query - Natural fit for hierarchical data (parent/child via GSI1)</p> <p>Negative: - More complex key design requires careful documentation - Hot partition risk if single entity has extreme traffic - GSI costs for every write (mitigated by sparse indexes)</p>"},{"location":"adr/001-single-table-dynamodb/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Multi-table design: Rejected due to cross-table transaction limitations and higher operational complexity</li> <li>Adjacency list only: Rejected; GSIs provide cleaner access patterns for resource aggregation</li> </ul>"},{"location":"adr/002-integer-arithmetic-millitokens/","title":"ADR-002: Integer Arithmetic with Millitokens","text":"<p>Status: Accepted Date: 2026-01-09 Commit: 3902c8c Milestone: v0.1.0</p>"},{"location":"adr/002-integer-arithmetic-millitokens/#context","title":"Context","text":"<p>Token bucket algorithms require tracking fractional tokens during refill calculations. In distributed systems, floating-point arithmetic can cause precision issues:</p> <ul> <li>IEEE 754 floating-point has representation errors (0.1 + 0.2 \u2260 0.3)</li> <li>Different clients/languages may have slightly different FP implementations</li> <li>Accumulated rounding errors cause bucket drift over time</li> <li>DynamoDB stores numbers as strings, adding serialization concerns</li> </ul>"},{"location":"adr/002-integer-arithmetic-millitokens/#decision","title":"Decision","text":"<p>Store all token values as millitokens (\u00d71000) using integer arithmetic.</p> <p>Implementation: - Internal storage: <code>tokens_milli</code> (integer) - User-facing API: <code>tokens</code> (float, converted at boundary) - Refill stored as fraction: <code>refill_amount</code> / <code>refill_period_seconds</code> - All bucket math uses integer operations</p>"},{"location":"adr/002-integer-arithmetic-millitokens/#consequences","title":"Consequences","text":"<p>Positive: - Exact arithmetic: no precision loss across any number of operations - Deterministic: same calculation yields identical results everywhere - Simple debugging: values are exact integers - DynamoDB-friendly: integers serialize cleanly</p> <p>Negative: - API boundary conversion required (minor complexity) - Sub-millitoken precision not supported (acceptable for rate limiting) - Developers must remember internal representation when debugging</p>"},{"location":"adr/002-integer-arithmetic-millitokens/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Decimal type: Rejected; Python's Decimal doesn't map cleanly to DynamoDB Number type</li> <li>Floating-point with rounding: Rejected; accumulated errors in long-running buckets</li> <li>Fixed-point with higher precision (microtokens): Rejected; millitokens sufficient for rate limiting use cases</li> </ul>"},{"location":"adr/003-cloudformation-infrastructure/","title":"ADR-003: CloudFormation Infrastructure Deployment","text":"<p>Status: Accepted Date: 2026-01-10 PR: #8 Milestone: v0.1.0</p>"},{"location":"adr/003-cloudformation-infrastructure/#context","title":"Context","text":"<p>zae-limiter requires DynamoDB tables, Lambda functions, DynamoDB Streams, IAM roles, and CloudWatch resources. Users need a way to deploy and manage this infrastructure.</p> <p>Options considered: - Programmatic table creation via boto3 - CloudFormation templates - CDK constructs - Terraform modules</p>"},{"location":"adr/003-cloudformation-infrastructure/#decision","title":"Decision","text":"<p>Use CloudFormation as the primary infrastructure deployment mechanism, with a CLI for user convenience.</p> <p>Implementation: - Embedded CloudFormation template (<code>cfn_template.yaml</code>) - CLI commands: <code>deploy</code>, <code>delete</code>, <code>status</code>, <code>cfn-template</code> - Stack naming convention: <code>ZAEL-{identifier}</code> prefix - Auto-detection of LocalStack for local development</p>"},{"location":"adr/003-cloudformation-infrastructure/#consequences","title":"Consequences","text":"<p>Positive: - Declarative infrastructure with drift detection - Easy cleanup: delete entire stack removes all resources - Native AWS integration (no external tools required) - Template export for users who want customization - Consistent naming across all AWS resources</p> <p>Negative: - CloudFormation deployment is slower than direct API calls - Template complexity grows with features (alarms, DLQ, etc.) - LocalStack CloudFormation support occasionally lags AWS</p>"},{"location":"adr/003-cloudformation-infrastructure/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Programmatic creation only: Rejected; no drift detection, harder cleanup, inconsistent state on partial failures</li> <li>CDK-first: Rejected; adds Node.js dependency, higher barrier for simple deployments</li> <li>Terraform: Rejected; external tool dependency, different ecosystem than target users</li> </ul>"},{"location":"adr/004-declarative-stack-options/","title":"ADR-004: Declarative Infrastructure with StackOptions","text":"<p>Status: Accepted Date: 2026-01-12 PR: #69 Milestone: v0.2.0</p>"},{"location":"adr/004-declarative-stack-options/#context","title":"Context","text":"<p>The initial <code>create_stack=True</code> boolean parameter was insufficient for production deployments. Users needed to configure Lambda memory, alarms, SNS topics, and other stack parameters. The API had grown to include both <code>create_stack: bool</code> and <code>stack_parameters: dict[str, str]</code>, which was error-prone and not type-safe.</p>"},{"location":"adr/004-declarative-stack-options/#decision","title":"Decision","text":"<p>Replace <code>create_stack</code> and <code>stack_parameters</code> with a unified <code>stack_options: StackOptions | None</code> parameter.</p> <p>Implementation: - <code>StackOptions</code> frozen dataclass with all configuration - Validation in <code>__post_init__</code> for bounds checking - <code>to_parameters()</code> method for CloudFormation conversion - <code>None</code> = don't manage infrastructure; <code>StackOptions()</code> = manage with defaults</p>"},{"location":"adr/004-declarative-stack-options/#consequences","title":"Consequences","text":"<p>Positive: - Type-safe configuration with IDE autocomplete - Self-documenting API (all options visible in dataclass) - Validation at construction time, not deployment time - Clear semantics: presence of StackOptions = infrastructure management enabled - Enables \"self-deploying\" applications</p> <p>Negative: - Breaking change from <code>create_stack</code> parameter - More verbose for simple cases (<code>StackOptions()</code> vs <code>create_stack=True</code>)</p>"},{"location":"adr/004-declarative-stack-options/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Keep boolean + dict: Rejected; not type-safe, no validation, poor discoverability</li> <li>Builder pattern: Rejected; more complex API for same outcome</li> <li>Separate configuration file: Rejected; adds deployment complexity, harder to keep in sync</li> </ul>"},{"location":"adr/005-exception-hierarchy/","title":"ADR-005: Categorized Exception Hierarchy","text":"<p>Status: Accepted Date: 2026-01-11 PR: #53 Issue: #29 Milestone: v0.2.0</p>"},{"location":"adr/005-exception-hierarchy/#context","title":"Context","text":"<p>The initial exception design had flat inheritance from <code>Exception</code>, making it difficult to catch categories of errors. <code>EntityNotFoundError</code> inherited from <code>RateLimitError</code> despite not being a rate limit issue. Users couldn't distinguish infrastructure failures from entity errors.</p>"},{"location":"adr/005-exception-hierarchy/#decision","title":"Decision","text":"<p>Implement categorized exception hierarchy with semantic grouping.</p> <p>Hierarchy: <pre><code>ZAELimiterError (base)\n\u251c\u2500\u2500 RateLimitError (rate limiting)\n\u2502   \u251c\u2500\u2500 RateLimitExceeded\n\u2502   \u2514\u2500\u2500 RateLimiterUnavailable\n\u251c\u2500\u2500 InfrastructureError (AWS/CloudFormation)\n\u2502   \u251c\u2500\u2500 StackCreationError\n\u2502   \u2514\u2500\u2500 InfrastructureNotFoundError\n\u251c\u2500\u2500 EntityError (CRUD operations)\n\u2502   \u251c\u2500\u2500 EntityNotFoundError\n\u2502   \u2514\u2500\u2500 EntityExistsError\n\u2514\u2500\u2500 VersionError (compatibility)\n    \u251c\u2500\u2500 VersionMismatchError\n    \u2514\u2500\u2500 IncompatibleSchemaError\n</code></pre></p>"},{"location":"adr/005-exception-hierarchy/#consequences","title":"Consequences","text":"<p>Positive: - Catch broad categories (<code>except RateLimitError</code>) or specific exceptions - Semantic clarity: exception type indicates problem domain - Follows Python conventions (<code>requests.RequestException</code>, etc.) - Backward compatible: existing catches still work</p> <p>Negative: - More exception classes to maintain - Migration required for code catching moved exceptions (e.g., <code>EntityNotFoundError</code>)</p>"},{"location":"adr/005-exception-hierarchy/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Flat hierarchy: Rejected; no category-level catching, poor semantics</li> <li>Error codes instead of types: Rejected; not Pythonic, loses type checking benefits</li> <li>Fewer categories: Rejected; infrastructure vs entity distinction valuable for error handling</li> </ul>"},{"location":"adr/006-flat-schema-snapshots/","title":"ADR-006: Flat Schema for Usage Snapshots","text":"<p>Status: Accepted Date: 2026-01-11 (initial), 2026-01-16 (confirmed) PRs: #20, #172 Issue: #168 Milestone: v0.1.0, v0.4.0</p>"},{"location":"adr/006-flat-schema-snapshots/#context","title":"Context","text":"<p>Usage snapshots aggregate consumption data (tpm, rpm, total_events) per entity/resource/time window. The Lambda aggregator uses <code>UpdateItem</code> with <code>ADD</code> for atomic counter increments. Initial implementation used nested <code>data.M</code> maps like other record types.</p> <p>DynamoDB limitation discovered: You cannot SET a map path (<code>#data = if_not_exists(#data, :map)</code>) AND ADD to paths within it (<code>#data.counter</code>) in the same UpdateExpression. It fails with \"overlapping document paths\" error.</p>"},{"location":"adr/006-flat-schema-snapshots/#decision","title":"Decision","text":"<p>Use flat schema (top-level attributes) for usage snapshot records, diverging from the nested <code>data.M</code> pattern used elsewhere.</p> <p>Snapshot structure: <pre><code>{\n    \"PK\": \"ENTITY#user-1\",\n    \"SK\": \"#USAGE#gpt-4#2024-01-01T14:00:00Z\",\n    \"resource\": \"gpt-4\",      # Top-level\n    \"window\": \"hourly\",       # Top-level\n    \"tpm\": 5000,              # Counter at top-level\n    \"total_events\": 10,       # Counter at top-level\n}\n</code></pre></p>"},{"location":"adr/006-flat-schema-snapshots/#consequences","title":"Consequences","text":"<p>Positive: - Atomic upsert with ADD counters works correctly - Single UpdateItem call creates or updates record - No pre-existence check required</p> <p>Negative: - Schema inconsistency with other record types (entities, buckets use nested <code>data.M</code>) - Established pattern for v0.6.0 full schema flattening (see #180)</p>"},{"location":"adr/006-flat-schema-snapshots/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Two-step create-then-update: Rejected; race conditions, higher latency, more RCU/WCU</li> <li>Conditional expressions with retries: Rejected; complex error handling, still potential races</li> <li>Store in separate table: Rejected; loses single-table benefits, complicates transactions</li> </ul>"},{"location":"adr/007-input-validation/","title":"ADR-007: Input Validation for Injection Prevention","text":"<p>Status: Accepted Date: 2026-01-12 PR: #75 Issue: #48 Milestone: v0.2.0</p>"},{"location":"adr/007-input-validation/#context","title":"Context","text":"<p>DynamoDB keys use <code>#</code> as a delimiter (e.g., <code>ENTITY#user-1#BUCKET#gpt-4</code>). Without validation, malicious input containing <code>#</code> could:</p> <ul> <li>Traverse to different record types</li> <li>Access other entities' data</li> <li>Corrupt key structure</li> </ul> <p>This is analogous to SQL injection but for DynamoDB key-based access patterns.</p>"},{"location":"adr/007-input-validation/#decision","title":"Decision","text":"<p>Add comprehensive input validation at model construction time, forbidding the <code>#</code> delimiter character in all user-provided identifiers.</p> <p>Validation rules:</p> Field Pattern Max Length <code>entity_id</code>, <code>parent_id</code> <code>^[a-zA-Z0-9][a-zA-Z0-9_.\\-:@]*$</code> 256 <code>limit_name</code>, <code>resource</code> <code>^[a-zA-Z][a-zA-Z0-9_.\\-]*$</code> 64 <p>New exceptions: - <code>ValidationError</code> (base) - <code>InvalidIdentifierError</code> (entity_id, parent_id) - <code>InvalidNameError</code> (limit_name, resource)</p>"},{"location":"adr/007-input-validation/#consequences","title":"Consequences","text":"<p>Positive: - Injection attacks impossible by construction - Early failure with clear error messages - Supports common ID formats: UUIDs, API keys, emails - Validation happens once at model creation, not on every operation</p> <p>Negative: - Some previously-valid IDs may be rejected (containing <code>#</code>) - Migration required for existing data with invalid characters</p>"},{"location":"adr/007-input-validation/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Escape/encode special characters: Rejected; complex, error-prone, obscures data in DynamoDB console</li> <li>Validate only at repository layer: Rejected; too late, models could be passed around with invalid data</li> <li>Allowlist specific formats (UUID only): Rejected; too restrictive for diverse use cases</li> </ul>"},{"location":"adr/008-security-audit-logging/","title":"ADR-008: Security Audit Logging","text":"<p>Status: Accepted Date: 2026-01-12 PR: #76 Issue: #47 Milestone: v0.2.0</p>"},{"location":"adr/008-security-audit-logging/#context","title":"Context","text":"<p>Rate limiting systems control access to resources, making them security-sensitive. Compliance requirements (SOC 2, HIPAA) and security best practices require audit trails for:</p> <ul> <li>Who changed rate limits and when</li> <li>Entity lifecycle (creation, deletion)</li> <li>Configuration modifications</li> </ul> <p>Without audit logging, investigating security incidents or proving compliance is difficult.</p>"},{"location":"adr/008-security-audit-logging/#decision","title":"Decision","text":"<p>Store audit events in DynamoDB alongside rate limiting data, with automatic TTL-based expiration.</p> <p>Audit events logged:</p> Action Trigger Details <code>entity_created</code> <code>create_entity()</code> name, parent_id, metadata <code>entity_deleted</code> <code>delete_entity()</code> records_deleted count <code>limits_set</code> <code>set_limits()</code> resource, limits config <code>limits_deleted</code> <code>delete_limits()</code> resource <p>Key structure: <code>PK=AUDIT#{entity_id}, SK=#AUDIT#{timestamp}</code></p> <p>Optional <code>principal</code> parameter tracks who performed the action.</p>"},{"location":"adr/008-security-audit-logging/#consequences","title":"Consequences","text":"<p>Positive: - Full audit trail without external dependencies - Same access patterns as other data (single table) - Automatic cleanup via DynamoDB TTL (default 90 days) - Principal tracking enables accountability</p> <p>Negative: - Storage cost for audit records (mitigated by TTL) - No real-time alerting (would require separate system) - Audit records deleted with TTL, not archived (see #77 for S3 archival)</p>"},{"location":"adr/008-security-audit-logging/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>CloudTrail only: Rejected; doesn't capture application-level details (which limits changed)</li> <li>External audit service: Rejected; adds dependency, latency, cost</li> <li>Separate audit table: Rejected; loses transactional consistency with entity operations</li> </ul>"},{"location":"adr/009-version-migration-system/","title":"ADR-009: Schema Version Migration System","text":"<p>Status: Accepted Date: 2026-01-10 PR: #15 Milestone: v0.1.0</p>"},{"location":"adr/009-version-migration-system/#context","title":"Context","text":"<p>As the library evolves, DynamoDB schema changes may be required. Without version tracking:</p> <ul> <li>Clients can't detect incompatible infrastructure</li> <li>No mechanism to run schema migrations</li> <li>Lambda and client code can drift out of sync</li> <li>Rolling updates are unsafe</li> </ul>"},{"location":"adr/009-version-migration-system/#decision","title":"Decision","text":"<p>Implement version tracking in both DynamoDB and CloudFormation, with a migration framework for schema changes.</p> <p>Components:</p> <ol> <li>Version record: <code>PK=SYSTEM#, SK=#VERSION</code> stores current schema version</li> <li>Stack tags: CloudFormation stack tagged with <code>SchemaVersion</code></li> <li>Lambda env var: <code>SCHEMA_VERSION</code> for runtime compatibility checks</li> <li>Migration registry: Python framework for versioned migrations</li> </ol> <p>Client parameters: - <code>auto_update</code>: Auto-update Lambda on version mismatch (default: True, configured via <code>RepositoryBuilder.auto_update()</code>)</p> <p>Note: <code>strict_version</code> and <code>skip_version_check</code> were removed in v0.10.0 when version management moved from RateLimiter to Repository/RepositoryBuilder.</p>"},{"location":"adr/009-version-migration-system/#consequences","title":"Consequences","text":"<p>Positive: - Safe rolling updates: detect incompatibility before operations - Automated Lambda updates when client library upgraded - Migration framework ready for future schema changes - Clear versioning across all components</p> <p>Negative: - Additional DynamoDB read on first operation (version check) - Complexity in version comparison logic - Migrations must be backward-compatible or coordinated</p>"},{"location":"adr/009-version-migration-system/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>No versioning: Rejected; silent failures on schema mismatch, unsafe upgrades</li> <li>Stack tags only: Rejected; doesn't help Lambda or clients detect issues at runtime</li> <li>External version store (SSM): Rejected; adds dependency, latency, different IAM permissions</li> </ul>"},{"location":"adr/010-total-consumed-counter/","title":"ADR-010: Total Consumed Counter for Accurate Delta Tracking","text":"<p>Status: Accepted Date: 2026-01-16 PR: #169 Issue: #179 Milestone: v0.4.0</p>"},{"location":"adr/010-total-consumed-counter/#context","title":"Context","text":"<p>The Lambda aggregator processes DynamoDB Streams to create usage snapshots. Initial implementation derived consumption from token bucket state changes:</p> <pre><code>consumption = old_tokens - new_tokens\n</code></pre> <p>This fails when token refill rate exceeds consumption rate. Example with 10M TPM limit: - Refill during 100ms operation: ~16,667 tokens - Actual consumption: 1,000 tokens - Calculated delta: -15,667 (wrong!)</p> <p>The fundamental problem: token bucket state conflates consumption with refill.</p>"},{"location":"adr/010-total-consumed-counter/#decision","title":"Decision","text":"<p>Add <code>total_consumed_milli</code> counter that tracks net consumption independently of refill.</p> <p>Implementation: - Counter stored as flat top-level attribute (not nested in <code>data.M</code>) - Consume: <code>counter += amount * 1000</code> - Release/adjust(negative): <code>counter -= amount * 1000</code> - Delta calculation: <code>new_counter - old_counter</code></p> <p>Why flat attribute: Enables atomic ADD operations in UpdateExpression without \"overlapping document paths\" error (same reason as ADR-006).</p>"},{"location":"adr/010-total-consumed-counter/#consequences","title":"Consequences","text":"<p>Positive: - Accurate consumption tracking regardless of refill rate - Works at any scale (tested with 10M+ TPM) - Simple delta calculation in aggregator - Net tracking handles both consume and release operations</p> <p>Negative: - Hybrid schema: most bucket fields nested, counter flat - Additional attribute in every bucket record - Existing buckets need migration (counter initialized to 0)</p>"},{"location":"adr/010-total-consumed-counter/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Track consumption in separate record: Rejected; doubles write operations, transaction complexity</li> <li>Calculate from refill formula: Rejected; requires knowing exact timing, error-prone</li> <li>Store last_consumed timestamp: Rejected; doesn't handle variable consumption rates</li> </ul>"},{"location":"adr/011-api-cli-parity/","title":"ADR-011: API/CLI Interface Parity","text":"<p>Status: Accepted Date: 2026-01-15 PRs: #141, #153, #188 Milestone: v0.3.0</p>"},{"location":"adr/011-api-cli-parity/#context","title":"Context","text":"<p>zae-limiter serves two distinct user personas:</p> <ol> <li>Developers integrate rate limiting into applications via Python API</li> <li>Operators manage infrastructure, debug issues, and run reports via CLI</li> </ol> <p>Early development added features to one interface without considering the other, creating gaps: - <code>get_status()</code> existed in API but no CLI equivalent - <code>audit list</code> existed in CLI but no API method - Naming inconsistencies between interfaces</p>"},{"location":"adr/011-api-cli-parity/#decision","title":"Decision","text":"<p>Maintain interface parity with explicit exceptions based on use case.</p> <p>Parity matrix:</p> Feature Type API CLI Rationale Infrastructure ops \u2705 \u2705 Both personas manage stacks Data queries \u2705 \u2705 Debugging from code or terminal Admin actions \u2705 \u2705 Automation needs both Runtime limiting \u2705 \u274c Only meaningful in application context Template exports \u274c \u2705 One-time ops task, not programmatic <p>Naming alignment: API method names map predictably to CLI commands.</p>"},{"location":"adr/011-api-cli-parity/#consequences","title":"Consequences","text":"<p>Positive: - Consistent user experience across interfaces - Features discoverable in both contexts - Automation scripts can use either interface - Documentation covers both without gaps</p> <p>Negative: - More implementation work per feature (two interfaces) - Must maintain naming discipline across interfaces - Some features feel forced in one interface (e.g., <code>cfn-template</code> as API)</p>"},{"location":"adr/011-api-cli-parity/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>CLI wraps API only: Rejected; some operations are CLI-native (interactive prompts, template export)</li> <li>API only: Rejected; operators need CLI for shell scripts and debugging</li> <li>No parity requirement: Rejected; leads to fragmented UX and documentation gaps</li> </ul>"},{"location":"adr/012-cloudformation-docs-parity/","title":"ADR-012: CloudFormation Documentation Parity","text":"<p>Status: Superseded by ADR-013 Date: 2026-01-19</p>"},{"location":"adr/012-cloudformation-docs-parity/#context","title":"Context","text":"<p>The CloudFormation template (<code>cfn_template.yaml</code>) defines all infrastructure resources for zae-limiter. The operator documentation (<code>docs/infra/cloudformation.md</code>) includes a Mermaid diagram and detailed documentation of parameters, resources, and outputs.</p> <p>When the template is modified (new parameters, resources, conditions, or outputs), the documentation can become stale, leading to: - Operators discovering features only by reading the template - Mermaid diagram missing new resource relationships - Parameter tables incomplete or outdated - Output tables missing new exports</p>"},{"location":"adr/012-cloudformation-docs-parity/#decision","title":"Decision","text":"<p>Whenever the CloudFormation template is modified, the documentation at <code>docs/infra/cloudformation.md</code> must be updated to reflect:</p> <ol> <li>Mermaid diagram - Add/remove resources and relationships</li> <li>Parameters table - Add/remove/update parameter descriptions</li> <li>Outputs table - Add/remove stack outputs</li> <li>Resource sections - Document new resource types</li> </ol> <p>This is enforced through the <code>docs-updater</code> agent which is invoked after infrastructure changes.</p>"},{"location":"adr/012-cloudformation-docs-parity/#consequences","title":"Consequences","text":"<p>Positive: - Operators can rely on documentation being current - Mermaid diagram provides accurate visual overview - Parameter and output tables are authoritative references</p> <p>Negative: - Additional work when modifying CloudFormation template - Requires discipline to invoke docs-updater agent</p>"},{"location":"adr/012-cloudformation-docs-parity/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Auto-generate docs from template: Rejected; loses narrative context and customization examples</li> <li>No parity requirement: Rejected; documentation drift degrades operator experience</li> </ul>"},{"location":"adr/013-module-documentation-parity/","title":"ADR-013: Bidirectional Source-Documentation Parity","text":"<p>Status: Proposed Date: 2026-01-19 Supersedes: ADR-012</p>"},{"location":"adr/013-module-documentation-parity/#context","title":"Context","text":"<p>Source code and documentation frequently drift out of sync. When <code>limiter.py</code> adds a <code>repository</code> parameter, the getting-started guide still shows the old constructor. When <code>cli.py</code> adds <code>--enable-tracing</code>, the CLI reference is missing it. When someone updates docs to describe a planned feature, users try to use APIs that don't exist yet.</p> <p>The project has narrow-scope ADRs (ADR-011 for API/CLI parity, ADR-012 for CloudFormation docs), but contributors must guess which documentation files need updating for changes outside those areas.</p>"},{"location":"adr/013-module-documentation-parity/#decision","title":"Decision","text":"<p>Maintain a bidirectional mapping between source modules and documentation. When either side changes, verify the other is synchronized.</p> Source Documentation What to Sync <code>limiter.py</code> <code>docs/api/limiter.md</code>, <code>docs/guide/basic-usage.md</code> Constructor signatures, method examples <code>models.py</code> <code>docs/api/models.md</code> Dataclass fields, factory methods <code>exceptions.py</code> <code>docs/api/exceptions.md</code> Exception classes, error fields <code>cli.py</code> <code>docs/cli.md</code> Commands, flags, usage examples <code>repository.py</code> <code>docs/contributing/architecture.md</code> Protocol methods, schema patterns <code>schema.py</code> <code>docs/contributing/architecture.md</code> Key patterns, GSI definitions <code>bucket.py</code> <code>docs/guide/token-bucket.md</code> Algorithm formulas, refill math <code>infra/cfn_template.yaml</code> <code>docs/infra/cloudformation.md</code> Mermaid diagram, parameters, outputs <code>infra/</code> (other) <code>docs/infra/deployment.md</code> CLI examples, StackOptions fields <code>aggregator/</code> <code>docs/guide/usage-snapshots.md</code> Stream processing, snapshot schema <code>__init__.py</code> <code>docs/api/index.md</code> Public exports, module docstring"},{"location":"adr/013-module-documentation-parity/#consequences","title":"Consequences","text":"<p>Positive: - Contributors know exactly which files to update for any change - Users can trust that documented examples match actual behavior - Reviewers can check documentation coverage during PR review</p> <p>Negative: - Every code change requires checking corresponding documentation - Matrix needs updating when new modules are added</p>"},{"location":"adr/013-module-documentation-parity/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Convention-based mapping (e.g., <code>foo.py</code> \u2192 <code>docs/foo.md</code>): Rejected; our docs structure doesn't mirror source structure, and implicit rules are easily forgotten</li> <li>Documentation-only reviews: Rejected; catching drift after the fact means users already hit broken examples</li> </ul>"},{"location":"adr/100-centralized-config/","title":"ADR-100: Centralized Configuration Access Patterns","text":"<p>Status: Proposed Date: 2026-01-18 Issue: #129 Milestone: v0.5.0</p>"},{"location":"adr/100-centralized-config/#context","title":"Context","text":"<p>zae-limiter is a distributed rate limiting library where multiple clients must behave consistently. Currently:</p> <ol> <li>Limits passed explicitly - Each <code>acquire()</code> call requires limits</li> <li>No global defaults - Cannot set system-wide or resource-level default limits</li> <li>No caching - <code>use_stored_limits=True</code> queries DynamoDB on every call</li> <li>Scattered config - Behavior settings are constructor-only, risking inconsistent fail-open/fail-closed behavior</li> </ol>"},{"location":"adr/100-centralized-config/#decision","title":"Decision","text":"<p>Implement centralized configuration with these architectural choices:</p> Decision ADR Summary Schema format ADR-101 Flat schema (no nested <code>data.M</code>) for atomic counters Config hierarchy ADR-102 Three levels: System &gt; Resource &gt; Entity Caching strategy ADR-103 60s TTL with negative caching API behavior ADR-104 Stored limits as default Read consistency ADR-105 Eventually consistent reads"},{"location":"adr/100-centralized-config/#consequences","title":"Consequences","text":"<p>Positive: - Consistent behavior across distributed clients - Negligible cost with caching (~0.00025 RCU/request at scale) - Enables per-resource and per-entity customization - Clean upgrade path to v0.6.0 full schema migration</p> <p>Negative: - Max 60s staleness for config changes - Additional complexity in resolution logic - Breaking change for explicit-limits-only users</p>"},{"location":"adr/100-centralized-config/#access-patterns-added","title":"Access Patterns Added","text":"Pattern Query Index Get system config <code>PK=SYSTEM#, SK begins_with #LIMIT#</code> Primary Get resource config <code>PK=RESOURCE#{resource}, SK begins_with #LIMIT#</code> Primary Get entity config <code>PK=ENTITY#{id}, SK begins_with #LIMIT#</code> Primary"},{"location":"adr/100-centralized-config/#implementation","title":"Implementation","text":"<p>See linked issues for implementation details:</p> <ul> <li>#130 - Store system/resource config</li> <li>#131 - System-level default limits</li> <li>#135 - Client-side config cache</li> <li>#180 - v0.6.0 full schema flattening</li> </ul>"},{"location":"adr/101-flat-schema-config/","title":"ADR-101: Flat Schema for Config Records","text":"<p>Status: Accepted Date: 2026-01-18 Issue: #129</p>"},{"location":"adr/101-flat-schema-config/#context","title":"Context","text":"<p>The codebase has three DynamoDB schema patterns:</p> Pattern Records Use Case Nested <code>data.M</code> Entities, Limits, Audit, Version No atomic counters needed Hybrid Buckets (<code>total_consumed_milli</code> flat) Mostly nested + one atomic counter Flat Snapshots Atomic upsert with ADD counters <p>DynamoDB rejects UpdateExpressions that combine <code>SET #data = if_not_exists(#data, :map)</code> with <code>ADD #data.counter :delta</code> due to \"overlapping document paths\" (issues #168, #179).</p> <p>New config records need atomic <code>config_version</code> counter increments for cache invalidation.</p>"},{"location":"adr/101-flat-schema-config/#decision","title":"Decision","text":"<p>Use flat schema (no nested <code>data.M</code>) for all new config records at System, Resource, and Entity levels. This matches the snapshot pattern established in v0.4.0.</p> <p>v0.6.0 recommendation: Flatten all existing record types (entities, limits, audit, version) for consistency. See #180.</p>"},{"location":"adr/101-flat-schema-config/#consequences","title":"Consequences","text":"<p>Positive: - Enables atomic <code>config_version</code> counter increments - Consistent with snapshot pattern (v0.4.0) - Sets standard: flat schema for all new records - Forward compatible with v0.6.0 full schema migration</p> <p>Negative: - v0.6.0 will require migration work to flatten existing records - Two schema patterns coexist until v0.6.0</p>"},{"location":"adr/101-flat-schema-config/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/101-flat-schema-config/#nested-datam-schema","title":"Nested <code>data.M</code> Schema","text":"<p>Rejected: Inconsistent with flat snapshot pattern; DynamoDB prevents atomic counters with nested paths.</p>"},{"location":"adr/101-flat-schema-config/#hybrid-schema-like-buckets","title":"Hybrid Schema (like buckets)","text":"<p>Rejected: Adds complexity; better to standardize on flat for new records.</p>"},{"location":"adr/102-config-hierarchy/","title":"ADR-102: Three-Level Configuration Hierarchy","text":"<p>Status: Superseded by ADR-118 Date: 2026-01-18 Issues: #129, #130, #131</p>"},{"location":"adr/102-config-hierarchy/#context","title":"Context","text":"<p>zae-limiter clients need consistent configuration across distributed instances. Currently:</p> <ol> <li>No global defaults - Cannot set system-wide default limits that apply to all resources</li> <li>No resource defaults - Cannot set per-resource limits without per-entity configuration</li> <li>Scattered config - Behavior settings (<code>on_unavailable</code>) are constructor-only</li> <li>Risk of inconsistency - Different clients may have different fail-open/fail-closed behavior</li> </ol> <p>Operators need to set global defaults while allowing per-resource and per-entity overrides.</p>"},{"location":"adr/102-config-hierarchy/#decision","title":"Decision","text":"<p>Implement a three-level configuration hierarchy with precedence: Entity &gt; Resource &gt; System &gt; Constructor defaults.</p> Level PK SK Purpose System <code>SYSTEM#</code> <code>#LIMIT#{limit_name}</code> Global defaults for ALL resources System <code>SYSTEM#</code> <code>#CONFIG</code> Behavior config (<code>on_unavailable</code>, etc.) Resource <code>RESOURCE#{resource}</code> <code>#LIMIT#{limit_name}</code> Per-resource overrides Entity <code>ENTITY#{id}</code> <code>#LIMIT#{resource}#{limit_name}</code> Per-entity+resource overrides <p>Key distinction: - System limits apply universally (no resource association) - Resource limits override system defaults for a specific resource - Entity limits override resource/system defaults for a specific entity+resource pair</p> <p>Config field scope:</p> Field System Resource Entity Limit fields (<code>capacity</code>, etc.) \u2705 \u2705 \u2705 <code>on_unavailable</code> \u2705 \u274c \u274c <code>auto_update</code>, <code>strict_version</code> \u2705 \u274c \u274c"},{"location":"adr/102-config-hierarchy/#consequences","title":"Consequences","text":"<p>Positive: - Consistent behavior across distributed clients - Enables per-resource overrides (expensive model \u2192 lower limits) - Premium users can have different limits via entity config - Clean separation: system = global, resource = per-model, entity = per-user</p> <p>Negative: - 3 levels to check per cache miss (mitigated by caching, see ADR-103) - More complex resolution logic</p>"},{"location":"adr/102-config-hierarchy/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/102-config-hierarchy/#single-level-system-only","title":"Single-level (System only)","text":"<p>Rejected: No per-resource or per-entity customization; insufficient for real-world use cases.</p>"},{"location":"adr/102-config-hierarchy/#two-level-system-entity","title":"Two-level (System + Entity)","text":"<p>Rejected: Resource-level is common (different limits per model); would force entity-level duplication.</p>"},{"location":"adr/102-config-hierarchy/#system-config-keyed-by-resource-original-design","title":"System config keyed by resource (original design)","text":"<p>Rejected: Redundant with resource-level config; system should be truly global defaults.</p>"},{"location":"adr/103-config-caching/","title":"ADR-103: Client-Side Config Caching with TTL","text":"<p>Status: Superseded by ADR-122 Date: 2026-01-18 Issue: #135</p>"},{"location":"adr/103-config-caching/#context","title":"Context","text":"<p>The three-level config hierarchy (ADR-102) requires fetching 3 DynamoDB items per <code>acquire()</code> call. Without caching:</p> <ul> <li>Cost: 1.5 RCU per request (unacceptable at scale)</li> <li>Latency: BatchGetItem round-trip on every request</li> </ul> <p>Config changes are infrequent (typically during deployment or admin operations), making aggressive caching appropriate.</p>"},{"location":"adr/103-config-caching/#decision","title":"Decision","text":"<p>Implement in-memory TTL caching per RateLimiter instance with 60-second TTL and negative caching.</p> <p>Negative caching: Cache \"no entity config exists\" to avoid repeated misses for the 95%+ of users without custom limits.</p> <p>Cache invalidation: - Automatic: TTL expiry (60s) - Manual: <code>repo.invalidate_config_cache()</code> method (on Repository, not RateLimiter)</p> <p>No distributed invalidation: Config changes propagate via TTL expiry (max 60s staleness). This avoids infrastructure complexity (SNS/EventBridge) for infrequent operations.</p>"},{"location":"adr/103-config-caching/#consequences","title":"Consequences","text":"<p>Positive: - High-frequency traffic: 99.98% cache hit rate (100 req/sec \u00d7 60s = 6K hits per miss) - Negligible amortized cost: +0.00025 RCU per request at scale - Negative caching reduces cost for sparse traffic patterns</p> <p>Negative: - Max 60s staleness for config changes - No cross-process invalidation (each instance has independent cache) - Memory usage scales with unique entity\u00d7resource combinations</p>"},{"location":"adr/103-config-caching/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/103-config-caching/#no-caching","title":"No Caching","text":"<p>Rejected: 1.5 RCU per acquire is unacceptable; poor latency.</p>"},{"location":"adr/103-config-caching/#distributed-cache-rediselasticache","title":"Distributed Cache (Redis/ElastiCache)","text":"<p>Rejected: Adds infrastructure dependency; 60s staleness is acceptable for config.</p>"},{"location":"adr/103-config-caching/#dynamodb-streams-for-invalidation","title":"DynamoDB Streams for Invalidation","text":"<p>Rejected: Requires Lambda infrastructure; complexity not justified for config updates.</p>"},{"location":"adr/104-stored-limits-default/","title":"ADR-104: Stored Limits as Default Behavior","text":"<p>Status: Accepted Date: 2026-01-18 Issue: #130</p>"},{"location":"adr/104-stored-limits-default/#context","title":"Context","text":"<p>Currently, <code>acquire()</code> requires explicit limits or opt-in via <code>use_stored_limits=True</code>:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10000)],  # Required\n    use_stored_limits=False,  # Default\n):\n    pass\n</code></pre> <p>This creates friction: users must pass limits on every call or remember to opt-in. With centralized config (ADR-102), stored limits become the natural default.</p>"},{"location":"adr/104-stored-limits-default/#decision","title":"Decision","text":"<p>Change the default behavior: always resolve limits from stored config (System &gt; Resource &gt; Entity hierarchy).</p> <p>Resolution order: 1. Entity config \u2192 if exists, use it 2. Resource config \u2192 if exists, use it 3. System config \u2192 fallback 4. Error if no config found anywhere</p> <p>Backward compatibility: - <code>limits</code> parameter accepted as override (useful for testing, migration) - <code>use_stored_limits=False</code> deprecated with warning in v0.5.0, removed in v1.0</p>"},{"location":"adr/104-stored-limits-default/#consequences","title":"Consequences","text":"<p>Positive: - Simpler API: no limits parameter needed in common case - Centralized control: ops can change limits without code deployment - Consistent behavior: all clients use same stored config</p> <p>Negative: - Breaking change for users relying on explicit limits only - Requires config to be set up before use (or <code>limits</code> override)</p>"},{"location":"adr/104-stored-limits-default/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/104-stored-limits-default/#keep-opt-in-use_stored_limitstrue","title":"Keep Opt-In (<code>use_stored_limits=True</code>)","text":"<p>Rejected: Adds friction; stored config is the better default now that hierarchy exists.</p>"},{"location":"adr/104-stored-limits-default/#remove-limits-parameter-entirely","title":"Remove <code>limits</code> Parameter Entirely","text":"<p>Rejected: Useful for testing and gradual migration; keep as override option.</p>"},{"location":"adr/105-eventual-consistency/","title":"ADR-105: Eventually Consistent Reads for Config","text":"<p>Status: Accepted Date: 2026-01-18 Issue: #129</p>"},{"location":"adr/105-eventual-consistency/#context","title":"Context","text":"<p>DynamoDB offers two read consistency modes:</p> Consistency Cost Typical Latency Strongly consistent 1 RCU / 4KB Higher Eventually consistent 0.5 RCU / 4KB Lower <p>Config reads fetch 3 items per cache miss (System, Resource, Entity). With caching (ADR-103), we already accept 60s staleness for config changes.</p>"},{"location":"adr/105-eventual-consistency/#decision","title":"Decision","text":"<p>Use eventually consistent reads for all config fetches.</p> <p>Rationale: Since the caching layer accepts 60s staleness, sub-second DynamoDB eventual consistency is negligible. This reduces config fetch cost from 3 RCU to 1.5 RCU per cache miss.</p>"},{"location":"adr/105-eventual-consistency/#consequences","title":"Consequences","text":"<p>Positive: - 50% RCU cost reduction for config reads - Lower latency (eventually consistent reads are faster) - Aligned with caching semantics (staleness already accepted)</p> <p>Negative: - Theoretical sub-second staleness on config reads (negligible given 60s cache TTL)</p>"},{"location":"adr/105-eventual-consistency/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/105-eventual-consistency/#strongly-consistent-reads","title":"Strongly Consistent Reads","text":"<p>Rejected: 2x cost for no practical benefit; caching already introduces 60s staleness window.</p>"},{"location":"adr/105-eventual-consistency/#mixed-consistency-strong-for-entity-eventual-for-systemresource","title":"Mixed Consistency (strong for entity, eventual for system/resource)","text":"<p>Rejected: Adds complexity; consistency should be uniform across config levels.</p>"},{"location":"adr/106-audit-entity-ids-for-config/","title":"ADR-106: Audit Entity IDs for Config Levels","text":"<p>Status: Accepted Date: 2026-01-19 Issue: #130</p>"},{"location":"adr/106-audit-entity-ids-for-config/#context","title":"Context","text":"<p>The audit logging system requires an <code>entity_id</code> for all audit events. This works naturally for entity-level operations where the entity_id is the actual entity being modified.</p> <p>However, system-level and resource-level config changes (introduced in #130) have no natural entity. System config applies globally, and resource config applies to a resource name rather than a specific entity.</p> <p>Additionally, operators need to query audit trails for config changes separately from entity changes. Mixing config audits with entity audits under arbitrary entity IDs would make compliance queries difficult.</p>"},{"location":"adr/106-audit-entity-ids-for-config/#decision","title":"Decision","text":"<p>Use special prefixes for config-level audit entity IDs: - System config: <code>$SYSTEM</code> - Resource config: <code>$RESOURCE:{resource_name}</code> (e.g., <code>$RESOURCE:gpt-4</code>)</p> <p>The <code>$</code> prefix is chosen because it cannot appear in valid entity IDs (which must start with alphanumeric characters per validation rules).</p>"},{"location":"adr/106-audit-entity-ids-for-config/#consequences","title":"Consequences","text":"<p>Positive: - Clear distinction between entity and config audit events - Operators can query all system config changes via <code>entity_id=$SYSTEM</code> - Resource config audits are grouped by resource name - No collision risk with real entity IDs</p> <p>Negative: - Introduces a reserved character convention that must be documented - Audit queries for \"all changes\" must now include both entity and <code>$</code>-prefixed patterns</p>"},{"location":"adr/106-audit-entity-ids-for-config/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/106-audit-entity-ids-for-config/#use-literal-strings-without-prefix-eg-system","title":"Use literal strings without prefix (e.g., \"SYSTEM\")","text":"<p>Rejected: Could collide with actual entity IDs if a user creates an entity named \"SYSTEM\".</p>"},{"location":"adr/106-audit-entity-ids-for-config/#skip-audit-logging-for-config-changes","title":"Skip audit logging for config changes","text":"<p>Rejected: Config changes are security-sensitive operations that require audit trails for compliance.</p>"},{"location":"adr/107-iam-roles-for-application-access/","title":"ADR-107: IAM Roles for Application Access","text":"<p>Status: Accepted Date: 2026-01-19 Issue: #132</p>"},{"location":"adr/107-iam-roles-for-application-access/#context","title":"Context","text":"<p>Users deploying zae-limiter must create their own IAM policies to access the DynamoDB table. This requires understanding the exact DynamoDB actions needed for different use cases (applications vs. administrators vs. monitoring), leading to either overly permissive policies or trial-and-error debugging of permission errors.</p> <p>The CloudFormation stack currently only creates the Lambda execution role for the aggregator. Different deployment patterns require different access levels: applications need transactional write access for <code>acquire()</code>, administrators need full CRUD for configuration management, and monitoring systems need read-only access.</p>"},{"location":"adr/107-iam-roles-for-application-access/#decision","title":"Decision","text":"<p>The CloudFormation stack creates three optional IAM roles (AppRole, AdminRole, ReadOnlyRole) with least-privilege DynamoDB permissions, enabled by default and controlled via <code>--no-iam-roles</code> flag or <code>StackOptions.create_iam_roles=False</code>.</p>"},{"location":"adr/107-iam-roles-for-application-access/#consequences","title":"Consequences","text":"<p>Positive: - Easy onboarding with correct IAM permissions out-of-the-box - Least-privilege security enforced by default - Clear separation between app/admin/monitoring access patterns - Roles respect existing <code>permission_boundary</code> and <code>role_name_format</code> options - No new IAM permission requirements (stack already needs <code>iam:CreateRole</code> for Lambda)</p> <p>Negative: - Three additional IAM roles per stack increases IAM resource count - Users with existing IAM setup may have redundant roles (use <code>--no-iam-roles</code>)</p>"},{"location":"adr/107-iam-roles-for-application-access/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/107-iam-roles-for-application-access/#inline-iam-policies-in-documentation-only","title":"Inline IAM policies in documentation only","text":"<p>Rejected because: Users still need to create and maintain policies manually, defeating the goal of easy onboarding.</p>"},{"location":"adr/107-iam-roles-for-application-access/#single-role-with-configurable-permissions","title":"Single role with configurable permissions","text":"<p>Rejected because: A single role can't satisfy least-privilege for different access patterns; applications shouldn't have config deletion rights.</p>"},{"location":"adr/107-iam-roles-for-application-access/#iam-policies-attached-to-user-provided-roles","title":"IAM policies attached to user-provided roles","text":"<p>Rejected because: Increases deployment complexity by requiring users to pre-create roles and pass ARNs as parameters.</p>"},{"location":"adr/108-repository-protocol/","title":"ADR-108: Repository Protocol Design","text":"<p>Status: Accepted Date: 2026-01-19 Issue: #150 Milestone: v0.5.0</p>"},{"location":"adr/108-repository-protocol/#context","title":"Context","text":"<p><code>RateLimiter</code> tightly couples business logic to DynamoDB by constructing its own <code>Repository</code> internally. This creates testing friction, backend lock-in, and misplaced infrastructure concerns. Users wanting alternative backends (Redis #149, SQLite #156, In-Memory #157) would need invasive changes, and third-party packages cannot implement backends without depending on zae-limiter.</p>"},{"location":"adr/108-repository-protocol/#decision","title":"Decision","text":"<p>Use Python's <code>typing.Protocol</code> with <code>@runtime_checkable</code> decorator to define <code>RepositoryProtocol</code>. This enables duck typing, third-party backends without zae-limiter dependency, and easy mock injection for testing.</p> <p>Key design choices:</p> <ol> <li>Protocol over ABC: Any object with matching methods satisfies the protocol\u2014no inheritance required</li> <li>Infrastructure ownership: Repository owns data access and infrastructure (<code>StackOptions</code>); RateLimiter owns business logic only</li> <li>Method categorization:</li> <li>Required: entity CRUD, bucket operations, transactions, limit config, lifecycle</li> <li>Optional: audit events, usage snapshots (backend-specific, not in protocol)</li> <li>Capability-gated: batch operations (detected via <code>capabilities</code> property)</li> <li>Infrastructure API: <code>ensure_infrastructure()</code> replaces <code>create_stack()</code>; <code>stack_options</code> passed to constructor, not method</li> </ol> <p>See #150 for implementation details and method signatures.</p>"},{"location":"adr/108-repository-protocol/#consequences","title":"Consequences","text":"<p>Positive: - Clean separation of concerns (data vs business logic) - Backend flexibility without breaking changes - Third-party extensibility without zae-limiter dependency - Testability via mock injection - Type safety with <code>@runtime_checkable</code></p> <p>Negative: - More verbose construction (two objects instead of one) - Deprecation period requires maintaining both constructor signatures - Optional methods require type narrowing to access</p>"},{"location":"adr/108-repository-protocol/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/108-repository-protocol/#abstract-base-class-abc","title":"Abstract Base Class (ABC)","text":"<p>Rejected: Requires inheritance, preventing duck typing; less Pythonic for interfaces.</p>"},{"location":"adr/108-repository-protocol/#keep-stackoptions-on-ratelimiter","title":"Keep StackOptions on RateLimiter","text":"<p>Rejected: Conflates business logic with infrastructure; violates single responsibility.</p>"},{"location":"adr/108-repository-protocol/#separate-sync-and-async-protocols","title":"Separate Sync and Async Protocols","text":"<p>Rejected: Increases surface area; <code>SyncRateLimiter</code> can wrap async with <code>asyncio.run()</code>.</p>"},{"location":"adr/109-backend-capability-matrix/","title":"ADR-109: Backend Capability Matrix","text":"<p>Status: Accepted Date: 2026-01-19 Issue: #150 Milestone: v0.5.0</p>"},{"location":"adr/109-backend-capability-matrix/#context","title":"Context","text":"<p>The RepositoryProtocol extraction (#150) enables multiple storage backends (Redis #149, SQLite #156, In-Memory #157, Cosmos DB #158, Firestore #159, OCI NoSQL #160). Each backend has different capabilities. This ADR defines which features are required versus optional.</p>"},{"location":"adr/109-backend-capability-matrix/#decision","title":"Decision","text":"<p>Define a three-tier capability system:</p> Tier Requirement Examples Core Required for all backends Token bucket, entity CRUD, transactions Standard Expected for production Hierarchical limits, cascade, TTL Extended Backend-specific, optional Audit logging, usage snapshots, infrastructure <p>Core features (all backends MUST implement): entity CRUD, bucket operations, atomic transactions, limit configuration, lifecycle management.</p> <p>Standard features (production backends SHOULD implement): hierarchical entities via <code>parent_id</code>, cascade support, TTL management, optimistic locking.</p> <p>Extended features (declared via <code>BackendCapabilities</code>): audit logging, usage snapshots, infrastructure management, change streams, batch operations. Backends declare support via capability flags; RateLimiter checks before using.</p>"},{"location":"adr/109-backend-capability-matrix/#capability-matrix","title":"Capability Matrix","text":"Backend Audit Snapshots Infra Mgmt Streams Batch DynamoDB Yes Yes CloudFormation Yes Yes Redis Streams Consumer Manual Yes Pipeline SQLite Table Polling N/A No No In-Memory No No N/A No No Cosmos DB TBD TBD ARM/Terraform Yes Bulk Firestore TBD TBD Terraform Yes getAll <p>See #150 for method signatures and implementation details.</p>"},{"location":"adr/109-backend-capability-matrix/#consequences","title":"Consequences","text":"<p>Positive: - Clear contract for backend implementers - Users know what to expect from each backend - Core features guaranteed; extensibility without breaking changes</p> <p>Negative: - Feature disparity between backends - Documentation and testing matrix grows with each backend</p>"},{"location":"adr/109-backend-capability-matrix/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/109-backend-capability-matrix/#all-features-required","title":"All features required","text":"<p>Rejected: Forces backends to implement unsuitable features (e.g., In-Memory with audit logging).</p>"},{"location":"adr/109-backend-capability-matrix/#no-capability-declaration","title":"No capability declaration","text":"<p>Rejected: Users can't discover available features.</p>"},{"location":"adr/109-backend-capability-matrix/#separate-protocols-per-tier","title":"Separate protocols per tier","text":"<p>Rejected: Overly complex; single protocol with capabilities is cleaner.</p>"},{"location":"adr/110-deprecation-constructor/","title":"ADR-110: Deprecation Strategy for RateLimiter Constructor","text":"<p>Status: Accepted Date: 2026-01-19 Issue: #150 Milestone: v0.5.0</p>"},{"location":"adr/110-deprecation-constructor/#context","title":"Context","text":"<p>The <code>RateLimiter</code> constructor conflates business logic (<code>on_unavailable</code>) with data access configuration (<code>name</code>, <code>region</code>, <code>endpoint_url</code>, <code>stack_options</code>). Per ADR-108, Repository should own data access and infrastructure, while RateLimiter owns only business logic. This requires deprecating the old constructor parameters.</p>"},{"location":"adr/110-deprecation-constructor/#decision","title":"Decision","text":"<p>Deprecate <code>name</code>, <code>region</code>, <code>endpoint_url</code>, and <code>stack_options</code> parameters on <code>RateLimiter</code> and <code>SyncRateLimiter</code>. Introduce a <code>repository</code> parameter accepting <code>RepositoryProtocol</code>.</p> <p>Deprecation rules: 1. Old parameters emit <code>DeprecationWarning</code> with <code>stacklevel=2</code> 2. Passing both <code>repository</code> and <code>name</code> raises <code>ValueError</code> 3. When neither provided, default to <code>Repository(name=\"limiter\")</code> for backward compatibility 4. Applies to both <code>RateLimiter</code> and <code>SyncRateLimiter</code></p> <p>Timeline:</p> Version Behavior v0.4.x Only old signature v0.5.0 Both work; old emits warning v0.6.0\u2013v1.x Warning remains v2.0.0 Old parameters removed <p>See #150 for migration guide and examples.</p>"},{"location":"adr/110-deprecation-constructor/#consequences","title":"Consequences","text":"<p>Positive: - Clear separation of concerns - Enables mock repositories for testing - Gradual migration with 1+ major version cycle</p> <p>Negative: - More verbose construction - Users must migrate before v2.0.0 - Docs must cover both patterns during transition</p>"},{"location":"adr/110-deprecation-constructor/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/110-deprecation-constructor/#keep-parameters-add-repository-as-optional","title":"Keep Parameters, Add Repository as Optional","text":"<p>Rejected: Creates ambiguity; doesn't achieve separation goal.</p>"},{"location":"adr/110-deprecation-constructor/#remove-immediately-breaking-change","title":"Remove Immediately (Breaking Change)","text":"<p>Rejected: Violates semver; users face immediate breakage.</p>"},{"location":"adr/110-deprecation-constructor/#factory-method-ratelimiterfrom_repository","title":"Factory Method (<code>RateLimiter.from_repository()</code>)","text":"<p>Rejected: Two \"right\" ways; cleaner to have single constructor with deprecation.</p>"},{"location":"adr/111-flatten-all-records/","title":"ADR-111: Flatten All DynamoDB Records to Top-Level Attributes","text":"<p>Status: Accepted Date: 2026-01-25 Issue: #180</p>"},{"location":"adr/111-flatten-all-records/#context","title":"Context","text":"<p>The codebase accumulated three DynamoDB schema patterns: nested <code>data.M</code> maps (entities, limits, audit events, version records), hybrid (buckets with one flat counter), and flat (usage snapshots and config records). ADR-006 and ADR-010 introduced flat attributes to solve DynamoDB's \"overlapping document paths\" limitation. ADR-101 standardized flat schema for all new config records and explicitly recommended flattening existing record types in v0.6.0.</p> <p>The mixed patterns create inconsistency in serialization/deserialization code, complicate the aggregator Lambda (which must navigate nested paths), and make the codebase harder to maintain. Every new feature must decide which pattern to use, adding cognitive overhead.</p>"},{"location":"adr/111-flatten-all-records/#decision","title":"Decision","text":"<p>All DynamoDB record types must use flat schema (top-level attributes, no nested <code>data.M</code> wrapper). Deserialization reads flat format only. Pre-1.0.0 semver allows breaking changes without migration \u2014 existing nested records are not supported. Serialization produces only flat format.</p>"},{"location":"adr/111-flatten-all-records/#consequences","title":"Consequences","text":"<p>Positive: - Uniform schema across all record types eliminates pattern inconsistency - Simpler serialization code without <code>data.M</code> wrapper construction - Aggregator Lambda reads flat attributes directly instead of navigating nested paths - Enables atomic operations on any attribute without \"overlapping paths\" errors - No branching logic in deserializers</p> <p>Negative: - Existing nested <code>data.M</code> records from pre-0.6.0 deployments must be recreated (no migration path provided pre-1.0.0) - DynamoDB reserved words (<code>name</code>, <code>resource</code>, <code>action</code>, <code>timestamp</code>) require <code>ExpressionAttributeNames</code> aliases in all expressions</p>"},{"location":"adr/111-flatten-all-records/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/111-flatten-all-records/#keep-nested-datam-for-existing-records","title":"Keep nested <code>data.M</code> for existing records","text":"<p>Rejected because: Perpetuates schema inconsistency; ADR-101 already committed to flattening in v0.6.0.</p>"},{"location":"adr/111-flatten-all-records/#big-bang-migration-write-stops-until-all-records-migrated","title":"Big-bang migration (write stops until all records migrated)","text":"<p>Rejected because: Requires downtime; pre-1.0.0 semver makes migration unnecessary \u2014 breaking changes are expected.</p>"},{"location":"adr/111-flatten-all-records/#flatten-only-on-read-no-serialization-changes","title":"Flatten only on read (no serialization changes)","text":"<p>Rejected because: Leaves old-format records indefinitely; new writes would still produce nested format, preventing convergence.</p>"},{"location":"adr/112-cascade-per-entity/","title":"ADR-112: Move Cascade from Per-Call to Per-Entity Configuration","text":"<p>Status: Accepted Date: 2026-01-25</p>"},{"location":"adr/112-cascade-per-entity/#context","title":"Context","text":"<p>Cascade mode controls whether <code>acquire()</code> consumes tokens from both a child entity and its parent. Currently cascade is a per-call boolean parameter on <code>acquire(cascade=True)</code>, requiring callers to remember to pass it on every call. This is error-prone: forgetting <code>cascade=True</code> silently skips parent enforcement, and different call sites for the same entity may pass inconsistent values.</p> <p>Cascade is a property of the entity's relationship to its parent \u2014 it describes how the child participates in the hierarchy, not a per-request decision. Storing it on the entity makes the behavior consistent and eliminates a class of caller errors.</p> <p>The library is pre-1.0, so breaking parameter removal is acceptable without a deprecation period.</p>"},{"location":"adr/112-cascade-per-entity/#decision","title":"Decision","text":"<p>The <code>cascade</code> parameter must be removed from <code>acquire()</code> and stored as a <code>cascade: bool = False</code> attribute on the child entity's <code>#META</code> record. <code>create_entity()</code> must accept <code>cascade</code> as a parameter. <code>_do_acquire()</code> must read <code>entity.cascade</code> to determine whether to include the parent in the transaction.</p> <p><code>cascade</code> is a DynamoDB reserved word and must use <code>ExpressionAttributeNames</code> aliases in all expressions, consistent with the existing handling of <code>name</code>, <code>resource</code>, <code>action</code>, and <code>timestamp</code> (ADR-111).</p> <p>Existing entities without the <code>cascade</code> attribute must deserialize with <code>cascade=False</code> (backward compatible default).</p>"},{"location":"adr/112-cascade-per-entity/#consequences","title":"Consequences","text":"<p>Positive: - Cascade behavior is consistent for all calls to the same entity - Callers cannot accidentally omit cascade - Entity metadata is self-describing \u2014 inspecting the entity reveals its cascade behavior - No new DynamoDB reads: <code>acquire()</code> already fetches the entity's <code>#META</code> record</p> <p>Negative: - Breaking change: all callers passing <code>cascade=True</code> to <code>acquire()</code> must move it to <code>create_entity()</code> - Changing cascade for an existing entity requires entity recreation or a new <code>update_entity()</code> API</p>"},{"location":"adr/112-cascade-per-entity/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/112-cascade-per-entity/#keep-cascade-as-per-call-parameter","title":"Keep cascade as per-call parameter","text":"<p>Rejected because: Error-prone, inconsistent across call sites, and conflates a static entity property with a runtime decision.</p>"},{"location":"adr/112-cascade-per-entity/#store-as-enum-noneparentall_ancestors","title":"Store as enum (<code>none|parent|all_ancestors</code>)","text":"<p>Rejected because: The codebase only supports 2-level hierarchy. A boolean is sufficient; a future ADR can supersede if deeper cascading is needed.</p>"},{"location":"adr/112-cascade-per-entity/#store-on-parent-entity-instead-of-child","title":"Store on parent entity instead of child","text":"<p>Rejected because: The child decides whether to cascade up. Storing on the parent would require the parent to know about all children's behavior, adding coordination overhead.</p>"},{"location":"adr/113-lambda-packaging/","title":"ADR-113: Lambda Packaging","text":"<p>Status: Accepted Date: 2026-01-27 Issue: #154</p>"},{"location":"adr/113-lambda-packaging/#context","title":"Context","text":"<p>The Lambda aggregator previously bundled the entire <code>zae_limiter</code> package with all runtime dependencies into the Lambda zip. This resulted in a ~17 MB deployment package containing libraries like <code>aioboto3</code>, <code>aiohttp</code>, <code>click</code>, <code>pip</code>, and other packages that the aggregator never uses. The aggregator only needs <code>boto3</code> (provided by the Lambda runtime), <code>aws-lambda-powertools</code>, and <code>zae_limiter.schema</code>.</p> <p>The project needed a packaging approach that: - Produces a small Lambda zip (~1-2 MB instead of ~17 MB) - Only bundles what the aggregator actually uses - Works cross-platform (macOS/Windows host building for Linux Lambda) - Does not require Docker - Is compatible with LocalStack free tier (no Lambda Layers)</p>"},{"location":"adr/113-lambda-packaging/#decision","title":"Decision","text":"<ol> <li> <p>Separate the aggregator into its own top-level package <code>zae_limiter_aggregator</code> (installed alongside <code>zae_limiter</code> from the same wheel).</p> </li> <li> <p>Minimal Lambda zip \u2014 The Lambda builder copies only:</p> </li> <li><code>zae_limiter_aggregator/</code> (all <code>.py</code> files)</li> <li><code>zae_limiter/__init__.py</code> (empty stub \u2014 avoids importing <code>aioboto3</code>)</li> <li><code>zae_limiter/schema.py</code> (full copy \u2014 only imports <code>typing</code>, no external deps)</li> <li> <p><code>[lambda]</code> extra dependencies via <code>aws-lambda-builders</code> (only <code>aws-lambda-powertools</code>)</p> </li> <li> <p>Empty <code>__init__.py</code> stub \u2014 Python's import system executes <code>zae_limiter/__init__.py</code> when the aggregator does <code>from zae_limiter.schema import ...</code>. The real <code>__init__.py</code> imports <code>aioboto3</code> which isn't available in Lambda. The empty stub avoids this.</p> </li> <li> <p><code>aws-lambda-builders</code> remains a base dependency for cross-platform pip installs of the <code>[lambda]</code> extra.</p> </li> </ol>"},{"location":"adr/113-lambda-packaging/#consequences","title":"Consequences","text":"<p>Positive: - Lambda zip size reduced from ~17 MB to ~1-2 MB (aws-lambda-powertools + source files only) - No <code>aioboto3</code>, <code>aiohttp</code>, <code>botocore</code>, <code>click</code>, <code>pip</code> in the Lambda zip - <code>boto3</code> provided by Lambda runtime \u2014 no need to bundle - Cross-platform builds work without Docker - Compatible with LocalStack free tier (no Lambda Layers required) - Dev/unreleased versions work because local packages are copied, not downloaded from PyPI - Clean separation of concerns: aggregator is independently importable</p> <p>Negative: - Two packages to manage in the wheel (<code>zae_limiter</code> + <code>zae_limiter_aggregator</code>) - Empty <code>__init__.py</code> stub is a packaging workaround (not a true standalone package) - <code>aws-lambda-builders</code> and <code>pip</code> remain as base dependencies</p>"},{"location":"adr/113-lambda-packaging/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/113-lambda-packaging/#lambda-layers","title":"Lambda Layers","text":"<p>Rejected because: LocalStack free tier does not support Lambda Layers, breaking local development.</p>"},{"location":"adr/113-lambda-packaging/#separate-pypi-package-zae-limiter-lambda","title":"Separate PyPI package (zae-limiter-lambda)","text":"<p>Rejected because: Requires shipping a zip file artifact and keeping two packages in sync, adding maintenance burden.</p>"},{"location":"adr/113-lambda-packaging/#docker-based-builds-samcdk","title":"Docker-based builds (SAM/CDK)","text":"<p>Rejected because: Requires Docker installed on the build machine, adding a heavy dependency for what should be a lightweight CLI operation.</p>"},{"location":"adr/113-lambda-packaging/#pip-platform-with-only-binary","title":"pip --platform with --only-binary","text":"<p>Rejected because: Only works for packages with pre-built wheels; fails for packages requiring compilation, and aws-lambda-builders already wraps this approach with better error handling.</p>"},{"location":"adr/113-lambda-packaging/#bundle-full-zae_limiter-with-all-deps","title":"Bundle full zae_limiter with all deps","text":"<p>Rejected because: Produces ~17 MB zip with unnecessary packages (aioboto3, aiohttp, click, pip) that the aggregator never imports.</p>"},{"location":"adr/114-composite-bucket-items/","title":"ADR-114: Composite Bucket Items","text":"<p>Status: Proposed Date: 2026-01-28 Issue: #248</p>"},{"location":"adr/114-composite-bucket-items/#context","title":"Context","text":"<p>Each rate limit (rpm, tpm) for an entity+resource is stored as a separate DynamoDB item with SK <code>#BUCKET#{resource}#{limit_name}</code>. For an entity with N limits, <code>acquire()</code> reads N+1 items via BatchGetItem and writes N items via TransactWriteItems. The transaction 2x WCU tax means 2 limits with cascade costs 11 CU per acquire, scaling linearly with limit count.</p> <p>GSI2 produces N entries per entity+resource (one per limit), inflating resource aggregation queries. The per-limit item design also prevents atomic operations across limits \u2014 each item is updated independently within the transaction.</p> <p>Entity metadata (<code>#META</code>) must remain a separate item because it carries GSI1 keys for parent\u2192children queries. Merging META into bucket items would duplicate it across resources and break GSI1 deduplication. The existing 60s config cache already skips META reads on cache hits.</p>"},{"location":"adr/114-composite-bucket-items/#decision","title":"Decision","text":"<p>All limits for an entity+resource must be stored in a single composite DynamoDB item with SK <code>#BUCKET#{resource}</code>. Per-limit attributes must use the prefix <code>b_{limit_name}_{field}</code> with short field names: <code>tk</code> (tokens), <code>cp</code> (capacity), <code>bx</code> (burst), <code>ra</code> (refill amount), <code>rp</code> (refill period), <code>tc</code> (total consumed). GSI2SK must be per-entity (<code>BUCKET#{entity_id}</code>), not per-limit.</p>"},{"location":"adr/114-composite-bucket-items/#consequences","title":"Consequences","text":"<p>Positive: - Acquire cost is constant regardless of limit count (1 item read, 1 item write) - Non-cascade acquire drops from 5.5 CU to 2 CU; cascade drops from 11 CU to 6 CU - GSI2 entries reduced from N per entity+resource to 1 - All limits for an entity+resource are atomically readable and writable</p> <p>Negative: - Breaking schema change requiring migration (new SK format) - Per-limit attributes use short names (<code>tk</code>, <code>cp</code>) that are less readable than current names - Deserialization must enumerate prefixed attributes to reconstruct BucketState objects - Adding or removing limits requires updating a shared item rather than creating/deleting items</p>"},{"location":"adr/114-composite-bucket-items/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/114-composite-bucket-items/#keep-separate-items-use-updateitem-instead-of-putitem","title":"Keep separate items, use UpdateItem instead of PutItem","text":"<p>Rejected because: fixes lost updates but does not reduce item count, CU cost, or GSI2 inflation \u2014 the core scaling problem remains.</p>"},{"location":"adr/114-composite-bucket-items/#merge-entity-metadata-into-composite-bucket-item","title":"Merge entity metadata into composite bucket item","text":"<p>Rejected because: duplicates META across resources, breaks GSI1 parent\u2192children queries, and requires fan-out writes on metadata changes.</p>"},{"location":"adr/114-composite-bucket-items/#nested-map-per-limit-limitsrpmtokens_milli","title":"Nested map per limit (limits.rpm.tokens_milli)","text":"<p>Rejected because: DynamoDB cannot use atomic ADD on nested paths without overlapping SET+ADD errors (ADR-111, issue #168).</p>"},{"location":"adr/115-add-based-writes-lazy-refill/","title":"ADR-115: ADD-Based Writes with Lazy Refill","text":"<p>Status: Proposed Date: 2026-01-28 Issue: #248 Depends on: ADR-114</p>"},{"location":"adr/115-add-based-writes-lazy-refill/#context","title":"Context","text":"<p>The current write pattern uses PutItem (full item replacement) inside TransactWriteItems. Under concurrent writes, the last writer overwrites previous writers' consumption and the <code>total_consumed_milli</code> counter \u2014 a lost update bug. Token balance and aggregator accuracy both degrade under contention.</p> <p>Refill is currently computed and stored in the token balance on each write. When two writers read the same state and both apply refill, the winning PutItem correctly reflects one refill window, but the losing writer's consumption is lost entirely. Separating refill from consumption in the write path would allow atomic consumption tracking independent of refill timing.</p> <p>The composite bucket item (ADR-114) provides a single item per entity+resource, enabling a shared refill timestamp that doubles as an optimistic lock for all limits simultaneously.</p>"},{"location":"adr/115-add-based-writes-lazy-refill/#decision","title":"Decision","text":"<p>Writers must use DynamoDB ADD to atomically decrement token balances and increment consumption counters. Refill must not be stored in <code>tk</code>; instead, effective tokens must be computed at read time as <code>min(stored_tk + elapsed * rate, burst)</code>. A single shared <code>rf</code> attribute must serve as both the refill baseline and the optimistic lock. The repository must implement four write paths: Create (PutItem with <code>attribute_not_exists</code>), Normal (ADD with refill+consumption, condition <code>rf = :expected</code>), Retry (ADD consumption only, condition <code>tk &gt;= :consumed</code> per limit), and Adjust (unconditional ADD, may go negative).</p>"},{"location":"adr/115-add-based-writes-lazy-refill/#consequences","title":"Consequences","text":"<p>Positive: - No lost updates: concurrent consumptions are correctly counted via atomic ADD - No double refill: single <code>rf</code> lock ensures only one writer claims each refill window - Retry requires no re-read (1 WCU, consumption-only ADD) - Negative tokens prevented on acquire (condition <code>tk &gt;= :consumed</code>); allowed on adjust by design - Aggregator sees correct consumption counters regardless of contention - Lock condition is always <code>rf = :expected</code> regardless of limit count</p> <p>Negative: - Four write paths increase repository complexity - Retry path may reject requests that were initially approved on stale data - Under high contention (~500ms window), refill is slightly under-counted (limiter becomes more restrictive, not less) - Lease adjust becomes the only path that can push tokens negative, changing the current invariant</p>"},{"location":"adr/115-add-based-writes-lazy-refill/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/115-add-based-writes-lazy-refill/#putitem-with-optimistic-locking-version-counter","title":"PutItem with optimistic locking (version counter)","text":"<p>Rejected because: full item replacement still loses concurrent writers' consumption \u2014 ADD is required for correct concurrent accounting.</p>"},{"location":"adr/115-add-based-writes-lazy-refill/#per-limit-refill-timestamps","title":"Per-limit refill timestamps","text":"<p>Rejected because: grows condition expression with limit count, risks partial refill window claims, and adds an attribute per limit. Single <code>rf</code> is simpler and free since all limits are updated on every acquire.</p>"},{"location":"adr/115-add-based-writes-lazy-refill/#add-for-consumption-no-optimistic-lock","title":"ADD for consumption, no optimistic lock","text":"<p>Rejected because: without the <code>rf</code> lock, concurrent writers each compute and ADD refill independently, causing double-refill proportional to contention.</p>"},{"location":"adr/116-iam-role-naming/","title":"ADR-116: IAM Role Naming Convention","text":"<p>Status: Proposed Date: 2026-01-30 Issue: #252</p>"},{"location":"adr/116-iam-role-naming/#context","title":"Context","text":"<p>IAM role names can exceed AWS's 64-character limit when using <code>role_name_format</code> with long stack names. The current implementation has two bugs:</p> <ol> <li>All roles embed <code>-aggregator-role</code> in their names instead of component-specific suffixes (e.g., AppRole becomes <code>{format}-aggregator-role-app</code> instead of something shorter)</li> <li>Validation checks stack name and format template separately, not the combined result</li> </ol> <p>With enterprise environments using permission boundaries (e.g., <code>role_name_format=\"PowerUserPB-{}\"</code>), users hit the 64-char limit unexpectedly when derived roles append additional suffixes like <code>-readonly</code>.</p>"},{"location":"adr/116-iam-role-naming/#decision","title":"Decision","text":"<p>IAM role names must follow the pattern: <code>{format}.replace(\"{}\", f\"{stack_name}-{component}\")</code> where component is one of: <code>aggr</code> (4 chars), <code>app</code> (3 chars), <code>admin</code> (5 chars), <code>read</code> (4 chars). All component names must be \u2264 8 characters to ensure users who choose valid stack names today won't break on library upgrades.</p>"},{"location":"adr/116-iam-role-naming/#consequences","title":"Consequences","text":"<p>Positive: - Shorter role names leave room for longer stack names and format templates - Each role has a distinct, meaningful name (not all embedding \"aggregator\") - Validation catches length violations early with actionable error messages - 8-char invariant provides upgrade safety margin for future components</p> <p>Negative: - Breaking change: existing role names change (e.g., <code>{stack}-aggregator-role</code> \u2192 <code>{stack}-aggr</code>) - CloudFormation will replace IAM roles during stack updates, causing brief Lambda failures</p>"},{"location":"adr/116-iam-role-naming/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/116-iam-role-naming/#keep-aggregator-role-suffix-for-lambda-only","title":"Keep <code>-aggregator-role</code> suffix for Lambda only","text":"<p>Rejected because: The current bug embeds this verbose suffix in all roles via incorrect logic, wasting character budget.</p>"},{"location":"adr/116-iam-role-naming/#use-numeric-suffixes-role-1-role-2","title":"Use numeric suffixes (role-1, role-2)","text":"<p>Rejected because: Not self-documenting; operators can't identify role purpose from name.</p>"},{"location":"adr/117-managed-policies-by-default/","title":"ADR-117: Managed Policies by Default","text":"<p>Status: Accepted Date: 2026-01-31 Issue: #272 Supersedes: ADR-107 (partial)</p>"},{"location":"adr/117-managed-policies-by-default/#context","title":"Context","text":"<p>ADR-107 introduced IAM roles (AppRole, AdminRole, ReadOnlyRole) with inline policies as the default deployment option. However, this couples infrastructure to user IAM configuration: users who want to attach permissions to their own roles or users must either parse the CloudFormation template to extract policy documents, or accept redundant roles in their account.</p> <p>Many enterprise environments require consistent IAM role naming conventions, use federated identity, or have existing roles that need rate limiter access. Creating managed policies instead of roles provides the same least-privilege permissions while giving users flexibility to attach policies to their preferred principals.</p>"},{"location":"adr/117-managed-policies-by-default/#decision","title":"Decision","text":"<p>The CloudFormation stack creates three IAM managed policies (AppPolicy, AdminPolicy, ReadOnlyPolicy) by default. IAM roles are opt-in via <code>--create-iam-roles</code> flag or <code>StackOptions.create_iam_roles=True</code>. When roles are created, they attach the managed policies rather than using inline policies.</p>"},{"location":"adr/117-managed-policies-by-default/#consequences","title":"Consequences","text":"<p>Positive: - Users can attach policies to existing roles, users, or federated identities - Policies are always created, providing documentation of required permissions - Roles remain available for simple deployments via opt-in flag - No duplicate permission definitions (roles reference managed policies) - Policy ARNs exported for easy integration with external tooling</p> <p>Negative: - Breaking change: existing deployments expecting roles must add <code>--create-iam-roles</code> - Three IAM managed policies per stack regardless of whether roles are needed</p>"},{"location":"adr/117-managed-policies-by-default/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/117-managed-policies-by-default/#keep-roles-as-default-add-policies-as-opt-in","title":"Keep roles as default, add policies as opt-in","text":"<p>Rejected because: Policies are universally useful (attach to any principal), while roles are only useful for simple deployments.</p>"},{"location":"adr/117-managed-policies-by-default/#output-policy-documents-in-stack-outputs-instead-of-managed-policies","title":"Output policy documents in stack outputs instead of managed policies","text":"<p>Rejected because: JSON in outputs is hard to consume; managed policies integrate with IAM natively.</p>"},{"location":"adr/117-managed-policies-by-default/#restricted-iam-environments","title":"Restricted IAM Environments","text":"<p>For environments without IAM permissions (e.g., PowerUserAccess):</p> <ul> <li><code>--no-iam</code>: Skips all IAM resources (managed policies, roles)</li> <li><code>--aggregator-role-arn &lt;arn&gt;</code>: Use pre-existing role for Lambda aggregator</li> </ul> <p>Combined: <code>--no-iam --aggregator-role-arn &lt;arn&gt;</code> enables full deployment without any <code>iam:*</code> permissions.</p> Flag Combination Policies App Roles Aggr Role Lambda (default) Created No Created Enabled <code>--no-iam</code> No No No Disabled <code>--no-iam --aggregator-role-arn</code> No No External Enabled <code>--aggregator-role-arn</code> Created No External Enabled <code>--create-iam-roles</code> Created Created Created Enabled <code>--no-iam --create-iam-roles</code> Error - - -"},{"location":"adr/118-four-level-config-hierarchy/","title":"ADR-118: Four-Level Configuration Hierarchy","text":"<p>Status: Accepted Date: 2026-02-02 Issue: #297 Supersedes: ADR-102</p>"},{"location":"adr/118-four-level-config-hierarchy/#context","title":"Context","text":"<p>ADR-102 established a three-level configuration hierarchy (Entity &gt; Resource &gt; System). However, this design lacks a way to set entity-wide defaults that apply to all resources for that entity without duplicating configuration for each resource.</p> <p>Operators need to set per-entity defaults (e.g., premium tier limits) that apply across all resources, while still allowing resource-specific entity overrides for edge cases.</p>"},{"location":"adr/118-four-level-config-hierarchy/#decision","title":"Decision","text":"<p>Extend the hierarchy to four levels: Entity (resource-specific) &gt; Entity (<code>_default_</code>) &gt; Resource &gt; System &gt; Constructor defaults.</p> <p>When resolving limits for <code>acquire(entity_id, resource)</code>: 1. Check entity config for the specific resource 2. Check entity config for <code>_default_</code> (fallback for all resources) 3. Check resource-level defaults 4. Check system-level defaults 5. Use constructor override parameter</p> <p>Entity <code>_default_</code> config is treated as a default for TTL purposes (TTL applied), distinguishing it from resource-specific entity config (no TTL).</p>"},{"location":"adr/118-four-level-config-hierarchy/#consequences","title":"Consequences","text":"<p>Positive: - Premium users can have elevated limits on all resources with a single config entry - Resource-specific entity overrides still take precedence when needed - Backward compatible\u2014existing three-level configs work unchanged</p> <p>Negative: - One additional cache lookup per resolution when entity+resource config misses - Slightly more complex resolution logic</p>"},{"location":"adr/118-four-level-config-hierarchy/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/118-four-level-config-hierarchy/#keep-three-level-hierarchy","title":"Keep three-level hierarchy","text":"<p>Rejected because: Operators would need to duplicate entity config for every resource, which is error-prone and tedious.</p>"},{"location":"adr/118-four-level-config-hierarchy/#treat-entity-_default_-as-custom-config-no-ttl","title":"Treat entity <code>_default_</code> as custom config (no TTL)","text":"<p>Rejected because: Entity <code>_default_</code> is semantically a default, not a resource-specific customization; TTL should apply.</p>"},{"location":"adr/119-bucket-ttl-strategy/","title":"ADR-119: Bucket TTL Strategy","text":"<p>Status: Accepted Date: 2026-02-02 Issue: #271, #296</p>"},{"location":"adr/119-bucket-ttl-strategy/#context","title":"Context","text":"<p>Buckets using system or resource default limits should auto-expire to reduce DynamoDB storage costs for ephemeral entities (anonymous users, one-time callers). The original implementation used a flat 24-hour TTL, but this caused slow-refill buckets to expire before fully refilling\u2014a bucket with 1000 capacity and 10 tokens/minute refill takes ~100 minutes to fill, but with infrequent access patterns could expire mid-refill.</p> <p>Separately, entities with explicitly configured custom limits represent important accounts (premium users, key customers) whose state should persist indefinitely. Losing their bucket state grants an unintended rate limit reset.</p>"},{"location":"adr/119-bucket-ttl-strategy/#decision","title":"Decision","text":"<ol> <li>Time-to-fill based TTL: Bucket TTL is calculated as <code>max_time_to_fill \u00d7 multiplier</code> where <code>time_to_fill = (capacity / refill_amount) \u00d7 refill_period_seconds</code>. Default multiplier is 7.</li> <li>TTL by config source: Buckets using entity custom limits have no TTL (persist indefinitely). Buckets using entity <code>_default_</code>, resource, or system defaults have TTL applied.</li> </ol>"},{"location":"adr/119-bucket-ttl-strategy/#consequences","title":"Consequences","text":"<p>Positive: - Slow-refill buckets have sufficient time to fully refill before expiring - Important entities (custom limits) never lose rate limit state - Ephemeral entities auto-cleanup, reducing storage costs</p> <p>Negative: - TTL removal/addition on upgrade/downgrade adds complexity to write path</p>"},{"location":"adr/119-bucket-ttl-strategy/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/119-bucket-ttl-strategy/#flat-24-hour-ttl-for-all-default-limit-buckets","title":"Flat 24-hour TTL for all default-limit buckets","text":"<p>Rejected because: Slow-refill limits (capacity &gt;&gt; refill_amount) expire before fully refilling, causing unexpected rate limit resets.</p>"},{"location":"adr/119-bucket-ttl-strategy/#ttl-for-all-buckets-including-custom-limits","title":"TTL for all buckets including custom limits","text":"<p>Rejected because: Custom limits signal explicit intent\u2014losing state for premium users is unacceptable.</p>"},{"location":"adr/119-bucket-ttl-strategy/#3-or-14-multiplier","title":"3\u00d7 or 14\u00d7 multiplier","text":"<p>Rejected because: 7\u00d7 balances storage cost (not too long) with refill safety (multiple full cycles). Configurable via <code>bucket_ttl_refill_multiplier</code> for edge cases.</p>"},{"location":"adr/120-bucket-param-sync/","title":"ADR-120: Bucket Param Sync","text":"<p>Status: Accepted Date: 2026-02-02 Issue: #294</p>"},{"location":"adr/120-bucket-param-sync/#context","title":"Context","text":"<p>When entity limits change via <code>set_limits()</code>, existing buckets retain stale static parameters (capacity, burst, refill_amount, refill_period) until the bucket is recreated. This causes confusing behavior where operators update limits but the change doesn't take effect until the bucket expires or is manually deleted.</p> <p>For example, an operator doubles an entity's rate limit from 100 to 200 RPM, but the entity continues to be limited at 100 RPM because the bucket still has the old capacity value.</p>"},{"location":"adr/120-bucket-param-sync/#decision","title":"Decision","text":"<p>When <code>set_limits()</code> updates entity config, existing bucket static parameters (capacity, burst, refill_amount, refill_period) are synchronized via conditional update. The update uses <code>attribute_exists(PK)</code> to skip if the bucket doesn't exist yet.</p>"},{"location":"adr/120-bucket-param-sync/#consequences","title":"Consequences","text":"<p>Positive: - Limit changes take effect immediately on existing buckets - Operators get predictable behavior when updating limits - No manual intervention required to apply new limits</p> <p>Negative: - Additional DynamoDB write on <code>set_limits()</code> (conditional update) - Write may fail silently if bucket doesn't exist (by design)</p>"},{"location":"adr/120-bucket-param-sync/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/120-bucket-param-sync/#require-bucket-deletion-before-limit-change","title":"Require bucket deletion before limit change","text":"<p>Rejected because: Poor operator experience\u2014requires manual intervention and loses current token state.</p>"},{"location":"adr/120-bucket-param-sync/#lazy-sync-on-next-acquire","title":"Lazy sync on next acquire","text":"<p>Rejected because: Adds complexity to the hot path (<code>acquire</code>) and delays when the change takes effect.</p>"},{"location":"adr/121-native-sync-unasync/","title":"ADR-121: Native Sync Implementation via Unasync Pattern","text":""},{"location":"adr/121-native-sync-unasync/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adr/121-native-sync-unasync/#context","title":"Context","text":"<p>The <code>SyncRateLimiter</code> class wrapped the async <code>RateLimiter</code> using <code>asyncio.run_until_complete()</code>. This approach failed in environments with their own async runtime (Gevent, Eventlet) because:</p> <ul> <li>Gevent/Eventlet use greenlet-based cooperative concurrency</li> <li>asyncio's event loop conflicts with monkey-patched I/O</li> <li>The wrapper blocked entire greenlet pools or failed outright</li> </ul>"},{"location":"adr/121-native-sync-unasync/#decision","title":"Decision","text":"<p>Adopt the unasync pattern used by httpx, httpcore, and urllib3:</p> <ol> <li>Async code (aioboto3) is the source of truth</li> <li>AST transformation generates sync code (boto3) at build time</li> <li>Generated code is committed to git for documentation and debugging</li> <li>Pre-commit and CI verify generated code stays in sync</li> </ol>"},{"location":"adr/121-native-sync-unasync/#transformation-rules","title":"Transformation Rules","text":"Async Sync <code>async def</code> <code>def</code> <code>await expr</code> <code>expr</code> <code>async with</code> <code>with</code> <code>async for</code> <code>for</code> <code>aioboto3</code> <code>boto3</code> <code>asyncio.Lock</code> <code>threading.Lock</code> <code>asyncio.sleep</code> <code>time.sleep</code> <code>asynccontextmanager</code> <code>contextmanager</code> <code>RateLimiter</code> <code>SyncRateLimiter</code> <code>Repository</code> <code>SyncRepository</code> <code>RepositoryProtocol</code> <code>SyncRepositoryProtocol</code>"},{"location":"adr/121-native-sync-unasync/#file-mapping","title":"File Mapping","text":"Source Generated repository_protocol.py sync_repository_protocol.py repository.py sync_repository.py limiter.py sync_limiter.py lease.py sync_lease.py config_cache.py sync_config_cache.py infra/stack_manager.py infra/sync_stack_manager.py infra/discovery.py infra/sync_discovery.py"},{"location":"adr/121-native-sync-unasync/#build-integration","title":"Build Integration","text":"<ul> <li>Hatch build hook: Generates sync code before wheel/sdist</li> <li>Pre-commit hook: Verifies generated code is up-to-date</li> <li>CI verification: Blocks PRs with stale generated code</li> </ul>"},{"location":"adr/121-native-sync-unasync/#consequences","title":"Consequences","text":""},{"location":"adr/121-native-sync-unasync/#positive","title":"Positive","text":"<ul> <li>Single source of truth: Maintain async code only</li> <li>Native performance: No event loop overhead in sync contexts</li> <li>Gevent/Eventlet compatible: boto3 blocking I/O becomes cooperative via monkey-patching</li> <li>Debuggable: Generated code is committed, has line numbers</li> <li>Correct types: Both versions have proper type hints</li> </ul>"},{"location":"adr/121-native-sync-unasync/#negative","title":"Negative","text":"<ul> <li>Build complexity: Requires AST transformer and verification hooks</li> <li>PR noise: Generated code changes appear in diffs</li> <li>Two test suites: Both async and sync tests must pass</li> <li>Transformer maintenance: New async patterns may need transformer updates</li> </ul>"},{"location":"adr/121-native-sync-unasync/#neutral","title":"Neutral","text":"<ul> <li>Generated files have header indicating they're auto-generated</li> <li>Developers must run <code>python scripts/generate_sync.py</code> after modifying async code</li> </ul>"},{"location":"adr/121-native-sync-unasync/#references","title":"References","text":"<ul> <li>Design doc: <code>docs/plans/2026-02-02-native-sync-unasync-design.md</code></li> <li>Implementation plan: <code>docs/plans/2026-02-02-native-sync-implementation.md</code></li> <li>httpx unasync: https://github.com/encode/httpx/tree/master/scripts</li> <li>httpcore unasync: https://github.com/encode/httpcore</li> </ul>"},{"location":"adr/121-policy-rename-clarity/","title":"ADR-121: Rename IAM Policies for Clarity","text":"<p>Status: Accepted Date: 2026-02-02 Issue: #307 Amends: ADR-117</p>"},{"location":"adr/121-policy-rename-clarity/#context","title":"Context","text":"<p>ADR-117 introduced three IAM managed policies: <code>AppPolicy</code>, <code>AdminPolicy</code>, and <code>ReadOnlyPolicy</code>. The naming implied a separation between \"application\" and \"admin\" operations, but this distinction was artificial:</p> <ul> <li><code>AppPolicy</code> was intended for applications running <code>acquire()</code>, but couldn't create entities (<code>PutItem</code> missing)</li> <li><code>AdminPolicy</code> was described as \"for ops team managing config\"</li> </ul> <p>In practice, applications that create entities on-demand (e.g., for new users) need <code>AdminPolicy</code>, not <code>AppPolicy</code>. The middle ground of \"can create entities but can't set limits\" doesn't exist as a real use case.</p>"},{"location":"adr/121-policy-rename-clarity/#decision","title":"Decision","text":"<p>Rename policies to reflect their actual purpose:</p> Old Name New Name Default Suffix Purpose <code>AppPolicy</code> <code>AcquireOnlyPolicy</code> <code>-acq</code> Minimal: <code>acquire()</code> path only <code>AdminPolicy</code> <code>FullAccessPolicy</code> <code>-full</code> All operations <code>ReadOnlyPolicy</code> <code>ReadOnlyPolicy</code> <code>-read</code> Read-only monitoring <p>Additionally: - Add <code>BatchGetItem</code> to <code>ReadOnlyPolicy</code> (it's a read operation) - Add <code>Scan</code> and <code>DescribeTable</code> to <code>FullAccessPolicy</code> (true full access)</p>"},{"location":"adr/121-policy-rename-clarity/#permission-matrix","title":"Permission Matrix","text":"Action ReadOnly AcquireOnly FullAccess <code>GetItem</code> \u2705 \u2705 \u2705 <code>BatchGetItem</code> \u2705 \u2705 \u2705 <code>Query</code> \u2705 \u2705 \u2705 <code>Scan</code> \u2705 \u274c \u2705 <code>DescribeTable</code> \u2705 \u274c \u2705 <code>TransactWriteItems</code> \u274c \u2705 \u2705 <code>PutItem</code> \u274c \u274c \u2705 <code>UpdateItem</code> \u274c \u274c \u2705 <code>DeleteItem</code> \u274c \u274c \u2705 <code>BatchWriteItem</code> \u274c \u274c \u2705"},{"location":"adr/121-policy-rename-clarity/#consequences","title":"Consequences","text":"<p>Positive: - Names set correct expectations (no false promise of \"app\" vs \"admin\" split) - <code>FullAccessPolicy</code> is truly full access (includes monitoring operations) - <code>ReadOnlyPolicy</code> includes all read operations</p> <p>Negative: - Breaking change for users referencing old policy names/ARNs - CloudFormation export names change (<code>-AppPolicyArn</code> \u2192 <code>-AcquireOnlyPolicyArn</code>)</p>"},{"location":"adr/121-policy-rename-clarity/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/121-policy-rename-clarity/#keep-old-names-with-updated-documentation","title":"Keep old names with updated documentation","text":"<p>Rejected because: Names like \"AppPolicy\" actively mislead users about what the policy permits, regardless of documentation.</p>"},{"location":"adr/121-policy-rename-clarity/#add-a-fourth-policy-tier-for-entity-management","title":"Add a fourth policy tier for entity management","text":"<p>Rejected because: The \"can create entities but can't set limits\" use case doesn't exist in practice.</p>"},{"location":"adr/122-resolve-limits-on-repository/","title":"ADR-122: Move Limit Resolution to Repository Protocol","text":"<p>Status: Accepted Date: 2026-02-08 Supersedes: ADR-103</p>"},{"location":"adr/122-resolve-limits-on-repository/#context","title":"Context","text":"<p>ADR-103 introduced client-side config caching as a <code>ConfigCache</code> class owned by <code>RateLimiter</code>. ADR-108 established the <code>RepositoryProtocol</code> for backend abstraction. Currently, <code>RateLimiter</code> orchestrates the 4-level hierarchy resolution (ADR-118) by threading repository fetch methods as callbacks into <code>ConfigCache</code>. This places data access orchestration logic \u2014 \"fetch up to 4 keys, return the first hit\" \u2014 in the business logic layer.</p> <p>Analysis of how other backends would implement this resolution reveals it is a universal data access pattern: SQL solves it with <code>UNION ALL + ORDER BY + LIMIT 1</code> in one query, Redis with a Lua script evaluating multiple keys server-side, Cosmos DB with a stored procedure, and Firestore with <code>getAll()</code> + priority scan. Every backend resolves it in one round-trip using native caching (query cache, DAX, built-in TTL, offline persistence). The current design forces all backends to share a Python-side <code>ConfigCache</code> that only makes sense for DynamoDB.</p>"},{"location":"adr/122-resolve-limits-on-repository/#decision","title":"Decision","text":"<p>Add <code>resolve_limits()</code> to <code>RepositoryProtocol</code>. Each backend implementation must resolve the 4-level config hierarchy (ADR-118) and manage its own caching strategy. <code>ConfigCache</code> becomes an internal implementation detail of the DynamoDB <code>Repository</code>, not a limiter-owned component. Cache management methods (<code>invalidate_config_cache()</code>, <code>get_cache_stats()</code>) move to the repository protocol.</p> <p><code>RateLimiter</code> must not implement config resolution logic or own caching state. It calls <code>repository.resolve_limits(entity_id, resource)</code> and receives the effective limits, the <code>on_unavailable</code> action, and the config source.</p>"},{"location":"adr/122-resolve-limits-on-repository/#consequences","title":"Consequences","text":"<p>Positive: - Backends use native resolution and caching (SQL query cache, Redis TTL, DAX, Firestore offline persistence) - <code>RateLimiter</code> loses ~100 lines of orchestration code and the <code>config_cache_ttl</code> constructor parameter - New backends implement one method instead of understanding the <code>ConfigCache</code> callback protocol - Caching strategy becomes a backend concern \u2014 DynamoDB uses in-memory TTL, Redis needs none</p> <p>Negative: - Every backend must implement the 4-level hierarchy correctly (testable via protocol conformance tests) - <code>config_cache_ttl</code> moves from <code>RateLimiter</code> to <code>Repository</code> constructor (breaking change) - <code>invalidate_config_cache()</code> semantics vary by backend (no-op for Redis, meaningful for DynamoDB)</p>"},{"location":"adr/122-resolve-limits-on-repository/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"adr/122-resolve-limits-on-repository/#cachingrepository-decorator-composition-pattern","title":"CachingRepository decorator (composition pattern)","text":"<p>Rejected because: Forces a Python-side cache on all backends, even those with native caching; adds an abstraction layer that most backends don't need.</p>"},{"location":"adr/122-resolve-limits-on-repository/#separate-configresolverprotocol","title":"Separate ConfigResolverProtocol","text":"<p>Rejected because: Introduces a second protocol for users to understand; resolution is fundamentally a data access operation that belongs on the repository.</p>"},{"location":"adr/122-resolve-limits-on-repository/#keep-caching-in-ratelimiter","title":"Keep caching in RateLimiter","text":"<p>Rejected because: Forces every backend to expose 4 individual fetch methods and accept the Python-side caching strategy, preventing use of native backend capabilities.</p>"},{"location":"api/","title":"API Reference","text":"<p>This section contains the complete API documentation for zae-limiter, auto-generated from source code docstrings.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>The main components of the API are:</p> Component Description <code>RateLimiter</code> Async rate limiter client <code>SyncRateLimiter</code> Synchronous rate limiter client <code>Repository</code> DynamoDB data access and infrastructure management <code>RepositoryProtocol</code> Protocol for pluggable backends <code>Limit</code> Rate limit configuration <code>StackOptions</code> Infrastructure deployment configuration <code>CacheStats</code> Cache performance statistics <code>ConfigSource</code> Config resolution source identifier <code>RateLimitExceeded</code> Exception when limit is exceeded"},{"location":"api/#quick-reference","title":"Quick Reference","text":""},{"location":"api/#creating-a-limiter","title":"Creating a Limiter","text":"<pre><code>from zae_limiter import RateLimiter, SyncRateLimiter, Repository\nfrom zae_limiter.sync_repository import SyncRepository\n\n# Async (preferred)\nrepo = Repository(name=\"my-app\", region=\"us-east-1\")\nlimiter = RateLimiter(repository=repo)\n\n# Sync (preferred)\nrepo = SyncRepository(name=\"my-app\", region=\"us-east-1\")\nlimiter = SyncRateLimiter(repository=repo)\n</code></pre>"},{"location":"api/#defining-limits","title":"Defining Limits","text":"<pre><code>from zae_limiter import Limit\n\n# Factory methods\nLimit.per_second(\"rps\", 10)\nLimit.per_minute(\"rpm\", 100)\nLimit.per_hour(\"rph\", 1000)\nLimit.per_day(\"rpd\", 10000)\n\n# With burst capacity\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n\n# Custom period\nLimit.custom(\"requests\", capacity=50, refill_amount=50, refill_period_seconds=30)\n</code></pre>"},{"location":"api/#acquiring-limits","title":"Acquiring Limits","text":"<pre><code>from zae_limiter import RateLimiter, Limit, RateLimitExceeded\n\nlimiter = RateLimiter(name=\"limiter\")\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ) as lease:\n        # Do work\n        await lease.adjust(rpm=5)  # Adjust if needed\nexcept RateLimitExceeded as e:\n    print(f\"Retry after: {e.retry_after_seconds}s\")\n</code></pre>"},{"location":"api/#handling-exceptions","title":"Handling Exceptions","text":"<pre><code>from zae_limiter import RateLimitExceeded, RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        pass\nexcept RateLimitExceeded as e:\n    # Rate limit exceeded\n    print(e.retry_after_seconds)\n    print(e.violations)\n    print(e.as_dict())\nexcept RateLimiterUnavailable as e:\n    # DynamoDB unavailable\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"api/#module-structure","title":"Module Structure","text":"<pre><code>zae_limiter/\n\u251c\u2500\u2500 __init__.py            # Public API exports\n\u251c\u2500\u2500 limiter.py             # RateLimiter (async)\n\u251c\u2500\u2500 sync_limiter.py        # Generated: SyncRateLimiter\n\u251c\u2500\u2500 models.py              # Limit, Entity, LimitStatus, BucketState, StackOptions, ...\n\u251c\u2500\u2500 exceptions.py          # RateLimitExceeded, RateLimiterUnavailable, ...\n\u251c\u2500\u2500 repository.py          # Repository (async DynamoDB operations)\n\u251c\u2500\u2500 sync_repository.py     # Generated: SyncRepository\n\u251c\u2500\u2500 repository_protocol.py # RepositoryProtocol (backend abstraction)\n\u251c\u2500\u2500 sync_repository_protocol.py  # Generated: SyncRepositoryProtocol\n\u251c\u2500\u2500 lease.py               # Lease (async context manager)\n\u251c\u2500\u2500 sync_lease.py          # Generated: SyncLease\n\u251c\u2500\u2500 config_cache.py        # Client-side config caching with TTL (async)\n\u251c\u2500\u2500 sync_config_cache.py   # Generated: SyncConfigCache\n\u251c\u2500\u2500 bucket.py              # Token bucket algorithm\n\u251c\u2500\u2500 schema.py              # DynamoDB key builders\n\u251c\u2500\u2500 naming.py              # Resource name validation\n\u251c\u2500\u2500 locust.py              # Locust load testing integration (RateLimiterUser, RateLimiterSession)\n\u251c\u2500\u2500 local.py               # LocalStack management commands\n\u251c\u2500\u2500 cli.py                 # CLI commands\n\u2514\u2500\u2500 infra/\n    \u251c\u2500\u2500 stack_manager.py   # StackManager (async CloudFormation operations)\n    \u251c\u2500\u2500 sync_stack_manager.py    # Generated: SyncStackManager\n    \u251c\u2500\u2500 discovery.py       # Multi-stack discovery and listing (async)\n    \u251c\u2500\u2500 sync_discovery.py  # Generated: SyncInfrastructureDiscovery\n    \u251c\u2500\u2500 lambda_builder.py  # Lambda deployment package builder\n    \u2514\u2500\u2500 cfn_template.yaml  # CloudFormation template\n</code></pre>"},{"location":"api/#public-exports","title":"Public Exports","text":"<p>The following are exported from <code>zae_limiter</code>:</p> <pre><code>from zae_limiter import (\n    # Version\n    __version__,\n\n    # Main classes\n    RateLimiter,\n    SyncRateLimiter,\n    Repository,\n    SyncRepository,\n    RepositoryProtocol,\n    SyncRepositoryProtocol,\n    Lease,\n    SyncLease,\n    StackManager,\n    SyncStackManager,\n    SyncConfigCache,\n\n    # Models\n    Limit,\n    LimiterInfo,\n    LimitName,\n    Entity,\n    LimitStatus,\n    BucketState,\n    UsageSnapshot,\n    UsageSummary,\n    ResourceCapacity,\n    EntityCapacity,\n    StackOptions,\n    BackendCapabilities,\n    Status,\n    CacheStats,\n    ConfigSource,\n\n    # Audit\n    AuditEvent,\n    AuditAction,\n\n    # Enums\n    OnUnavailable,\n\n    # Exceptions - Base\n    ZAELimiterError,\n\n    # Exceptions - Categories\n    RateLimitError,\n    InfrastructureError,\n    EntityError,\n    VersionError,\n\n    # Exceptions - Rate Limit\n    RateLimitExceeded,\n\n    # Exceptions - Entity\n    EntityNotFoundError,\n    EntityExistsError,\n\n    # Exceptions - Infrastructure\n    RateLimiterUnavailable,\n    StackCreationError,\n    StackAlreadyExistsError,\n    InfrastructureNotFoundError,\n\n    # Exceptions - Version\n    VersionMismatchError,\n    IncompatibleSchemaError,\n\n    # Exceptions - Validation\n    ValidationError,\n    InvalidIdentifierError,\n    InvalidNameError,\n)\n</code></pre>"},{"location":"api/#detailed-documentation","title":"Detailed Documentation","text":"<ul> <li>RateLimiter - Main rate limiter classes</li> <li>Repository - Data access and infrastructure management</li> <li>Models - Data models and configuration</li> <li>Exceptions - Exception types and handling</li> </ul>"},{"location":"api/exceptions/","title":"Exceptions","text":"<p>Exception types raised by zae-limiter.</p>"},{"location":"api/exceptions/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>ZAELimiterError (base)\n\u251c\u2500\u2500 RateLimitError\n\u2502   \u251c\u2500\u2500 RateLimitExceeded\n\u2502   \u2514\u2500\u2500 RateLimiterUnavailable\n\u251c\u2500\u2500 EntityError\n\u2502   \u251c\u2500\u2500 EntityNotFoundError\n\u2502   \u2514\u2500\u2500 EntityExistsError\n\u251c\u2500\u2500 InfrastructureError\n\u2502   \u251c\u2500\u2500 StackCreationError\n\u2502   \u251c\u2500\u2500 StackAlreadyExistsError\n\u2502   \u2514\u2500\u2500 InfrastructureNotFoundError\n\u2514\u2500\u2500 VersionError\n    \u251c\u2500\u2500 VersionMismatchError\n    \u2514\u2500\u2500 IncompatibleSchemaError\n</code></pre>"},{"location":"api/exceptions/#base-exception","title":"Base Exception","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.ZAELimiterError","title":"ZAELimiterError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all zae-limiter errors.</p> <p>All exceptions raised by this library inherit from this class, allowing callers to catch all library-specific errors with a single except clause.</p>"},{"location":"api/exceptions/#rate-limit-exceptions","title":"Rate Limit Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded","title":"RateLimitExceeded","text":"<pre><code>RateLimitExceeded(statuses)\n</code></pre> <p>               Bases: <code>RateLimitError</code></p> <p>Raised when one or more rate limits would be exceeded.</p> <p>Provides full visibility into ALL limits that were checked, both passed and failed, to help callers understand the full picture.</p> <p>Attributes:</p> Name Type Description <code>statuses</code> <p>Status of ALL limits checked (both passed and failed)</p> <code>violations</code> <p>Only the limits that were exceeded</p> <code>passed</code> <p>Only the limits that passed</p> <code>retry_after_seconds</code> <p>Time until ALL requested capacity is available</p> <code>primary_violation</code> <p>The violation with longest retry time (bottleneck)</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded.retry_after_header","title":"retry_after_header  <code>property</code>","text":"<pre><code>retry_after_header\n</code></pre> <p>Value for HTTP Retry-After header (integer seconds).</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded.as_dict","title":"as_dict","text":"<pre><code>as_dict()\n</code></pre> <p>Serialize for JSON API responses.</p> <p>Returns a dictionary suitable for returning in a 429 response body.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimiterUnavailable","title":"RateLimiterUnavailable","text":"<pre><code>RateLimiterUnavailable(message, cause=None, *, stack_name=None, entity_id=None, resource=None)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when DynamoDB is unavailable and on_unavailable=OnUnavailable.BLOCK.</p> <p>This indicates a transient infrastructure issue, not a rate limit. When using OnUnavailable.BLOCK (the default), your application should be prepared to catch this exception and handle degraded mode gracefully.</p> <p>Attributes:</p> Name Type Description <code>cause</code> <p>The underlying exception that caused the unavailability</p> <code>stack_name</code> <p>The stack/table that was being accessed</p> <code>entity_id</code> <p>The entity being rate limited (if applicable)</p> <code>resource</code> <p>The resource being rate limited (if applicable)</p>"},{"location":"api/exceptions/#entity-exceptions","title":"Entity Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.EntityNotFoundError","title":"EntityNotFoundError","text":"<pre><code>EntityNotFoundError(entity_id)\n</code></pre> <p>               Bases: <code>EntityError</code></p> <p>Raised when an entity is not found.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.EntityExistsError","title":"EntityExistsError","text":"<pre><code>EntityExistsError(entity_id)\n</code></pre> <p>               Bases: <code>EntityError</code></p> <p>Raised when trying to create an entity that already exists.</p>"},{"location":"api/exceptions/#infrastructure-exceptions","title":"Infrastructure Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.StackCreationError","title":"StackCreationError","text":"<pre><code>StackCreationError(stack_name, reason, events=None)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when CloudFormation stack creation fails.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.StackAlreadyExistsError","title":"StackAlreadyExistsError","text":"<pre><code>StackAlreadyExistsError(stack_name, reason, events=None)\n</code></pre> <p>               Bases: <code>StackCreationError</code></p> <p>Raised when stack already exists (informational).</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.InfrastructureNotFoundError","title":"InfrastructureNotFoundError","text":"<pre><code>InfrastructureNotFoundError(stack_name)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when expected infrastructure doesn't exist.</p> <p>This typically means the CloudFormation stack or DynamoDB table hasn't been deployed yet.</p>"},{"location":"api/exceptions/#version-exceptions","title":"Version Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.VersionMismatchError","title":"VersionMismatchError","text":"<pre><code>VersionMismatchError(client_version, schema_version, lambda_version, message, can_auto_update=False)\n</code></pre> <p>               Bases: <code>VersionError</code></p> <p>Raised when client and infrastructure versions are incompatible.</p> <p>This error indicates that the client library version doesn't match the deployed infrastructure and auto-update is disabled or failed.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.IncompatibleSchemaError","title":"IncompatibleSchemaError","text":"<pre><code>IncompatibleSchemaError(client_version, schema_version, message, migration_guide_url=None)\n</code></pre> <p>               Bases: <code>VersionError</code></p> <p>Raised when schema version requires manual migration.</p> <p>This indicates a major version difference that cannot be automatically reconciled.</p>"},{"location":"api/exceptions/#exception-handling-examples","title":"Exception Handling Examples","text":""},{"location":"api/exceptions/#basic-handling","title":"Basic Handling","text":"<pre><code>from zae_limiter import RateLimitExceeded, RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        await do_work()\nexcept RateLimitExceeded as e:\n    # Handle rate limit exceeded\n    print(f\"Rate limited. Retry after {e.retry_after_seconds}s\")\nexcept RateLimiterUnavailable as e:\n    # Handle service unavailable\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"api/exceptions/#http-api-response","title":"HTTP API Response","text":"<pre><code>from fastapi import HTTPException\nfrom fastapi.responses import JSONResponse\n\n@app.post(\"/api/endpoint\")\nasync def endpoint():\n    try:\n        async with limiter.acquire(...):\n            return await process_request()\n    except RateLimitExceeded as e:\n        return JSONResponse(\n            status_code=429,\n            content=e.as_dict(),\n            headers={\"Retry-After\": e.retry_after_header},\n        )\n    except RateLimiterUnavailable:\n        raise HTTPException(status_code=503, detail=\"Service temporarily unavailable\")\n</code></pre>"},{"location":"api/exceptions/#detailed-error-information","title":"Detailed Error Information","text":"<pre><code>try:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 1)],\n        consume={\"rpm\": 2},  # Exceeds capacity to trigger error\n    ):\n        pass\nexcept RateLimitExceeded as e:\n    # All limit statuses (both passed and failed)\n    for status in e.statuses:\n        print(f\"Limit: {status.limit_name}\")\n        print(f\"  Entity: {status.entity_id}\")\n        print(f\"  Available: {status.available}\")\n        print(f\"  Requested: {status.requested}\")\n        print(f\"  Exceeded: {status.exceeded}\")\n        print(f\"  Retry after: {status.retry_after_seconds}s\")\n\n    # Only the violations\n    print(f\"Violations: {len(e.violations)}\")\n    for v in e.violations:\n        print(f\"  - {v.limit_name}: {v.available} available\")\n\n    # Only the passed limits\n    print(f\"Passed: {len(e.passed)}\")\n\n    # Primary bottleneck (longest wait time)\n    print(f\"Bottleneck: {e.primary_violation.limit_name}\")\n    print(f\"Total retry after: {e.retry_after_seconds}s\")\n</code></pre>"},{"location":"api/exceptions/#as_dict-output","title":"as_dict() Output","text":"<p>The <code>as_dict()</code> method returns a dictionary suitable for API responses:</p> <pre><code>{\n    \"error\": \"rate_limit_exceeded\",\n    \"message\": \"Rate limit exceeded for user-123/api: [rpm]. Retry after 45.2s\",\n    \"retry_after_seconds\": 45.2,\n    \"retry_after_ms\": 45200,\n    \"limits\": [\n        {\n            \"entity_id\": \"user-123\",\n            \"resource\": \"api\",\n            \"limit_name\": \"rpm\",\n            \"capacity\": 100,\n            \"burst\": 100,\n            \"available\": -5,\n            \"requested\": 10,\n            \"exceeded\": True,\n            \"retry_after_seconds\": 45.2,\n        },\n        {\n            \"entity_id\": \"user-123\",\n            \"resource\": \"api\",\n            \"limit_name\": \"tpm\",\n            \"capacity\": 10000,\n            \"burst\": 10000,\n            \"available\": 8500,\n            \"requested\": 500,\n            \"exceeded\": False,\n            \"retry_after_seconds\": 0.0,\n        },\n    ],\n}\n</code></pre> <p>Single <code>limits</code> array</p> <p>All limits (both exceeded and passed) are returned in a single <code>limits</code> array. Use the <code>exceeded</code> field to distinguish between violations and passed limits.</p>"},{"location":"api/limiter/","title":"RateLimiter","text":"<p>The main rate limiter classes for async and sync usage.</p>"},{"location":"api/limiter/#ratelimiter-async","title":"RateLimiter (Async)","text":""},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter","title":"RateLimiter","text":"<pre><code>RateLimiter(repository=None, name=None, region=None, endpoint_url=None, stack_options=None, on_unavailable=_UNSET, auto_update=_UNSET, bucket_ttl_refill_multiplier=_UNSET, speculative_writes=True)\n</code></pre> <p>Async rate limiter backed by DynamoDB.</p> <p>Implements token bucket algorithm with support for: - Multiple limits per entity/resource - Two-level hierarchy (parent/child entities) - Cascade mode (consume from entity + parent) - Stored limit configs - Usage analytics</p> <p>Example (new API - preferred):     from zae_limiter import RateLimiter, Repository, StackOptions</p> <pre><code>repo = Repository(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\nlimiter = RateLimiter(repository=repo)\n</code></pre> <p>Example (old API - deprecated):     limiter = RateLimiter(         name=\"my-app\",         region=\"us-east-1\",         stack_options=StackOptions(),     )</p> <p>Parameters:</p> Name Type Description Default <code>repository</code> <code>RepositoryProtocol | None</code> <p>Repository instance (new API, preferred). Pass a Repository or any RepositoryProtocol implementation.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>DEPRECATED. Use <code>Repository(name=...)</code> instead.</p> <code>None</code> <code>region</code> <code>str | None</code> <p>DEPRECATED. Use <code>Repository(region=...)</code> instead.</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>DEPRECATED. Use <code>Repository(endpoint_url=...)</code> instead.</p> <code>None</code> <code>stack_options</code> <code>StackOptions | None</code> <p>DEPRECATED. Use <code>Repository(stack_options=...)</code> instead.</p> <code>None</code> <code>on_unavailable</code> <code>OnUnavailable | Any</code> <p>DEPRECATED. Use <code>set_system_defaults(on_unavailable=...)</code> or pass <code>on_unavailable=</code> to <code>acquire()</code> instead.</p> <code>_UNSET</code> <code>auto_update</code> <code>bool | Any</code> <p>DEPRECATED. Use <code>Repository.builder(...).auto_update().build()</code> instead.</p> <code>_UNSET</code> <code>bucket_ttl_refill_multiplier</code> <code>int | Any</code> <p>DEPRECATED. Use <code>Repository.builder(...).bucket_ttl_multiplier().build()</code> instead.</p> <code>_UNSET</code> <code>speculative_writes</code> <code>bool</code> <p>Enable speculative UpdateItem fast path. When True, acquire() tries a speculative write first, falling back to the full read-write path only when needed.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both repository and name/region/endpoint_url/stack_options are provided.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.name","title":"name  <code>property</code>","text":"<pre><code>name\n</code></pre> <p>DEPRECATED. Use <code>repository.stack_name</code> instead.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.stack_name","title":"stack_name  <code>property</code>","text":"<pre><code>stack_name\n</code></pre> <p>DEPRECATED. Use <code>repository.stack_name</code> instead.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.table_name","title":"table_name  <code>property</code>","text":"<pre><code>table_name\n</code></pre> <p>DEPRECATED. Use <code>repository.stack_name</code> instead.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.list_deployed","title":"list_deployed  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_deployed(region=None, endpoint_url=None)\n</code></pre> <p>List all deployed rate limiter instances in a region.</p> <p>This is a class method that discovers existing deployments without requiring an initialized RateLimiter instance. It queries CloudFormation for stacks tagged with <code>ManagedBy=zae-limiter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>region</code> <code>str | None</code> <p>AWS region (default: use boto3 defaults)</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>CloudFormation endpoint (for LocalStack)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[LimiterInfo]</code> <p>List of LimiterInfo objects describing deployed instances.</p> <code>list[LimiterInfo]</code> <p>Sorted by user-friendly name. Excludes deleted stacks.</p> Example <p>Raises:</p> Type Description <code>ClientError</code> <p>If CloudFormation API call fails</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.list_deployed--discover-all-limiters-in-us-east-1","title":"Discover all limiters in us-east-1","text":"<p>limiters = await RateLimiter.list_deployed(region=\"us-east-1\") for limiter in limiters:     if limiter.is_healthy:         print(f\"\u2713 {limiter.user_name}: {limiter.version}\")     elif limiter.is_failed:         print(f\"\u2717 {limiter.user_name}: {limiter.stack_status}\")</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.close","title":"close  <code>async</code>","text":"<pre><code>close()\n</code></pre> <p>Close the underlying connections.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.is_available","title":"is_available  <code>async</code>","text":"<pre><code>is_available(timeout=1.0)\n</code></pre> <p>Check if the rate limiter backend (DynamoDB) is reachable.</p> <p>Performs a lightweight health check without requiring initialization. This method never raises exceptions - it returns False on any error.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>Maximum time in seconds to wait for response (default: 1.0)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if DynamoDB table is reachable, False otherwise.</p> Example <p>limiter = RateLimiter(name=\"my-app\", region=\"us-east-1\") if await limiter.is_available():     async with limiter.acquire(...) as lease:         ... else:     # Handle degraded mode     pass</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.create_entity","title":"create_entity  <code>async</code>","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, cascade=False, metadata=None, principal=None)\n</code></pre> <p>Create a new entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Unique identifier for the entity</p> required <code>name</code> <code>str | None</code> <p>Human-readable name (defaults to entity_id)</p> <code>None</code> <code>parent_id</code> <code>str | None</code> <p>Parent entity ID (None for root/project entities)</p> <code>None</code> <code>cascade</code> <code>bool</code> <p>If True, acquire() will also consume from parent entity</p> <code>False</code> <code>metadata</code> <code>dict[str, str] | None</code> <p>Additional metadata to store</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code> <p>Returns:</p> Type Description <code>Entity</code> <p>The created Entity</p> <p>Raises:</p> Type Description <code>EntityExistsError</code> <p>If entity already exists</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_entity","title":"get_entity  <code>async</code>","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_entity","title":"delete_entity  <code>async</code>","text":"<pre><code>delete_entity(entity_id, principal=None)\n</code></pre> <p>Delete an entity and all its related data.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity to delete</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_children","title":"get_children  <code>async</code>","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all children of a parent entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_audit_events","title":"get_audit_events  <code>async</code>","text":"<pre><code>get_audit_events(entity_id, limit=100, start_event_id=None)\n</code></pre> <p>Get audit events for an entity.</p> <p>Retrieves security audit events logged for administrative operations on the specified entity, ordered by most recent first.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity to query</p> required <code>limit</code> <code>int</code> <p>Maximum number of events to return (default: 100)</p> <code>100</code> <code>start_event_id</code> <code>str | None</code> <p>Event ID to start after (for pagination)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[AuditEvent]</code> <p>List of AuditEvent objects, ordered by most recent first</p> Example <p>events = await limiter.get_audit_events(\"proj-1\") for event in events:     print(f\"{event.timestamp}: {event.action} by {event.principal}\")</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_usage_snapshots","title":"get_usage_snapshots  <code>async</code>","text":"<pre><code>get_usage_snapshots(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None, limit=100, next_key=None)\n</code></pre> <p>Query usage snapshots for historical consumption data.</p> <p>Usage snapshots are created by the aggregator Lambda from DynamoDB stream events. They track token consumption per entity/resource within time windows (hourly, daily).</p> <p>Supports two query modes: 1. Entity-scoped: Provide entity_id (optionally with resource filter) 2. Resource-scoped: Provide resource to query across all entities</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query (uses primary key)</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource name filter (required if entity_id is None)</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by window type (\"hourly\", \"daily\")</p> <code>None</code> <code>start_time</code> <code>datetime | None</code> <p>Filter snapshots &gt;= this timestamp</p> <code>None</code> <code>end_time</code> <code>datetime | None</code> <p>Filter snapshots &lt;= this timestamp</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum items to fetch from DynamoDB per page (default: 100)</p> <code>100</code> <code>next_key</code> <code>dict[str, Any] | None</code> <p>Pagination cursor from previous call</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[UsageSnapshot], dict[str, Any] | None]</code> <p>Tuple of (snapshots, next_key). next_key is None if no more results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p> Note <p>The <code>limit</code> parameter controls the DynamoDB query batch size. Client-side filters (window_type, start_time, end_time) are applied after fetching, so the returned count may be less than <code>limit</code>. Use <code>next_key</code> to paginate through all matching results.</p> Example"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_usage_snapshots--get-hourly-snapshots-for-an-entity","title":"Get hourly snapshots for an entity","text":"<p>snapshots, cursor = await limiter.get_usage_snapshots(     entity_id=\"user-123\",     resource=\"gpt-4\",     window_type=\"hourly\",     start_time=datetime(2024, 1, 1),     end_time=datetime(2024, 1, 31), ) for snap in snapshots:     print(f\"{snap.window_start}: {snap.counters}\")</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_usage_snapshots--paginate-through-results","title":"Paginate through results","text":"<p>while cursor:     more, cursor = await limiter.get_usage_snapshots(         entity_id=\"user-123\",         next_key=cursor,     )</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_usage_summary","title":"get_usage_summary  <code>async</code>","text":"<pre><code>get_usage_summary(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None)\n</code></pre> <p>Get aggregated usage summary across multiple snapshots.</p> <p>Fetches all matching snapshots and computes total and average consumption statistics. Useful for billing, reporting, and capacity planning.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource name filter (required if entity_id is None)</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by window type (\"hourly\", \"daily\")</p> <code>None</code> <code>start_time</code> <code>datetime | None</code> <p>Filter snapshots &gt;= this timestamp</p> <code>None</code> <code>end_time</code> <code>datetime | None</code> <p>Filter snapshots &lt;= this timestamp</p> <code>None</code> <p>Returns:</p> Type Description <code>UsageSummary</code> <p>UsageSummary with total and average consumption per limit type</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p> Example <p>summary = await limiter.get_usage_summary(     entity_id=\"user-123\",     resource=\"gpt-4\",     window_type=\"hourly\",     start_time=datetime(2024, 1, 1),     end_time=datetime(2024, 1, 31), ) print(f\"Total tokens: {summary.total.get('tpm', 0)}\") print(f\"Average per hour: {summary.average.get('tpm', 0.0):.1f}\") print(f\"Snapshots: {summary.snapshot_count}\")</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.acquire","title":"acquire  <code>async</code>","text":"<pre><code>acquire(entity_id, resource, consume, limits=None, use_stored_limits=False, on_unavailable=None)\n</code></pre> <p>Acquire rate limit capacity.</p> <p>Limits are resolved automatically from stored config using four-tier hierarchy: Entity &gt; Entity Default &gt; Resource &gt; System. Pass <code>limits</code> to override.</p> <p>Cascade behavior is controlled by the entity's <code>cascade</code> flag, set at entity creation time via <code>create_entity(cascade=True)</code>. When enabled, acquire() automatically consumes from both the entity and its parent.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to acquire capacity for</p> required <code>resource</code> <code>str</code> <p>Resource being accessed (e.g., \"gpt-4\")</p> required <code>consume</code> <code>dict[str, int]</code> <p>Amounts to consume by limit name</p> required <code>limits</code> <code>list[Limit] | None</code> <p>Override stored config with explicit limits (optional)</p> <code>None</code> <code>use_stored_limits</code> <code>bool</code> <p>DEPRECATED - limits are now always resolved from stored config. This parameter will be removed in v1.0.</p> <code>False</code> <code>on_unavailable</code> <code>OnUnavailable | None</code> <p>Override default on_unavailable behavior</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncIterator[Lease]</code> <p>Lease for managing additional consumption</p> <p>Raises:</p> Type Description <code>RateLimitExceeded</code> <p>If any limit would be exceeded</p> <code>RateLimiterUnavailable</code> <p>If DynamoDB unavailable and BLOCK</p> <code>ValidationError</code> <p>If no limits configured at any level</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.available","title":"available  <code>async</code>","text":"<pre><code>available(entity_id, resource, limits=None, use_stored_limits=False)\n</code></pre> <p>Check available capacity without consuming.</p> <p>Limits are resolved using four-tier hierarchy: Entity &gt; Entity Default &gt; Resource &gt; System. If no stored limits found, falls back to the <code>limits</code> parameter.</p> <p>Returns minimum available across entity (and parent if cascade). Can return negative values if bucket is in debt.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>limits</code> <code>list[Limit] | None</code> <p>Override limits (optional, falls back to stored config)</p> <code>None</code> <code>use_stored_limits</code> <code>bool</code> <p>DEPRECATED - limits are now always resolved from stored config. This parameter will be removed in v1.0.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping limit_name -&gt; available tokens</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If no limits found at any level and no override provided</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.time_until_available","title":"time_until_available  <code>async</code>","text":"<pre><code>time_until_available(entity_id, resource, needed, limits=None, use_stored_limits=False)\n</code></pre> <p>Calculate seconds until requested capacity is available.</p> <p>Limits are resolved using four-tier hierarchy: Entity &gt; Entity Default &gt; Resource &gt; System. If no stored limits found, falls back to the <code>limits</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>needed</code> <code>dict[str, int]</code> <p>Required amounts by limit name</p> required <code>limits</code> <code>list[Limit] | None</code> <p>Override limits (optional, falls back to stored config)</p> <code>None</code> <code>use_stored_limits</code> <code>bool</code> <p>DEPRECATED - limits are now always resolved from stored config. This parameter will be removed in v1.0.</p> <code>False</code> <p>Returns:</p> Type Description <code>float</code> <p>Seconds until available (0.0 if already available)</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If no limits found at any level and no override provided</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.set_limits","title":"set_limits  <code>async</code>","text":"<pre><code>set_limits(entity_id, limits, resource=DEFAULT_RESOURCE, principal=None)\n</code></pre> <p>Store limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to set limits for</p> required <code>limits</code> <code>list[Limit]</code> <p>Limits to store</p> required <code>resource</code> <code>str</code> <p>Resource these limits apply to (or default)</p> <code>DEFAULT_RESOURCE</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_limits","title":"get_limits  <code>async</code>","text":"<pre><code>get_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Get stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to get limits for</p> required <code>resource</code> <code>str</code> <p>Resource to get limits for</p> <code>DEFAULT_RESOURCE</code> <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of stored limits (empty if none)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_limits","title":"delete_limits  <code>async</code>","text":"<pre><code>delete_limits(entity_id, resource=DEFAULT_RESOURCE, principal=None)\n</code></pre> <p>Delete stored limit configs for an entity.</p> <p>Reconciles existing buckets to fallback config (resource/system defaults) by syncing limit fields, setting TTL, and removing stale limit attributes (issue #327).</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to delete limits for</p> required <code>resource</code> <code>str</code> <p>Resource to delete limits for</p> <code>DEFAULT_RESOURCE</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.list_entities_with_custom_limits","title":"list_entities_with_custom_limits  <code>async</code>","text":"<pre><code>list_entities_with_custom_limits(resource, limit=None, cursor=None)\n</code></pre> <p>List all entities that have custom limit configurations.</p> <p>Uses GSI3 sparse index for efficient queries. Only entities with custom limits for the specified resource are returned.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to filter by.</p> required <code>limit</code> <code>int | None</code> <p>Maximum number of entities to return. None for all.</p> <code>None</code> <code>cursor</code> <code>str | None</code> <p>Pagination cursor from previous call.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[str], str | None]</code> <p>Tuple of (entity_ids, next_cursor). next_cursor is None if no more results.</p> Example"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.list_entities_with_custom_limits--get-all-entities-with-custom-limits-for-gpt-4","title":"Get all entities with custom limits for gpt-4","text":"<p>entities, cursor = await limiter.list_entities_with_custom_limits(\"gpt-4\") for entity_id in entities:     print(entity_id)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.list_entities_with_custom_limits--paginate-through-results","title":"Paginate through results","text":"<p>while cursor:     more, cursor = await limiter.list_entities_with_custom_limits(         \"gpt-4\", cursor=cursor     )     entities.extend(more)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.list_resources_with_entity_configs","title":"list_resources_with_entity_configs  <code>async</code>","text":"<pre><code>list_resources_with_entity_configs()\n</code></pre> <p>List all resources that have entity-level custom limit configurations.</p> <p>Uses the entity config resources registry for efficient O(1) lookup.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list of resource names with at least one entity having custom limits</p> Example <p>resources = await limiter.list_resources_with_entity_configs() for resource in resources:     entities, _ = await limiter.list_entities_with_custom_limits(resource)     print(f\"{resource}: {len(entities)} entities with custom limits\")</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.set_resource_defaults","title":"set_resource_defaults  <code>async</code>","text":"<pre><code>set_resource_defaults(resource, limits, principal=None)\n</code></pre> <p>Store default limit configs for a resource.</p> <p>Resource defaults override system defaults for the specified resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>limits</code> <code>list[Limit]</code> <p>Limits to store</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_resource_defaults","title":"get_resource_defaults  <code>async</code>","text":"<pre><code>get_resource_defaults(resource)\n</code></pre> <p>Get stored default limit configs for a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of stored limits (empty if none)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_resource_defaults","title":"delete_resource_defaults  <code>async</code>","text":"<pre><code>delete_resource_defaults(resource, principal=None)\n</code></pre> <p>Delete stored default limit configs for a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.list_resources_with_defaults","title":"list_resources_with_defaults  <code>async</code>","text":"<pre><code>list_resources_with_defaults()\n</code></pre> <p>List all resources that have default limit configs.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.set_system_defaults","title":"set_system_defaults  <code>async</code>","text":"<pre><code>set_system_defaults(limits, on_unavailable=None, principal=None)\n</code></pre> <p>Store system-wide default limits and config.</p> <p>System defaults apply to ALL resources unless overridden at resource or entity level.</p> <p>Parameters:</p> Name Type Description Default <code>limits</code> <code>list[Limit]</code> <p>Limits to store (apply globally to all resources)</p> required <code>on_unavailable</code> <code>OnUnavailable | None</code> <p>Behavior when DynamoDB unavailable (optional)</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_system_defaults","title":"get_system_defaults  <code>async</code>","text":"<pre><code>get_system_defaults()\n</code></pre> <p>Get system-wide default limits and config.</p> <p>Returns:</p> Type Description <code>tuple[list[Limit], OnUnavailable | None]</code> <p>Tuple of (limits, on_unavailable). on_unavailable may be None if not set.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_system_defaults","title":"delete_system_defaults  <code>async</code>","text":"<pre><code>delete_system_defaults(principal=None)\n</code></pre> <p>Delete all system-wide default limits and config.</p> <p>Parameters:</p> Name Type Description Default <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_resource_capacity","title":"get_resource_capacity  <code>async</code>","text":"<pre><code>get_resource_capacity(resource, limit_name, parents_only=False)\n</code></pre> <p>Get aggregated capacity for a resource across all entities.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to query</p> required <code>limit_name</code> <code>str</code> <p>Limit name to query</p> required <code>parents_only</code> <code>bool</code> <p>If True, only include parent entities</p> <code>False</code> <p>Returns:</p> Type Description <code>ResourceCapacity</code> <p>ResourceCapacity with aggregated data</p>"},{"location":"api/limiter/#syncratelimiter","title":"SyncRateLimiter","text":""},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter","title":"SyncRateLimiter","text":"<pre><code>SyncRateLimiter(repository=None, name=None, region=None, endpoint_url=None, stack_options=None, on_unavailable=_UNSET, auto_update=_UNSET, bucket_ttl_refill_multiplier=_UNSET, speculative_writes=True)\n</code></pre> <p>Async rate limiter backed by DynamoDB.</p> <p>Implements token bucket algorithm with support for: - Multiple limits per entity/resource - Two-level hierarchy (parent/child entities) - Cascade mode (consume from entity + parent) - Stored limit configs - Usage analytics</p> <p>Example (new API - preferred):     from zae_limiter import SyncRateLimiter, SyncRepository, StackOptions</p> <pre><code>repo = SyncRepository(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\nlimiter = SyncRateLimiter(repository=repo)\n</code></pre> <p>Example (old API - deprecated):     limiter = SyncRateLimiter(         name=\"my-app\",         region=\"us-east-1\",         stack_options=StackOptions(),     )</p> <p>Parameters:</p> Name Type Description Default <code>repository</code> <code>SyncRepositoryProtocol | None</code> <p>SyncRepository instance (new API, preferred). Pass a SyncRepository or any SyncRepositoryProtocol implementation.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>DEPRECATED. Use <code>SyncRepository(name=...)</code> instead.</p> <code>None</code> <code>region</code> <code>str | None</code> <p>DEPRECATED. Use <code>SyncRepository(region=...)</code> instead.</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>DEPRECATED. Use <code>SyncRepository(endpoint_url=...)</code> instead.</p> <code>None</code> <code>stack_options</code> <code>StackOptions | None</code> <p>DEPRECATED. Use <code>SyncRepository(stack_options=...)</code> instead.</p> <code>None</code> <code>on_unavailable</code> <code>OnUnavailable | Any</code> <p>DEPRECATED. Use <code>set_system_defaults(on_unavailable=...)</code> or pass <code>on_unavailable=</code> to <code>acquire()</code> instead.</p> <code>_UNSET</code> <code>auto_update</code> <code>bool | Any</code> <p>DEPRECATED. Use <code>SyncRepository.builder(...).auto_update().build()</code> instead.</p> <code>_UNSET</code> <code>bucket_ttl_refill_multiplier</code> <code>int | Any</code> <p>DEPRECATED. Use <code>SyncRepository.builder(...).bucket_ttl_multiplier().build()</code> instead.</p> <code>_UNSET</code> <code>speculative_writes</code> <code>bool</code> <p>Enable speculative UpdateItem fast path. When True, acquire() tries a speculative write first, falling back to the full read-write path only when needed.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both repository and name/region/endpoint_url/stack_options are provided.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.name","title":"name  <code>property</code>","text":"<pre><code>name\n</code></pre> <p>DEPRECATED. Use <code>repository.stack_name</code> instead.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.stack_name","title":"stack_name  <code>property</code>","text":"<pre><code>stack_name\n</code></pre> <p>DEPRECATED. Use <code>repository.stack_name</code> instead.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.table_name","title":"table_name  <code>property</code>","text":"<pre><code>table_name\n</code></pre> <p>DEPRECATED. Use <code>repository.stack_name</code> instead.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.list_deployed","title":"list_deployed  <code>classmethod</code>","text":"<pre><code>list_deployed(region=None, endpoint_url=None)\n</code></pre> <p>List all deployed rate limiter instances in a region.</p> <p>This is a class method that discovers existing deployments without requiring an initialized SyncRateLimiter instance. It queries CloudFormation for stacks tagged with <code>ManagedBy=zae-limiter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>region</code> <code>str | None</code> <p>AWS region (default: use boto3 defaults)</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>CloudFormation endpoint (for LocalStack)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[LimiterInfo]</code> <p>List of LimiterInfo objects describing deployed instances.</p> <code>list[LimiterInfo]</code> <p>Sorted by user-friendly name. Excludes deleted stacks.</p> Example <p>Raises:</p> Type Description <code>ClientError</code> <p>If CloudFormation API call fails</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.list_deployed--discover-all-limiters-in-us-east-1","title":"Discover all limiters in us-east-1","text":"<p>limiters = SyncRateLimiter.list_deployed(region=\"us-east-1\") for limiter in limiters:     if limiter.is_healthy:         print(f\"\u2713 {limiter.user_name}: {limiter.version}\")     elif limiter.is_failed:         print(f\"\u2717 {limiter.user_name}: {limiter.stack_status}\")</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Close the underlying connections.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.is_available","title":"is_available","text":"<pre><code>is_available(timeout=1.0)\n</code></pre> <p>Check if the rate limiter backend (DynamoDB) is reachable.</p> <p>Performs a lightweight health check without requiring initialization. This method never raises exceptions - it returns False on any error.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>Maximum time in seconds to wait for response (default: 1.0)</p> <code>1.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if DynamoDB table is reachable, False otherwise.</p> Example <p>limiter = SyncRateLimiter(name=\"my-app\", region=\"us-east-1\") if limiter.is_available():     async with limiter.acquire(...) as lease:         ... else:     # Handle degraded mode     pass</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.create_entity","title":"create_entity","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, cascade=False, metadata=None, principal=None)\n</code></pre> <p>Create a new entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Unique identifier for the entity</p> required <code>name</code> <code>str | None</code> <p>Human-readable name (defaults to entity_id)</p> <code>None</code> <code>parent_id</code> <code>str | None</code> <p>Parent entity ID (None for root/project entities)</p> <code>None</code> <code>cascade</code> <code>bool</code> <p>If True, acquire() will also consume from parent entity</p> <code>False</code> <code>metadata</code> <code>dict[str, str] | None</code> <p>Additional metadata to store</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code> <p>Returns:</p> Type Description <code>Entity</code> <p>The created Entity</p> <p>Raises:</p> Type Description <code>EntityExistsError</code> <p>If entity already exists</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_entity","title":"get_entity","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.delete_entity","title":"delete_entity","text":"<pre><code>delete_entity(entity_id, principal=None)\n</code></pre> <p>Delete an entity and all its related data.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity to delete</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_children","title":"get_children","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all children of a parent entity.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_audit_events","title":"get_audit_events","text":"<pre><code>get_audit_events(entity_id, limit=100, start_event_id=None)\n</code></pre> <p>Get audit events for an entity.</p> <p>Retrieves security audit events logged for administrative operations on the specified entity, ordered by most recent first.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity to query</p> required <code>limit</code> <code>int</code> <p>Maximum number of events to return (default: 100)</p> <code>100</code> <code>start_event_id</code> <code>str | None</code> <p>Event ID to start after (for pagination)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[AuditEvent]</code> <p>List of AuditEvent objects, ordered by most recent first</p> Example <p>events = limiter.get_audit_events(\"proj-1\") for event in events:     print(f\"{event.timestamp}: {event.action} by {event.principal}\")</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_usage_snapshots","title":"get_usage_snapshots","text":"<pre><code>get_usage_snapshots(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None, limit=100, next_key=None)\n</code></pre> <p>Query usage snapshots for historical consumption data.</p> <p>Usage snapshots are created by the aggregator Lambda from DynamoDB stream events. They track token consumption per entity/resource within time windows (hourly, daily).</p> <p>Supports two query modes: 1. Entity-scoped: Provide entity_id (optionally with resource filter) 2. Resource-scoped: Provide resource to query across all entities</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query (uses primary key)</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource name filter (required if entity_id is None)</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by window type (\"hourly\", \"daily\")</p> <code>None</code> <code>start_time</code> <code>datetime | None</code> <p>Filter snapshots &gt;= this timestamp</p> <code>None</code> <code>end_time</code> <code>datetime | None</code> <p>Filter snapshots &lt;= this timestamp</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum items to fetch from DynamoDB per page (default: 100)</p> <code>100</code> <code>next_key</code> <code>dict[str, Any] | None</code> <p>Pagination cursor from previous call</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[UsageSnapshot], dict[str, Any] | None]</code> <p>Tuple of (snapshots, next_key). next_key is None if no more results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p> Note <p>The <code>limit</code> parameter controls the DynamoDB query batch size. Client-side filters (window_type, start_time, end_time) are applied after fetching, so the returned count may be less than <code>limit</code>. Use <code>next_key</code> to paginate through all matching results.</p> Example"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_usage_snapshots--get-hourly-snapshots-for-an-entity","title":"Get hourly snapshots for an entity","text":"<p>snapshots, cursor = limiter.get_usage_snapshots(     entity_id=\"user-123\",     resource=\"gpt-4\",     window_type=\"hourly\",     start_time=datetime(2024, 1, 1),     end_time=datetime(2024, 1, 31), ) for snap in snapshots:     print(f\"{snap.window_start}: {snap.counters}\")</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_usage_snapshots--paginate-through-results","title":"Paginate through results","text":"<p>while cursor:     more, cursor = limiter.get_usage_snapshots(         entity_id=\"user-123\",         next_key=cursor,     )</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_usage_summary","title":"get_usage_summary","text":"<pre><code>get_usage_summary(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None)\n</code></pre> <p>Get aggregated usage summary across multiple snapshots.</p> <p>Fetches all matching snapshots and computes total and average consumption statistics. Useful for billing, reporting, and capacity planning.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource name filter (required if entity_id is None)</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by window type (\"hourly\", \"daily\")</p> <code>None</code> <code>start_time</code> <code>datetime | None</code> <p>Filter snapshots &gt;= this timestamp</p> <code>None</code> <code>end_time</code> <code>datetime | None</code> <p>Filter snapshots &lt;= this timestamp</p> <code>None</code> <p>Returns:</p> Type Description <code>UsageSummary</code> <p>UsageSummary with total and average consumption per limit type</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p> Example <p>summary = limiter.get_usage_summary(     entity_id=\"user-123\",     resource=\"gpt-4\",     window_type=\"hourly\",     start_time=datetime(2024, 1, 1),     end_time=datetime(2024, 1, 31), ) print(f\"Total tokens: {summary.total.get('tpm', 0)}\") print(f\"Average per hour: {summary.average.get('tpm', 0.0):.1f}\") print(f\"Snapshots: {summary.snapshot_count}\")</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.acquire","title":"acquire","text":"<pre><code>acquire(entity_id, resource, consume, limits=None, use_stored_limits=False, on_unavailable=None)\n</code></pre> <p>Acquire rate limit capacity.</p> <p>Limits are resolved automatically from stored config using four-tier hierarchy: Entity &gt; Entity Default &gt; Resource &gt; System. Pass <code>limits</code> to override.</p> <p>Cascade behavior is controlled by the entity's <code>cascade</code> flag, set at entity creation time via <code>create_entity(cascade=True)</code>. When enabled, acquire() automatically consumes from both the entity and its parent.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to acquire capacity for</p> required <code>resource</code> <code>str</code> <p>Resource being accessed (e.g., \"gpt-4\")</p> required <code>consume</code> <code>dict[str, int]</code> <p>Amounts to consume by limit name</p> required <code>limits</code> <code>list[Limit] | None</code> <p>Override stored config with explicit limits (optional)</p> <code>None</code> <code>use_stored_limits</code> <code>bool</code> <p>DEPRECATED - limits are now always resolved from stored config. This parameter will be removed in v1.0.</p> <code>False</code> <code>on_unavailable</code> <code>OnUnavailable | None</code> <p>Override default on_unavailable behavior</p> <code>None</code> <p>Yields:</p> Type Description <code>SyncLease</code> <p>SyncLease for managing additional consumption</p> <p>Raises:</p> Type Description <code>RateLimitExceeded</code> <p>If any limit would be exceeded</p> <code>RateLimiterUnavailable</code> <p>If DynamoDB unavailable and BLOCK</p> <code>ValidationError</code> <p>If no limits configured at any level</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.available","title":"available","text":"<pre><code>available(entity_id, resource, limits=None, use_stored_limits=False)\n</code></pre> <p>Check available capacity without consuming.</p> <p>Limits are resolved using four-tier hierarchy: Entity &gt; Entity Default &gt; Resource &gt; System. If no stored limits found, falls back to the <code>limits</code> parameter.</p> <p>Returns minimum available across entity (and parent if cascade). Can return negative values if bucket is in debt.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>limits</code> <code>list[Limit] | None</code> <p>Override limits (optional, falls back to stored config)</p> <code>None</code> <code>use_stored_limits</code> <code>bool</code> <p>DEPRECATED - limits are now always resolved from stored config. This parameter will be removed in v1.0.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping limit_name -&gt; available tokens</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If no limits found at any level and no override provided</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.time_until_available","title":"time_until_available","text":"<pre><code>time_until_available(entity_id, resource, needed, limits=None, use_stored_limits=False)\n</code></pre> <p>Calculate seconds until requested capacity is available.</p> <p>Limits are resolved using four-tier hierarchy: Entity &gt; Entity Default &gt; Resource &gt; System. If no stored limits found, falls back to the <code>limits</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>needed</code> <code>dict[str, int]</code> <p>Required amounts by limit name</p> required <code>limits</code> <code>list[Limit] | None</code> <p>Override limits (optional, falls back to stored config)</p> <code>None</code> <code>use_stored_limits</code> <code>bool</code> <p>DEPRECATED - limits are now always resolved from stored config. This parameter will be removed in v1.0.</p> <code>False</code> <p>Returns:</p> Type Description <code>float</code> <p>Seconds until available (0.0 if already available)</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If no limits found at any level and no override provided</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.set_limits","title":"set_limits","text":"<pre><code>set_limits(entity_id, limits, resource=DEFAULT_RESOURCE, principal=None)\n</code></pre> <p>Store limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to set limits for</p> required <code>limits</code> <code>list[Limit]</code> <p>Limits to store</p> required <code>resource</code> <code>str</code> <p>Resource these limits apply to (or default)</p> <code>DEFAULT_RESOURCE</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_limits","title":"get_limits","text":"<pre><code>get_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Get stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to get limits for</p> required <code>resource</code> <code>str</code> <p>Resource to get limits for</p> <code>DEFAULT_RESOURCE</code> <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of stored limits (empty if none)</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.delete_limits","title":"delete_limits","text":"<pre><code>delete_limits(entity_id, resource=DEFAULT_RESOURCE, principal=None)\n</code></pre> <p>Delete stored limit configs for an entity.</p> <p>Reconciles existing buckets to fallback config (resource/system defaults) by syncing limit fields, setting TTL, and removing stale limit attributes (issue #327).</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to delete limits for</p> required <code>resource</code> <code>str</code> <p>Resource to delete limits for</p> <code>DEFAULT_RESOURCE</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.list_entities_with_custom_limits","title":"list_entities_with_custom_limits","text":"<pre><code>list_entities_with_custom_limits(resource, limit=None, cursor=None)\n</code></pre> <p>List all entities that have custom limit configurations.</p> <p>Uses GSI3 sparse index for efficient queries. Only entities with custom limits for the specified resource are returned.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to filter by.</p> required <code>limit</code> <code>int | None</code> <p>Maximum number of entities to return. None for all.</p> <code>None</code> <code>cursor</code> <code>str | None</code> <p>Pagination cursor from previous call.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[str], str | None]</code> <p>Tuple of (entity_ids, next_cursor). next_cursor is None if no more results.</p> Example"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.list_entities_with_custom_limits--get-all-entities-with-custom-limits-for-gpt-4","title":"Get all entities with custom limits for gpt-4","text":"<p>entities, cursor = limiter.list_entities_with_custom_limits(\"gpt-4\") for entity_id in entities:     print(entity_id)</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.list_entities_with_custom_limits--paginate-through-results","title":"Paginate through results","text":"<p>while cursor:     more, cursor = limiter.list_entities_with_custom_limits(         \"gpt-4\", cursor=cursor     )     entities.extend(more)</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.list_resources_with_entity_configs","title":"list_resources_with_entity_configs","text":"<pre><code>list_resources_with_entity_configs()\n</code></pre> <p>List all resources that have entity-level custom limit configurations.</p> <p>Uses the entity config resources registry for efficient O(1) lookup.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list of resource names with at least one entity having custom limits</p> Example <p>resources = limiter.list_resources_with_entity_configs() for resource in resources:     entities, _ = limiter.list_entities_with_custom_limits(resource)     print(f\"{resource}: {len(entities)} entities with custom limits\")</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.set_resource_defaults","title":"set_resource_defaults","text":"<pre><code>set_resource_defaults(resource, limits, principal=None)\n</code></pre> <p>Store default limit configs for a resource.</p> <p>Resource defaults override system defaults for the specified resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>limits</code> <code>list[Limit]</code> <p>Limits to store</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_resource_defaults","title":"get_resource_defaults","text":"<pre><code>get_resource_defaults(resource)\n</code></pre> <p>Get stored default limit configs for a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of stored limits (empty if none)</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.delete_resource_defaults","title":"delete_resource_defaults","text":"<pre><code>delete_resource_defaults(resource, principal=None)\n</code></pre> <p>Delete stored default limit configs for a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.list_resources_with_defaults","title":"list_resources_with_defaults","text":"<pre><code>list_resources_with_defaults()\n</code></pre> <p>List all resources that have default limit configs.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.set_system_defaults","title":"set_system_defaults","text":"<pre><code>set_system_defaults(limits, on_unavailable=None, principal=None)\n</code></pre> <p>Store system-wide default limits and config.</p> <p>System defaults apply to ALL resources unless overridden at resource or entity level.</p> <p>Parameters:</p> Name Type Description Default <code>limits</code> <code>list[Limit]</code> <p>Limits to store (apply globally to all resources)</p> required <code>on_unavailable</code> <code>OnUnavailable | None</code> <p>Behavior when DynamoDB unavailable (optional)</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_system_defaults","title":"get_system_defaults","text":"<pre><code>get_system_defaults()\n</code></pre> <p>Get system-wide default limits and config.</p> <p>Returns:</p> Type Description <code>tuple[list[Limit], OnUnavailable | None]</code> <p>Tuple of (limits, on_unavailable). on_unavailable may be None if not set.</p>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.delete_system_defaults","title":"delete_system_defaults","text":"<pre><code>delete_system_defaults(principal=None)\n</code></pre> <p>Delete all system-wide default limits and config.</p> <p>Parameters:</p> Name Type Description Default <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging (optional)</p> <code>None</code>"},{"location":"api/limiter/#zae_limiter.sync_limiter.SyncRateLimiter.get_resource_capacity","title":"get_resource_capacity","text":"<pre><code>get_resource_capacity(resource, limit_name, parents_only=False)\n</code></pre> <p>Get aggregated capacity for a resource across all entities.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to query</p> required <code>limit_name</code> <code>str</code> <p>Limit name to query</p> required <code>parents_only</code> <code>bool</code> <p>If True, only include parent entities</p> <code>False</code> <p>Returns:</p> Type Description <code>ResourceCapacity</code> <p>ResourceCapacity with aggregated data</p>"},{"location":"api/limiter/#onunavailable","title":"OnUnavailable","text":""},{"location":"api/limiter/#zae_limiter.limiter.OnUnavailable","title":"OnUnavailable","text":"<p>               Bases: <code>Enum</code></p> <p>Behavior when DynamoDB is unavailable.</p>"},{"location":"api/models/","title":"Models","text":"<p>Data models for rate limit configuration and status.</p>"},{"location":"api/models/#limit","title":"Limit","text":""},{"location":"api/models/#zae_limiter.models.Limit","title":"Limit  <code>dataclass</code>","text":"<pre><code>Limit(name, capacity, burst, refill_amount, refill_period_seconds)\n</code></pre> <p>Token bucket rate limit configuration.</p> <p>Refill rate is stored as a fraction (refill_amount / refill_period_seconds) to avoid floating point precision issues.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier for this limit type (e.g., \"rpm\", \"tpm\")</p> <code>capacity</code> <code>int</code> <p>Max tokens that refill over the period (sustained rate)</p> <code>burst</code> <code>int</code> <p>Max tokens in bucket (&gt;= capacity, allows bursting)</p> <code>refill_amount</code> <code>int</code> <p>Numerator of refill rate</p> <code>refill_period_seconds</code> <code>int</code> <p>Denominator of refill rate</p>"},{"location":"api/models/#zae_limiter.models.Limit.refill_rate","title":"refill_rate  <code>property</code>","text":"<pre><code>refill_rate\n</code></pre> <p>Tokens per second (for display/debugging).</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_second","title":"per_second  <code>classmethod</code>","text":"<pre><code>per_second(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per second.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_minute","title":"per_minute  <code>classmethod</code>","text":"<pre><code>per_minute(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per minute.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_hour","title":"per_hour  <code>classmethod</code>","text":"<pre><code>per_hour(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per hour.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_day","title":"per_day  <code>classmethod</code>","text":"<pre><code>per_day(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per day.</p>"},{"location":"api/models/#zae_limiter.models.Limit.custom","title":"custom  <code>classmethod</code>","text":"<pre><code>custom(name, capacity, refill_amount, refill_period_seconds, burst=None)\n</code></pre> <p>Create a custom limit with explicit refill rate.</p> Sustain 100/sec with burst of 1000 <p>Limit.custom(\"requests\", capacity=100, refill_amount=100,             refill_period_seconds=1, burst=1000)</p>"},{"location":"api/models/#zae_limiter.models.Limit.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Serialize to dictionary for storage.</p>"},{"location":"api/models/#zae_limiter.models.Limit.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Deserialize from dictionary.</p>"},{"location":"api/models/#zae_limiter.models.Limit.from_bucket_state","title":"from_bucket_state  <code>classmethod</code>","text":"<pre><code>from_bucket_state(state)\n</code></pre> <p>Reconstruct a Limit from BucketState fields.</p>"},{"location":"api/models/#entity","title":"Entity","text":""},{"location":"api/models/#zae_limiter.models.Entity","title":"Entity  <code>dataclass</code>","text":"<pre><code>Entity(id, name=None, parent_id=None, cascade=False, metadata=dict(), created_at=None)\n</code></pre> <p>An entity that can have rate limits applied.</p> <p>Entities can be parents (projects) or children (API keys). Children have a parent_id reference.</p> <p>Note: This model does not validate in post_init to support DynamoDB deserialization and avoid performance overhead. Validation is performed in Repository.create_entity() at the API boundary.</p>"},{"location":"api/models/#zae_limiter.models.Entity.is_parent","title":"is_parent  <code>property</code>","text":"<pre><code>is_parent\n</code></pre> <p>True if this entity has no parent (is a root/project).</p>"},{"location":"api/models/#zae_limiter.models.Entity.is_child","title":"is_child  <code>property</code>","text":"<pre><code>is_child\n</code></pre> <p>True if this entity has a parent.</p>"},{"location":"api/models/#limitstatus","title":"LimitStatus","text":""},{"location":"api/models/#zae_limiter.models.LimitStatus","title":"LimitStatus  <code>dataclass</code>","text":"<pre><code>LimitStatus(entity_id, resource, limit_name, limit, available, requested, exceeded, retry_after_seconds)\n</code></pre> <p>Status of a specific limit check.</p> <p>Returned in RateLimitExceeded to provide full visibility into all limits that were checked.</p> <p>Note: This is an internal model created by the limiter from validated inputs. No validation is performed here to avoid performance overhead.</p>"},{"location":"api/models/#zae_limiter.models.LimitStatus.deficit","title":"deficit  <code>property</code>","text":"<pre><code>deficit\n</code></pre> <p>How many tokens short we are (0 if not exceeded).</p>"},{"location":"api/models/#bucketstate","title":"BucketState","text":""},{"location":"api/models/#zae_limiter.models.BucketState","title":"BucketState  <code>dataclass</code>","text":"<pre><code>BucketState(entity_id, resource, limit_name, tokens_milli, last_refill_ms, capacity_milli, burst_milli, refill_amount_milli, refill_period_ms, total_consumed_milli=None)\n</code></pre> <p>Internal state of a token bucket.</p> <p>All token values are stored in millitokens (x1000) for precision.</p> <p>Note: This is an internal model. Validation is performed in from_limit() for user-provided inputs, not in post_init to support DynamoDB deserialization and avoid performance overhead on frequent operations.</p>"},{"location":"api/models/#zae_limiter.models.BucketState.tokens","title":"tokens  <code>property</code>","text":"<pre><code>tokens\n</code></pre> <p>Current tokens (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.capacity","title":"capacity  <code>property</code>","text":"<pre><code>capacity\n</code></pre> <p>Capacity (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.burst","title":"burst  <code>property</code>","text":"<pre><code>burst\n</code></pre> <p>Burst (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.from_limit","title":"from_limit  <code>classmethod</code>","text":"<pre><code>from_limit(entity_id, resource, limit, now_ms)\n</code></pre> <p>Create a new bucket at full capacity from a Limit.</p> <p>Note: This is an internal factory method. Validation of entity_id and resource is performed at the API boundary (RateLimiter public methods) before calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier (pre-validated by caller)</p> required <code>resource</code> <code>str</code> <p>Resource name (pre-validated by caller)</p> required <code>limit</code> <code>Limit</code> <p>Limit configuration (validated via post_init)</p> required <code>now_ms</code> <code>int</code> <p>Current time in milliseconds</p> required"},{"location":"api/models/#auditevent","title":"AuditEvent","text":""},{"location":"api/models/#zae_limiter.models.AuditEvent","title":"AuditEvent  <code>dataclass</code>","text":"<pre><code>AuditEvent(event_id, timestamp, action, entity_id, principal=None, resource=None, details=dict())\n</code></pre> <p>Security audit event for tracking modifications.</p> <p>Audit events are logged for security-sensitive operations: - Entity creation and deletion - Limit configuration changes</p> <p>Attributes:</p> Name Type Description <code>event_id</code> <code>str</code> <p>Unique identifier for the event (timestamp-based)</p> <code>timestamp</code> <code>str</code> <p>ISO timestamp when the event occurred</p> <code>action</code> <code>str</code> <p>Type of action (see AuditAction constants)</p> <code>entity_id</code> <code>str</code> <p>ID of the entity affected</p> <code>principal</code> <code>str | None</code> <p>Caller identity who performed the action (optional)</p> <code>resource</code> <code>str | None</code> <p>Resource name for limit-related actions (optional)</p> <code>details</code> <code>dict[str, Any]</code> <p>Additional action-specific details</p>"},{"location":"api/models/#zae_limiter.models.AuditEvent.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Serialize to dictionary for storage.</p>"},{"location":"api/models/#zae_limiter.models.AuditEvent.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Deserialize from dictionary.</p>"},{"location":"api/models/#auditaction","title":"AuditAction","text":""},{"location":"api/models/#zae_limiter.models.AuditAction","title":"AuditAction","text":"<p>Audit action type constants.</p>"},{"location":"api/models/#usagesnapshot","title":"UsageSnapshot","text":""},{"location":"api/models/#zae_limiter.models.UsageSnapshot","title":"UsageSnapshot  <code>dataclass</code>","text":"<pre><code>UsageSnapshot(entity_id, resource, window_start, window_end, window_type, counters, total_events)\n</code></pre> <p>Aggregated usage for a time window.</p> <p>Created by the aggregator Lambda from DynamoDB stream events. Tracks token consumption per limit type within a time window.</p> <p>Attributes:</p> Name Type Description <code>entity_id</code> <code>str</code> <p>Entity that consumed tokens</p> <code>resource</code> <code>str</code> <p>Resource being rate-limited (e.g., \"gpt-4\")</p> <code>window_start</code> <code>str</code> <p>ISO timestamp of window start (e.g., \"2024-01-01T14:00:00Z\")</p> <code>window_end</code> <code>str</code> <p>ISO timestamp of window end</p> <code>window_type</code> <code>str</code> <p>Window granularity (\"hourly\", \"daily\")</p> <code>counters</code> <code>dict[str, int]</code> <p>Consumption by limit name (e.g., {\"tpm\": 5000, \"rpm\": 10})</p> <code>total_events</code> <code>int</code> <p>Number of consumption events in this window</p>"},{"location":"api/models/#usagesummary","title":"UsageSummary","text":""},{"location":"api/models/#zae_limiter.models.UsageSummary","title":"UsageSummary  <code>dataclass</code>","text":"<pre><code>UsageSummary(snapshot_count, total, average, min_window_start, max_window_start)\n</code></pre> <p>Aggregated usage summary across multiple snapshots.</p> <p>Returned by <code>RateLimiter.get_usage_summary()</code> to provide total and average consumption statistics over a time range.</p> <p>Attributes:</p> Name Type Description <code>snapshot_count</code> <code>int</code> <p>Number of snapshots aggregated</p> <code>total</code> <code>dict[str, int]</code> <p>Sum of consumption by limit name (e.g., {\"tpm\": 50000, \"rpm\": 100})</p> <code>average</code> <code>dict[str, float]</code> <p>Average consumption per snapshot by limit name</p> <code>min_window_start</code> <code>str | None</code> <p>Earliest snapshot window start (ISO timestamp)</p> <code>max_window_start</code> <code>str | None</code> <p>Latest snapshot window start (ISO timestamp)</p> Example <p>summary = await limiter.get_usage_summary(     entity_id=\"user-123\",     resource=\"gpt-4\",     window_type=\"hourly\", ) print(f\"Total tokens: {summary.total.get('tpm', 0)}\") print(f\"Average per hour: {summary.average.get('tpm', 0.0):.1f}\")</p>"},{"location":"api/models/#limiterinfo","title":"LimiterInfo","text":""},{"location":"api/models/#zae_limiter.models.LimiterInfo","title":"LimiterInfo  <code>dataclass</code>","text":"<pre><code>LimiterInfo(stack_name, user_name, region, stack_status, creation_time, last_updated_time=None, version=None, lambda_version=None, schema_version=None, stack_type=None)\n</code></pre> <p>Information about a deployed rate limiter instance.</p> <p>Represents a CloudFormation stack discovered in a region via <code>RateLimiter.list_deployed()</code> or the <code>zae-limiter list</code> CLI command. This is a READ-ONLY model describing observed infrastructure state.</p> Example <p>Attributes:</p> Name Type Description <code>stack_name</code> <code>str</code> <p>Full CloudFormation stack name (e.g., \"my-app\")</p> <code>user_name</code> <code>str</code> <p>User-friendly name (e.g., \"my-app\")</p> <code>region</code> <code>str</code> <p>AWS region where the stack is deployed</p> <code>stack_status</code> <code>str</code> <p>CloudFormation stack status (e.g., \"CREATE_COMPLETE\")</p> <code>creation_time</code> <code>str</code> <p>ISO 8601 timestamp of stack creation</p> <code>last_updated_time</code> <code>str | None</code> <p>ISO 8601 timestamp of last update (None if never updated)</p> <code>version</code> <code>str | None</code> <p>Value of zae-limiter:version tag (client version at deployment)</p> <code>lambda_version</code> <code>str | None</code> <p>Value of zae-limiter:lambda-version tag</p> <code>schema_version</code> <code>str | None</code> <p>Value of zae-limiter:schema-version tag</p>"},{"location":"api/models/#zae_limiter.models.LimiterInfo--discover-all-limiters-in-us-east-1","title":"Discover all limiters in us-east-1","text":"<p>limiters = await RateLimiter.list_deployed(region=\"us-east-1\") for limiter in limiters:     if limiter.is_failed:         print(f\"\u26a0\ufe0f  {limiter.user_name}: {limiter.stack_status}\")</p>"},{"location":"api/models/#zae_limiter.models.LimiterInfo.is_healthy","title":"is_healthy  <code>property</code>","text":"<pre><code>is_healthy\n</code></pre> <p>Stack is in a stable, operational state.</p>"},{"location":"api/models/#zae_limiter.models.LimiterInfo.is_in_progress","title":"is_in_progress  <code>property</code>","text":"<pre><code>is_in_progress\n</code></pre> <p>Stack operation is in progress.</p>"},{"location":"api/models/#zae_limiter.models.LimiterInfo.is_failed","title":"is_failed  <code>property</code>","text":"<pre><code>is_failed\n</code></pre> <p>Stack is in a failed or rollback state.</p>"},{"location":"api/models/#stackoptions","title":"StackOptions","text":""},{"location":"api/models/#zae_limiter.models.StackOptions","title":"StackOptions  <code>dataclass</code>","text":"<pre><code>StackOptions(snapshot_windows='hourly,daily', usage_retention_days=90, audit_retention_days=90, enable_aggregator=True, pitr_recovery_days=None, log_retention_days=30, lambda_timeout=60, lambda_memory=256, enable_alarms=True, alarm_sns_topic=None, lambda_duration_threshold_pct=80, permission_boundary=None, role_name_format=None, policy_name_format=None, enable_audit_archival=True, audit_archive_glacier_days=90, enable_tracing=False, create_iam_roles=False, create_iam=True, aggregator_role_arn=None, enable_deletion_protection=False, tags=None)\n</code></pre> <p>Configuration options for CloudFormation stack creation and updates.</p> <p>When passed to RateLimiter constructor, triggers automatic stack creation. When None is passed (default), no stack creation is attempted.</p> <p>Attributes:</p> Name Type Description <code>snapshot_windows</code> <code>str</code> <p>Comma-separated list of snapshot windows (e.g., \"hourly,daily\")</p> <code>usage_retention_days</code> <code>int</code> <p>Number of days to retain usage snapshots</p> <code>audit_retention_days</code> <code>int</code> <p>Number of days to retain audit records in DynamoDB</p> <code>enable_aggregator</code> <code>bool</code> <p>Deploy Lambda aggregator for usage snapshots</p> <code>pitr_recovery_days</code> <code>int | None</code> <p>Point-in-Time Recovery period (1-35, None for AWS default)</p> <code>log_retention_days</code> <code>int</code> <p>CloudWatch log retention period in days (must be valid CloudWatch value)</p> <code>lambda_timeout</code> <code>int</code> <p>Lambda timeout in seconds (1-900)</p> <code>lambda_memory</code> <code>int</code> <p>Lambda memory size in MB (128-3008)</p> <code>enable_alarms</code> <code>bool</code> <p>Deploy CloudWatch alarms for monitoring</p> <code>alarm_sns_topic</code> <code>str | None</code> <p>SNS topic ARN for alarm notifications</p> <code>lambda_duration_threshold_pct</code> <code>int</code> <p>Duration alarm threshold as percentage of timeout (1-100)</p> <code>permission_boundary</code> <code>str | None</code> <p>IAM permission boundary (policy name or full ARN)</p> <code>role_name_format</code> <code>str | None</code> <p>Format template for role name, {} = default role name</p> <code>policy_name_format</code> <code>str | None</code> <p>Format template for managed policy name, {} = default policy name</p> <code>enable_audit_archival</code> <code>bool</code> <p>Archive expired audit events to S3 via TTL</p> <code>audit_archive_glacier_days</code> <code>int</code> <p>Days before transitioning archives to Glacier IR (1-3650)</p> <code>enable_tracing</code> <code>bool</code> <p>Enable AWS X-Ray tracing for Lambda aggregator</p> <code>create_iam_roles</code> <code>bool</code> <p>Create App/Admin/ReadOnly IAM roles (default: False). Managed policies are always created unless create_iam=False.</p> <code>create_iam</code> <code>bool</code> <p>Create IAM resources (policies and roles). Set to False for restricted IAM environments (e.g., PowerUserAccess). When False, aggregator is disabled unless aggregator_role_arn is provided.</p> <code>aggregator_role_arn</code> <code>str | None</code> <p>ARN of an existing IAM role for the Lambda aggregator. Use this when deploying without iam:CreateRole permissions.</p> <code>enable_deletion_protection</code> <code>bool</code> <p>Enable DynamoDB table deletion protection</p> <code>tags</code> <code>dict[str, str] | None</code> <p>User-defined tags to apply to the CloudFormation stack. Dict of key-value pairs. AWS tag constraints apply (max 50 total including managed tags, key 1-128 chars, value 0-256 chars). The <code>aws:</code> prefix is reserved.</p>"},{"location":"api/models/#zae_limiter.models.StackOptions.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Validate options and emit deprecation warning.</p>"},{"location":"api/models/#zae_limiter.models.StackOptions.get_role_name","title":"get_role_name","text":"<pre><code>get_role_name(stack_name, component)\n</code></pre> <p>Get the final role name for a given stack name and component.</p> <p>Parameters:</p> Name Type Description Default <code>stack_name</code> <code>str</code> <p>Stack name</p> required <code>component</code> <code>str</code> <p>Role component (aggr, app, admin, read)</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Final role name, or None if role_name_format not set</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If resulting name exceeds 64 characters</p>"},{"location":"api/models/#zae_limiter.models.StackOptions.get_policy_name","title":"get_policy_name","text":"<pre><code>get_policy_name(stack_name, component)\n</code></pre> <p>Get the final policy name for a given stack name and component.</p> <p>Parameters:</p> Name Type Description Default <code>stack_name</code> <code>str</code> <p>Stack name</p> required <code>component</code> <code>str</code> <p>Policy component (app, admin, read)</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Final policy name, or None if policy_name_format not set</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If resulting name exceeds 128 characters</p>"},{"location":"api/models/#zae_limiter.models.StackOptions.to_parameters","title":"to_parameters","text":"<pre><code>to_parameters(stack_name=None)\n</code></pre> <p>Convert to stack parameters dict for StackManager.</p> <p>Parameters:</p> Name Type Description Default <code>stack_name</code> <code>str | None</code> <p>Stack name for role_name_format substitution</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict with snake_case keys matching stack_manager parameter mapping.</p>"},{"location":"api/models/#status","title":"Status","text":""},{"location":"api/models/#zae_limiter.models.Status","title":"Status  <code>dataclass</code>","text":"<pre><code>Status(available, latency_ms, stack_status, table_status, aggregator_enabled, name, region, schema_version, lambda_version, client_version, table_item_count, table_size_bytes, app_role_arn=None, admin_role_arn=None, readonly_role_arn=None)\n</code></pre> <p>Comprehensive status of a rate limiter instance.</p> <p>Consolidates connectivity, infrastructure, identity, versions, and table metrics into a single status object. Used by the CLI <code>status</code> command.</p> <p>Attributes:</p> Name Type Description <code>available</code> <code>bool</code> <p>Whether DynamoDB is reachable and responding</p> <code>latency_ms</code> <code>float | None</code> <p>Round-trip latency in milliseconds (None if unavailable)</p> <code>stack_status</code> <code>str | None</code> <p>CloudFormation stack status (e.g., 'CREATE_COMPLETE')</p> <code>table_status</code> <code>str | None</code> <p>DynamoDB table status (e.g., 'ACTIVE')</p> <code>aggregator_enabled</code> <code>bool</code> <p>Whether Lambda aggregator is deployed</p> <code>name</code> <code>str</code> <p>Resource name</p> <code>region</code> <code>str | None</code> <p>AWS region (None if using default)</p> <code>schema_version</code> <code>str | None</code> <p>Deployed schema version</p> <code>lambda_version</code> <code>str | None</code> <p>Deployed Lambda version</p> <code>client_version</code> <code>str</code> <p>Current client library version</p> <code>table_item_count</code> <code>int | None</code> <p>Approximate item count in table</p> <code>table_size_bytes</code> <code>int | None</code> <p>Approximate table size in bytes</p> <code>app_role_arn</code> <code>str | None</code> <p>IAM role ARN for applications (None if roles disabled)</p> <code>admin_role_arn</code> <code>str | None</code> <p>IAM role ARN for administrators (None if roles disabled)</p> <code>readonly_role_arn</code> <code>str | None</code> <p>IAM role ARN for read-only access (None if roles disabled)</p>"},{"location":"api/models/#backendcapabilities","title":"BackendCapabilities","text":""},{"location":"api/models/#zae_limiter.models.BackendCapabilities","title":"BackendCapabilities  <code>dataclass</code>","text":"<pre><code>BackendCapabilities(supports_audit_logging=False, supports_usage_snapshots=False, supports_infrastructure_management=False, supports_change_streams=False, supports_batch_operations=False)\n</code></pre> <p>Declares which extended features a backend supports.</p> <p>Used by RateLimiter to gracefully degrade when features are unavailable. Backend implementations should return an instance from their <code>capabilities</code> property.</p> <p>See ADR-109 for the capability matrix across backends.</p>"},{"location":"api/models/#zae_limiter.models.BackendCapabilities.supports_audit_logging","title":"supports_audit_logging  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supports_audit_logging = False\n</code></pre> <p>Whether the backend supports audit event storage and retrieval.</p>"},{"location":"api/models/#zae_limiter.models.BackendCapabilities.supports_usage_snapshots","title":"supports_usage_snapshots  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supports_usage_snapshots = False\n</code></pre> <p>Whether the backend supports usage snapshot aggregation.</p>"},{"location":"api/models/#zae_limiter.models.BackendCapabilities.supports_infrastructure_management","title":"supports_infrastructure_management  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supports_infrastructure_management = False\n</code></pre> <p>Whether the backend supports declarative infrastructure (e.g., CloudFormation).</p>"},{"location":"api/models/#zae_limiter.models.BackendCapabilities.supports_change_streams","title":"supports_change_streams  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supports_change_streams = False\n</code></pre> <p>Whether the backend supports real-time change notifications.</p>"},{"location":"api/models/#zae_limiter.models.BackendCapabilities.supports_batch_operations","title":"supports_batch_operations  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supports_batch_operations = False\n</code></pre> <p>Whether the backend supports batch_get_buckets() for optimized reads.</p>"},{"location":"api/models/#resourcecapacity","title":"ResourceCapacity","text":""},{"location":"api/models/#zae_limiter.models.ResourceCapacity","title":"ResourceCapacity  <code>dataclass</code>","text":"<pre><code>ResourceCapacity(resource, limit_name, total_capacity, total_available, utilization_pct, entities)\n</code></pre> <p>Aggregated capacity info for a resource across entities.</p>"},{"location":"api/models/#entitycapacity","title":"EntityCapacity","text":""},{"location":"api/models/#zae_limiter.models.EntityCapacity","title":"EntityCapacity  <code>dataclass</code>","text":"<pre><code>EntityCapacity(entity_id, capacity, available, utilization_pct)\n</code></pre> <p>Capacity info for a single entity.</p>"},{"location":"api/models/#speculativeresult","title":"SpeculativeResult","text":""},{"location":"api/models/#zae_limiter.repository_protocol.SpeculativeResult","title":"SpeculativeResult  <code>dataclass</code>","text":"<pre><code>SpeculativeResult(success, buckets=list(), cascade=False, parent_id=None, old_buckets=None, parent_result=None)\n</code></pre> <p>Result of a speculative UpdateItem attempt.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <p>True if the speculative write succeeded.</p> <code>buckets</code> <code>list[BucketState]</code> <p>On success, deserialized BucketStates from ALL_NEW response.</p> <code>cascade</code> <code>bool</code> <p>On success, whether the entity has cascade enabled.</p> <code>parent_id</code> <code>str | None</code> <p>On success, the entity's parent_id (if any).</p> <code>old_buckets</code> <code>list[BucketState] | None</code> <p>On failure, deserialized BucketStates from ALL_OLD response. None if the bucket doesn't exist (first acquire).</p> <code>parent_result</code> <code>SpeculativeResult | None</code> <p>On cache hit + cascade, nested parent SpeculativeResult from parallel UpdateItem. None for cache miss, non-cascade, or failure.</p>"},{"location":"api/models/#cachestats","title":"CacheStats","text":""},{"location":"api/models/#zae_limiter.config_cache.CacheStats","title":"CacheStats  <code>dataclass</code>","text":"<pre><code>CacheStats(hits=0, misses=0, size=0, ttl_seconds=0)\n</code></pre> <p>Statistics for cache performance monitoring.</p>"},{"location":"api/models/#zae_limiter.config_cache.CacheStats.as_dict","title":"as_dict","text":"<pre><code>as_dict()\n</code></pre> <p>Return stats as a dictionary.</p>"},{"location":"api/repository/","title":"Repository","text":"<p>The <code>Repository</code> class owns all DynamoDB data access and infrastructure management. <code>RateLimiter</code> delegates data operations to the repository while owning business logic.</p>"},{"location":"api/repository/#preferred-usage-pattern","title":"Preferred Usage Pattern","text":"<pre><code>from zae_limiter import RateLimiter, Repository, StackOptions\n\n# Create repository with infrastructure config\nrepo = Repository(\n    name=\"my-app\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(lambda_memory=512),\n)\n\n# Infrastructure is created/updated automatically on first use\nlimiter = RateLimiter(repository=repo)\n</code></pre> <p>See ADR-108 for the design rationale.</p>"},{"location":"api/repository/#repository_1","title":"Repository","text":""},{"location":"api/repository/#zae_limiter.repository.Repository","title":"Repository","text":"<pre><code>Repository(name, region=None, endpoint_url=None, stack_options=None, config_cache_ttl=60)\n</code></pre> <p>Async DynamoDB repository for rate limiter data.</p> <p>Handles all DynamoDB operations including entities, buckets, limit configs, and transactions.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Resource identifier (e.g., \"my-app\"). Used as the CloudFormation stack_name and DynamoDB table_name.</p> required <code>region</code> <code>str | None</code> <p>AWS region (e.g., \"us-east-1\").</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>Custom endpoint URL (e.g., LocalStack).</p> <code>None</code> <code>stack_options</code> <code>StackOptions | None</code> <p>Configuration for CloudFormation infrastructure. Pass StackOptions to enable declarative infrastructure management.</p> <code>None</code> <code>config_cache_ttl</code> <code>int</code> <p>TTL in seconds for config cache (default: 60, 0 to disable). Controls caching of resolved limit configs in resolve_limits().</p> <code>60</code> Example"},{"location":"api/repository/#zae_limiter.repository.Repository--basic-usage","title":"Basic usage","text":"<p>repo = Repository(name=\"my-app\", region=\"us-east-1\")</p>"},{"location":"api/repository/#zae_limiter.repository.Repository--with-infrastructure-management-adr-108","title":"With infrastructure management (ADR-108)","text":"<p>repo = Repository(     name=\"my-app\",     region=\"us-east-1\",     stack_options=StackOptions(lambda_memory=512, enable_alarms=True), )</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.namespace_name","title":"namespace_name  <code>property</code>","text":"<pre><code>namespace_name\n</code></pre> <p>The human-readable namespace name.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.namespace_id","title":"namespace_id  <code>property</code>","text":"<pre><code>namespace_id\n</code></pre> <p>The opaque namespace ID used in DynamoDB keys.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.capabilities","title":"capabilities  <code>property</code>","text":"<pre><code>capabilities\n</code></pre> <p>Declare which extended features this backend supports.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.builder","title":"builder  <code>classmethod</code>","text":"<pre><code>builder(name, region=None, *, endpoint_url=None)\n</code></pre> <p>Create a RepositoryBuilder for fluent configuration.</p> Example <p>repo = await (     Repository.builder(\"my-app\", \"us-east-1\")     .namespace(\"default\")     .lambda_memory(512)     .build() )</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.namespace","title":"namespace  <code>async</code>","text":"<pre><code>namespace(name, *, on_unavailable=None, bucket_ttl_multiplier=None)\n</code></pre> <p>Return a scoped Repository for the given namespace.</p> <p>The scoped repo shares the DynamoDB client, entity cache, and namespace cache with the parent, but has its own <code>ConfigCache</code> and namespace identity.  Calling <code>close()</code> on a scoped repo is a no-op (it does not close the shared client).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Namespace name to resolve.</p> required <code>on_unavailable</code> <code>OnUnavailableAction | None</code> <p>Override on_unavailable behavior for this namespace (\"allow\" or \"block\").  Persisted via <code>set_system_defaults()</code>.</p> <code>None</code> <code>bucket_ttl_multiplier</code> <code>int | None</code> <p>Override bucket TTL multiplier for this scoped repo.  Defaults to the parent's value.</p> <code>None</code> <p>Returns:</p> Type Description <code>Repository</code> <p>A new Repository scoped to the resolved namespace.</p> <p>Raises:</p> Type Description <code>NamespaceNotFoundError</code> <p>If the namespace is not registered.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.close","title":"close  <code>async</code>","text":"<pre><code>close()\n</code></pre> <p>Close the DynamoDB client.</p> <p>No-op for scoped repos (created via <code>namespace()</code>).</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.create_table","title":"create_table  <code>async</code>","text":"<pre><code>create_table()\n</code></pre> <p>Create the DynamoDB table if it doesn't exist.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.delete_table","title":"delete_table  <code>async</code>","text":"<pre><code>delete_table()\n</code></pre> <p>Delete the DynamoDB table.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.delete_stack","title":"delete_stack  <code>async</code>","text":"<pre><code>delete_stack()\n</code></pre> <p>Delete the CloudFormation stack and all associated resources.</p> <p>Permanently removes the stack including DynamoDB table, Lambda aggregator, IAM roles, and CloudWatch log groups. Waits for deletion to complete. No-op if stack doesn't exist.</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If deletion fails.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.ensure_infrastructure","title":"ensure_infrastructure  <code>async</code>","text":"<pre><code>ensure_infrastructure()\n</code></pre> <p>Ensure DynamoDB infrastructure exists.</p> <p>.. deprecated::     Use <code>Repository.builder(...).build()</code> instead, which handles     infrastructure creation during the build step.</p> <p>Creates CloudFormation stack using stack_options passed to the constructor. No-op if stack_options was not provided.</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If CloudFormation stack creation fails</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.create_stack","title":"create_stack  <code>async</code>","text":"<pre><code>create_stack(stack_options=None)\n</code></pre> <p>Create DynamoDB infrastructure via CloudFormation.</p> <p>.. deprecated:: 0.6.0     Use :meth:<code>ensure_infrastructure</code> instead. Pass stack_options     to the Repository constructor. Will be removed in v2.0.0.</p> <p>Parameters:</p> Name Type Description Default <code>stack_options</code> <code>StackOptions | None</code> <p>Configuration for CloudFormation stack. If None, uses the stack_options passed to the constructor.</p> <code>None</code> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If CloudFormation stack creation fails</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.register_namespace","title":"register_namespace  <code>async</code>","text":"<pre><code>register_namespace(namespace)\n</code></pre> <p>Register a namespace in the registry (idempotent).</p> <p>Creates forward (name -&gt; ID) and reverse (ID -&gt; name) mappings. Idempotent: returns existing ID if namespace already registered.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>Namespace name to register.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The namespace_id (either newly created or existing).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If namespace is the reserved namespace <code>\"_\"</code>.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.register_namespaces","title":"register_namespaces  <code>async</code>","text":"<pre><code>register_namespaces(namespaces)\n</code></pre> <p>Bulk-register multiple namespaces.</p> <p>Registers all namespaces in DynamoDB (forward + reverse records each).</p> <p>Parameters:</p> Name Type Description Default <code>namespaces</code> <code>list[str]</code> <p>List of namespace names to register.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Mapping of <code>{name: namespace_id}</code> for all namespaces.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any namespace is the reserved namespace <code>\"_\"</code>.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_namespace","title":"get_namespace  <code>async</code>","text":"<pre><code>get_namespace(namespace)\n</code></pre> <p>Get details for a single namespace by name.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>Namespace name to look up.</p> required <p>Returns:</p> Type Description <code>dict[str, str] | None</code> <p>Dict with <code>{name, namespace_id, status, created_at}</code></p> <code>dict[str, str] | None</code> <p>or <code>None</code> if not found.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.list_namespaces","title":"list_namespaces  <code>async</code>","text":"<pre><code>list_namespaces()\n</code></pre> <p>List all active namespaces with their IDs.</p> <p>Performs a Query on <code>PK = \"_/SYSTEM#\"</code> with <code>SK begins_with \"#NAMESPACE#\"</code> (forward records only).</p> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of <code>{name, namespace_id, created_at}</code> dicts.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.delete_namespace","title":"delete_namespace  <code>async</code>","text":"<pre><code>delete_namespace(namespace)\n</code></pre> <p>Soft-delete a namespace. O(1) for data plane.</p> <p>Removes the forward record and marks the reverse record as <code>status=\"deleted\"</code>.  Data items are NOT deleted \u2014 they remain orphaned under the namespace's random ID prefix.</p> <p>No-op if the namespace does not exist.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str</code> <p>Namespace name to delete.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If namespace is the reserved namespace <code>\"_\"</code>.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.recover_namespace","title":"recover_namespace  <code>async</code>","text":"<pre><code>recover_namespace(namespace_id)\n</code></pre> <p>Recover a deleted namespace by its ID.</p> <p>Reads the reverse record to find the original name, re-creates the forward record, and marks the reverse record as active.</p> <p>Parameters:</p> Name Type Description Default <code>namespace_id</code> <code>str</code> <p>Opaque namespace ID to recover.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The recovered namespace name.</p> <p>Raises:</p> Type Description <code>EntityNotFoundError</code> <p>If the reverse record does not exist.</p> <code>ValueError</code> <p>If the reverse record has <code>status=\"purging\"</code> or <code>status=\"active\"</code>.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.list_orphan_namespaces","title":"list_orphan_namespaces  <code>async</code>","text":"<pre><code>list_orphan_namespaces()\n</code></pre> <p>List deleted namespaces with orphaned data.</p> <p>Queries reverse records (<code>SK begins_with \"#NSID#\"</code>) and filters for <code>status=\"deleted\"</code>.</p> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of <code>{namespace_id, namespace, deleted_at}</code> dicts.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.purge_namespace","title":"purge_namespace  <code>async</code>","text":"<pre><code>purge_namespace(namespace_id)\n</code></pre> <p>Purge all orphaned data for a deleted namespace.</p> <p>Verifies the namespace is in <code>\"deleted\"</code> status, transitions to <code>\"purging\"</code>, queries GSI4 to find all items, deletes them in batches, then removes the reverse record.</p> <p>Safe to call on a non-existent namespace_id (no-op).</p> <p>Parameters:</p> Name Type Description Default <code>namespace_id</code> <code>str</code> <p>Opaque namespace ID to purge.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the namespace is <code>\"active\"</code> (cannot purge an active namespace).</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.create_entity","title":"create_entity  <code>async</code>","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, cascade=False, metadata=None, principal=None)\n</code></pre> <p>Create a new entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Unique identifier for the entity</p> required <code>name</code> <code>str | None</code> <p>Optional display name (defaults to entity_id)</p> <code>None</code> <code>parent_id</code> <code>str | None</code> <p>Optional parent entity ID (for hierarchical limits)</p> <code>None</code> <code>cascade</code> <code>bool</code> <p>If True, acquire() will also consume from parent entity</p> <code>False</code> <code>metadata</code> <code>dict[str, str] | None</code> <p>Optional key-value metadata</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code> <p>Returns:</p> Type Description <code>Entity</code> <p>The created Entity</p> <p>Raises:</p> Type Description <code>InvalidIdentifierError</code> <p>If entity_id or parent_id is invalid</p> <code>EntityExistsError</code> <p>If entity already exists</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_entity","title":"get_entity  <code>async</code>","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.delete_entity","title":"delete_entity  <code>async</code>","text":"<pre><code>delete_entity(entity_id, principal=None)\n</code></pre> <p>Delete an entity and all its related records.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity to delete</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_children","title":"get_children  <code>async</code>","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all children of a parent entity.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_bucket","title":"get_bucket  <code>async</code>","text":"<pre><code>get_bucket(entity_id, resource, limit_name)\n</code></pre> <p>Get a single limit's bucket from the composite item.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_buckets","title":"get_buckets  <code>async</code>","text":"<pre><code>get_buckets(entity_id, resource=None)\n</code></pre> <p>Get all buckets for an entity, optionally filtered by resource.</p> <p>With composite items, each item contains all limits for one resource.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.batch_get_buckets","title":"batch_get_buckets  <code>async</code>","text":"<pre><code>batch_get_buckets(keys)\n</code></pre> <p>Batch get composite buckets in a single DynamoDB call.</p> <p>With composite items, each (entity_id, resource) pair is a single DynamoDB item containing all limits. Returns individual BucketStates keyed by (entity_id, resource, limit_name) for backward compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list[tuple[str, str]]</code> <p>List of (entity_id, resource) tuples</p> required <p>Returns:</p> Type Description <code>dict[tuple[str, str, str], BucketState]</code> <p>Dict mapping (entity_id, resource, limit_name) to BucketState.</p> <code>dict[tuple[str, str, str], BucketState]</code> <p>Missing composite items are not included in the result.</p> Note <p>DynamoDB BatchGetItem supports up to 100 items per request. For larger batches, this method automatically chunks the requests.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.batch_get_entity_and_buckets","title":"batch_get_entity_and_buckets  <code>async</code>","text":"<pre><code>batch_get_entity_and_buckets(entity_id, bucket_keys)\n</code></pre> <p>Fetch entity metadata and composite buckets in a single BatchGetItem.</p> <p>With composite items, each (entity_id, resource) pair is a single DynamoDB item. Includes the entity's #META record alongside bucket records to avoid a separate get_entity() round trip.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity whose META record to include</p> required <code>bucket_keys</code> <code>list[tuple[str, str]]</code> <p>List of (entity_id, resource) for composite buckets</p> required <p>Returns:</p> Type Description <code>Entity | None</code> <p>Tuple of (entity_or_none, bucket_dict) where bucket_dict maps</p> <code>dict[tuple[str, str, str], BucketState]</code> <p>(entity_id, resource, limit_name) to BucketState.</p> Note <p>DynamoDB BatchGetItem supports up to 100 items per request. The META key counts toward that limit.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.batch_get_configs","title":"batch_get_configs  <code>async</code>","text":"<pre><code>batch_get_configs(keys)\n</code></pre> <p>Batch get config items in a single DynamoDB call.</p> <p>Fetches config records (entity, resource, system level) in a single BatchGetItem request and returns deserialized limits.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list[tuple[str, str]]</code> <p>List of (PK, SK) tuples identifying config items</p> required <p>Returns:</p> Type Description <code>dict[tuple[str, str], tuple[list[Limit], OnUnavailableAction | None]]</code> <p>Dict mapping (PK, SK) to (limits, on_unavailable) tuples.</p> <code>dict[tuple[str, str], tuple[list[Limit], OnUnavailableAction | None]]</code> <p>on_unavailable is extracted from system config items (None for others).</p> <code>dict[tuple[str, str], tuple[list[Limit], OnUnavailableAction | None]]</code> <p>Missing items are not included in the result.</p> Note <p>DynamoDB BatchGetItem supports up to 100 items per request. For larger batches, this method automatically chunks the requests. Uses eventually consistent reads (0.5 RCU per item).</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_or_create_bucket","title":"get_or_create_bucket  <code>async</code>","text":"<pre><code>get_or_create_bucket(entity_id, resource, limit)\n</code></pre> <p>Get an existing bucket or create a new one with the given limit.</p> <p>If the bucket exists, it is returned. If not, a new bucket is created with capacity set to the limit's capacity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name (e.g., \"gpt-4\")</p> required <code>limit</code> <code>Limit</code> <p>Limit configuration for the bucket</p> required <p>Returns:</p> Type Description <code>BucketState</code> <p>Existing or newly created BucketState</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.build_bucket_put_item","title":"build_bucket_put_item","text":"<pre><code>build_bucket_put_item(state, ttl_seconds=86400)\n</code></pre> <p>Build a PutItem for a composite bucket (for use in transactions).</p> <p>Wraps build_composite_create for backward compatibility with protocol.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.build_bucket_update_item","title":"build_bucket_update_item","text":"<pre><code>build_bucket_update_item(entity_id, resource, limit_name, new_tokens_milli, new_last_refill_ms, expected_tokens_milli=None)\n</code></pre> <p>Build an UpdateItem for a single limit in a composite bucket.</p> <p>Legacy method \u2014 prefer build_composite_normal/retry/adjust for composite writes. This updates one limit's tk within the composite item.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.build_composite_create","title":"build_composite_create","text":"<pre><code>build_composite_create(entity_id, resource, states, now_ms, ttl_seconds=86400, cascade=False, parent_id=None)\n</code></pre> <p>Build a PutItem for creating a new composite bucket.</p> <p>Used on first acquire for an entity+resource. Condition ensures no concurrent creation race (attribute_not_exists).</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>states</code> <code>list[BucketState]</code> <p>BucketState objects for each limit</p> required <code>now_ms</code> <code>int</code> <p>Current timestamp in milliseconds</p> required <code>ttl_seconds</code> <code>int | None</code> <p>TTL in seconds from now, or None to omit TTL</p> <code>86400</code> <code>cascade</code> <code>bool</code> <p>Whether the entity has cascade enabled</p> <code>False</code> <code>parent_id</code> <code>str | None</code> <p>The entity's parent_id (if any)</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.build_composite_normal","title":"build_composite_normal","text":"<pre><code>build_composite_normal(entity_id, resource, consumed, refill_amounts, now_ms, expected_rf, ttl_seconds=None)\n</code></pre> <p>Build an UpdateItem for the normal write path (ADR-115 path 2).</p> <p>ADD tk:(refill - consumed), tc:consumed for each limit. SET rf:now. CONDITION rf = :expected.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>consumed</code> <code>dict[str, int]</code> <p>Amount consumed per limit (millitokens)</p> required <code>refill_amounts</code> <code>dict[str, int]</code> <p>Refill amount per limit (millitokens)</p> required <code>now_ms</code> <code>int</code> <p>Current timestamp in milliseconds</p> required <code>expected_rf</code> <code>int</code> <p>Expected refill timestamp for optimistic lock</p> required <code>ttl_seconds</code> <code>int | None</code> <p>TTL behavior: - None: Don't change TTL - 0: REMOVE ttl (entity has custom limits) - &gt;0: SET ttl to (now + ttl_seconds)</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.build_composite_retry","title":"build_composite_retry","text":"<pre><code>build_composite_retry(entity_id, resource, consumed)\n</code></pre> <p>Build an UpdateItem for the retry write path (ADR-115 path 3).</p> <p>Lost optimistic lock \u2014 skip refill, only consume. ADD tk:(-consumed), tc:consumed for each limit. CONDITION: tk &gt;= consumed per limit (prevent negative on acquire).</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.build_composite_adjust","title":"build_composite_adjust","text":"<pre><code>build_composite_adjust(entity_id, resource, deltas)\n</code></pre> <p>Build an UpdateItem for the adjust write path (ADR-115 path 4).</p> <p>Unconditional ADD for post-hoc correction. Can go negative by design. Positive delta = consumed more (subtract tokens, add to counter). Negative delta = consumed less (add tokens, subtract from counter).</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.transact_write","title":"transact_write  <code>async</code>","text":"<pre><code>transact_write(items)\n</code></pre> <p>Execute a write, using single-item API when possible to halve WCU cost.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.write_each","title":"write_each  <code>async</code>","text":"<pre><code>write_each(items)\n</code></pre> <p>Write items independently without cross-item atomicity (1 WCU each).</p> <p>Each item is dispatched as a single PutItem, UpdateItem, or DeleteItem call. Use for unconditional writes (e.g., ADD adjustments) where partial success is acceptable.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.speculative_consume","title":"speculative_consume  <code>async</code>","text":"<pre><code>speculative_consume(entity_id, resource, consume, ttl_seconds=None)\n</code></pre> <p>Attempt speculative UpdateItem with condition check.</p> <p>Checks entity cache for cascade metadata. If cache hit + cascade, issues child+parent UpdateItems concurrently via asyncio.gather and returns nested parent_result.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>consume</code> <code>dict[str, int]</code> <p>Amount per limit (tokens, not milli)</p> required <code>ttl_seconds</code> <code>int | None</code> <p>TTL in seconds from now, or None for no TTL change</p> <code>None</code> <p>Returns:</p> Type Description <code>SpeculativeResult</code> <p>SpeculativeResult with:</p> <code>SpeculativeResult</code> <ul> <li>On cache hit + cascade + both succeed: parent_result populated</li> </ul> <code>SpeculativeResult</code> <ul> <li>On cache miss or non-cascade: parent_result is None</li> </ul> <code>SpeculativeResult</code> <ul> <li>On failure: old_buckets from ALL_OLD (or None if bucket missing)</li> </ul>"},{"location":"api/repository/#zae_limiter.repository.Repository.set_limits","title":"set_limits  <code>async</code>","text":"<pre><code>set_limits(entity_id, limits, resource=DEFAULT_RESOURCE, principal=None)\n</code></pre> <p>Store limit configs for an entity (composite format, ADR-114).</p> <p>All limits for an entity+resource are stored in a single composite item with SK '#CONFIG#{resource}'. This reduces cache-miss cost from N GetItem calls to 1 GetItem call.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity</p> required <code>limits</code> <code>list[Limit]</code> <p>List of Limit configurations to store</p> required <code>resource</code> <code>str</code> <p>Resource name (defaults to \"default\")</p> <code>DEFAULT_RESOURCE</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.reconcile_bucket_to_defaults","title":"reconcile_bucket_to_defaults  <code>async</code>","text":"<pre><code>reconcile_bucket_to_defaults(entity_id, resource, effective_limits, stale_limit_names=None)\n</code></pre> <p>Reconcile bucket to effective defaults after config deletion (issue #327).</p> <p>Updates limit fields (cp, bx, ra, rp) to match the new effective limits, sets TTL (since entity is now on defaults), and removes stale limit attributes that no longer exist in the effective config.</p> <p>No-op if bucket doesn't exist (uses attribute_exists(PK) condition).</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>effective_limits</code> <code>list[Limit]</code> <p>The new effective limits (resource/system defaults)</p> required <code>stale_limit_names</code> <code>set[str] | None</code> <p>Limit names to REMOVE from bucket (limits that were in the deleted entity config but not in effective defaults)</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_limits","title":"get_limits  <code>async</code>","text":"<pre><code>get_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Get stored limit configs for an entity (composite format, ADR-114).</p> <p>Reads a single composite item with SK '#CONFIG#{resource}' containing all limits for the entity+resource pair.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.delete_limits","title":"delete_limits  <code>async</code>","text":"<pre><code>delete_limits(entity_id, resource=DEFAULT_RESOURCE, principal=None)\n</code></pre> <p>Delete stored limit configs for an entity (composite format, ADR-114).</p> <p>Deletes the single composite config item for this entity+resource.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity</p> required <code>resource</code> <code>str</code> <p>Resource name (defaults to \"default\")</p> <code>DEFAULT_RESOURCE</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.list_entities_with_custom_limits","title":"list_entities_with_custom_limits  <code>async</code>","text":"<pre><code>list_entities_with_custom_limits(resource, limit=None, cursor=None)\n</code></pre> <p>List all entities that have custom limit configurations for a resource.</p> <p>Uses GSI3 sparse index for efficient queries. Only entity-level configs have GSI3 attributes, so this query returns only entities with custom limits (not system or resource defaults).</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to filter by (required).</p> required <code>limit</code> <code>int | None</code> <p>Maximum number of entities to return. None for all.</p> <code>None</code> <code>cursor</code> <code>str | None</code> <p>Pagination cursor from previous call. None for first page.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[str], str | None]</code> <p>Tuple of (entity_ids, next_cursor). next_cursor is None if no more results.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.list_resources_with_entity_configs","title":"list_resources_with_entity_configs  <code>async</code>","text":"<pre><code>list_resources_with_entity_configs()\n</code></pre> <p>List all resources that have entity-level custom limit configs.</p> <p>Uses the entity config resources registry (wide column with ref counts) for efficient O(1) lookup. Returns resources with count &gt; 0.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list of resource names with at least one entity having custom limits</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.set_resource_defaults","title":"set_resource_defaults  <code>async</code>","text":"<pre><code>set_resource_defaults(resource, limits, principal=None)\n</code></pre> <p>Store default limit configs for a resource (composite format, ADR-114).</p> <p>All limits for a resource are stored in a single composite item with SK '#CONFIG'. This reduces cache-miss cost.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>limits</code> <code>list[Limit]</code> <p>List of Limit configurations to store</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_resource_defaults","title":"get_resource_defaults  <code>async</code>","text":"<pre><code>get_resource_defaults(resource)\n</code></pre> <p>Get stored default limit configs for a resource (composite format, ADR-114).</p> <p>Reads a single composite item with SK '#CONFIG' containing all limits for the resource.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.delete_resource_defaults","title":"delete_resource_defaults  <code>async</code>","text":"<pre><code>delete_resource_defaults(resource, principal=None)\n</code></pre> <p>Delete stored default limit configs for a resource (composite format, ADR-114).</p> <p>Deletes the single composite config item for this resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.list_resources_with_defaults","title":"list_resources_with_defaults  <code>async</code>","text":"<pre><code>list_resources_with_defaults()\n</code></pre> <p>List all resources that have default limit configs from the resource registry.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.set_system_defaults","title":"set_system_defaults  <code>async</code>","text":"<pre><code>set_system_defaults(limits, on_unavailable=None, principal=None)\n</code></pre> <p>Store system-wide default limits and config (composite format, ADR-114).</p> <p>All system limits and config (on_unavailable) are stored in a single composite item with SK '#CONFIG'. This reduces cache-miss cost.</p> <p>Parameters:</p> Name Type Description Default <code>limits</code> <code>list[Limit]</code> <p>List of Limit configurations (apply to all resources)</p> required <code>on_unavailable</code> <code>OnUnavailableAction | None</code> <p>Behavior when DynamoDB unavailable (\"allow\" or \"block\")</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_system_defaults","title":"get_system_defaults  <code>async</code>","text":"<pre><code>get_system_defaults()\n</code></pre> <p>Get system-wide default limits and config (composite format, ADR-114).</p> <p>Reads a single composite item with SK '#CONFIG' containing all limits and on_unavailable setting.</p> <p>Returns:</p> Type Description <code>tuple[list[Limit], OnUnavailableAction | None]</code> <p>Tuple of (limits, on_unavailable). on_unavailable may be None if not set.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.delete_system_defaults","title":"delete_system_defaults  <code>async</code>","text":"<pre><code>delete_system_defaults(principal=None)\n</code></pre> <p>Delete all system-wide default limits and config (composite format, ADR-114).</p> <p>Deletes the single composite config item for system defaults.</p> <p>Parameters:</p> Name Type Description Default <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_system_limits","title":"get_system_limits  <code>async</code>","text":"<pre><code>get_system_limits()\n</code></pre> <p>Get system-wide default limits (without config).</p> <p>This is a convenience method that returns only the limits. Use get_system_defaults() to also get on_unavailable config.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_version_record","title":"get_version_record  <code>async</code>","text":"<pre><code>get_version_record()\n</code></pre> <p>Get the infrastructure version record.</p> <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Version record with schema_version, lambda_version, etc.</p> <code>dict[str, Any] | None</code> <p>None if no version record exists.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.ping","title":"ping  <code>async</code>","text":"<pre><code>ping()\n</code></pre> <p>Check if the DynamoDB table is reachable.</p> <p>Performs a lightweight GetItem operation to verify connectivity. Does not verify the table is initialized or has valid data.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the table is reachable, False otherwise.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.set_version_record","title":"set_version_record  <code>async</code>","text":"<pre><code>set_version_record(schema_version, lambda_version=None, client_min_version='0.0.0', updated_by=None)\n</code></pre> <p>Set the infrastructure version record.</p> <p>Parameters:</p> Name Type Description Default <code>schema_version</code> <code>str</code> <p>Current schema version (e.g., \"1.0.0\")</p> required <code>lambda_version</code> <code>str | None</code> <p>Currently deployed Lambda version</p> <code>None</code> <code>client_min_version</code> <code>str</code> <p>Minimum compatible client version</p> <code>'0.0.0'</code> <code>updated_by</code> <code>str | None</code> <p>Identifier of what performed the update</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_audit_events","title":"get_audit_events  <code>async</code>","text":"<pre><code>get_audit_events(entity_id, limit=100, start_event_id=None)\n</code></pre> <p>Get audit events for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>ID of the entity to query</p> required <code>limit</code> <code>int</code> <p>Maximum number of events to return</p> <code>100</code> <code>start_event_id</code> <code>str | None</code> <p>Event ID to start after (for pagination)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[AuditEvent]</code> <p>List of AuditEvent objects, ordered by most recent first</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_usage_snapshots","title":"get_usage_snapshots  <code>async</code>","text":"<pre><code>get_usage_snapshots(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None, limit=100, next_key=None)\n</code></pre> <p>Query usage snapshots with filtering and pagination.</p> <p>Supports two query modes: 1. Entity-scoped: Query by entity_id (uses primary key) 2. Resource-scoped: Query by resource across all entities (uses GSI2)</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query (mutually exclusive for efficient queries)</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource name filter (required if entity_id is None)</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by window type (\"hourly\", \"daily\")</p> <code>None</code> <code>start_time</code> <code>str | None</code> <p>Filter snapshots &gt;= this timestamp (ISO format)</p> <code>None</code> <code>end_time</code> <code>str | None</code> <p>Filter snapshots &lt;= this timestamp (ISO format)</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum items to fetch from DynamoDB per page (default: 100)</p> <code>100</code> <code>next_key</code> <code>dict[str, Any] | None</code> <p>Pagination cursor from previous call</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[UsageSnapshot], dict[str, Any] | None]</code> <p>Tuple of (snapshots, next_key). next_key is None if no more results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p> Note <p>The <code>limit</code> parameter controls the DynamoDB query batch size. Client-side filters (window_type, start_time, end_time) are applied after fetching, so the returned count may be less than <code>limit</code>. Use <code>next_key</code> to paginate through all matching results.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_usage_summary","title":"get_usage_summary  <code>async</code>","text":"<pre><code>get_usage_summary(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None)\n</code></pre> <p>Aggregate usage across snapshots into a summary.</p> <p>Fetches all matching snapshots (auto-paginates internally) and computes: - Total consumption per limit type - Average consumption per snapshot per limit type - Time range of aggregated data</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource name filter</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by window type (\"hourly\", \"daily\")</p> <code>None</code> <code>start_time</code> <code>str | None</code> <p>Filter snapshots &gt;= this timestamp (ISO format)</p> <code>None</code> <code>end_time</code> <code>str | None</code> <p>Filter snapshots &lt;= this timestamp (ISO format)</p> <code>None</code> <p>Returns:</p> Type Description <code>UsageSummary</code> <p>UsageSummary with aggregated statistics</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_resource_buckets","title":"get_resource_buckets  <code>async</code>","text":"<pre><code>get_resource_buckets(resource, limit_name=None)\n</code></pre> <p>Get all buckets for a resource across all entities.</p> <p>With composite items, each GSI2 entry is one composite item per entity. Returns individual BucketStates, optionally filtered by limit_name.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.resolve_limits","title":"resolve_limits  <code>async</code>","text":"<pre><code>resolve_limits(entity_id, resource)\n</code></pre> <p>Resolve effective limits using the four-level config hierarchy.</p> <p>Uses ConfigCache with batched fetch optimization. Falls back to sequential individual GetItem calls if batch resolution fails.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to resolve limits for</p> required <code>resource</code> <code>str</code> <p>Resource being accessed</p> required <p>Returns:</p> Type Description <code>tuple[list[Limit] | None, OnUnavailableAction | None, ConfigSource | None]</code> <p>Tuple of (limits, on_unavailable, config_source)</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.resolve_on_unavailable","title":"resolve_on_unavailable  <code>async</code>","text":"<pre><code>resolve_on_unavailable()\n</code></pre> <p>Resolve on_unavailable from system config, with caching fallback.</p> <p>Returns the on_unavailable action from system config. Caches the value after first successful load so it's available as fallback when DynamoDB is unreachable. Defaults to \"block\" if no system config exists and no cached value is available.</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.invalidate_config_cache","title":"invalidate_config_cache  <code>async</code>","text":"<pre><code>invalidate_config_cache()\n</code></pre> <p>Invalidate all cached config entries (ADR-122).</p>"},{"location":"api/repository/#zae_limiter.repository.Repository.get_cache_stats","title":"get_cache_stats","text":"<pre><code>get_cache_stats()\n</code></pre> <p>Get config cache performance statistics (ADR-122).</p>"},{"location":"api/repository/#repositoryprotocol","title":"RepositoryProtocol","text":"<p>The <code>RepositoryProtocol</code> defines the interface for pluggable backends. Implement this protocol to use a different storage backend (e.g., for testing).</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol","title":"RepositoryProtocol","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for rate limiter data backends.</p> <p>All storage backends (DynamoDB, Redis, SQLite, In-Memory) must implement this protocol to work with RateLimiter. The protocol is divided into:</p> <ul> <li>Properties: Backend identification and configuration</li> <li>Lifecycle: Connection management</li> <li>Entity operations: CRUD for rate-limited entities</li> <li>Bucket operations: Token bucket state management</li> <li>Limit config: Stored limit configurations at entity/resource/system level</li> <li>Version management: Schema and Lambda version tracking</li> <li>Audit logging: Security audit trail</li> <li>Usage snapshots: Historical consumption tracking</li> </ul> Example"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol--custom-backend-implementation","title":"Custom backend implementation","text":"<p>class MyBackend:     @property     def region(self) -&gt; str | None:         return \"us-east-1\"</p> <pre><code>async def get_entity(self, entity_id: str) -&gt; Entity | None:\n    ...\n</code></pre>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol--duck-typing-no-inheritance-needed","title":"Duck typing - no inheritance needed","text":"<p>repo = MyBackend() assert isinstance(repo, RepositoryProtocol)  # True at runtime</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.region","title":"region  <code>property</code>","text":"<pre><code>region\n</code></pre> <p>AWS region (or None for local/in-memory backends).</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.endpoint_url","title":"endpoint_url  <code>property</code>","text":"<pre><code>endpoint_url\n</code></pre> <p>Custom endpoint URL (e.g., LocalStack, local DynamoDB).</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.stack_name","title":"stack_name  <code>property</code>","text":"<pre><code>stack_name\n</code></pre> <p>CloudFormation stack name.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.table_name","title":"table_name  <code>property</code>","text":"<pre><code>table_name\n</code></pre> <p>DynamoDB table name (same as stack_name).</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.namespace_name","title":"namespace_name  <code>property</code>","text":"<pre><code>namespace_name\n</code></pre> <p>The human-readable namespace name.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.namespace_id","title":"namespace_id  <code>property</code>","text":"<pre><code>namespace_id\n</code></pre> <p>The opaque namespace ID used in DynamoDB keys.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.capabilities","title":"capabilities  <code>property</code>","text":"<pre><code>capabilities\n</code></pre> <p>Declare which extended features this backend supports.</p> <p>Returns:</p> Type Description <code>BackendCapabilities</code> <p>BackendCapabilities instance with feature flags.</p> Example <p>if repo.capabilities.supports_audit_logging:     events = await repo.get_audit_events(entity_id)</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.namespace","title":"namespace  <code>async</code>","text":"<pre><code>namespace(name, *, on_unavailable=None, bucket_ttl_multiplier=None)\n</code></pre> <p>Return a scoped repository for the given namespace.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Namespace name to resolve.</p> required <code>on_unavailable</code> <code>OnUnavailableAction | None</code> <p>Override on_unavailable for this namespace.</p> <code>None</code> <code>bucket_ttl_multiplier</code> <code>int | None</code> <p>Override bucket TTL multiplier.</p> <code>None</code> <p>Returns:</p> Type Description <code>RepositoryProtocol</code> <p>A repository scoped to the resolved namespace.</p> <p>Raises:</p> Type Description <code>NamespaceNotFoundError</code> <p>If the namespace is not registered.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.register_namespace","title":"register_namespace  <code>async</code>","text":"<pre><code>register_namespace(namespace)\n</code></pre> <p>Register a namespace (idempotent). Returns the namespace_id.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.register_namespaces","title":"register_namespaces  <code>async</code>","text":"<pre><code>register_namespaces(namespaces)\n</code></pre> <p>Bulk-register namespaces. Returns <code>{name: namespace_id}</code>.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_namespace","title":"get_namespace  <code>async</code>","text":"<pre><code>get_namespace(namespace)\n</code></pre> <p>Get namespace details by name. Returns dict or <code>None</code>.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.list_namespaces","title":"list_namespaces  <code>async</code>","text":"<pre><code>list_namespaces()\n</code></pre> <p>List active namespaces. Returns <code>[{name, namespace_id, created_at}]</code>.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.delete_namespace","title":"delete_namespace  <code>async</code>","text":"<pre><code>delete_namespace(namespace)\n</code></pre> <p>Soft-delete a namespace. No-op if not found.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.recover_namespace","title":"recover_namespace  <code>async</code>","text":"<pre><code>recover_namespace(namespace_id)\n</code></pre> <p>Recover a deleted namespace. Returns the namespace name.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.list_orphan_namespaces","title":"list_orphan_namespaces  <code>async</code>","text":"<pre><code>list_orphan_namespaces()\n</code></pre> <p>List deleted namespaces. Returns <code>[{namespace_id, namespace, deleted_at}]</code>.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.purge_namespace","title":"purge_namespace  <code>async</code>","text":"<pre><code>purge_namespace(namespace_id)\n</code></pre> <p>Purge all data for a deleted namespace. No-op if not found.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.close","title":"close  <code>async</code>","text":"<pre><code>close()\n</code></pre> <p>Close the backend connection and release resources.</p> <p>Must be called when the repository is no longer needed. Safe to call multiple times.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.ping","title":"ping  <code>async</code>","text":"<pre><code>ping()\n</code></pre> <p>Check if the backend is reachable.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the backend is accessible, False otherwise.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.ensure_infrastructure","title":"ensure_infrastructure  <code>async</code>","text":"<pre><code>ensure_infrastructure()\n</code></pre> <p>Ensure backend infrastructure exists.</p> <p>For DynamoDB: Creates CloudFormation stack if stack_options was provided to the constructor. For other backends: May create required resources or be a no-op.</p> <p>Uses the options passed to the constructor. No-op if not provided.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.create_entity","title":"create_entity  <code>async</code>","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, cascade=False, metadata=None, principal=None)\n</code></pre> <p>Create a new entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Unique identifier for the entity</p> required <code>name</code> <code>str | None</code> <p>Human-readable name (defaults to entity_id)</p> <code>None</code> <code>parent_id</code> <code>str | None</code> <p>Parent entity ID for hierarchical limits</p> <code>None</code> <code>cascade</code> <code>bool</code> <p>If True, acquire() will also consume from parent entity</p> <code>False</code> <code>metadata</code> <code>dict[str, str] | None</code> <p>Additional key-value metadata</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code> <p>Returns:</p> Type Description <code>Entity</code> <p>The created Entity</p> <p>Raises:</p> Type Description <code>EntityExistsError</code> <p>If entity already exists</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_entity","title":"get_entity  <code>async</code>","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier</p> required <p>Returns:</p> Type Description <code>Entity | None</code> <p>Entity if found, None otherwise</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.delete_entity","title":"delete_entity  <code>async</code>","text":"<pre><code>delete_entity(entity_id, principal=None)\n</code></pre> <p>Delete an entity and all related records.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to delete</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_children","title":"get_children  <code>async</code>","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all child entities of a parent.</p> <p>Parameters:</p> Name Type Description Default <code>parent_id</code> <code>str</code> <p>Parent entity ID</p> required <p>Returns:</p> Type Description <code>list[Entity]</code> <p>List of child entities</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_bucket","title":"get_bucket  <code>async</code>","text":"<pre><code>get_bucket(entity_id, resource, limit_name)\n</code></pre> <p>Get a token bucket by entity/resource/limit.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name (e.g., \"gpt-4\")</p> required <code>limit_name</code> <code>str</code> <p>Limit name (e.g., \"tpm\", \"rpm\")</p> required <p>Returns:</p> Type Description <code>BucketState | None</code> <p>BucketState if found, None otherwise</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_buckets","title":"get_buckets  <code>async</code>","text":"<pre><code>get_buckets(entity_id, resource)\n</code></pre> <p>Get all token buckets for an entity/resource pair.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the buckets</p> required <code>resource</code> <code>str</code> <p>Resource name (e.g., \"gpt-4\")</p> required <p>Returns:</p> Type Description <code>list[BucketState]</code> <p>List of bucket states for all limits on this resource</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_or_create_bucket","title":"get_or_create_bucket  <code>async</code>","text":"<pre><code>get_or_create_bucket(entity_id, resource, limit)\n</code></pre> <p>Get an existing bucket or create a new one with the given limit.</p> <p>This is the primary method for initializing token buckets. If a bucket exists, it is returned. If not, a new bucket is created with capacity set to the limit's capacity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name (e.g., \"gpt-4\")</p> required <code>limit</code> <code>Limit</code> <p>Limit configuration for the bucket</p> required <p>Returns:</p> Type Description <code>BucketState</code> <p>Existing or newly created BucketState</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.batch_get_buckets","title":"batch_get_buckets  <code>async</code>","text":"<pre><code>batch_get_buckets(keys)\n</code></pre> <p>Batch get composite buckets in a single call.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list[tuple[str, str]]</code> <p>List of (entity_id, resource) tuples</p> required <p>Returns:</p> Type Description <code>dict[tuple[str, str, str], BucketState]</code> <p>Dict mapping (entity_id, resource, limit_name) to BucketState.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.batch_get_entity_and_buckets","title":"batch_get_entity_and_buckets  <code>async</code>","text":"<pre><code>batch_get_entity_and_buckets(entity_id, bucket_keys)\n</code></pre> <p>Fetch entity metadata and composite buckets in a single call.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity whose metadata to include</p> required <code>bucket_keys</code> <code>list[tuple[str, str]]</code> <p>List of (entity_id, resource) for composite buckets</p> required <p>Returns:</p> Type Description <code>tuple[Entity | None, dict[tuple[str, str, str], BucketState]]</code> <p>Tuple of (entity_or_none, bucket_dict).</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_resource_buckets","title":"get_resource_buckets  <code>async</code>","text":"<pre><code>get_resource_buckets(resource, limit_name=None)\n</code></pre> <p>Get all buckets for a resource across all entities.</p> <p>Used for capacity reporting and aggregation.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>limit_name</code> <code>str | None</code> <p>Optional filter by limit name</p> <code>None</code> <p>Returns:</p> Type Description <code>list[BucketState]</code> <p>List of bucket states</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.build_bucket_put_item","title":"build_bucket_put_item","text":"<pre><code>build_bucket_put_item(state, ttl_seconds=86400)\n</code></pre> <p>Build a transaction item for upserting a bucket.</p> <p>This is a synchronous method used to build transaction payloads.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>BucketState</code> <p>Bucket state to persist</p> required <code>ttl_seconds</code> <code>int</code> <p>Time-to-live for the record</p> <code>86400</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Transaction item dict for use with transact_write</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.build_composite_create","title":"build_composite_create","text":"<pre><code>build_composite_create(entity_id, resource, states, now_ms, ttl_seconds=86400, cascade=False, parent_id=None)\n</code></pre> <p>Build a PutItem for creating a new composite bucket.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>states</code> <code>list[BucketState]</code> <p>BucketState objects for each limit</p> required <code>now_ms</code> <code>int</code> <p>Current timestamp in milliseconds</p> required <code>ttl_seconds</code> <code>int | None</code> <p>TTL in seconds from now, or None to omit TTL</p> <code>86400</code> <code>cascade</code> <code>bool</code> <p>Whether the entity has cascade enabled</p> <code>False</code> <code>parent_id</code> <code>str | None</code> <p>The entity's parent_id (if any)</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.build_composite_normal","title":"build_composite_normal","text":"<pre><code>build_composite_normal(entity_id, resource, consumed, refill_amounts, now_ms, expected_rf, ttl_seconds=None)\n</code></pre> <p>Build an UpdateItem for the normal write path (ADR-115 path 2).</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>consumed</code> <code>dict[str, int]</code> <p>Amount consumed per limit (millitokens)</p> required <code>refill_amounts</code> <code>dict[str, int]</code> <p>Refill amount per limit (millitokens)</p> required <code>now_ms</code> <code>int</code> <p>Current timestamp in milliseconds</p> required <code>expected_rf</code> <code>int</code> <p>Expected refill timestamp for optimistic lock</p> required <code>ttl_seconds</code> <code>int | None</code> <p>TTL behavior (None=no change, 0=remove, &gt;0=set)</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.build_composite_retry","title":"build_composite_retry","text":"<pre><code>build_composite_retry(entity_id, resource, consumed)\n</code></pre> <p>Build an UpdateItem for the retry write path (ADR-115 path 3).</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>consumed</code> <code>dict[str, int]</code> <p>Amount consumed per limit (millitokens)</p> required"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.build_composite_adjust","title":"build_composite_adjust","text":"<pre><code>build_composite_adjust(entity_id, resource, deltas)\n</code></pre> <p>Build an UpdateItem for the adjust write path (ADR-115 path 4).</p> <p>Unconditional ADD for post-hoc correction. Can go negative by design. Positive delta = consumed more (subtract tokens, add to counter). Negative delta = consumed less (add tokens, subtract from counter).</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>deltas</code> <code>dict[str, int]</code> <p>Delta per limit (millitokens, positive=consume, negative=release)</p> required"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.transact_write","title":"transact_write  <code>async</code>","text":"<pre><code>transact_write(items)\n</code></pre> <p>Execute a write of one or more items.</p> <p>Single-item batches use the corresponding single-item API (PutItem, UpdateItem, or DeleteItem) to halve WCU cost. Multi-item batches use TransactWriteItems for atomicity.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict[str, Any]]</code> <p>List of transaction items from build_bucket_put_item</p> required <p>Raises:</p> Type Description <code>TransactionCanceledException</code> <p>If multi-item transaction fails</p> <code>ConditionalCheckFailedException</code> <p>If single-item condition fails</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.write_each","title":"write_each  <code>async</code>","text":"<pre><code>write_each(items)\n</code></pre> <p>Write items independently without cross-item atomicity.</p> <p>Each item is dispatched as a single PutItem, UpdateItem, or DeleteItem call (1 WCU each). Use for unconditional writes (e.g., ADD adjustments) where partial success is acceptable.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict[str, Any]]</code> <p>List of items to write independently</p> required"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.speculative_consume","title":"speculative_consume  <code>async</code>","text":"<pre><code>speculative_consume(entity_id, resource, consume, ttl_seconds=None)\n</code></pre> <p>Attempt speculative UpdateItem with condition check.</p> <p>Issues an UpdateItem with ADD -consumed and condition <code>attribute_exists(PK) AND tk &gt;= consumed</code> for each limit. Uses <code>ReturnValuesOnConditionCheckFailure=ALL_OLD</code> to return the current item state on failure.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>consume</code> <code>dict[str, int]</code> <p>Amount per limit (tokens, not milli)</p> required <code>ttl_seconds</code> <code>int | None</code> <p>TTL in seconds from now, or None for no TTL change</p> <code>None</code> <p>Returns:</p> Type Description <code>SpeculativeResult</code> <p>SpeculativeResult with success flag and either:</p> <code>SpeculativeResult</code> <ul> <li>On success: buckets, cascade, parent_id from ALL_NEW</li> </ul> <code>SpeculativeResult</code> <ul> <li>On failure with ALL_OLD: old_buckets from ALL_OLD</li> </ul> <code>SpeculativeResult</code> <ul> <li>On failure without ALL_OLD: old_buckets is None (bucket missing)</li> </ul>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.reconcile_bucket_to_defaults","title":"reconcile_bucket_to_defaults  <code>async</code>","text":"<pre><code>reconcile_bucket_to_defaults(entity_id, resource, effective_limits, stale_limit_names=None)\n</code></pre> <p>Reconcile bucket to effective defaults after config deletion (issue #327).</p> <p>Updates limit fields to match effective limits, sets TTL, and removes stale limit attributes. No-op if bucket doesn't exist.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity owning the bucket</p> required <code>resource</code> <code>str</code> <p>Resource name</p> required <code>effective_limits</code> <code>list[Limit]</code> <p>New effective limits (resource/system defaults)</p> required <code>stale_limit_names</code> <code>set[str] | None</code> <p>Limit names to REMOVE from bucket</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.set_limits","title":"set_limits  <code>async</code>","text":"<pre><code>set_limits(entity_id, limits, resource='_default_', principal=None)\n</code></pre> <p>Store limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to configure</p> required <code>limits</code> <code>list[Limit]</code> <p>Limit configurations</p> required <code>resource</code> <code>str</code> <p>Resource these limits apply to</p> <code>'_default_'</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_limits","title":"get_limits  <code>async</code>","text":"<pre><code>get_limits(entity_id, resource='_default_')\n</code></pre> <p>Get stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to query</p> required <code>resource</code> <code>str</code> <p>Resource to get limits for</p> <code>'_default_'</code> <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of limits (empty if none configured)</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.delete_limits","title":"delete_limits  <code>async</code>","text":"<pre><code>delete_limits(entity_id, resource='_default_', principal=None)\n</code></pre> <p>Delete stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to delete limits for</p> required <code>resource</code> <code>str</code> <p>Resource to delete limits for</p> <code>'_default_'</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.list_entities_with_custom_limits","title":"list_entities_with_custom_limits  <code>async</code>","text":"<pre><code>list_entities_with_custom_limits(resource, limit=None, cursor=None)\n</code></pre> <p>List all entities that have custom limit configurations for a resource.</p> <p>Uses GSI3 sparse index for efficient queries.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to filter by (required).</p> required <code>limit</code> <code>int | None</code> <p>Maximum number of entities to return. None for all.</p> <code>None</code> <code>cursor</code> <code>str | None</code> <p>Pagination cursor from previous call. None for first page.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[str], str | None]</code> <p>Tuple of (entity_ids, next_cursor). next_cursor is None if no more results.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.list_resources_with_entity_configs","title":"list_resources_with_entity_configs  <code>async</code>","text":"<pre><code>list_resources_with_entity_configs()\n</code></pre> <p>List all resources that have entity-level custom limit configurations.</p> <p>Uses the entity config resources registry for efficient O(1) lookup.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list of resource names with at least one entity having custom limits</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.set_resource_defaults","title":"set_resource_defaults  <code>async</code>","text":"<pre><code>set_resource_defaults(resource, limits, principal=None)\n</code></pre> <p>Store default limits for a resource.</p> <p>Resource defaults apply to all entities accessing this resource unless overridden at the entity level.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>limits</code> <code>list[Limit]</code> <p>Default limits</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_resource_defaults","title":"get_resource_defaults  <code>async</code>","text":"<pre><code>get_resource_defaults(resource)\n</code></pre> <p>Get default limits for a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of limits (empty if none configured)</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.delete_resource_defaults","title":"delete_resource_defaults  <code>async</code>","text":"<pre><code>delete_resource_defaults(resource, principal=None)\n</code></pre> <p>Delete default limits for a resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource name</p> required <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.list_resources_with_defaults","title":"list_resources_with_defaults  <code>async</code>","text":"<pre><code>list_resources_with_defaults()\n</code></pre> <p>List all resources that have default limits configured.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of resource names</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.set_system_defaults","title":"set_system_defaults  <code>async</code>","text":"<pre><code>set_system_defaults(limits, on_unavailable=None, principal=None)\n</code></pre> <p>Store system-wide default limits and config.</p> <p>System defaults apply to ALL resources unless overridden.</p> <p>Parameters:</p> Name Type Description Default <code>limits</code> <code>list[Limit]</code> <p>Global default limits</p> required <code>on_unavailable</code> <code>OnUnavailableAction | None</code> <p>Behavior when backend unavailable (\"allow\" or \"block\")</p> <code>None</code> <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_system_defaults","title":"get_system_defaults  <code>async</code>","text":"<pre><code>get_system_defaults()\n</code></pre> <p>Get system-wide default limits and config.</p> <p>Returns:</p> Type Description <code>tuple[list[Limit], OnUnavailableAction | None]</code> <p>Tuple of (limits, on_unavailable). on_unavailable may be None.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.delete_system_defaults","title":"delete_system_defaults  <code>async</code>","text":"<pre><code>delete_system_defaults(principal=None)\n</code></pre> <p>Delete all system-wide defaults.</p> <p>Parameters:</p> Name Type Description Default <code>principal</code> <code>str | None</code> <p>Caller identity for audit logging</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_version_record","title":"get_version_record  <code>async</code>","text":"<pre><code>get_version_record()\n</code></pre> <p>Get the infrastructure version record.</p> <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Version record with schema_version, lambda_version, etc.</p> <code>dict[str, Any] | None</code> <p>None if no version record exists.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.set_version_record","title":"set_version_record  <code>async</code>","text":"<pre><code>set_version_record(schema_version, lambda_version=None, client_min_version='0.0.0', updated_by=None)\n</code></pre> <p>Set the infrastructure version record.</p> <p>Parameters:</p> Name Type Description Default <code>schema_version</code> <code>str</code> <p>Current schema version (e.g., \"1.0.0\")</p> required <code>lambda_version</code> <code>str | None</code> <p>Currently deployed Lambda version</p> <code>None</code> <code>client_min_version</code> <code>str</code> <p>Minimum compatible client version</p> <code>'0.0.0'</code> <code>updated_by</code> <code>str | None</code> <p>Identifier of what performed the update</p> <code>None</code>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_audit_events","title":"get_audit_events  <code>async</code>","text":"<pre><code>get_audit_events(entity_id, limit=100, start_event_id=None)\n</code></pre> <p>Get audit events for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to query</p> required <code>limit</code> <code>int</code> <p>Maximum events to return</p> <code>100</code> <code>start_event_id</code> <code>str | None</code> <p>Pagination cursor (event ID to start after)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[AuditEvent]</code> <p>List of audit events, most recent first</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_usage_snapshots","title":"get_usage_snapshots  <code>async</code>","text":"<pre><code>get_usage_snapshots(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None, limit=100, next_key=None)\n</code></pre> <p>Query usage snapshots with filtering and pagination.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query (uses primary key)</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource filter (required if entity_id is None)</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by \"hourly\" or \"daily\"</p> <code>None</code> <code>start_time</code> <code>str | None</code> <p>Filter snapshots &gt;= this timestamp (ISO format)</p> <code>None</code> <code>end_time</code> <code>str | None</code> <p>Filter snapshots &lt;= this timestamp (ISO format)</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum items per page</p> <code>100</code> <code>next_key</code> <code>dict[str, Any] | None</code> <p>Pagination cursor from previous call</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[UsageSnapshot], dict[str, Any] | None]</code> <p>Tuple of (snapshots, next_key). next_key is None if no more results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_usage_summary","title":"get_usage_summary  <code>async</code>","text":"<pre><code>get_usage_summary(entity_id=None, resource=None, window_type=None, start_time=None, end_time=None)\n</code></pre> <p>Aggregate usage across snapshots into a summary.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str | None</code> <p>Entity to query</p> <code>None</code> <code>resource</code> <code>str | None</code> <p>Resource filter</p> <code>None</code> <code>window_type</code> <code>str | None</code> <p>Filter by \"hourly\" or \"daily\"</p> <code>None</code> <code>start_time</code> <code>str | None</code> <p>Filter snapshots &gt;= this timestamp</p> <code>None</code> <code>end_time</code> <code>str | None</code> <p>Filter snapshots &lt;= this timestamp</p> <code>None</code> <p>Returns:</p> Type Description <code>UsageSummary</code> <p>UsageSummary with total, average, and time range</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither entity_id nor resource is provided</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.resolve_limits","title":"resolve_limits  <code>async</code>","text":"<pre><code>resolve_limits(entity_id, resource)\n</code></pre> <p>Resolve effective limits using the four-level config hierarchy.</p> <p>Resolution order (first non-empty wins): 1. Entity-level config for this specific resource 2. Entity-level <code>_default_</code> config (fallback for all resources) 3. Resource-level defaults 4. System-level defaults</p> <p>Backend implementations should use native caching and resolution strategies. For DynamoDB, this uses ConfigCache with batched fetch optimization.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to resolve limits for</p> required <code>resource</code> <code>str</code> <p>Resource being accessed</p> required <p>Returns:</p> Type Description <code>list[Limit] | None</code> <p>Tuple of (limits, on_unavailable, config_source) where:</p> <code>OnUnavailableAction | None</code> <ul> <li>limits: Resolved limits or None if nothing found at any level</li> </ul> <code>ConfigSource | None</code> <ul> <li>on_unavailable: System-level unavailability behavior (if any)</li> </ul> <code>tuple[list[Limit] | None, OnUnavailableAction | None, ConfigSource | None]</code> <ul> <li>config_source: \"entity\", \"entity_default\", \"resource\", \"system\", or None if no config found</li> </ul>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.resolve_on_unavailable","title":"resolve_on_unavailable  <code>async</code>","text":"<pre><code>resolve_on_unavailable()\n</code></pre> <p>Resolve on_unavailable from system config, with caching fallback.</p> <p>Returns the on_unavailable action. Caches the value after first successful load for use as fallback when DynamoDB is unreachable. Defaults to \"block\" if no system config and no cached value.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.invalidate_config_cache","title":"invalidate_config_cache  <code>async</code>","text":"<pre><code>invalidate_config_cache()\n</code></pre> <p>Invalidate all cached config entries.</p> <p>Backends with caching should evict all entries. Backends without caching (e.g., Redis with native TTL) should no-op.</p> <p>Call after modifying config to force immediate refresh.</p>"},{"location":"api/repository/#zae_limiter.repository_protocol.RepositoryProtocol.get_cache_stats","title":"get_cache_stats","text":"<pre><code>get_cache_stats()\n</code></pre> <p>Get config cache performance statistics.</p> <p>Returns statistics for monitoring cache behavior: - hits: Cache hits (avoided backend reads) - misses: Cache misses (backend reads performed) - size: Current entry count - ttl: TTL in seconds</p> <p>Backends without caching should return zero-valued stats.</p> <p>Returns:</p> Type Description <code>CacheStats</code> <p>CacheStats object with cache metrics</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to zae-limiter!</p>"},{"location":"contributing/#quick-start","title":"Quick Start","text":"<pre><code>git clone https://github.com/zeroae/zae-limiter.git\ncd zae-limiter\nuv sync --all-extras\nuv tool install hatch  # Required for sync code generation\npytest\n</code></pre>"},{"location":"contributing/#development-guides","title":"Development Guides","text":"Guide Description Development Setup Environment setup, running tests, code quality LocalStack Local AWS development environment Testing Test organization, pytest fixtures, CI Architecture DynamoDB schema, token bucket algorithm"},{"location":"contributing/#detailed-reference","title":"Detailed Reference","text":"<p>For comprehensive development instructions including:</p> <ul> <li>Build commands and linting</li> <li>Commit message conventions</li> <li>Code review guidelines</li> <li>Release process</li> </ul> <p>See CLAUDE.md in the repository root.</p>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Create a feature branch from <code>main</code></li> <li>Make changes following project conventions</li> <li>Ensure CI passes (lint, type check, tests)</li> <li>Submit PR for review</li> </ol> <p>All changes must go through pull requests. Direct commits to <code>main</code> are not allowed.</p>"},{"location":"contributing/architecture/","title":"Architecture","text":"<p>This guide covers the internal architecture of zae-limiter, including the DynamoDB schema and token bucket implementation.</p>"},{"location":"contributing/architecture/#dynamodb-schema-single-table","title":"DynamoDB Schema (Single Table)","text":"<p>All data is stored in a single DynamoDB table using a composite key pattern:</p> Record Type PK SK Entity metadata <code>ENTITY#{id}</code> <code>#META</code> Bucket <code>ENTITY#{id}</code> <code>#BUCKET#{resource}#{limit_name}</code> Entity config <code>ENTITY#{id}</code> <code>#CONFIG#{resource}</code> Resource config <code>RESOURCE#{resource}</code> <code>#CONFIG</code> System config <code>SYSTEM#</code> <code>#CONFIG</code> Usage snapshot <code>ENTITY#{id}</code> <code>#USAGE#{resource}#{window_key}</code> System version <code>SYSTEM#</code> <code>#VERSION</code> Audit events <code>AUDIT#{entity_id}</code> <code>#AUDIT#{timestamp}</code>"},{"location":"contributing/architecture/#global-secondary-indexes","title":"Global Secondary Indexes","text":"Index Purpose Key Pattern GSI1 Parent \u2192 Children lookup <code>GSI1PK=PARENT#{id}</code> \u2192 <code>GSI1SK=CHILD#{id}</code> GSI2 Resource aggregation <code>GSI2PK=RESOURCE#{name}</code> \u2192 buckets/usage GSI3 Entity config queries (sparse) <code>GSI3PK=ENTITY_CONFIG#{resource}</code> \u2192 <code>GSI3SK=entity_id</code>"},{"location":"contributing/architecture/#access-patterns","title":"Access Patterns","text":"Pattern Query Get entity <code>PK=ENTITY#{id}, SK=#META</code> Get buckets <code>PK=ENTITY#{id}, SK begins_with #BUCKET#</code> Batch get buckets <code>BatchGetItem</code> with multiple PK/SK pairs Get children GSI1: <code>GSI1PK=PARENT#{id}</code> Resource capacity GSI2: <code>GSI2PK=RESOURCE#{name}, SK begins_with BUCKET#</code> Get version <code>PK=SYSTEM#, SK=#VERSION</code> Get audit events <code>PK=AUDIT#{entity_id}, SK begins_with #AUDIT#</code> Get usage snapshots <code>PK=ENTITY#{id}, SK begins_with #USAGE#</code> Get system config <code>PK=SYSTEM#, SK=#CONFIG</code> Get resource config <code>PK=RESOURCE#{resource}, SK=#CONFIG</code> Get entity config <code>PK=ENTITY#{id}, SK=#CONFIG#{resource}</code> List entities with custom limits GSI3: <code>GSI3PK=ENTITY_CONFIG#{resource}</code>"},{"location":"contributing/architecture/#optimized-read-patterns","title":"Optimized Read Patterns","text":"<p>The <code>acquire()</code> operation uses <code>BatchGetItem</code> to fetch all required buckets in a single DynamoDB round trip (see Issue #133):</p> <pre><code># Before: N sequential GetItem calls\nfor entity_id, resource, limit_name in bucket_keys:\n    bucket = await get_bucket(entity_id, resource, limit_name)\n\n# After: 1 BatchGetItem call\nbuckets = await batch_get_buckets(bucket_keys)\n</code></pre> <p>This optimization is particularly beneficial for cascade scenarios where both entity and parent buckets are fetched together, reducing latency from 2\u00d7N round trips to 1.</p>"},{"location":"contributing/architecture/#config-resolution-adr-122","title":"Config Resolution (ADR-122)","text":"<p>Config resolution uses the 4-level hierarchy: Entity (resource-specific) &gt; Entity (<code>_default_</code>) &gt; Resource &gt; System. This logic lives on <code>Repository.resolve_limits()</code>, not on <code>RateLimiter</code>. Each backend can use native resolution strategies (e.g., SQL <code>UNION ALL</code>, Redis Lua scripts). The DynamoDB implementation uses <code>BatchGetItem</code> for all 4 config keys in a single round trip, with <code>ConfigCache</code> as an internal caching layer (60s TTL by default).</p> <pre><code># Repository resolves limits internally (ADR-122)\nlimits, on_unavailable, config_source = await repo.resolve_limits(entity_id, resource)\n# config_source: \"entity\", \"entity_default\", \"resource\", \"system\", or None\n</code></pre> <p>Cache management methods (<code>invalidate_config_cache()</code>, <code>get_cache_stats()</code>) are on <code>Repository</code>, not <code>RateLimiter</code>. The <code>config_cache_ttl</code> parameter is on the <code>Repository</code> constructor.</p>"},{"location":"contributing/architecture/#item-structure","title":"Item Structure","text":"<p>All records use flat schema (v0.6.0+, top-level attributes, no nested <code>data.M</code>). See ADR-111.</p> <pre><code># Entity record (FLAT structure):\n{\n    \"PK\": \"ENTITY#user-1\",\n    \"SK\": \"#META\",\n    \"entity_id\": \"user-1\",\n    \"name\": \"User One\",\n    \"parent_id\": null,\n    \"metadata\": {...}\n}\n</code></pre> <p>Bucket records (composite, one item per entity+resource):</p> <pre><code># Bucket record (FLAT structure, ADR-114/115):\n{\n    \"PK\": \"ENTITY#user-1\",\n    \"SK\": \"#BUCKET#gpt-4\",\n    \"entity_id\": \"user-1\",\n    \"resource\": \"gpt-4\",\n    \"b_tpm_tk\": 9500000,            # tokens_milli for tpm limit\n    \"b_tpm_cp\": 10000000,           # capacity_milli for tpm limit\n    \"b_tpm_tc\": 500000,             # total_consumed_milli for tpm\n    \"b_rpm_tk\": 95000,              # tokens_milli for rpm limit\n    \"b_rpm_cp\": 100000,             # capacity_milli for rpm limit\n    \"b_rpm_tc\": 5000,               # total_consumed_milli for rpm\n    \"rf\": 1704067200000,            # last_refill_ms (shared across limits)\n    \"GSI2PK\": \"RESOURCE#gpt-4\",\n    \"ttl\": 1234567890\n}\n</code></pre> <p>The <code>total_consumed_milli</code> counter tracks net consumption (increases on consume, decreases on release) and is used by the aggregator Lambda to accurately calculate consumption deltas. This counter is independent of token bucket refill, solving the issue where <code>old_tokens - new_tokens</code> gives incorrect results when refill rate exceeds consumption rate. See Issue #179.</p> <p>Usage snapshots use a FLAT structure (no nested <code>data</code> map):</p> <pre><code># Usage snapshot (FLAT structure):\n{\n    \"PK\": \"ENTITY#user-1\",\n    \"SK\": \"#USAGE#gpt-4#2024-01-01T14:00:00Z\",\n    \"entity_id\": \"user-1\",\n    \"resource\": \"gpt-4\",        # Top-level attribute\n    \"window\": \"hourly\",         # Top-level attribute\n    \"window_start\": \"...\",      # Top-level attribute\n    \"tpm\": 5000,                # Counter at top-level\n    \"total_events\": 10,         # Counter at top-level\n    \"GSI2PK\": \"RESOURCE#gpt-4\",\n    \"ttl\": 1234567890\n}\n</code></pre> <p>Why snapshots are flat: DynamoDB has a limitation where you cannot SET a map path (<code>#data = if_not_exists(#data, :map)</code>) AND ADD to paths within it (<code>#data.counter</code>) in the same UpdateExpression - it fails with \"overlapping document paths\" error. Snapshots require atomic upsert (create-or-update) with ADD counters for usage aggregation, so they use a flat structure to enable single-call atomic updates.</p> <p>See: Issue #168</p> <p>Config records use composite items (v0.8.0+, ADR-114). All limits for a config level are stored in a single item:</p> <pre><code># Resource config (composite, FLAT structure):\n{\n    \"PK\": \"RESOURCE#gpt-4\",           # or SYSTEM# or ENTITY#{id}\n    \"SK\": \"#CONFIG\",                   # or #CONFIG#{resource} for entity level\n    \"resource\": \"gpt-4\",\n    \"l_tpm_cp\": 100000,               # capacity for tpm limit\n    \"l_tpm_bx\": 100000,               # burst for tpm limit\n    \"l_tpm_ra\": 100000,               # refill_amount for tpm limit\n    \"l_tpm_rp\": 60,                   # refill_period_seconds for tpm limit\n    \"config_version\": 1               # Atomic counter for cache invalidation\n}\n</code></pre> <p>Config records use four-level precedence: Entity (resource-specific) &gt; Entity (default) &gt; Resource &gt; System &gt; Constructor defaults.</p> <p>Key builders:</p> <ul> <li><code>pk_system()</code> - Returns <code>SYSTEM#</code></li> <li><code>pk_resource(resource)</code> - Returns <code>RESOURCE#{resource}</code></li> <li><code>pk_entity(entity_id)</code> - Returns <code>ENTITY#{entity_id}</code></li> <li><code>sk_config()</code> - Returns <code>#CONFIG</code> (system/resource level)</li> <li><code>sk_config(resource)</code> - Returns <code>#CONFIG#{resource}</code> (entity level)</li> </ul> <p>Audit entity IDs for config levels (see ADR-106):</p> <ul> <li>System config: Uses <code>$SYSTEM</code> as entity_id</li> <li>Resource config: Uses <code>$RESOURCE:{resource_name}</code> (e.g., <code>$RESOURCE:gpt-4</code>)</li> </ul>"},{"location":"contributing/architecture/#token-bucket-implementation","title":"Token Bucket Implementation","text":"<p>For a conceptual overview of the token bucket algorithm, see the User Guide. This section covers implementation details for contributors.</p>"},{"location":"contributing/architecture/#core-functions","title":"Core Functions","text":"<p>The algorithm is implemented in <code>bucket.py</code>:</p> Function Purpose <code>refill_bucket()</code> Calculate refilled tokens with drift compensation <code>try_consume()</code> Atomic check-and-consume operation <code>force_consume()</code> Force consume (can go negative) <code>calculate_retry_after()</code> Calculate wait time for deficit <code>calculate_available()</code> Calculate currently available tokens <code>build_limit_status()</code> Build a LimitStatus for a bucket check <code>would_refill_satisfy()</code> Check if refilling would allow a request to succeed (speculative writes)"},{"location":"contributing/architecture/#mathematical-formulas","title":"Mathematical Formulas","text":"<p>Refill calculation (lazy, on-demand):</p> <pre><code>tokens_to_add = (elapsed_ms \u00d7 refill_amount_milli) // refill_period_ms\n</code></pre> <p>Drift compensation (prevents accumulated rounding errors):</p> <pre><code>time_used_ms = (tokens_to_add \u00d7 refill_period_ms) // refill_amount_milli\nnew_last_refill = last_refill_ms + time_used_ms\n</code></pre> <p>The inverse calculation ensures we only \"consume\" the time that corresponds to whole tokens, preventing drift over many refill cycles.</p> <p>Retry-after calculation:</p> <pre><code>time_ms = (deficit_milli \u00d7 refill_period_ms) // refill_amount_milli\nretry_seconds = (time_ms + 1) / 1000.0  # +1ms rounds up\n</code></pre>"},{"location":"contributing/architecture/#integer-arithmetic-for-precision","title":"Integer Arithmetic for Precision","text":"<p>All token values are stored as millitokens (\u00d71000) to avoid floating-point precision issues in distributed systems:</p> <pre><code># User sees: 100 tokens/minute\n# Stored as: 100,000 millitokens/minute\ncapacity_milli = 100_000\n</code></pre> <p>Why integers matter in distributed systems:</p> <ul> <li>Floating-point operations can produce different results on different hardware</li> <li>DynamoDB stores numbers as strings, so precision loss can occur during serialization</li> <li>Rate limiting across multiple nodes requires identical calculations</li> </ul>"},{"location":"contributing/architecture/#refill-rate-storage","title":"Refill Rate Storage","text":"<p>Refill rates are stored as a fraction (amount/period) rather than a decimal:</p> <pre><code># 100 tokens per minute stored as:\nrefill_amount_milli = 100_000  # millitokens (numerator)\nrefill_period_ms = 60_000      # milliseconds (denominator)\n</code></pre> <p>This avoids representing <code>1.6667 tokens/second</code> as a float. Instead:</p> <pre><code># 100 tokens/minute = 100,000 millitokens / 60,000 ms\n# Integer division handles the math precisely\n</code></pre>"},{"location":"contributing/architecture/#lazy-refill-with-drift-compensation","title":"Lazy Refill with Drift Compensation","text":"<p>Tokens are calculated on-demand rather than via a background timer. The <code>refill_bucket()</code> function:</p> <ol> <li>Calculates elapsed time since last refill</li> <li>Computes tokens to add using integer division</li> <li>Tracks \"time consumed\" to prevent drift</li> </ol> <pre><code># From bucket.py:refill_bucket()\ntokens_to_add = (elapsed_ms * refill_amount_milli) // refill_period_ms\n\n# Drift compensation: only advance time for tokens actually added\ntime_used_ms = (tokens_to_add * refill_period_ms) // refill_amount_milli\nnew_last_refill = last_refill_ms + time_used_ms\n</code></pre> <p>Without drift compensation, repeated calls with small time intervals would accumulate rounding errors.</p>"},{"location":"contributing/architecture/#negative-buckets-debt","title":"Negative Buckets (Debt)","text":"<p>Buckets can go negative to support post-hoc reconciliation:</p> <pre><code># Estimate 500 tokens, actually used 2000\nasync with limiter.acquire(consume={\"tpm\": 500}) as lease:\n    actual = await call_llm()  # Returns 2000 tokens\n    await lease.adjust(tpm=2000 - 500)  # Bucket at -1500\n</code></pre> <p>The <code>force_consume()</code> function handles this:</p> <pre><code># From bucket.py:force_consume()\n# Consume can go negative - no bounds checking\nnew_tokens_milli = refill.new_tokens_milli - (amount * 1000)\n</code></pre> <p>The debt is repaid as tokens refill over time. A bucket at -1500 millitokens needs 1.5 minutes to reach 0 (at 1000 tokens/minute).</p>"},{"location":"contributing/architecture/#burst-capacity","title":"Burst Capacity","text":"<p>Burst allows temporary exceeding of sustained rate:</p> <pre><code># Sustained: 10k tokens/minute\n# Burst: 15k tokens (one-time)\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n</code></pre> <p>When <code>burst &gt; capacity</code>, users can consume up to <code>burst</code> tokens immediately, then sustain at <code>capacity</code> rate.</p>"},{"location":"contributing/architecture/#design-decisions","title":"Design Decisions","text":"Decision Rationale Integer over float Identical results across distributed nodes; no precision drift Lazy over continuous No background timers; accurate retry_after; efficient Negative allowed Estimate-then-reconcile pattern; operations with unknown cost Fraction over decimal Exact representation of rates like 100/minute"},{"location":"contributing/architecture/#atomicity-and-write-paths","title":"Atomicity and Write Paths","text":""},{"location":"contributing/architecture/#write-path-overview","title":"Write Path Overview","text":"<p>The <code>acquire()</code> context manager uses three distinct write paths, each with different atomicity and cost characteristics:</p> Write Path Method API Used WCU Cost Atomicity Initial consumption <code>_commit_initial()</code> <code>transact_write()</code> 2 WCU (transaction) or 1 WCU (single item) Cross-item atomic Post-enter adjustments <code>_commit_adjustments()</code> <code>write_each()</code> 1 WCU per item Independent per item Rollback (on exception) <code>_rollback()</code> <code>write_each()</code> 1 WCU per item Independent per item Aggregator refill <code>try_refill_bucket()</code> <code>UpdateItem</code> 1 WCU Single item"},{"location":"contributing/architecture/#transactwriteitems-initial-consumption","title":"TransactWriteItems (Initial Consumption)","text":"<p>The initial consumption write (<code>_commit_initial()</code>) uses <code>transact_write()</code>, which selects the DynamoDB API based on item count:</p> <ul> <li>Single item: Uses PutItem/UpdateItem (1 WCU) -- non-cascade case</li> <li>Multiple items: Uses TransactWriteItems (2 WCU per item) -- cascade case</li> </ul> <pre><code># Cascade: atomic multi-entity write\n# 1. Consume from child entity bucket\n# 2. Consume from parent entity bucket\n# Both succeed or both fail\n</code></pre> <p>Transaction limits: max 100 items per transaction.</p>"},{"location":"contributing/architecture/#independent-writes-adjustments-and-rollbacks","title":"Independent Writes (Adjustments and Rollbacks)","text":"<p>Adjustments (<code>_commit_adjustments()</code>) and rollbacks (<code>_rollback()</code>) use <code>write_each()</code>, which dispatches each item independently as a single PutItem, UpdateItem, or DeleteItem call (1 WCU each). This is safe because:</p> <ul> <li>These operations produce unconditional ADD expressions (no condition checks)</li> <li>Partial success is acceptable -- each item's delta is self-contained</li> <li>No cross-item invariant needs to hold between adjustment writes</li> </ul> <pre><code># write_each: each item written independently\n# Item 1: ADD child bucket delta    (1 WCU)\n# Item 2: ADD parent bucket delta   (1 WCU)\n# No transaction overhead\n</code></pre> <p>This halves the WCU cost compared to using TransactWriteItems for these paths.</p>"},{"location":"contributing/architecture/#speculative-write-path-issue-315","title":"Speculative Write Path (Issue #315)","text":"<p>When <code>speculative_writes=True</code>, <code>acquire()</code> adds a fast path before the normal read-write flow:</p> Write Path Method API Used WCU Cost Atomicity Speculative consumption <code>speculative_consume()</code> Conditional <code>UpdateItem</code> 1 WCU (success) or 0 WCU (reject) Single item Speculative compensation <code>_compensate_speculative()</code> via <code>write_each()</code> <code>UpdateItem</code> 1 WCU Single item Parallel speculative (issue #318) <code>speculative_consume()</code> via <code>asyncio.gather</code> 2x <code>UpdateItem</code> 2 WCU Independent items Parent-only slow path <code>_try_parent_only_acquire()</code> via <code>_commit_initial()</code> <code>UpdateItem</code> 1 WCU Single item <p>The speculative path uses <code>ReturnValuesOnConditionCheckFailure=ALL_OLD</code> to inspect bucket state on failure without a separate read. On success, <code>ReturnValues=ALL_NEW</code> provides the post-write state including denormalized <code>cascade</code> and <code>parent_id</code> fields.</p> <pre><code>Speculative flow (first acquire \u2014 sequential, populates entity cache):\n1. UpdateItem with condition: attribute_exists(PK) AND tk &gt;= consumed\n   +- SUCCESS -&gt; Populate entity cache, Lease is pre-committed\n   |  +- cascade=False -&gt; DONE\n   |  +- cascade=True -&gt; Speculative UpdateItem on parent (sequential)\n   |     +- SUCCESS -&gt; DONE (child + parent both speculative)\n   |     +- FAIL -&gt; [parent failure handling]\n   +- FAIL -&gt; Check ALL_OLD\n      +- No item (bucket missing) -&gt; Fall back to normal path\n      +- Refill would help -&gt; Fall back to normal path\n      +- Refill won't help -&gt; RateLimitExceeded (fast rejection)\n\nSpeculative flow (subsequent acquire \u2014 parallel, issue #318):\n1. Entity cache hit: cascade=True, parent_id known\n2. asyncio.gather(child_speculative, parent_speculative)\n   +- BOTH SUCCEED -&gt; DONE (1 round trip, 0 RCU, 2 WCU)\n   +- CHILD FAILS, PARENT SUCCEEDS -&gt; Compensate parent, check child\n   +- CHILD SUCCEEDS, PARENT FAILS -&gt; [parent failure handling]\n   +- BOTH FAIL -&gt; Check child ALL_OLD, fall back or fast-reject\n\nParent failure handling (shared by sequential and parallel paths):\n   +- No ALL_OLD / missing limit -&gt; Compensate child, fall back\n   +- Refill won't help -&gt; Compensate child, RateLimitExceeded\n   +- Refill would help -&gt; Parent-only slow path (read + write parent)\n      +- SUCCESS -&gt; DONE (child speculative + parent slow path)\n      +- FAIL -&gt; Compensate child, fall back to full slow path\n</code></pre> <p>Cascade and <code>parent_id</code> are denormalized into composite bucket items (via <code>build_composite_create</code>) so the speculative path avoids a separate entity metadata lookup.</p> <p>Deferred cascade compensation: When the child speculative write succeeds but the parent fails, child compensation is deferred. If refill would help the parent, a parent-only slow path is attempted: read parent buckets (0.5 RCU), refill + try_consume, write via single-item UpdateItem (1 WCU). This avoids the cost of compensating the child (1 WCU), re-reading it (0.5 RCU), and using TransactWriteItems for the full cascade write (4 WCU). The child is only compensated when the parent-only path also fails.</p> <p>Entity metadata cache (issue #318): <code>Repository._entity_cache</code> stores <code>{entity_id: (cascade, parent_id)}</code> as immutable metadata (no TTL). After the first acquire populates the cache, <code>speculative_consume()</code> issues child and parent speculative writes concurrently via <code>asyncio.gather</code>. This reduces cascade latency from 2 sequential round trips to 1 parallel round trip. In the sync codepath, <code>asyncio.gather(a, b)</code> is transformed to <code>self._run_in_executor(lambda: a, lambda: b)</code> using a lazy <code>ThreadPoolExecutor(max_workers=2)</code> for true parallel execution. The <code>_compensate_speculative()</code> method handles compensation for either child or parent when one side of the parallel write fails.</p>"},{"location":"contributing/architecture/#aggregator-refill-path-issue-317","title":"Aggregator Refill Path (Issue #317)","text":"<p>The Lambda aggregator proactively refills token buckets for active entities, keeping speculative writes on the fast path (1 RT) instead of falling back to the slow path (3 RT).</p> Write Path Method API Used WCU Cost Atomicity Aggregator refill <code>try_refill_bucket()</code> Conditional <code>UpdateItem</code> 1 WCU (success) or 0 WCU (lock lost) Single item <p>The aggregator processes DynamoDB Stream records in each batch to:</p> <ol> <li>Aggregate bucket states -- <code>aggregate_bucket_states()</code> accumulates <code>tc</code> deltas and keeps    the last NewImage per (entity_id, resource) across all stream records in the batch</li> <li>Compute refill -- For each bucket, <code>try_refill_bucket()</code> calls <code>refill_bucket()</code> to    calculate the refill delta, then checks if projected tokens are insufficient to cover    the observed consumption rate</li> <li>Write refill -- Issues a single <code>UpdateItem</code> with <code>ADD b_{limit}_tk +refill_delta</code>    and <code>SET rf = :now</code>, conditioned on <code>rf = :expected_rf</code> (optimistic lock)</li> </ol> <pre><code>Aggregator refill flow (per composite bucket):\n1. Aggregate tc deltas + last NewImage across stream batch\n2. For each limit: refill_bucket(tk, rf, now, bx, ra, rp)\n   +- refill_delta = new_tk - current_tk\n   +- projected = new_tk after refill\n   +- consumption_estimate = max(0, accumulated tc_delta)\n   +- projected &gt;= consumption_estimate -&gt; SKIP (sufficient tokens)\n3. Any limit needs refill?\n   +- NO -&gt; SKIP\n   +- YES -&gt; UpdateItem (ADD tk +delta, SET rf = :now, condition rf = :expected_rf)\n      +- SUCCESS -&gt; refill written (1 WCU)\n      +- ConditionalCheckFailedException -&gt; silently skip (another writer updated rf)\n</code></pre> <p>Key design properties:</p> <ul> <li>ADD is commutative with concurrent speculative writes -- the aggregator uses <code>ADD</code>   for token deltas, so a concurrent <code>speculative_consume()</code> (also <code>ADD</code>) does not conflict</li> <li>Optimistic lock on <code>rf</code> prevents double-refill with the client slow path or another   aggregator invocation</li> <li>No read required -- all state is derived from stream record NewImage fields</li> </ul>"},{"location":"contributing/architecture/#optimistic-locking","title":"Optimistic Locking","text":"<p>Entity metadata uses version numbers for optimistic locking:</p> <pre><code># Read entity with version 5\n# Update fails if version changed\ncondition_expression=\"version = :expected_version\"\n</code></pre>"},{"location":"contributing/architecture/#project-structure","title":"Project Structure","text":"<pre><code>src/zae_limiter/\n\u251c\u2500\u2500 __init__.py            # Public API exports\n\u251c\u2500\u2500 models.py              # Limit, Entity, LimitStatus, BucketState, StackOptions, ...\n\u251c\u2500\u2500 exceptions.py          # RateLimitExceeded, RateLimiterUnavailable, etc.\n\u251c\u2500\u2500 naming.py              # Resource name validation\n\u251c\u2500\u2500 bucket.py              # Token bucket math (integer arithmetic)\n\u251c\u2500\u2500 schema.py              # DynamoDB key builders\n\u251c\u2500\u2500 repository_protocol.py # RepositoryProtocol for backend abstraction\n\u251c\u2500\u2500 repository.py          # DynamoDB operations\n\u251c\u2500\u2500 config_cache.py        # Client-side config caching with TTL\n\u251c\u2500\u2500 lease.py               # Lease context manager\n\u251c\u2500\u2500 limiter.py             # RateLimiter, SyncRateLimiter\n\u251c\u2500\u2500 local.py               # LocalStack management commands\n\u251c\u2500\u2500 cli.py                 # CLI commands (deploy, delete, status, list, local, ...)\n\u251c\u2500\u2500 version.py             # Version tracking and compatibility\n\u251c\u2500\u2500 migrations/            # Schema migration framework\n\u251c\u2500\u2500 visualization/         # Usage snapshot formatting and display\n\u2514\u2500\u2500 infra/\n    \u251c\u2500\u2500 stack_manager.py    # CloudFormation stack operations\n    \u251c\u2500\u2500 lambda_builder.py   # Lambda deployment package builder\n    \u251c\u2500\u2500 discovery.py        # Multi-stack discovery and listing\n    \u2514\u2500\u2500 cfn_template.yaml   # CloudFormation template\n\nsrc/zae_limiter_aggregator/   # Lambda aggregator (top-level package)\n\u251c\u2500\u2500 __init__.py               # Re-exports handler, processor types\n\u251c\u2500\u2500 handler.py                # Lambda entry point (returns refills_written count)\n\u251c\u2500\u2500 processor.py              # Stream processing: usage snapshots + bucket refill\n\u2514\u2500\u2500 archiver.py               # S3 audit archival (gzip JSONL)\n</code></pre>"},{"location":"contributing/architecture/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Write-on-enter: <code>acquire()</code> writes initial consumption to DynamoDB before yielding the lease, making tokens immediately visible to concurrent callers. On exception, a compensating write restores the consumed tokens</li> <li>Bucket can go negative: <code>lease.adjust()</code> never throws, allows debt</li> <li>Cascade is per-entity config: Set <code>cascade=True</code> on <code>create_entity()</code> to auto-cascade to parent on every <code>acquire()</code></li> <li>Stored limits are the default (v0.5.0+): Limits resolved from System/Resource/Entity config automatically. Pass <code>limits</code> parameter to override</li> <li>Initial writes are atomic: Multi-entity initial consumption uses <code>transact_write()</code> for cross-item atomicity</li> <li>Adjustments and rollbacks use independent writes: <code>write_each()</code> dispatches each item as a single-item API call (1 WCU each), avoiding transaction overhead for unconditional ADD operations</li> <li>Speculative writes skip reads: With <code>speculative_writes=True</code>, <code>acquire()</code> tries a conditional UpdateItem first, saving 1 round trip and 1 RCU when the bucket has sufficient tokens</li> <li>Entity metadata cache enables parallel cascade: <code>Repository._entity_cache</code> stores immutable <code>(cascade, parent_id)</code> per entity. After first acquire, cascade speculative writes run concurrently via <code>asyncio.gather</code></li> <li>Aggregator-assisted refill: The Lambda aggregator proactively refills buckets for active entities, keeping speculative writes on the fast path by ensuring buckets have sufficient tokens between client requests</li> </ol>"},{"location":"contributing/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup - Setting up your environment</li> <li>Testing - Test organization and fixtures</li> </ul>"},{"location":"contributing/development/","title":"Development Setup","text":"<p>This guide covers setting up a local development environment for zae-limiter.</p>"},{"location":"contributing/development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or 3.12</li> <li>uv (recommended) or conda</li> <li>Docker (for LocalStack integration tests)</li> </ul>"},{"location":"contributing/development/#setup","title":"Setup","text":""},{"location":"contributing/development/#using-uv-recommended","title":"Using uv (Recommended)","text":"<pre><code>git clone --recurse-submodules https://github.com/zeroae/zae-limiter.git\ncd zae-limiter\nuv sync --all-extras\nuv tool install hatch  # Required for sync code generation\n</code></pre>"},{"location":"contributing/development/#using-conda","title":"Using conda","text":"<pre><code>git clone --recurse-submodules https://github.com/zeroae/zae-limiter.git\ncd zae-limiter\nconda create -n zae-limiter python=3.12\nconda activate zae-limiter\npip install -e \".[dev]\"\npip install hatch  # Required for sync code generation\n</code></pre> <p>Already cloned?</p> <p>If you cloned without <code>--recurse-submodules</code>, run: <pre><code>git submodule update --init --recursive\n</code></pre></p>"},{"location":"contributing/development/#running-tests","title":"Running Tests","text":"<pre><code># Run all unit tests\npytest tests/unit/ -v\n\n# Run with coverage\npytest --cov=zae_limiter --cov-report=html\n\n# Run specific test file\npytest tests/unit/test_limiter.py -v\n</code></pre> <p>For integration tests with LocalStack, see the Testing Guide.</p>"},{"location":"contributing/development/#code-quality","title":"Code Quality","text":"<pre><code># Format code\nruff format .\n\n# Lint and auto-fix\nruff check --fix .\n\n# Type checking\nmypy src/zae_limiter\n</code></pre>"},{"location":"contributing/development/#commit-messages","title":"Commit Messages","text":"<p>Follow the ZeroAE commit conventions:</p> <pre><code># Examples\nfeat(limiter): add hierarchical rate limiting support\nfix(bucket): prevent integer overflow in refill calculation\ndocs(readme): add CloudFormation deployment guide\nrefactor(schema): simplify DynamoDB key structure\n</code></pre> <p>Project scopes: <code>limiter</code>, <code>bucket</code>, <code>cli</code>, <code>infra</code>, <code>ci</code>, <code>aggregator</code>, <code>models</code>, <code>schema</code>, <code>repository</code>, <code>lease</code>, <code>exceptions</code>, <code>test</code>, <code>benchmark</code></p>"},{"location":"contributing/development/#documentation","title":"Documentation","text":"<p>To preview documentation locally:</p> <pre><code>uv run mkdocs serve --livereload --dirty\n</code></pre> <p>Then open http://localhost:8000/zae-limiter/ in your browser.</p> <p>Live reload requires <code>--livereload</code></p> <p>Due to a known issue with Click 8.3.x, the <code>--livereload</code> flag must be explicitly passed for automatic browser refresh to work.</p>"},{"location":"contributing/development/#next-steps","title":"Next Steps","text":"<ul> <li>LocalStack - Local AWS development</li> <li>Testing - Test organization and fixtures</li> <li>Architecture - DynamoDB schema and design decisions</li> </ul>"},{"location":"contributing/localstack/","title":"LocalStack Development","text":"<p>LocalStack provides a local AWS environment for development and testing. This guide covers setting up zae-limiter with LocalStack.</p>"},{"location":"contributing/localstack/#why-localstack","title":"Why LocalStack?","text":"<ul> <li>Free - No AWS costs during development</li> <li>Fast - No network latency</li> <li>Isolated - No risk to production data</li> <li>Full stack - DynamoDB, Lambda, Streams, CloudFormation</li> </ul>"},{"location":"contributing/localstack/#quick-start","title":"Quick Start","text":""},{"location":"contributing/localstack/#1-start-localstack","title":"1. Start LocalStack","text":"CLI (Preferred)Docker ComposeDocker <p>The <code>zae-limiter local</code> commands are the source of truth for LocalStack container configuration:</p> <pre><code># Start LocalStack\nzae-limiter local up\n\n# Start and show deploy instructions\nzae-limiter local up --name my-app\n\n# Check status\nzae-limiter local status\n\n# View logs\nzae-limiter local logs --follow\n\n# Stop\nzae-limiter local down\n</code></pre> <p>See CLI Reference for full options.</p> <p>The project includes a pre-configured <code>docker-compose.yml</code> at the repository root:</p> <pre><code># From the project root\ndocker compose up -d\n</code></pre> <pre><code>docker run -d \\\n  --name zae-limiter-localstack \\\n  -p 4566:4566 \\\n  -e SERVICES=dynamodb,dynamodbstreams,lambda,cloudformation,logs,iam,cloudwatch,sqs,s3,sts,resourcegroupstaggingapi \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v \"${TMPDIR:-/tmp}/localstack:/var/lib/localstack\" \\\n  localstack/localstack:4\n</code></pre> <p>Docker Socket Required</p> <p>The Docker socket mount (<code>-v /var/run/docker.sock:/var/run/docker.sock</code>) is required for LocalStack to spawn Lambda functions as Docker containers.</p>"},{"location":"contributing/localstack/#2-deploy-infrastructure","title":"2. Deploy Infrastructure","text":"<pre><code>zae-limiter deploy \\\n    --name limiter \\\n    --endpoint-url http://localhost:4566 \\\n    --region us-east-1\n</code></pre>"},{"location":"contributing/localstack/#3-use-in-code","title":"3. Use in Code","text":"<pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(\n    name=\"limiter\",\n    endpoint_url=\"http://localhost:4566\",\n    region=\"us-east-1\",\n)\n\nasync with limiter.acquire(\n    entity_id=\"test-user\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"requests\", 100)],\n    consume={\"requests\": 1},\n) as lease:\n    print(\"Rate limited request!\")\n</code></pre>"},{"location":"contributing/localstack/#declarative-infrastructure","title":"Declarative Infrastructure","text":"<p>For quick iteration, declare infrastructure in code:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",\n    endpoint_url=\"http://localhost:4566\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Declare desired state\n)\n</code></pre>"},{"location":"contributing/localstack/#environment-variables","title":"Environment Variables","text":"<p>Configure via environment variables for easy switching:</p> <pre><code># .env.local\nAWS_ENDPOINT_URL=http://localhost:4566\nAWS_ACCESS_KEY_ID=test\nAWS_SECRET_ACCESS_KEY=test\nAWS_DEFAULT_REGION=us-east-1\n</code></pre> <pre><code>import os\n\nlimiter = RateLimiter(\n    name=\"limiter\",\n    endpoint_url=os.getenv(\"AWS_ENDPOINT_URL\"),\n    region=os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\"),\n)\n</code></pre>"},{"location":"contributing/localstack/#debugging","title":"Debugging","text":""},{"location":"contributing/localstack/#check-stack-status","title":"Check Stack Status","text":"<pre><code># List stacks\naws --endpoint-url=http://localhost:4566 cloudformation list-stacks\n\n# Describe stack\naws --endpoint-url=http://localhost:4566 cloudformation describe-stacks \\\n    --stack-name limiter\n</code></pre>"},{"location":"contributing/localstack/#inspect-dynamodb","title":"Inspect DynamoDB","text":"<pre><code># List tables\naws --endpoint-url=http://localhost:4566 dynamodb list-tables\n\n# Scan table\naws --endpoint-url=http://localhost:4566 dynamodb scan \\\n    --table-name limiter\n</code></pre>"},{"location":"contributing/localstack/#view-lambda-logs","title":"View Lambda Logs","text":"<pre><code># List functions\naws --endpoint-url=http://localhost:4566 lambda list-functions\n\n# Get logs (replace {name} with your stack name)\naws --endpoint-url=http://localhost:4566 logs tail \\\n    /aws/lambda/{name}-aggregator\n</code></pre>"},{"location":"contributing/localstack/#localstack-vs-dynamodb-local","title":"LocalStack vs DynamoDB Local","text":"Feature LocalStack DynamoDB Local DynamoDB Yes Yes Streams Yes Limited Lambda Yes No CloudFormation Yes No Cost Free Free Fidelity High Medium <p>Recommendation: Use LocalStack for full integration testing, DynamoDB Local for quick unit tests.</p>"},{"location":"contributing/localstack/#troubleshooting","title":"Troubleshooting","text":""},{"location":"contributing/localstack/#connection-refused","title":"Connection Refused","text":"<pre><code>Cannot connect to http://localhost:4566\n</code></pre> <p>Solution: Ensure LocalStack is running:</p> <pre><code>docker ps | grep localstack\n# or\ncurl http://localhost:4566/_localstack/health\n</code></pre>"},{"location":"contributing/localstack/#lambda-not-executing","title":"Lambda Not Executing","text":"<p>Check Lambda logs:</p> <pre><code>docker logs zae-limiter-localstack 2&gt;&amp;1 | grep -i lambda\n</code></pre> <p>Ensure the Lambda service is enabled:</p> <pre><code>docker run -e SERVICES=dynamodb,dynamodbstreams,lambda,cloudformation,logs,iam,cloudwatch,sqs,s3,sts,resourcegroupstaggingapi ...\n</code></pre>"},{"location":"contributing/localstack/#slow-performance","title":"Slow Performance","text":"<p>LocalStack can be slow on first request. Consider:</p> <ul> <li>Pre-warming containers</li> <li>Using persistence for faster restarts</li> <li>Reducing DEBUG level</li> </ul>"},{"location":"contributing/localstack/#next-steps","title":"Next Steps","text":"<ul> <li>Testing - pytest fixtures and CI configuration</li> <li>Development Setup - Local development environment</li> </ul>"},{"location":"contributing/testing/","title":"Testing","text":"<p>This guide covers test organization, pytest fixtures, and CI configuration for zae-limiter.</p>"},{"location":"contributing/testing/#test-organization","title":"Test Organization","text":"<p>Tests are organized by execution environment and scope:</p> <pre><code>tests/\n\u251c\u2500\u2500 conftest.py                  # Shared config (--run-aws flag)\n\u251c\u2500\u2500 unit/                        # Fast tests with mocked AWS (moto)\n\u2502   \u251c\u2500\u2500 test_limiter.py\n\u2502   \u251c\u2500\u2500 test_repository.py\n\u2502   \u2514\u2500\u2500 test_sync_limiter.py\n\u251c\u2500\u2500 integration/                 # LocalStack tests (repository-level)\n\u2502   \u2514\u2500\u2500 test_repository.py\n\u251c\u2500\u2500 e2e/                         # Full workflow tests (LocalStack + AWS)\n\u2502   \u251c\u2500\u2500 test_localstack.py\n\u2502   \u2514\u2500\u2500 test_aws.py\n\u251c\u2500\u2500 doctest/                     # Documentation code example tests\n\u2502   \u251c\u2500\u2500 conftest.py              # Ruff config, moto fixtures, skip tags\n\u2502   \u251c\u2500\u2500 test_docs_lint.py        # Lint all Python blocks with ruff\n\u2502   \u251c\u2500\u2500 test_docs_run.py         # Execute blocks against moto\n\u2502   \u2514\u2500\u2500 test_docs_integration.py # Execute blocks against LocalStack\n\u2514\u2500\u2500 benchmark/                   # Performance benchmarks (pytest-benchmark)\n    \u251c\u2500\u2500 test_operations.py       # Mocked benchmarks\n    \u2514\u2500\u2500 test_localstack.py       # LocalStack benchmarks\n</code></pre>"},{"location":"contributing/testing/#test-categories","title":"Test Categories","text":"Category Directory Backend What to Test Speed Unit <code>tests/unit/</code> moto (mocked) Business logic, bucket math, schema, exceptions Fast (~seconds) Integration <code>tests/integration/</code> LocalStack Repository operations, transactions, GSI queries Medium E2E <code>tests/e2e/</code> LocalStack or AWS Full workflows: CLI, rate limiting, hierarchical limits Slow Doctest <code>tests/doctest/</code> ruff / moto / LocalStack Documentation code examples are valid and runnable Fast Benchmark <code>tests/benchmark/</code> moto or LocalStack Latency (p50/p95/p99), throughput, cascade overhead Variable"},{"location":"contributing/testing/#pytest-markers","title":"Pytest Markers","text":"Marker Description How to Run (none) Unit tests <code>pytest tests/unit/</code> <code>@pytest.mark.integration</code> Requires LocalStack <code>pytest -m integration</code> <code>@pytest.mark.e2e</code> End-to-end workflows <code>pytest -m e2e</code> <code>@pytest.mark.aws</code> Real AWS (requires <code>--run-aws</code>) <code>pytest -m aws --run-aws</code> <code>@pytest.mark.benchmark</code> Performance benchmarks <code>pytest -m benchmark</code> <code>@pytest.mark.doctest</code> Documentation code examples <code>pytest tests/doctest/</code> <code>@pytest.mark.slow</code> Tests with &gt;30s waits Skip with <code>-m \"not slow\"</code>"},{"location":"contributing/testing/#pytest-fixtures","title":"pytest Fixtures","text":""},{"location":"contributing/testing/#localstack-endpoint-fixture","title":"LocalStack Endpoint Fixture","text":"<pre><code>import os\nimport pytest\n\n@pytest.fixture\ndef localstack_endpoint():\n    \"\"\"Get LocalStack endpoint from environment.\"\"\"\n    return os.getenv(\"AWS_ENDPOINT_URL\", \"http://localhost:4566\")\n</code></pre>"},{"location":"contributing/testing/#function-scoped-limiter-isolated","title":"Function-Scoped Limiter (Isolated)","text":"<pre><code>import uuid\nimport pytest\nfrom zae_limiter import Repository, RateLimiter, StackOptions\n\n@pytest.fixture(scope=\"function\")\nasync def limiter(localstack_endpoint):\n    \"\"\"\n    Create a rate limiter connected to LocalStack with automatic cleanup.\n\n    This fixture:\n    1. Creates a unique stack for test isolation\n    2. Yields the limiter for test use\n    3. Deletes the stack in teardown\n    \"\"\"\n    # Unique name prevents test interference\n    name = f\"test-{uuid.uuid4().hex[:8]}\"\n\n    repo = Repository(\n        name=name,\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n    limiter = RateLimiter(repository=repo)\n\n    async with limiter:\n        yield limiter\n\n    # Cleanup: delete the CloudFormation stack\n    await repo.delete_stack()\n\n\n@pytest.mark.integration\nasync def test_rate_limiting(limiter):\n    async with limiter.acquire(\n        entity_id=\"test-user\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"requests\", 10)],\n        consume={\"requests\": 1},\n    ):\n        pass  # Success\n</code></pre>"},{"location":"contributing/testing/#session-scoped-limiter-faster","title":"Session-Scoped Limiter (Faster)","text":"<p>For test suites where stack creation overhead is significant:</p> <pre><code>@pytest.fixture(scope=\"session\")\nasync def shared_limiter(localstack_endpoint):\n    \"\"\"\n    Session-scoped limiter for faster test execution.\n\n    Trade-off: Tests share state, less isolation.\n    \"\"\"\n    repo = Repository(\n        name=\"integration-test-shared\",\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n    limiter = RateLimiter(repository=repo)\n\n    async with limiter:\n        yield limiter\n\n    await repo.delete_stack()\n</code></pre>"},{"location":"contributing/testing/#sync-fixture-example","title":"Sync Fixture Example","text":"<pre><code>@pytest.fixture(scope=\"function\")\ndef sync_limiter(localstack_endpoint):\n    \"\"\"Synchronous rate limiter with cleanup.\"\"\"\n    from zae_limiter import SyncRepository, SyncRateLimiter, StackOptions\n    import uuid\n\n    name = f\"test-sync-{uuid.uuid4().hex[:8]}\"\n\n    repo = SyncRepository(\n        name=name,\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n    limiter = SyncRateLimiter(repository=repo)\n\n    with limiter:\n        yield limiter\n\n    repo.delete_stack()\n</code></pre>"},{"location":"contributing/testing/#documentation-code-examples","title":"Documentation Code Examples","text":"<p>All Python code blocks in <code>docs/</code> are automatically tested using pytest-examples. Three test passes validate documentation quality:</p> Pass File What it checks Lint <code>test_docs_lint.py</code> All blocks pass ruff linting Run (moto) <code>test_docs_run.py</code> Runnable blocks execute against moto Integration <code>test_docs_integration.py</code> LocalStack-tagged blocks execute against LocalStack"},{"location":"contributing/testing/#running-doc-tests","title":"Running Doc Tests","text":"<pre><code># Lint all Python code blocks\nuv run pytest tests/doctest/test_docs_lint.py -v -p no:xdist -o \"addopts=\"\n\n# Run executable blocks against moto\nuv run pytest tests/doctest/test_docs_run.py -v -p no:xdist -o \"addopts=\"\n\n# Run LocalStack blocks (requires LocalStack running)\nuv run pytest tests/doctest/test_docs_integration.py -v -m integration -p no:xdist -o \"addopts=\"\n</code></pre>"},{"location":"contributing/testing/#code-fence-tags","title":"Code Fence Tags","text":"<p>Use tags to classify code blocks that can't run in the default (moto) environment:</p> Tag Effect When to use (none) Lint + run with moto Default for most blocks <code>{.python .lint-only}</code> Lint only, skip execution Fragments, pseudo-code, undefined helpers <code>{.python .requires-external}</code> Skip lint + execution Needs packages not in project deps <code>{.python .requires-localstack}</code> Run with LocalStack only Needs real CloudFormation/Lambda <p>The <code>{.python .tag}</code> syntax is compatible with MkDocs Material \u2014 the extra classes are silently ignored during rendering.</p>"},{"location":"contributing/testing/#adding-new-code-blocks","title":"Adding New Code Blocks","text":"<p>When adding Python code blocks to documentation:</p> <ol> <li>Write the block as standard <code>```python</code></li> <li>Run <code>uv run pytest tests/doctest/ -v -p no:xdist -o \"addopts=\"</code> to check</li> <li>If the block can't run standalone (uses undefined variables, bare <code>await</code>, etc.), change the fence to <code>```{.python .lint-only}</code></li> <li>If the block needs external packages, use <code>```{.python .requires-external}</code></li> </ol>"},{"location":"contributing/testing/#running-tests","title":"Running Tests","text":""},{"location":"contributing/testing/#unit-tests-only-no-docker","title":"Unit Tests Only (No Docker)","text":"<pre><code>pytest tests/unit/ -v\n</code></pre>"},{"location":"contributing/testing/#integration-tests-requires-localstack","title":"Integration Tests (Requires LocalStack)","text":"<pre><code># Start LocalStack\ndocker compose up -d\n\n# Set environment variables\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\n\n# Run integration tests\npytest tests/integration/ -v\n\n# Stop LocalStack\ndocker compose down\n</code></pre>"},{"location":"contributing/testing/#e2e-tests","title":"E2E Tests","text":"<pre><code># LocalStack E2E\npytest tests/e2e/test_localstack.py -v\n\n# Real AWS E2E (costs money!)\npytest tests/e2e/test_aws.py --run-aws -v\n</code></pre>"},{"location":"contributing/testing/#benchmarks","title":"Benchmarks","text":"<p>Performance benchmarks measure operation latency, throughput, and DynamoDB capacity. Benchmarks are essential for detecting performance regressions when optimizing operations like config caching and cascade resolution.</p> <p>Quick Start:</p> <pre><code># Mocked benchmarks (fast - no Docker needed)\nuv run pytest tests/benchmark/test_operations.py -v\n\n# LocalStack benchmarks (realistic latency - requires Docker)\ndocker compose up -d\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\nuv run pytest tests/benchmark/test_localstack.py -v\ndocker compose down\n\n# Export results to JSON for comparison\nuv run pytest tests/benchmark/ -v --benchmark-json=benchmark.json\n</code></pre> <p>Benchmark Categories:</p> Test File Backend Purpose Speed <code>test_operations.py</code> moto (mocked) Fast iteration, baseline measurements &lt; 10s <code>test_localstack.py</code> DynamoDB emulation Realistic network latency, real-world metrics 30-60s <code>test_latency.py</code> moto p50/p95/p99 latency breakdown &lt; 10s <code>test_throughput.py</code> moto Sequential/concurrent throughput &lt; 30s <code>test_capacity.py</code> moto RCU/WCU tracking &lt; 10s <code>test_aws.py</code> Real AWS Production metrics (optional) 60-120s <p>Performance Workflow:</p> <ol> <li> <p>Establish baseline before optimization: <pre><code>uv run pytest tests/benchmark/test_operations.py -v \\\n  --benchmark-json=baseline.json\n</code></pre></p> </li> <li> <p>Implement optimization (e.g., config caching, BatchGetItem)</p> </li> <li> <p>Compare against baseline: <pre><code>uv run pytest tests/benchmark/test_operations.py -v \\\n  --benchmark-compare=baseline.json\n</code></pre></p> </li> </ol> <p>Key Benchmarks:</p> Benchmark Purpose Typical Overhead <code>test_acquire_release_single_limit</code> Baseline operation ~1ms (mocked) <code>test_acquire_with_cached_config</code> Config cache hit &lt; 5% overhead <code>test_acquire_cold_config</code> Config cache miss &lt; 15% overhead <code>test_cascade_with_batchgetitem_optimization</code> Cascade optimization 10-20% improvement <code>test_cascade_with_config_cache_optimization</code> Combined optimizations 20-30% improvement <p>Interpreting Results:</p> <pre><code>test_operations.py::TestAcquireReleaseBenchmarks::test_acquire_release_single_limit\n  mean \u00b1 std dev: 1.23 \u00b1 0.15 ms [min: 0.98 ms, max: 1.65 ms] (PASS)\n</code></pre> <ul> <li><code>PASS</code>: Performance stable (no regression)</li> <li><code>FAIL</code>: Regression detected (&lt; -5% typical threshold)</li> <li>Positive/negative % = improvement/degradation vs baseline</li> </ul> <p>Storing Baselines:</p> <p>After establishing a good baseline, save it for future comparison:</p> <pre><code># Save baseline with version\ncp baseline.json docs/benchmark-v0.11.0.json\ngit add docs/benchmark-v0.11.0.json\n\n# Compare future runs\npytest tests/benchmark/ -v --benchmark-compare=docs/benchmark-v0.11.0.json\n</code></pre> <p>Adding New Benchmarks:</p> <p>When adding performance-sensitive code:</p> <ol> <li>Create test in appropriate benchmark file</li> <li>Include clear docstring explaining what's measured</li> <li>Compare against related baseline test</li> <li>Use <code>@pytest.mark.benchmark</code> marker for filtering</li> <li>Run locally and verify results</li> <li>Document expected performance targets</li> </ol> <p>Example:</p> <pre><code>@pytest.mark.benchmark\ndef test_acquire_with_new_optimization(self, benchmark, sync_limiter):\n    \"\"\"Measure acquire with new optimization.\n\n    Expected: 10% improvement over baseline due to [reason].\n    \"\"\"\n    limits = [Limit.per_minute(\"rpm\", 1_000_000)]\n\n    def operation():\n        with sync_limiter.acquire(\n            entity_id=\"bench-opt\",\n            resource=\"api\",\n            limits=limits,\n            consume={\"rpm\": 1},\n        ):\n            pass\n\n    benchmark(operation)\n</code></pre>"},{"location":"contributing/testing/#ci-configuration","title":"CI Configuration","text":"<p>Example GitHub Actions workflow for integration tests:</p> <pre><code># .github/workflows/ci-tests.yml\njobs:\n  integration:\n    runs-on: ubuntu-latest\n    services:\n      localstack:\n        image: localstack/localstack\n        ports:\n          - 4566:4566\n        env:\n          SERVICES: dynamodb,dynamodbstreams,lambda,cloudformation,logs,iam,cloudwatch,sqs\n        options: &gt;-\n          --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock\n    steps:\n      - uses: actions/checkout@v4\n      - run: pip install -e \".[dev]\"\n      - run: pytest -m integration\n        env:\n          AWS_ENDPOINT_URL: http://localhost:4566\n          AWS_ACCESS_KEY_ID: test\n          AWS_SECRET_ACCESS_KEY: test\n</code></pre>"},{"location":"contributing/testing/#when-to-add-tests","title":"When to Add Tests","text":"<ul> <li>New business logic (bucket calculations, limit validation) \u2192 <code>unit/</code></li> <li>New DynamoDB operations (queries, transactions, GSI) \u2192 <code>integration/</code></li> <li>New user-facing features (CLI commands, rate limiting workflows) \u2192 <code>e2e/</code></li> <li>AWS-specific behavior (alarms, DLQ, CloudWatch metrics) \u2192 <code>e2e/test_aws.py</code></li> <li>Performance-sensitive code (new operations, optimizations) \u2192 <code>benchmark/</code></li> </ul>"},{"location":"contributing/testing/#test-coverage","title":"Test Coverage","text":"<pre><code>pytest --cov=zae_limiter --cov-report=html\nopen htmlcov/index.html\n</code></pre>"},{"location":"contributing/testing/#next-steps","title":"Next Steps","text":"<ul> <li>LocalStack - Local AWS development environment</li> <li>Architecture - Understanding the codebase</li> </ul>"},{"location":"guide/basic-usage/","title":"Basic Usage","text":"<p>This guide covers common rate limiting patterns with zae-limiter.</p>"},{"location":"guide/basic-usage/#the-acquire-context-manager","title":"The Acquire Context Manager","text":"<p>The <code>acquire()</code> method is the primary API for rate limiting:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"user-123\",      # Who is being rate limited\n    resource=\"gpt-4\",          # What resource they're accessing\n    consume={\"rpm\": 1},        # How much to consume\n) as lease:\n    # Your code here - limits resolved from stored config\n    pass\n</code></pre> <p>Behavior:</p> <ul> <li>On entry: Checks limits, consumes tokens, and writes consumption to DynamoDB immediately</li> <li>On success: Commits any adjustments made during the context (no-op if none)</li> <li>On exception: Writes compensating deltas to restore consumed tokens (independent writes, 1 WCU each)</li> </ul> <p>Limits are resolved automatically from stored config (Entity &gt; Resource &gt; System). See Configuration Hierarchy for details.</p>"},{"location":"guide/basic-usage/#multiple-limits","title":"Multiple Limits","text":"<p>Track multiple limits in a single call:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    consume={\"rpm\": 1, \"tpm\": 500},\n) as lease:\n    response = await call_llm()\n</code></pre> <p>All limits are checked atomically. If any limit is exceeded, the request is rejected.</p> <p>When using stored config, configure multiple limits at setup time:</p> CLIPython <pre><code>zae-limiter resource set-defaults gpt-4 \\\n    -l rpm:100 \\\n    -l tpm:10000\n</code></pre> <pre><code>await limiter.set_resource_defaults(\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),       # 100 requests/minute\n        Limit.per_minute(\"tpm\", 10_000),    # 10,000 tokens/minute\n    ],\n)\n</code></pre> <p>Performance Tip</p> <p>Combining multiple limits into a single <code>acquire()</code> call is more efficient than separate calls. See Batch Operation Patterns for details.</p>"},{"location":"guide/basic-usage/#burst-capacity","title":"Burst Capacity","text":"<p>Allow temporary bursts above the sustained rate:</p> <pre><code># Sustain 10k tokens/minute, but allow bursts up to 15k\nlimits = [\n    Limit.per_minute(\"tpm\", 10_000, burst=15_000),\n]\n</code></pre> <p>The bucket starts full at <code>burst</code> capacity and refills at <code>capacity</code> tokens per period. See Token Bucket Algorithm for details on how burst and capacity interact.</p>"},{"location":"guide/basic-usage/#adjusting-consumption","title":"Adjusting Consumption","text":"<p>Use <code>lease.adjust()</code> to modify consumption after the fact:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    consume={\"tpm\": 500},  # Initial estimate\n) as lease:\n    response = await call_llm()\n\n    # Adjust based on actual usage\n    actual_tokens = response.usage.total_tokens\n    await lease.adjust(tpm=actual_tokens - 500)\n</code></pre> <p>Negative Adjustments</p> <p><code>adjust()</code> can go negative, allowing the bucket to go into debt. This is useful for post-hoc reconciliation when actual usage exceeds estimates. See Token Bucket Algorithm - Negative Buckets for how debt works.</p>"},{"location":"guide/basic-usage/#check-capacity-without-consuming","title":"Check Capacity Without Consuming","text":""},{"location":"guide/basic-usage/#check-available-tokens","title":"Check Available Tokens","text":"<pre><code>available = await limiter.available(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n)\nprint(f\"Available tokens: {available['tpm']}\")\n</code></pre>"},{"location":"guide/basic-usage/#check-time-until-available","title":"Check Time Until Available","text":"<pre><code>wait_seconds = await limiter.time_until_available(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    needed={\"tpm\": 5_000},\n)\n\nif wait_seconds &gt; 0:\n    print(f\"Need to wait {wait_seconds}s for capacity\")\n</code></pre>"},{"location":"guide/basic-usage/#automatic-limit-resolution","title":"Automatic Limit Resolution","text":"<p>zae-limiter automatically resolves limits from stored configurations using a four-level hierarchy. See Configuration Hierarchy for full details.</p> <p>Resolution order (highest to lowest precedence):</p> <ol> <li>Entity level (resource-specific) - Specific limits for an entity+resource pair</li> <li>Entity level (default) - Default limits for an entity (all resources)</li> <li>Resource level - Default limits for a resource (all entities)</li> <li>System level - Global defaults (all resources)</li> <li>Override parameter - Fallback if no stored config exists</li> </ol> <pre><code># Set system-wide defaults (lowest precedence)\nawait limiter.set_system_defaults(\n    limits=[Limit.per_minute(\"rpm\", 100)],\n)\n\n# Set resource defaults (overrides system for this resource)\nawait limiter.set_resource_defaults(\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"rpm\", 50)],\n)\n\n# Set entity-specific limits (highest precedence)\nawait limiter.set_limits(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 500),        # 5x normal\n        Limit.per_minute(\"tpm\", 50_000),     # 5x normal\n    ],\n)\n\n# Limits are resolved automatically - no special flag needed\nasync with limiter.acquire(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",\n    consume={\"rpm\": 1},  # Auto-resolves to entity-level (500 rpm)\n) as lease:\n    ...\n\n# Free user falls back to resource defaults (50 rpm)\nasync with limiter.acquire(\n    entity_id=\"user-free\",\n    resource=\"gpt-4\",\n    consume={\"rpm\": 1},  # Auto-resolves to resource-level\n) as lease:\n    ...\n\n# Override stored config for a specific call\nasync with limiter.acquire(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",\n    consume={\"rpm\": 1},\n    limits=[Limit.per_minute(\"rpm\", 10)],  # Explicit override\n) as lease:\n    ...\n</code></pre> <p>v0.5.0 Breaking Change</p> <p>Prior to v0.5.0, you needed <code>use_stored_limits=True</code> to enable limit lookup. This parameter is now deprecated - limits are always resolved automatically.</p>"},{"location":"guide/basic-usage/#entity-management","title":"Entity Management","text":""},{"location":"guide/basic-usage/#create-entities","title":"Create Entities","text":"<pre><code># Create a standalone entity\nawait limiter.create_entity(\n    entity_id=\"user-123\",\n    name=\"John Doe\",\n)\n\n# Create a child entity (API key under a project)\nawait limiter.create_entity(\n    entity_id=\"key-abc\",\n    parent_id=\"project-1\",\n    name=\"Production API Key\",\n)\n</code></pre>"},{"location":"guide/basic-usage/#get-entity-information","title":"Get Entity Information","text":"<pre><code>entity = await limiter.get_entity(\"user-123\")\nprint(f\"Name: {entity.name}\")\nprint(f\"Parent: {entity.parent_id}\")\n</code></pre>"},{"location":"guide/basic-usage/#error-handling","title":"Error Handling","text":""},{"location":"guide/basic-usage/#ratelimitexceeded-details","title":"RateLimitExceeded Details","text":"<pre><code>try:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"gpt-4\",\n        consume={\"rpm\": 2},  # Exceeds capacity to trigger error\n        limits=[Limit.per_minute(\"rpm\", 1)],\n    ):\n        pass\nexcept RateLimitExceeded as e:\n    # All limit statuses\n    for status in e.statuses:\n        print(f\"{status.limit_name}: {status.available}/{status.limit.capacity}\")\n\n    # Only violations\n    for v in e.violations:\n        print(f\"Exceeded: {v.limit_name}\")\n\n    # Primary bottleneck\n    print(f\"Bottleneck: {e.primary_violation.limit_name}\")\n\n    # For API responses\n    print(e.as_dict())\n</code></pre>"},{"location":"guide/basic-usage/#service-unavailable","title":"Service Unavailable","text":"<pre><code>from zae_limiter import RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"gpt-4\",\n        consume={\"rpm\": 1},\n    ):\n        pass\nexcept RateLimiterUnavailable as e:\n    # DynamoDB is unavailable\n    # Behavior depends on on_unavailable setting\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"guide/basic-usage/#config-cache","title":"Config Cache","text":"<p>zae-limiter caches config data (system defaults, resource defaults, entity limits) to reduce DynamoDB reads. The cache has a 60-second TTL by default.</p>"},{"location":"guide/basic-usage/#configuring-cache-ttl","title":"Configuring Cache TTL","text":"<pre><code>from zae_limiter import RateLimiter, Repository\n\n# Default: 60-second cache TTL\nrepo = Repository(name=\"my-app\", region=\"us-east-1\", config_cache_ttl=60)\nlimiter = RateLimiter(repository=repo)\n\n# Disable caching (for testing)\nrepo = Repository(name=\"my-app\", region=\"us-east-1\", config_cache_ttl=0)\nlimiter = RateLimiter(repository=repo)\n</code></pre>"},{"location":"guide/basic-usage/#automatic-cache-eviction","title":"Automatic Cache Eviction","text":"<p>Config-modifying methods (<code>set_limits()</code>, <code>delete_limits()</code>) automatically evict relevant cache entries. Manual invalidation is only needed after external changes (e.g., direct DynamoDB writes).</p>"},{"location":"guide/basic-usage/#manual-cache-invalidation","title":"Manual Cache Invalidation","text":"<p>After external config changes, force immediate refresh:</p> <pre><code>await repo.invalidate_config_cache()\n</code></pre>"},{"location":"guide/basic-usage/#monitoring-cache-performance","title":"Monitoring Cache Performance","text":"<pre><code>stats = repo.get_cache_stats()\nprint(f\"Hits: {stats.hits}, Misses: {stats.misses}\")\nprint(f\"Cache entries: {stats.size}\")\n</code></pre> <p>See Config Cache Tuning for advanced configuration.</p>"},{"location":"guide/basic-usage/#speculative-writes","title":"Speculative Writes","text":"<p>Speculative writes are enabled by default, skipping the read round trip for pre-warmed buckets. To disable them:</p> <pre><code>limiter = RateLimiter(\n    repository=Repository(name=\"my-app\", region=\"us-east-1\"),\n    speculative_writes=False,  # Disable speculative writes\n)\n</code></pre> <p>With speculative writes, <code>acquire()</code> attempts a conditional UpdateItem directly instead of reading bucket state first. On success, this saves one DynamoDB round trip (0 RCU, 1 WCU instead of 1 RCU + 1 WCU). When the bucket is exhausted and refill would not help, it rejects immediately without any writes (0 RCU, 0 WCU).</p> <p>The speculative path falls back to the normal read-write path when:</p> <ul> <li>The bucket does not exist yet (first acquire for an entity)</li> <li>A new limit was added that is not in the bucket</li> <li>Token refill since last access would provide enough capacity</li> </ul> <p>See Performance Tuning - Speculative Writes for detailed cost analysis and guidance on when to disable this feature.</p>"},{"location":"guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Hierarchical Limits - Parent/child rate limiting</li> <li>LLM Integration - Token estimation patterns</li> <li>Unavailability Handling - Handling service outages</li> </ul>"},{"location":"guide/config-hierarchy/","title":"Configuration Hierarchy","text":"<p>zae-limiter supports a four-level configuration hierarchy for rate limits, allowing you to set defaults at the system level and override them at the resource, entity default, or entity-resource level.</p>"},{"location":"guide/config-hierarchy/#overview","title":"Overview","text":"flowchart TD     A[Acquire Request] --&gt; B{Entity config&lt;br/&gt;for resource?}     B --&gt;|Yes| C[Use Entity Limits]     B --&gt;|No| D{Entity _default_&lt;br/&gt;config?}     D --&gt;|Yes| E[Use Entity Default Limits]     D --&gt;|No| F{Resource config?}     F --&gt;|Yes| G[Use Resource Limits]     F --&gt;|No| H{System config?}     H --&gt;|Yes| I[Use System Limits]     H --&gt;|No| J[Use Constructor Defaults] <p>Precedence order (highest to lowest):</p> <ol> <li>Entity limits (resource-specific) - Per-entity + specific resource overrides (e.g., premium user on gpt-4)</li> <li>Entity default limits - Per-entity <code>_default_</code> config (applies to all resources for that entity)</li> <li>Resource defaults - Per-resource limits (e.g., all users on gpt-4)</li> <li>System defaults - Global limits for all resources</li> <li>Constructor defaults - Fallback from code</li> </ol>"},{"location":"guide/config-hierarchy/#when-to-use-each-level","title":"When to Use Each Level","text":"Level Use Case Example System Universal defaults across all resources 100 RPM baseline for all models Resource Per-model or per-API limits gpt-4 gets 50 RPM, claude-3 gets 200 RPM Entity Default Per-user/tenant defaults for ALL resources Premium user gets 500 RPM on any model Entity (resource-specific) Per-user + specific model overrides Enterprise customer gets 10x only on gpt-4"},{"location":"guide/config-hierarchy/#python-api","title":"Python API","text":""},{"location":"guide/config-hierarchy/#system-defaults","title":"System Defaults","text":"<p>System defaults apply to all resources unless overridden:</p> <pre><code>from zae_limiter import RateLimiter, Limit, OnUnavailable\n\nlimiter = RateLimiter(name=\"my-app\", region=\"us-east-1\")\n\n# Set system-wide defaults (no resource parameter)\nawait limiter.set_system_defaults(\n    limits=[\n        Limit.per_minute(\"rpm\", 100),\n        Limit.per_minute(\"tpm\", 10_000),\n    ],\n    on_unavailable=OnUnavailable.ALLOW,  # Optional: behavior on DynamoDB failure\n)\n\n# Get system defaults\nlimits, on_unavailable = await limiter.get_system_defaults()\nprint(f\"on_unavailable: {on_unavailable}\")\nfor limit in limits:\n    print(f\"  {limit.name}: {limit.capacity}/min\")\n\n# Delete system defaults\nawait limiter.delete_system_defaults()\n</code></pre>"},{"location":"guide/config-hierarchy/#resource-defaults","title":"Resource Defaults","text":"<p>Resource defaults override system defaults for a specific resource:</p> <pre><code># Set resource-specific defaults (overrides system)\nawait limiter.set_resource_defaults(\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 50),       # Lower RPM for expensive model\n        Limit.per_minute(\"tpm\", 100_000),  # Higher TPM\n    ],\n)\n\n# Get resource defaults\ndefaults = await limiter.get_resource_defaults(\"gpt-4\")\n\n# List all resources with configured defaults\nresources = await limiter.list_resources_with_defaults()\n# ['gpt-4', 'claude-3', ...]\n\n# Delete resource defaults\nawait limiter.delete_resource_defaults(\"gpt-4\")\n</code></pre>"},{"location":"guide/config-hierarchy/#entity-default-limits","title":"Entity Default Limits","text":"<p>Entity default limits apply to all resources for a specific entity unless overridden by a resource-specific entity config:</p> <pre><code># Set entity-level defaults (applies to ALL resources for this entity)\nawait limiter.set_limits(\n    entity_id=\"user-premium\",\n    # resource defaults to \"_default_\" when omitted\n    limits=[\n        Limit.per_minute(\"rpm\", 500),       # 10x normal on any model\n        Limit.per_minute(\"tpm\", 100_000),\n    ],\n)\n\n# Get entity default limits\nlimits = await limiter.get_limits(entity_id=\"user-premium\")\n\n# Delete entity default limits\nawait limiter.delete_limits(entity_id=\"user-premium\")\n</code></pre>"},{"location":"guide/config-hierarchy/#entity-limits-resource-specific","title":"Entity Limits (Resource-Specific)","text":"<p>Entity limits override entity defaults, resource defaults, and system defaults for a specific entity+resource pair:</p> <pre><code># Set entity-specific limits for a particular resource (highest precedence)\nawait limiter.set_limits(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",  # Only applies to gpt-4\n    limits=[\n        Limit.per_minute(\"rpm\", 1000),      # Even higher for this specific model\n        Limit.per_minute(\"tpm\", 1_000_000),\n    ],\n)\n\n# Get entity limits for specific resource\nlimits = await limiter.get_limits(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",\n)\n\n# Delete entity limits for specific resource\nawait limiter.delete_limits(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",\n)\n</code></pre>"},{"location":"guide/config-hierarchy/#cli-commands","title":"CLI Commands","text":""},{"location":"guide/config-hierarchy/#system-defaults_1","title":"System Defaults","text":"<pre><code># Set system-wide defaults (applies to ALL resources)\nzae-limiter system set-defaults -l rpm:100 -l tpm:10000 --on-unavailable allow\n\n# Get system defaults\nzae-limiter system get-defaults\n\n# Delete system defaults\nzae-limiter system delete-defaults --yes\n</code></pre>"},{"location":"guide/config-hierarchy/#resource-defaults_1","title":"Resource Defaults","text":"<pre><code># Set resource-specific defaults\nzae-limiter resource set-defaults gpt-4 -l rpm:50 -l tpm:100000\n\n# Get resource defaults\nzae-limiter resource get-defaults gpt-4\n\n# List resources with defaults\nzae-limiter resource list\n\n# Delete resource defaults\nzae-limiter resource delete-defaults gpt-4 --yes\n</code></pre>"},{"location":"guide/config-hierarchy/#entity-default-limits_1","title":"Entity Default Limits","text":"<pre><code># Set entity default limits (applies to ALL resources)\nzae-limiter entity set-limits user-premium -l rpm:500 -l tpm:100000\n\n# Get entity default limits\nzae-limiter entity get-limits user-premium\n\n# Delete entity default limits\nzae-limiter entity delete-limits user-premium --yes\n</code></pre>"},{"location":"guide/config-hierarchy/#entity-limits-resource-specific_1","title":"Entity Limits (Resource-Specific)","text":"<pre><code># Set entity-specific limits for a particular resource\nzae-limiter entity set-limits user-premium --resource gpt-4 -l rpm:1000 -l tpm:1000000\n\n# Get entity limits for specific resource\nzae-limiter entity get-limits user-premium --resource gpt-4\n\n# Delete entity limits for specific resource\nzae-limiter entity delete-limits user-premium --resource gpt-4 --yes\n</code></pre>"},{"location":"guide/config-hierarchy/#example-multi-tier-pricing","title":"Example: Multi-Tier Pricing","text":"<p>Here's how to implement a typical SaaS pricing model:</p> <pre><code>async def setup_rate_limits(limiter: RateLimiter):\n    # 1. System defaults: Free tier baseline (all resources)\n    await limiter.set_system_defaults(\n        limits=[\n            Limit.per_minute(\"rpm\", 10),\n            Limit.per_minute(\"tpm\", 1_000),\n        ],\n        on_unavailable=OnUnavailable.BLOCK,\n    )\n\n    # 2. Resource defaults: Different limits per model\n    await limiter.set_resource_defaults(\n        resource=\"gpt-4\",\n        limits=[\n            Limit.per_minute(\"rpm\", 5),    # Expensive model: lower limits\n            Limit.per_minute(\"tpm\", 500),\n        ],\n    )\n\n    await limiter.set_resource_defaults(\n        resource=\"gpt-3.5-turbo\",\n        limits=[\n            Limit.per_minute(\"rpm\", 20),   # Cheap model: higher limits\n            Limit.per_minute(\"tpm\", 5_000),\n        ],\n    )\n\n    # 3. Entity default limits: Premium tier (applies to ALL models)\n    await limiter.set_limits(\n        entity_id=\"premium-user\",\n        # resource defaults to \"_default_\" - applies to all resources\n        limits=[\n            Limit.per_minute(\"rpm\", 100),  # 10x free tier on any model\n            Limit.per_minute(\"tpm\", 10_000),\n        ],\n    )\n\n    # 4. Entity resource-specific limits: Enterprise customer on specific model\n    await limiter.set_limits(\n        entity_id=\"enterprise-customer\",\n        resource=\"gpt-4\",  # Only gpt-4\n        limits=[\n            Limit.per_minute(\"rpm\", 500),  # 50x free tier\n            Limit.per_minute(\"tpm\", 100_000),\n        ],\n    )\n</code></pre> <p>With this setup:</p> User Resource RPM TPM Source Free user gpt-4 5 500 Resource default Free user gpt-3.5-turbo 20 5,000 Resource default Free user any other 10 1,000 System default Premium user gpt-4 100 10,000 Entity default Premium user gpt-3.5-turbo 100 10,000 Entity default Premium user any other 100 10,000 Entity default Enterprise gpt-4 500 100,000 Entity resource-specific Enterprise gpt-3.5-turbo 20 5,000 Resource default"},{"location":"guide/config-hierarchy/#system-config-on_unavailable","title":"System Config: on_unavailable","text":"<p>The <code>on_unavailable</code> setting controls behavior when DynamoDB is unreachable:</p> Value Behavior Use Case <code>ALLOW</code> Allow requests (fail open) High availability is critical <code>BLOCK</code> Block requests (fail closed) Rate limiting is critical <pre><code># Set at system level\nawait limiter.set_system_defaults(\n    limits=[Limit.per_minute(\"rpm\", 100), Limit.per_minute(\"tpm\", 10_000)],\n    on_unavailable=OnUnavailable.ALLOW,\n)\n</code></pre> <pre><code># Or via CLI\nzae-limiter system set-defaults -l rpm:100 --on-unavailable allow\n</code></pre> <p>Note</p> <p><code>on_unavailable</code> is only configurable at the system level, not per-resource or per-entity.</p>"},{"location":"guide/config-hierarchy/#replacement-semantics","title":"Replacement Semantics","text":"<p>When you set limits at any level, the new limits completely replace the previous ones:</p> <pre><code># Initial: rpm=100, tpm=10000\nawait limiter.set_system_defaults([\n    Limit.per_minute(\"rpm\", 100),\n    Limit.per_minute(\"tpm\", 10_000),\n])\n\n# After this: rpm is GONE, only tpm=20000 exists\nawait limiter.set_system_defaults([\n    Limit.per_minute(\"tpm\", 20_000),\n])\n</code></pre> <p>To add or update a single limit while preserving others, read first:</p> <pre><code># Read existing\ncurrent, on_unavail = await limiter.get_system_defaults()\n\n# Modify\ncurrent_dict = {l.name: l for l in current}\ncurrent_dict[\"rpm\"] = Limit.per_minute(\"rpm\", 200)\n\n# Write back\nawait limiter.set_system_defaults(list(current_dict.values()))\n</code></pre>"},{"location":"guide/config-hierarchy/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage - Rate limiting patterns</li> <li>Hierarchical Limits - Parent/child entity relationships</li> <li>Unavailability Handling - Handling DynamoDB outages</li> </ul>"},{"location":"guide/hierarchical/","title":"Hierarchical Limits","text":"<p>zae-limiter supports two-level hierarchies for rate limiting, enabling patterns like:</p> <ul> <li>Project \u2192 API Keys: Limit total project usage while also limiting individual keys</li> <li>Organization \u2192 Users: Organization-wide limits with per-user quotas</li> <li>Tenant \u2192 Services: Multi-tenant limits with service-level controls</li> </ul>"},{"location":"guide/hierarchical/#creating-a-hierarchy","title":"Creating a Hierarchy","text":"<pre><code># Create parent entity (project)\nawait limiter.create_entity(\n    entity_id=\"project-1\",\n    name=\"Production Project\",\n)\n\n# Create child entities (API keys) with cascade enabled\nawait limiter.create_entity(\n    entity_id=\"key-abc\",\n    parent_id=\"project-1\",\n    name=\"Web Application Key\",\n    cascade=True,  # Enforce parent limits on every acquire\n)\n\nawait limiter.create_entity(\n    entity_id=\"key-xyz\",\n    parent_id=\"project-1\",\n    name=\"Mobile App Key\",\n    cascade=True,\n)\n</code></pre>"},{"location":"guide/hierarchical/#cascade-mode","title":"Cascade Mode","text":"<p>Create entities with <code>cascade=True</code> to apply rate limits to both the child and parent on every <code>acquire()</code> call:</p> <pre><code># Cascade is set once at entity creation\nawait limiter.create_entity(\n    entity_id=\"key-abc\",\n    parent_id=\"project-1\",\n    cascade=True,  # All acquire() calls will also check parent\n)\n\n# acquire() automatically cascades to parent \u2014 no flag needed\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"tpm\", 10_000),  # Per-key limit\n    ],\n    consume={\"tpm\": 500},\n) as lease:\n    await call_api()\n</code></pre> <p>Performance Impact</p> <p>Cascade mode adds overhead: +1 GetEntity + parent bucket operations. Only enable when hierarchical enforcement is needed. See Batch Operation Patterns for optimization strategies.</p> <p>Speculative Writes with Cascade</p> <p>With <code>speculative_writes=True</code>, the first cascade acquire completes in 2 sequential round trips (0 RCU, 2 WCU). After the first acquire populates the entity metadata cache, subsequent cascade acquires issue child and parent writes in parallel -- completing in just 1 round trip (0 RCU, 2 WCU) with the same cost but lower latency. If the parent needs refill, a deferred compensation optimization avoids unnecessary child compensation by attempting a parent-only slow path first. See Speculative Writes for details.</p> <p>What happens:</p> <ol> <li>Check if <code>key-abc</code> has capacity (10k tpm)</li> <li>Check if <code>project-1</code> has capacity (uses same limits)</li> <li>If both pass, consume from both atomically</li> <li>If either fails, reject with details about which limit was exceeded</li> </ol>"},{"location":"guide/hierarchical/#different-limits-per-level","title":"Different Limits Per Level","text":"<p>Set different limits for parents and children:</p> <pre><code># Set project-level limits (higher)\nawait limiter.set_limits(\n    entity_id=\"project-1\",\n    limits=[\n        Limit.per_minute(\"tpm\", 100_000),  # 100k for entire project\n    ],\n)\n\n# Set key-level limits (lower)\nawait limiter.set_limits(\n    entity_id=\"key-abc\",\n    limits=[\n        Limit.per_minute(\"tpm\", 10_000),   # 10k per key\n    ],\n)\n\n# acquire() auto-cascades because key-abc was created with cascade=True\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=None,  # Auto-resolves from stored config\n    consume={\"tpm\": 500},\n) as lease:\n    await call_api()\n</code></pre>"},{"location":"guide/hierarchical/#understanding-cascade-behavior","title":"Understanding Cascade Behavior","text":""},{"location":"guide/hierarchical/#without-cascade","title":"Without Cascade","text":"<pre><code># Entity created without cascade (default)\nawait limiter.create_entity(entity_id=\"key-abc\", parent_id=\"project-1\")\n\n# Only checks/consumes from key-abc\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#with-cascade","title":"With Cascade","text":"<pre><code># Entity created with cascade enabled\nawait limiter.create_entity(entity_id=\"key-abc\", parent_id=\"project-1\", cascade=True)\n\n# Checks/consumes from BOTH key-abc AND project-1\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#error-handling-with-hierarchies","title":"Error Handling with Hierarchies","text":"<p>When an entity has cascade enabled, <code>RateLimitExceeded</code> includes statuses for all entities:</p> <pre><code>try:\n    async with limiter.acquire(\n        entity_id=\"key-abc\",  # Has cascade=True from create_entity()\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        pass\nexcept RateLimitExceeded as e:\n    for status in e.statuses:\n        print(f\"Entity: {status.entity_id}\")\n        print(f\"  Limit: {status.limit_name}\")\n        print(f\"  Available: {status.available}\")\n        print(f\"  Exceeded: {status.exceeded}\")\n</code></pre>"},{"location":"guide/hierarchical/#use-cases","title":"Use Cases","text":""},{"location":"guide/hierarchical/#multi-tenant-saas","title":"Multi-Tenant SaaS","text":"<pre><code># Tenant has 1M tokens/day\nawait limiter.set_limits(\n    entity_id=\"tenant-acme\",\n    limits=[Limit.per_day(\"tpd\", 1_000_000)],\n)\n\n# Create user under tenant with cascade enabled\nawait limiter.create_entity(entity_id=\"user-123\", parent_id=\"tenant-acme\", cascade=True)\n\n# Each user gets 100k tokens/day\nawait limiter.set_limits(\n    entity_id=\"user-123\",\n    limits=[Limit.per_day(\"tpd\", 100_000)],\n)\n\n# Rate limit user \u2014 auto-cascades to tenant\n# limits=None auto-resolves from stored config\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    limits=None,\n    consume={\"tpm\": 500},\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#api-key-management","title":"API Key Management","text":"<pre><code># Project limit: 10k RPM\nawait limiter.set_limits(\n    entity_id=\"project-prod\",\n    limits=[Limit.per_minute(\"rpm\", 10_000)],\n)\n\n# Production key: 5k RPM (half of project)\nawait limiter.set_limits(\n    entity_id=\"key-prod\",\n    limits=[Limit.per_minute(\"rpm\", 5_000)],\n)\n\n# Staging key: 1k RPM\nawait limiter.set_limits(\n    entity_id=\"key-staging\",\n    limits=[Limit.per_minute(\"rpm\", 1_000)],\n)\n</code></pre>"},{"location":"guide/hierarchical/#limitations","title":"Limitations","text":"<ul> <li>Two levels only: Parent \u2192 Child (no grandparents)</li> <li>Single parent: Each entity can have at most one parent</li> <li>Cascade is per-entity: Set <code>cascade=True</code> on <code>create_entity()</code> to enable; it applies to all <code>acquire()</code> calls for that entity</li> </ul>"},{"location":"guide/hierarchical/#next-steps","title":"Next Steps","text":"<ul> <li>LLM Integration - Token estimation patterns</li> <li>Unavailability Handling - Handling service outages</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/llm-integration/","title":"LLM Integration","text":"<p>LLM APIs are a natural fit for zae-limiter's estimate-then-reconcile pattern, especially when token counts are unknown until after the call completes. This guide covers patterns for integrating with LLM providers.</p> <p>Understanding the Algorithm</p> <p>This guide assumes familiarity with how rate limiting works. If you're new to token buckets, start with Token Bucket Algorithm to understand concepts like negative buckets (debt) that enable the estimate-then-reconcile pattern.</p>"},{"location":"guide/llm-integration/#the-challenge","title":"The Challenge","text":"<p>LLM APIs present unique rate limiting challenges:</p> <ol> <li>Token counts are unknown upfront - You don't know how many tokens a response will use</li> <li>Multiple limits - Providers often limit both requests and tokens</li> <li>Variable costs - Different models have different token limits</li> <li>Streaming responses - Token count only known after stream completes</li> </ol>"},{"location":"guide/llm-integration/#basic-pattern-estimate-and-reconcile","title":"Basic Pattern: Estimate and Reconcile","text":"<pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),       # Requests per minute\n        Limit.per_minute(\"tpm\", 10_000),    # Tokens per minute\n    ],\n    consume={\"rpm\": 1, \"tpm\": 500},  # Estimate 500 tokens\n) as lease:\n    response = await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    )\n\n    # Reconcile with actual usage\n    actual_tokens = response.usage.total_tokens\n    await lease.adjust(tpm=actual_tokens - 500)\n</code></pre>"},{"location":"guide/llm-integration/#estimation-strategies","title":"Estimation Strategies","text":""},{"location":"guide/llm-integration/#fixed-estimate","title":"Fixed Estimate","text":"<p>Simple but may over/under-estimate:</p> <pre><code>consume={\"tpm\": 500}  # Always estimate 500 tokens\n</code></pre>"},{"location":"guide/llm-integration/#input-based-estimate","title":"Input-Based Estimate","text":"<p>Estimate based on input length:</p> <pre><code>import tiktoken\n\ndef estimate_tokens(messages: list, model: str = \"gpt-4\") -&gt; int:\n    \"\"\"Estimate tokens for input messages.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    total = 0\n    for msg in messages:\n        total += len(encoding.encode(msg[\"content\"]))\n        total += 4  # Message overhead\n    total += 2  # Completion priming\n    return total\n\n# Use in rate limiting\ninput_tokens = estimate_tokens(messages)\nestimated_output = 500  # Rough estimate for output\ntotal_estimate = input_tokens + estimated_output\n\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    consume={\"tpm\": total_estimate},\n) as lease:\n    response = await call_llm()\n    actual = response.usage.total_tokens\n    await lease.adjust(tpm=actual - total_estimate)\n</code></pre>"},{"location":"guide/llm-integration/#max-tokens-estimate","title":"Max Tokens Estimate","text":"<p>Use max_tokens as upper bound:</p> <pre><code>max_tokens = 1000\n\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": input_tokens + max_tokens},\n) as lease:\n    response = await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        max_tokens=max_tokens,\n    )\n    actual = response.usage.total_tokens\n    await lease.adjust(tpm=actual - (input_tokens + max_tokens))\n</code></pre>"},{"location":"guide/llm-integration/#handling-streaming-responses","title":"Handling Streaming Responses","text":"<p>For streaming responses, token count is only available after the stream completes:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),\n        Limit.per_minute(\"tpm\", 10_000),\n    ],\n    consume={\"rpm\": 1, \"tpm\": estimated_tokens},\n) as lease:\n    chunks = []\n    async for chunk in await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        stream=True,\n    ):\n        chunks.append(chunk)\n        yield chunk  # Stream to client\n\n    # Get final usage from last chunk (OpenAI includes it)\n    if chunks[-1].usage:\n        actual = chunks[-1].usage.total_tokens\n        await lease.adjust(tpm=actual - estimated_tokens)\n</code></pre>"},{"location":"guide/llm-integration/#per-model-rate-limits","title":"Per-Model Rate Limits","text":"<p>Different models have different limits. Use the <code>resource</code> parameter:</p> <pre><code>MODEL_LIMITS = {\n    \"gpt-4\": [\n        Limit.per_minute(\"rpm\", 100),\n        Limit.per_minute(\"tpm\", 10_000),\n    ],\n    \"gpt-4-turbo\": [\n        Limit.per_minute(\"rpm\", 500),\n        Limit.per_minute(\"tpm\", 150_000),\n    ],\n    \"gpt-3.5-turbo\": [\n        Limit.per_minute(\"rpm\", 3500),\n        Limit.per_minute(\"tpm\", 90_000),\n    ],\n}\n\nasync def rate_limited_completion(\n    entity_id: str,\n    model: str,\n    messages: list,\n    estimated_tokens: int,\n):\n    limits = MODEL_LIMITS.get(model, MODEL_LIMITS[\"gpt-3.5-turbo\"])\n\n    async with limiter.acquire(\n        entity_id=entity_id,\n        resource=model,  # Different bucket per model\n        limits=limits,\n        consume={\"rpm\": 1, \"tpm\": estimated_tokens},\n    ) as lease:\n        response = await openai.chat.completions.create(\n            model=model,\n            messages=messages,\n        )\n        actual = response.usage.total_tokens\n        await lease.adjust(tpm=actual - estimated_tokens)\n        return response\n</code></pre>"},{"location":"guide/llm-integration/#negative-buckets-debt","title":"Negative Buckets (Debt)","text":"<p>zae-limiter allows buckets to go negative, which is useful when actual usage exceeds estimates:</p> <pre><code># Estimate: 500 tokens\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},\n) as lease:\n    response = await call_llm()\n\n    # Actual: 2000 tokens\n    # Adjustment: 2000 - 500 = 1500\n    await lease.adjust(tpm=1500)\n    # Bucket now at -1500 tokens (in debt)\n</code></pre> <p>The debt is repaid as tokens refill over time. This ensures accurate accounting while allowing requests to complete.</p>"},{"location":"guide/llm-integration/#pre-flight-capacity-check","title":"Pre-Flight Capacity Check","text":"<p>Check capacity before making expensive calls:</p> <pre><code>async def call_with_capacity_check(\n    entity_id: str,\n    model: str,\n    messages: list,\n    estimated_tokens: int,\n):\n    limits = MODEL_LIMITS[model]\n\n    # Check available capacity\n    available = await limiter.available(\n        entity_id=entity_id,\n        resource=model,\n        limits=limits,\n    )\n\n    if available[\"tpm\"] &lt; estimated_tokens:\n        # Not enough capacity - check when it will be available\n        wait_time = await limiter.time_until_available(\n            entity_id=entity_id,\n            resource=model,\n            limits=limits,\n            needed={\"tpm\": estimated_tokens},\n        )\n        raise RetryAfter(seconds=wait_time)\n\n    # Proceed with rate-limited call\n    async with limiter.acquire(...):\n        ...\n</code></pre>"},{"location":"guide/llm-integration/#integration-with-retry-libraries","title":"Integration with Retry Libraries","text":"<p>Combine with retry libraries like <code>tenacity</code>:</p> <pre><code>from tenacity import retry, retry_if_exception_type, wait_fixed\n\n@retry(\n    retry=retry_if_exception_type(RateLimitExceeded),\n    wait=wait_fixed(1),\n)\nasync def resilient_llm_call(entity_id: str, messages: list):\n    async with limiter.acquire(\n        entity_id=entity_id,\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        return await openai.chat.completions.create(\n            model=\"gpt-4\",\n            messages=messages,\n        )\n</code></pre> <p>Or use the retry information from the exception:</p> <pre><code>async def smart_retry_llm_call(entity_id: str, messages: list):\n    while True:\n        try:\n            async with limiter.acquire(...):\n                return await call_llm()\n        except RateLimitExceeded as e:\n            await asyncio.sleep(e.retry_after_seconds)\n</code></pre>"},{"location":"guide/llm-integration/#next-steps","title":"Next Steps","text":"<ul> <li>Unavailability Handling - Handling service outages</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/token-bucket/","title":"Token Bucket Algorithm","text":"<p>Understanding how rate limiting works helps you choose the right limits for your application. This page explains the token bucket algorithm and how zae-limiter implements it.</p>"},{"location":"guide/token-bucket/#the-classic-algorithm","title":"The Classic Algorithm","text":"<p>The token bucket algorithm controls request rates using a simple metaphor: imagine a bucket that holds tokens.</p> <ul> <li>Tokens accumulate over time at a fixed rate (the refill rate)</li> <li>Requests consume tokens from the bucket</li> <li>Requests are allowed if enough tokens are available</li> <li>Requests are rejected if the bucket is empty</li> </ul> flowchart LR     subgraph bucket[\"Token Bucket\"]         T[Tokens]     end     Time --&gt;|refill| T     T --&gt;|consume| Request     Request --&gt; Check{Enough tokens?}     Check --&gt;|Yes| Allow[Allow request]     Check --&gt;|No| Reject[Reject + retry_after] <p>This creates a natural rate limit: requests can burst up to the bucket's capacity, but sustained traffic is limited by the refill rate.</p>"},{"location":"guide/token-bucket/#how-zae-limiter-implements-it","title":"How zae-limiter Implements It","text":"<p>zae-limiter uses a modified token bucket optimized for distributed systems. Here's how it differs from the classic algorithm:</p> Aspect Classic Algorithm zae-limiter Token storage Floating-point numbers Integers (millitokens x1000) Refill timing Continuous background process Lazy (calculated on-demand) Minimum tokens 0 (never negative) Can go negative (debt) Precision May drift due to float errors Drift-compensated integers <p>These modifications enable:</p> <ul> <li>Distributed precision: Integer math produces identical results across all nodes</li> <li>Efficiency: No background timers or processes needed</li> <li>Estimate-then-reconcile: Negative buckets allow post-hoc cost adjustment</li> </ul>"},{"location":"guide/token-bucket/#key-concepts","title":"Key Concepts","text":""},{"location":"guide/token-bucket/#capacity-and-burst","title":"Capacity and Burst","text":"<p>Every limit has two key parameters:</p> <ul> <li>Capacity: The sustained rate (tokens that refill per period)</li> <li>Burst: The maximum bucket size (can be larger than capacity)</li> </ul> <pre><code># 10,000 tokens/minute sustained, 15,000 burst\nLimit.per_minute(\"tpm\", capacity=10_000, burst=15_000)\n</code></pre> graph TD     A[\"Bucket starts full at burst (15k)\"]     A --&gt;|\"consume 15k\"| B[\"Bucket empty (0)\"]     B --&gt;|\"wait 1 minute\"| C[\"Refills 10k tokens\"]     C --&gt;|\"wait 30 more seconds\"| D[\"Refills to burst (15k)\"]     D --&gt;|\"steady state\"| E[\"10k tokens/minute\"]      style A fill:#90EE90     style B fill:#FFB6C1     style C fill:#87CEEB     style D fill:#90EE90     style E fill:#87CEEB <p>Key insight: The bucket is larger (15k) but refills at the same rate (10k/minute). After fully depleting the burst, it takes 1.5 minutes to return to full capacity\u2014not 1 minute.</p> <p>When to use burst &gt; capacity:</p> <ul> <li>Startup surge: Handle initial traffic before steady state</li> <li>Bursty workloads: Allow temporary spikes followed by quiet periods</li> <li>User experience: Don't reject the first request just because a minute hasn't passed</li> </ul>"},{"location":"guide/token-bucket/#lazy-refill","title":"Lazy Refill","text":"<p>Unlike traditional implementations that continuously add tokens, zae-limiter calculates refills on-demand:</p> <pre><code>When a request arrives:\n1. Calculate elapsed time since last refill\n2. Add tokens based on elapsed time\n3. Check if enough tokens are available\n4. Consume tokens if allowed\n</code></pre> <p>Why this matters:</p> <ul> <li>Accurate <code>retry_after</code>: Time calculations are exact, not approximations</li> <li>No drift: Integer math with drift compensation prevents accumulated errors</li> <li>Efficient: No background processes consuming resources</li> </ul> <p>The refill formula:</p> <pre><code>tokens_to_add = elapsed_time \u00d7 refill_rate\n             = elapsed_ms \u00d7 refill_amount / refill_period\n</code></pre>"},{"location":"guide/token-bucket/#negative-buckets-debt","title":"Negative Buckets (Debt)","text":"<p>zae-limiter allows buckets to go negative, creating a \"debt\" that must be repaid before more tokens are available. This enables the estimate-then-reconcile pattern for operations with unknown cost.</p> sequenceDiagram     participant App     participant Bucket      Note over Bucket: tokens: 1,000      App-&gt;&gt;Bucket: consume(estimate=500)     Note over Bucket: tokens: 500      App-&gt;&gt;App: execute operation...     Note over App: actual cost: 2,000 units      App-&gt;&gt;Bucket: adjust(+1,500)     Note over Bucket: tokens: -1,000     Note over Bucket: Bucket is now in debt!      Note over Bucket: (time passes, tokens refill)     Note over Bucket: tokens: 0 \u2192 1,000 <p>Why allow negative tokens?</p> <p>Many operations have costs that are unknown until completion:</p> Domain Unknown cost Database queries Rows scanned, data returned File transfers Bytes transferred after compression Batch processing Items processed per batch API calls Metered usage calculated after <p>Negative buckets let you:</p> <ol> <li>Estimate cost upfront (consume)</li> <li>Execute the operation</li> <li>Reconcile based on actual cost (adjust)</li> </ol> <p>The debt is automatically repaid as tokens refill over time.</p> <pre><code>async with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    consume={\"rpm\": 5},  # Estimate 5 units\n) as lease:\n    result = await execute_operation()\n    actual = result.units_consumed  # 12\n    await lease.adjust(rpm=actual - 5)  # Add 7 to debt\n</code></pre> <p>See LLM Integration for a specific application of this pattern.</p>"},{"location":"guide/token-bucket/#practical-implications","title":"Practical Implications","text":""},{"location":"guide/token-bucket/#why-estimates-can-be-wrong","title":"Why estimates can be wrong","text":"<p>Because buckets can go negative, your initial estimate doesn't need to be perfect. Underestimate and adjust later:</p> <ul> <li>Estimate too low? Adjust adds to consumption</li> <li>Estimate too high? Adjust can return tokens (negative adjustment)</li> </ul>"},{"location":"guide/token-bucket/#why-retry_after-is-accurate","title":"Why <code>retry_after</code> is accurate","text":"<p>The lazy refill with drift compensation means <code>retry_after</code> tells you exactly when tokens will be available:</p> <pre><code>try:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"tpm\", 10_000)],\n        consume={\"tpm\": 1000},\n    ):\n        pass\nexcept RateLimitExceeded as e:\n    # This is the exact time to wait\n    await asyncio.sleep(e.retry_after_seconds)\n    # Now the request will succeed\n</code></pre>"},{"location":"guide/token-bucket/#choosing-the-right-limits","title":"Choosing the right limits","text":"Scenario Capacity Burst Rationale Steady API traffic 100 rpm 100 No bursting needed Bursty batch jobs 100 rpm 500 Allow 5x burst, then sustain LLM tokens 10k tpm 15k Handle variable response sizes Database queries 1k rows/min 5k Allow large result sets occasionally New user onboarding 10 rpm 50 Let users explore, then limit"},{"location":"guide/token-bucket/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage - Common rate limiting patterns</li> <li>LLM Integration - Token estimation strategies</li> <li>Architecture - Implementation details for contributors</li> </ul>"},{"location":"guide/unavailability/","title":"Unavailability Handling","text":"<p>zae-limiter provides configurable behavior when DynamoDB is unavailable. This guide covers the <code>on_unavailable</code> modes and how to choose the right one for your application.</p> <p>Scope</p> <p>This page covers infrastructure unavailability (DynamoDB errors, timeouts, throttling).</p> <p>For handling rate limit violations, see Basic Usage.</p>"},{"location":"guide/unavailability/#available-modes","title":"Available Modes","text":"Mode Behavior Use Case <code>BLOCK</code> Reject requests Security-critical, billing <code>ALLOW</code> Allow requests User experience priority"},{"location":"guide/unavailability/#what-triggers-on_unavailable-logic","title":"What Triggers on_unavailable Logic","text":"<p>The <code>on_unavailable</code> mode only applies to infrastructure errors. These exceptions always propagate regardless of mode:</p> <ul> <li><code>RateLimitExceeded</code> \u2014 Rate limit violated (business logic)</li> <li><code>ValidationError</code> \u2014 Invalid configuration (user error)</li> </ul> <p>Infrastructure errors that trigger on_unavailable:</p> <ul> <li>Connection timeouts</li> <li>DynamoDB throttling</li> <li>Network failures</li> <li>Service unavailable errors</li> </ul>"},{"location":"guide/unavailability/#block-default","title":"BLOCK (Default)","text":"<p>When DynamoDB is unavailable, reject all rate-limited requests by raising <code>RateLimiterUnavailable</code>.</p> <p>Exception Handling Required</p> <p>When using <code>BLOCK</code> mode (the default), your application must catch <code>RateLimiterUnavailable</code> to handle infrastructure failures gracefully. This exception inherits from <code>InfrastructureError</code>, not <code>RateLimitExceeded</code>.</p> <pre><code>from zae_limiter import RateLimiter, OnUnavailable, RateLimiterUnavailable\n\nlimiter = RateLimiter(\n    name=\"limiter\",\n    on_unavailable=OnUnavailable.BLOCK,  # Default\n)\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        await do_work()\nexcept RateLimiterUnavailable as e:\n    # DynamoDB is unavailable - handle degraded mode\n    print(JSONResponse(\n        status_code=503,\n        content={\"error\": \"Service temporarily unavailable\"},\n    ).status_code)\n</code></pre> <p>When to use:</p> <ul> <li>Billing/metering systems where accuracy is critical</li> <li>Security-sensitive operations</li> <li>When over-consumption has significant costs</li> <li>Compliance requirements</li> </ul>"},{"location":"guide/unavailability/#allow","title":"ALLOW","text":"<p>When DynamoDB is unavailable, allow requests to proceed:</p> <pre><code>limiter = RateLimiter(\n    name=\"limiter\",\n    on_unavailable=OnUnavailable.ALLOW,\n)\n\n# Requests proceed even if DynamoDB is down\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    consume={\"rpm\": 1},\n):\n    await do_work()  # Runs without rate limiting\n</code></pre> <p>When to use:</p> <ul> <li>User experience is the priority</li> <li>Brief outages are acceptable</li> <li>Rate limiting is a soft limit</li> <li>Development/staging environments</li> </ul>"},{"location":"guide/unavailability/#no-op-lease-behavior","title":"No-Op Lease Behavior","text":"<p>When <code>ALLOW</code> activates due to infrastructure failure:</p> <ul> <li>A no-op lease is returned with no bucket entries</li> <li><code>lease.consume()</code>, <code>lease.adjust()</code>, and <code>lease.release()</code> silently do nothing</li> <li>Your code cannot detect degraded mode from the lease itself</li> </ul> <p>To detect and log degraded operations, wrap with custom error handling:</p> <pre><code>async def acquire_with_metrics(limiter, **kwargs):\n    \"\"\"Wrapper that tracks degraded operations.\"\"\"\n    try:\n        async with limiter.acquire(**kwargs) as lease:\n            yield lease\n    except Exception as e:\n        # BLOCK caught the error - we're in degraded mode\n        # This only runs if you use BLOCK and catch manually\n        metrics.increment(\"rate_limiter.degraded\")\n        logger.warning(f\"Rate limiter degraded: {e}\")\n        raise\n</code></pre>"},{"location":"guide/unavailability/#per-request-override","title":"Per-Request Override","text":"<p>Override the default mode for specific requests:</p> <pre><code># Default to BLOCK\nlimiter = RateLimiter(\n    name=\"limiter\",\n    on_unavailable=OnUnavailable.BLOCK,\n)\n\n# But allow this specific request to proceed\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[...],\n    consume={\"requests\": 1},\n    on_unavailable=OnUnavailable.ALLOW,  # Override for this call\n) as lease:\n    await do_work()\n</code></pre>"},{"location":"guide/unavailability/#handling-unavailable-errors","title":"Handling Unavailable Errors","text":"<p>The <code>RateLimiterUnavailable</code> exception includes details about the failure:</p> <pre><code>from zae_limiter import RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        await do_work()\nexcept RateLimiterUnavailable as e:\n    # Log the underlying error\n    logger.error(f\"Rate limiter unavailable: {e}\")\n\n    # Decide how to handle\n    if is_critical_operation:\n        raise HTTPException(status_code=503)\n    else:\n        # Proceed without rate limiting\n        await do_work()\n</code></pre>"},{"location":"guide/unavailability/#best-practices","title":"Best Practices","text":""},{"location":"guide/unavailability/#1-choose-based-on-risk","title":"1. Choose Based on Risk","text":"<pre><code># High-risk: billing, security\nbilling_limiter = RateLimiter(\n    name=\"billing\",\n    on_unavailable=OnUnavailable.BLOCK,\n)\n\n# Lower-risk: general API\napi_limiter = RateLimiter(\n    name=\"api\",\n    on_unavailable=OnUnavailable.ALLOW,\n)\n</code></pre>"},{"location":"guide/unavailability/#2-graceful-degradation","title":"2. Graceful Degradation","text":"<p>Implement fallback behavior:</p> <pre><code>async def resilient_operation(entity_id: str):\n    try:\n        async with limiter.acquire(\n            entity_id=entity_id,\n            resource=\"api\",\n            on_unavailable=OnUnavailable.BLOCK,\n        ):\n            return await premium_operation()\n    except RateLimiterUnavailable:\n        # Fall back to degraded mode\n        logger.warning(\"Rate limiter unavailable, using fallback\")\n        return await basic_operation()\n</code></pre>"},{"location":"guide/unavailability/#3-health-checks","title":"3. Health Checks","text":"<p>Use <code>is_available()</code> to check rate limiter connectivity:</p> <pre><code>async def health_check():\n    checks = {}\n\n    # Check rate limiter connectivity\n    if await limiter.is_available():\n        checks[\"rate_limiter\"] = \"healthy\"\n    else:\n        checks[\"rate_limiter\"] = \"unhealthy\"\n\n    return checks\n</code></pre> <p>The <code>is_available()</code> method:</p> <ul> <li>Returns <code>True</code> if DynamoDB is reachable, <code>False</code> otherwise</li> <li>Never raises exceptions</li> <li>Uses a configurable timeout (default 1 second)</li> <li>Works without requiring initialization</li> </ul> <pre><code># FastAPI health endpoint example\n@app.get(\"/health\")\nasync def health():\n    return {\n        \"status\": \"healthy\" if await limiter.is_available() else \"degraded\",\n    }\n\n# Pre-flight check before operations\nif not await limiter.is_available():\n    logger.warning(\"Rate limiter unavailable, using fallback\")\n</code></pre>"},{"location":"guide/unavailability/#observability","title":"Observability","text":"<p>For monitoring rate limiter health and setting up alerts, see the Monitoring Guide.</p>"},{"location":"guide/unavailability/#next-steps","title":"Next Steps","text":"<ul> <li>Operations Guide - Troubleshooting and operational procedures</li> <li>Deployment - Infrastructure setup</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/usage-snapshots/","title":"Usage Snapshots","text":"<p>Usage snapshots provide historical consumption data for billing, reporting, and capacity planning. This guide explains how to query and use snapshot data.</p>"},{"location":"guide/usage-snapshots/#what-are-usage-snapshots","title":"What Are Usage Snapshots?","text":"<p>Usage snapshots are time-aggregated consumption records created by the Lambda aggregator from DynamoDB stream events. When you call <code>acquire()</code> and consume tokens, the aggregator automatically records this consumption into hourly and daily snapshots.</p> <p>Key characteristics:</p> <ul> <li>Automatic: Created by the Lambda aggregator without additional API calls</li> <li>Aggregated: Consumption is summed within time windows (hourly, daily)</li> <li>Retroactive: Data is available after the Lambda processes stream events</li> <li>Queryable: Access via API or CLI for reporting and analysis</li> </ul>"},{"location":"guide/usage-snapshots/#when-to-use-usage-snapshots","title":"When to Use Usage Snapshots","text":"Use Case Feature Billing reports Query consumption by entity/resource for a billing period Usage dashboards Display consumption trends over time Capacity planning Analyze usage patterns to inform limit adjustments Audit compliance Historical record of resource consumption <p>Snapshots vs Real-time Limits</p> <p>Use <code>get_usage_snapshots()</code> for historical analysis. For real-time limit status, use <code>get_status()</code> or check the <code>LimitStatus</code> returned by <code>acquire()</code>.</p>"},{"location":"guide/usage-snapshots/#querying-snapshots","title":"Querying Snapshots","text":""},{"location":"guide/usage-snapshots/#python-api","title":"Python API","text":"<p>Query snapshots for an entity:</p> <pre><code>from datetime import datetime\nfrom zae_limiter import RateLimiter\n\nlimiter = RateLimiter(name=\"my-app\", region=\"us-east-1\")\n\n# Get hourly snapshots for a user\nsnapshots, next_key = await limiter.get_usage_snapshots(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    window_type=\"hourly\",\n    start_time=datetime(2024, 1, 1),\n    end_time=datetime(2024, 1, 31),\n)\n\nfor snap in snapshots:\n    print(f\"{snap.window_start}: {snap.counters}\")\n</code></pre> <p>Query snapshots across all entities for a resource:</p> <pre><code># Get all consumption for gpt-4 across all users\nsnapshots, _ = await limiter.get_usage_snapshots(\n    resource=\"gpt-4\",\n    window_type=\"daily\",\n)\n</code></pre>"},{"location":"guide/usage-snapshots/#pagination","title":"Pagination","text":"<p>For large result sets, use the <code>next_key</code> cursor:</p> <pre><code>all_snapshots = []\nnext_key = None\n\nwhile True:\n    snapshots, next_key = await limiter.get_usage_snapshots(\n        entity_id=\"user-123\",\n        next_key=next_key,\n    )\n    all_snapshots.extend(snapshots)\n    if next_key is None:\n        break\n</code></pre> <p>Pagination Behavior</p> <p>The <code>limit</code> parameter controls the DynamoDB query batch size, not the guaranteed result count. Client-side filters (<code>window_type</code>, <code>start_time</code>, <code>end_time</code>) are applied after fetching, so the returned count may be less than <code>limit</code>. Always use <code>next_key</code> to ensure you retrieve all matching results.</p>"},{"location":"guide/usage-snapshots/#usage-summary","title":"Usage Summary","text":"<p>For aggregated statistics, use <code>get_usage_summary()</code>:</p> <pre><code>summary = await limiter.get_usage_summary(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    window_type=\"hourly\",\n    start_time=datetime(2024, 1, 1),\n    end_time=datetime(2024, 1, 31),\n)\n\nprint(f\"Total snapshots: {summary.snapshot_count}\")\nprint(f\"Total tokens: {summary.total['tpm']}\")\nprint(f\"Average per hour: {summary.average['tpm']}\")\nprint(f\"Time range: {summary.min_window_start} to {summary.max_window_start}\")\n</code></pre>"},{"location":"guide/usage-snapshots/#cli-commands","title":"CLI Commands","text":"<p>List snapshots:</p> <pre><code># Query by entity\nzae-limiter usage list --name my-app --entity-id user-123 --resource gpt-4\n\n# Query by resource across all entities\nzae-limiter usage list --name my-app --resource gpt-4 --window-type hourly\n\n# Filter by time range\nzae-limiter usage list --name my-app --entity-id user-123 \\\n    --start-time 2024-01-01T00:00:00Z --end-time 2024-01-31T23:59:59Z\n</code></pre> <p>Get summary:</p> <pre><code>zae-limiter usage summary --name my-app --entity-id user-123 --resource gpt-4\n</code></pre>"},{"location":"guide/usage-snapshots/#ascii-chart-visualization","title":"ASCII Chart Visualization","text":"<p>Display usage trends as ASCII charts with the <code>--plot</code> flag:</p> <pre><code># Install the plot extra\npip install 'zae-limiter[plot]'\n\n# Display usage as ASCII charts\nzae-limiter usage list --entity-id user-123 --plot\n\n# With resource filter\nzae-limiter usage list --entity-id user-123 --resource gpt-4 --plot\n</code></pre> <p>Example output:</p> <pre><code>Usage Plot: gpt-4 (hourly)\nEntity: user-123\n================================================================================\n\nRPM                             TPM\n----------------------------    -------------------------------\n51  \u2524        \u256d\u2500\u256e                5,141  \u2524        \u256d\u256e\n47  \u2524        \u2502 \u2570\u256e               4,719  \u2524        \u2502\u2570\u2500\u256e\n43  \u2524        \u2502  \u2570\u2500\u2500\u2500\u2500\u2500\u256e         4,297  \u2524       \u256d\u256f  \u2570\u2500\u2500\u2500\u2500\u2500\u256e\n38  \u2524       \u256d\u256f        \u2570\u256e        3,875  \u2524       \u2502         \u2570\u256e\n34  \u2524       \u2502          \u2502        3,453  \u2524       \u2502          \u2502\n30  \u2524      \u256d\u256f          \u2570\u256e       3,031  \u2524      \u256d\u256f          \u2570\u256e\n26  \u2524     \u256d\u256f            \u2570\u2500\u2500     2,610  \u2524     \u256d\u256f            \u2570\u2500\u2500\n 5  \u253c\u2500\u2500\u2500\u2500\u2500\u256f                       500  \u253c\u2500\u2500\u2500\u2500\u2500\u256f\n\nTime range: 2024-01-15T00:00:00Z to 2024-01-15T23:00:00Z\nData points: 24\n\nTotal: 24 snapshots\n</code></pre> <p>Features:</p> <ul> <li>Side-by-side layout: Multiple counters displayed in pairs for compact viewing</li> <li>Context header: Shows resource, window type, and entity ID</li> <li>Auto-downsampling: Large datasets (&gt;60 points) are automatically averaged to fit terminal width</li> <li>Right-aligned Y-axis: Proper alignment for values with thousands separators</li> </ul> <p>This is useful for quickly spotting usage trends and patterns directly in the terminal.</p>"},{"location":"guide/usage-snapshots/#snapshot-data-model","title":"Snapshot Data Model","text":"<p>Each snapshot contains:</p> Field Description <code>entity_id</code> The entity that consumed tokens <code>resource</code> The resource being rate limited <code>window_start</code> Start of the time window (ISO timestamp) <code>window_end</code> End of the time window (ISO timestamp) <code>window_type</code> \"hourly\" or \"daily\" <code>counters</code> Dict of limit_name \u2192 total consumption <code>total_events</code> Number of rate limit events in the window <p>Example snapshot:</p> <pre><code>UsageSnapshot(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    window_start=\"2024-01-15T10:00:00Z\",\n    window_end=\"2024-01-15T10:59:59.999999Z\",\n    window_type=\"hourly\",\n    counters={\"tpm\": 5000, \"rpm\": 25},\n    total_events=25,\n)\n</code></pre>"},{"location":"guide/usage-snapshots/#query-modes","title":"Query Modes","text":""},{"location":"guide/usage-snapshots/#entity-scoped-queries","title":"Entity-Scoped Queries","text":"<p>Provide <code>entity_id</code> to query snapshots for a specific entity:</p> <pre><code># Uses primary key (PK) - most efficient\nsnapshots, _ = await limiter.get_usage_snapshots(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",  # Optional: filter by resource\n)\n</code></pre>"},{"location":"guide/usage-snapshots/#resource-scoped-queries","title":"Resource-Scoped Queries","text":"<p>Provide only <code>resource</code> to query across all entities:</p> <pre><code># Uses GSI2 - aggregates across entities\nsnapshots, _ = await limiter.get_usage_snapshots(\n    resource=\"gpt-4\",\n)\n</code></pre> <p>This is useful for:</p> <ul> <li>Total consumption reports per resource</li> <li>Comparing usage across users/projects</li> <li>Capacity planning at the resource level</li> </ul>"},{"location":"guide/usage-snapshots/#relationship-to-other-features","title":"Relationship to Other Features","text":"flowchart LR     A[acquire] --&gt;|stream| B[DynamoDB Stream]     B --&gt;|triggers| C[Lambda Aggregator]     C --&gt;|creates| D[Usage Snapshots]     D --&gt;|query| E[get_usage_snapshots]     D --&gt;|aggregate| F[get_usage_summary] Feature Purpose Data <code>acquire()</code> Real-time rate limiting Current token state <code>get_status()</code> Check current limits Live bucket state <code>get_audit_events()</code> Security audit trail Who changed what <code>get_usage_snapshots()</code> Historical consumption Aggregated usage over time"},{"location":"guide/usage-snapshots/#best-practices","title":"Best Practices","text":"<ol> <li>Use window_type filtering: Query hourly vs daily based on your reporting needs</li> <li>Paginate large queries: Always handle <code>next_key</code> for complete results</li> <li>Use summary for totals: <code>get_usage_summary()</code> is more efficient than summing snapshots client-side</li> <li>Consider time ranges: Narrow your queries with <code>start_time</code>/<code>end_time</code> for better performance</li> </ol>"},{"location":"infra/auditing/","title":"Audit Logging","text":"<p>zae-limiter provides built-in audit logging for security-sensitive operations, enabling compliance tracking, troubleshooting, and incident investigation.</p>"},{"location":"infra/auditing/#overview","title":"Overview","text":"<p>The audit system automatically logs:</p> Action Trigger Details Captured <code>entity_created</code> Creating an entity name, parent_id, metadata <code>entity_deleted</code> Deleting an entity number of records deleted <code>limits_set</code> Configuring limits all limit configurations <code>limits_deleted</code> Removing limits resource name <p>Each audit event includes:</p> <ul> <li>Unique event ID - ULID (time-sortable, collision-free)</li> <li>Timestamp - ISO 8601 UTC</li> <li>Entity ID - The affected entity</li> <li>Principal - Who performed the action (optional)</li> <li>Details - Action-specific context</li> </ul>"},{"location":"infra/auditing/#audit-event-structure","title":"Audit Event Structure","text":"<pre><code>from zae_limiter import AuditEvent, AuditAction\n\n# Example audit event\nevent = AuditEvent(\n    event_id=\"01HQXYZ123ABC456DEF789GHI\",\n    timestamp=\"2024-01-15T10:30:00.000000+00:00\",\n    action=AuditAction.LIMITS_SET,\n    entity_id=\"api-key-123\",\n    principal=\"admin@example.com\",\n    resource=\"gpt-4\",\n    details={\n        \"limits\": [\n            {\"name\": \"rpm\", \"capacity\": 100, \"burst\": 150}\n        ]\n    }\n)\n</code></pre>"},{"location":"infra/auditing/#auditaction-constants","title":"AuditAction Constants","text":"Constant Value Description <code>ENTITY_CREATED</code> <code>\"entity_created\"</code> New entity was created <code>ENTITY_DELETED</code> <code>\"entity_deleted\"</code> Entity was deleted <code>LIMITS_SET</code> <code>\"limits_set\"</code> Limits were configured <code>LIMITS_DELETED</code> <code>\"limits_deleted\"</code> Limits were removed"},{"location":"infra/auditing/#principal-tracking","title":"Principal Tracking","text":"<p>Track who performed each action by passing the <code>principal</code> parameter to entity and limit management methods:</p> <pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\n# Track who created the entity\nawait limiter.create_entity(\n    entity_id=\"api-key-123\",\n    name=\"Production Key\",\n    principal=\"admin@example.com\",  # Tracks the caller\n)\n\n# Track who configured limits\nawait limiter.set_limits(\n    entity_id=\"api-key-123\",\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    principal=\"ops-team@example.com\",\n)\n\n# Track who deleted limits\nawait limiter.delete_limits(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    principal=\"ops-team@example.com\",\n)\n\n# Track who deleted the entity\nawait limiter.delete_entity(\n    entity_id=\"api-key-123\",\n    principal=\"admin@example.com\",\n)\n</code></pre>"},{"location":"infra/auditing/#auto-detection-of-aws-caller-identity","title":"Auto-Detection of AWS Caller Identity","text":"<p>When <code>principal</code> is not provided, zae-limiter automatically detects the AWS caller identity (ARN) using STS <code>GetCallerIdentity</code>. This means audit events automatically capture who made changes without requiring explicit principal tracking:</p> <pre><code># No principal specified - AWS ARN is auto-detected\nawait limiter.create_entity(\n    entity_id=\"api-key-123\",\n    name=\"Production Key\",\n)\n# Audit event will have principal like:\n# \"arn:aws:iam::123456789012:user/admin\"\n# or \"arn:aws:sts::123456789012:assumed-role/MyRole/session\"\n</code></pre> <p>Best Practice</p> <p>For human-readable audit trails, explicitly pass a <code>principal</code> that identifies the user or service (e.g., email address or service name). Auto-detection is useful as a fallback when the caller identity is not available at the application level.</p> <p>Valid principal formats:</p> <ul> <li>Email: <code>user@example.com</code></li> <li>Service: <code>auth-service-v2</code></li> <li>Any identifier: alphanumeric start, then alphanumeric/underscore/hyphen/dot/colon/@</li> </ul>"},{"location":"infra/auditing/#querying-audit-events","title":"Querying Audit Events","text":"<p>Retrieve audit events for an entity using the <code>get_audit_events()</code> method:</p> <pre><code>from zae_limiter import RateLimiter\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\n# Get recent audit events (most recent first)\nevents = await limiter.get_audit_events(\n    entity_id=\"api-key-123\",\n    limit=100,\n)\n\nfor event in events:\n    print(f\"{event.timestamp}: {event.action} by {event.principal}\")\n</code></pre>"},{"location":"infra/auditing/#synchronous-api","title":"Synchronous API","text":"<p>For synchronous code, use <code>SyncRateLimiter</code>:</p> <pre><code>from zae_limiter import SyncRateLimiter\n\nlimiter = SyncRateLimiter(name=\"limiter\", region=\"us-east-1\")\n\nevents = limiter.get_audit_events(entity_id=\"api-key-123\", limit=100)\nfor event in events:\n    print(f\"{event.timestamp}: {event.action} by {event.principal}\")\n</code></pre>"},{"location":"infra/auditing/#pagination","title":"Pagination","text":"<p>Use <code>start_event_id</code> for pagination through large result sets:</p> <pre><code># First page\nevents = await limiter.get_audit_events(\n    entity_id=\"api-key-123\",\n    limit=50,\n)\n\n# Next page (use last event's ID)\nif events:\n    more_events = await limiter.get_audit_events(\n        entity_id=\"api-key-123\",\n        limit=50,\n        start_event_id=events[-1].event_id,\n    )\n</code></pre>"},{"location":"infra/auditing/#cli-access","title":"CLI Access","text":"<p>Query audit events from the command line:</p> <pre><code># List audit events for an entity\nzae-limiter audit list --name limiter --entity-id api-key-123\n\n# Limit results\nzae-limiter audit list --entity-id api-key-123 --limit 10\n\n# Paginate\nzae-limiter audit list --entity-id api-key-123 --start-event-id 01HXYZ...\n</code></pre>"},{"location":"infra/auditing/#retention-and-ttl","title":"Retention and TTL","text":"<p>Audit events auto-expire after 90 days by default. This is configurable via the <code>ttl_seconds</code> parameter when logging events.</p> <p>DynamoDB TTL handles deletion automatically:</p> <ul> <li>Events are marked with an expiration timestamp</li> <li>DynamoDB deletes expired items within 48 hours of TTL</li> <li>Expired events are automatically archived to S3 (when enabled)</li> </ul>"},{"location":"infra/auditing/#s3-archival","title":"S3 Archival","text":"<p>When audit archival is enabled (default), expired audit events are automatically archived to S3 before being deleted from DynamoDB. This enables long-term retention for compliance requirements.</p>"},{"location":"infra/auditing/#how-it-works","title":"How It Works","text":"<ol> <li>TTL Expiration: DynamoDB marks audit events for deletion after 90 days</li> <li>Stream Trigger: The Lambda aggregator receives TTL deletion events via DynamoDB Streams</li> <li>Archive to S3: Events are written to S3 in compressed JSONL format</li> <li>Glacier Transition: After configurable days (default: 90), archives transition to Glacier Instant Retrieval</li> </ol>"},{"location":"infra/auditing/#configuration","title":"Configuration","text":""},{"location":"infra/auditing/#cli-deployment","title":"CLI Deployment","text":"<pre><code># Default: archival enabled, 90-day Glacier transition\nzae-limiter deploy --name limiter --region us-east-1\n\n# Custom Glacier transition period\nzae-limiter deploy --name limiter --audit-archive-glacier-days 180\n\n# Disable archival entirely\nzae-limiter deploy --name limiter --no-audit-archival\n</code></pre>"},{"location":"infra/auditing/#programmatic-deployment","title":"Programmatic Deployment","text":"<pre><code>from zae_limiter import RateLimiter, StackOptions\n\n# With custom archival settings\nlimiter = RateLimiter(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        enable_audit_archival=True,  # Default\n        audit_archive_glacier_days=180,  # Custom transition period\n    ),\n)\n</code></pre>"},{"location":"infra/auditing/#s3-bucket-structure","title":"S3 Bucket Structure","text":"<p>Archives are stored in an S3 bucket with a name auto-generated by CloudFormation, with date-based partitioning for efficient querying. The bucket name is available in the CloudFormation stack outputs (<code>AuditArchiveBucketName</code>).</p> <pre><code>s3://&lt;auto-generated-bucket-name&gt;/\n  audit/\n    year=YYYY/\n      month=MM/\n        day=DD/\n          audit-{request_id}-{timestamp}.jsonl.gz\n</code></pre> <p>Each file contains newline-delimited JSON records (gzip compressed):</p> <pre><code>{\"event_id\": \"01HQXYZ...\", \"action\": \"limits_set\", \"entity_id\": \"api-key-123\", ...}\n{\"event_id\": \"01HQXYZ...\", \"action\": \"entity_created\", \"entity_id\": \"api-key-456\", ...}\n</code></pre>"},{"location":"infra/auditing/#s3-bucket-security","title":"S3 Bucket Security","text":"<p>The archive bucket is created with security best practices:</p> <ul> <li>Server-side encryption: AES256 (S3-managed keys)</li> <li>Public access blocked: All public access settings disabled</li> <li>Lifecycle policy: Automatic transition to Glacier Instant Retrieval</li> </ul>"},{"location":"infra/auditing/#querying-archived-events","title":"Querying Archived Events","text":"<p>Use Amazon Athena to query archived audit events:</p> <pre><code>-- Create external table (one-time setup)\nCREATE EXTERNAL TABLE audit_archive (\n    event_id STRING,\n    timestamp STRING,\n    action STRING,\n    entity_id STRING,\n    principal STRING,\n    resource STRING,\n    details STRING\n)\nPARTITIONED BY (year STRING, month STRING, day STRING)\nROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'\nLOCATION 's3://&lt;audit-archive-bucket-name&gt;/audit/'\nTBLPROPERTIES ('compressionType'='gzip');\n\n-- Load partitions\nMSCK REPAIR TABLE audit_archive;\n\n-- Query audit events\nSELECT * FROM audit_archive\nWHERE year = '2024' AND month = '01'\nAND action = 'limits_set';\n</code></pre>"},{"location":"infra/auditing/#cloudformation-resources","title":"CloudFormation Resources","text":"<p>When audit archival is enabled, the following resources are created:</p> Resource Name Pattern Purpose S3 Bucket <code>{stack-name}-audit-archive</code> Archive storage IAM Policy (inline) Lambda S3:PutObject permission"},{"location":"infra/auditing/#cloudformation-outputs","title":"CloudFormation Outputs","text":"Output Description <code>AuditArchiveBucketName</code> S3 bucket name for archives <code>AuditArchiveBucketArn</code> S3 bucket ARN"},{"location":"infra/auditing/#dynamodb-access-patterns","title":"DynamoDB Access Patterns","text":"<p>Audit events are stored in the same DynamoDB table with the following schema:</p> Key Format Description PK <code>AUDIT#{entity_id}</code> Groups events by entity SK <code>#AUDIT#{event_id}</code> Sorts by event ID (chronological)"},{"location":"infra/auditing/#direct-dynamodb-queries","title":"Direct DynamoDB Queries","text":"<p>For advanced use cases, query audit events directly:</p> <pre><code>import boto3\n\ndynamodb = boto3.resource(\"dynamodb\")\ntable = dynamodb.Table(\"limiter\")\n\n# Query all audit events for an entity\nresponse = table.query(\n    KeyConditionExpression=\"PK = :pk AND begins_with(SK, :sk)\",\n    ExpressionAttributeValues={\n        \":pk\": \"AUDIT#api-key-123\",\n        \":sk\": \"#AUDIT#\",\n    },\n    ScanIndexForward=False,  # Most recent first\n    Limit=100,\n)\n\nfor item in response[\"Items\"]:\n    print(f\"{item['timestamp']}: {item['action']}\")\n</code></pre>"},{"location":"infra/auditing/#use-cases","title":"Use Cases","text":""},{"location":"infra/auditing/#compliance-auditing","title":"Compliance Auditing","text":"<p>Answer \"who changed what, when?\" for SOC2, HIPAA, or internal audits:</p> <pre><code>from zae_limiter import RateLimiter\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\n# Find all changes to a specific entity\nevents = await limiter.get_audit_events(entity_id=\"sensitive-api-key\")\n\nfor event in events:\n    print(f\"\"\"\n    Time: {event.timestamp}\n    Action: {event.action}\n    By: {event.principal or 'unknown'}\n    Details: {event.details}\n    \"\"\")\n</code></pre>"},{"location":"infra/auditing/#troubleshooting","title":"Troubleshooting","text":"<p>Investigate when limits were changed:</p> <pre><code>from zae_limiter import RateLimiter, AuditAction\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\n# Filter for limit changes\nevents = await limiter.get_audit_events(entity_id=\"api-key-123\")\nlimit_changes = [e for e in events if e.action in (\n    AuditAction.LIMITS_SET,\n    AuditAction.LIMITS_DELETED,\n)]\n\nfor event in limit_changes:\n    print(f\"{event.timestamp}: {event.action}\")\n    if event.details.get(\"limits\"):\n        for limit in event.details[\"limits\"]:\n            print(f\"  - {limit['name']}: {limit['capacity']}\")\n</code></pre>"},{"location":"infra/auditing/#security-incident-response","title":"Security Incident Response","text":"<p>Track entity deletions during an incident window:</p> <pre><code>from zae_limiter import RateLimiter, AuditAction\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\nevents = await limiter.get_audit_events(entity_id=\"compromised-key\")\ndeletions = [\n    e for e in events\n    if e.action == AuditAction.ENTITY_DELETED\n]\n\nfor event in deletions:\n    print(f\"Deleted at {event.timestamp} by {event.principal}\")\n</code></pre>"},{"location":"infra/auditing/#next-steps","title":"Next Steps","text":"<ul> <li>Production Deployment - Security best practices</li> <li>Monitoring - Observability and alerting</li> <li>API Reference - AuditEvent and AuditAction details</li> </ul>"},{"location":"infra/cloudformation/","title":"CloudFormation Template","text":"<p>This guide covers the CloudFormation template used by zae-limiter and how to customize it.</p>"},{"location":"infra/cloudformation/#template-overview","title":"Template Overview","text":"<p>The template creates:</p> flowchart TB     subgraph stack[CloudFormation Stack]         subgraph data[Data Layer]             table[(DynamoDB Table)]             stream([DynamoDB Stream])             s3[(S3 Bucket&lt;br/&gt;audit archive)]         end          subgraph compute[Compute Layer]             role[IAM Role]             lambda[[Lambda Aggregator]]         end          subgraph iam[Application IAM Policies]             acqPolicy[AcquireOnlyPolicy]             fullPolicy[FullAccessPolicy]             readPolicy[ReadOnlyPolicy]         end          subgraph observe[Observability]             logs[(CloudWatch Logs)]             alarms([CloudWatch Alarms])             dlq([Dead Letter Queue])         end     end      table --&gt; stream     stream --&gt; lambda     lambda --&gt; table     lambda --&gt; s3     role --&gt; lambda     lambda --&gt; logs     lambda -.-&gt;|on failure| dlq     alarms -.-&gt; lambda     alarms -.-&gt; dlq      acqPolicy -.-&gt; table     fullPolicy -.-&gt; table     readPolicy -.-&gt; table      click table \"#dynamodb-table\"     click stream \"#stream-configuration\"     click s3 \"#s3-audit-archive-bucket\"     click lambda \"#lambda-aggregator\"     click role \"#iam-permissions\"     click acqPolicy \"#application-iam-policies\"     click fullPolicy \"#application-iam-policies\"     click readPolicy \"#application-iam-policies\"     click dlq \"#add-dead-letter-queue\"     click alarms \"#add-cloudwatch-alarms\""},{"location":"infra/cloudformation/#export-template","title":"Export Template","text":"<pre><code># Export to file\nzae-limiter cfn-template &gt; template.yaml\n\n# View template\nzae-limiter cfn-template | less\n</code></pre>"},{"location":"infra/cloudformation/#template-parameters","title":"Template Parameters","text":"<p>The DynamoDB table name is automatically derived from the CloudFormation stack name using the <code>AWS::StackName</code> pseudo-parameter. This ensures consistency between stack and resource names.</p> Parameter Type Default Description <code>SnapshotWindows</code> String <code>hourly,daily</code> Comma-separated list of snapshot windows <code>SnapshotRetentionDays</code> Number <code>90</code> Days to retain usage snapshots (1-3650) <code>LambdaMemorySize</code> Number <code>256</code> Memory for aggregator Lambda (128-3008 MB) <code>LambdaTimeout</code> Number <code>60</code> Timeout for aggregator Lambda (1-900 seconds) <code>LambdaDurationThreshold</code> Number <code>54000</code> Duration alarm threshold in ms (90% of timeout) <code>EnableAggregator</code> String <code>true</code> Whether to deploy the aggregator Lambda <code>SchemaVersion</code> String <code>1.0.0</code> Schema version for infrastructure <code>PITRRecoveryPeriodDays</code> String (empty) PITR period (1-35 days, empty for AWS default) <code>EnableAlarms</code> String <code>true</code> Whether to deploy CloudWatch alarms <code>AlarmSNSTopicArn</code> String (empty) SNS topic ARN for alarm notifications <code>LogRetentionDays</code> Number <code>30</code> CloudWatch log retention (standard periods) <code>PermissionBoundary</code> String (empty) IAM permission boundary (ARN or policy name) <code>RoleName</code> String (empty) Custom IAM role name (use <code>{}</code> as placeholder for base name) <code>EnableAuditArchival</code> String <code>true</code> Archive expired audit events to S3 <code>AuditArchiveGlacierDays</code> Number <code>90</code> Days before Glacier IR transition (1-3650) <code>EnableTracing</code> String <code>false</code> Enable AWS X-Ray tracing for Lambda <code>EnableIAMRoles</code> String <code>true</code> Create App/Admin/ReadOnly IAM roles <code>EnableDeletionProtection</code> String <code>false</code> Enable DynamoDB table deletion protection"},{"location":"infra/cloudformation/#dynamodb-table","title":"DynamoDB Table","text":""},{"location":"infra/cloudformation/#schema","title":"Schema","text":"<pre><code>AttributeDefinitions:\n  - AttributeName: PK\n    AttributeType: S\n  - AttributeName: SK\n    AttributeType: S\n  - AttributeName: GSI1PK\n    AttributeType: S\n  - AttributeName: GSI1SK\n    AttributeType: S\n  - AttributeName: GSI2PK\n    AttributeType: S\n  - AttributeName: GSI2SK\n    AttributeType: S\n\nKeySchema:\n  - AttributeName: PK\n    KeyType: HASH\n  - AttributeName: SK\n    KeyType: RANGE\n</code></pre>"},{"location":"infra/cloudformation/#global-secondary-indexes","title":"Global Secondary Indexes","text":"<p>GSI1 - Parent to children lookups:</p> <pre><code>GlobalSecondaryIndexes:\n  - IndexName: GSI1\n    KeySchema:\n      - AttributeName: GSI1PK  # PARENT#{parent_id}\n        KeyType: HASH\n      - AttributeName: GSI1SK  # CHILD#{child_id}\n        KeyType: RANGE\n</code></pre> <p>GSI2 - Resource aggregation:</p> <pre><code>  - IndexName: GSI2\n    KeySchema:\n      - AttributeName: GSI2PK  # RESOURCE#{resource}\n        KeyType: HASH\n      - AttributeName: GSI2SK  # BUCKET#{entity_id}#{limit_name}\n        KeyType: RANGE\n</code></pre>"},{"location":"infra/cloudformation/#stream-configuration","title":"Stream Configuration","text":"<pre><code>StreamSpecification:\n  StreamViewType: NEW_AND_OLD_IMAGES\n</code></pre>"},{"location":"infra/cloudformation/#s3-audit-archive-bucket","title":"S3 Audit Archive Bucket","text":"<p>When <code>EnableAuditArchival</code> is <code>true</code>, the template creates an S3 bucket to store expired audit events.</p> <pre><code>AuditArchiveBucket:\n  Type: AWS::S3::Bucket\n  Condition: DeployAuditArchive\n  Properties:\n    # BucketName omitted: CloudFormation auto-generates a globally unique name\n    BucketEncryption:\n      ServerSideEncryptionConfiguration:\n        - ServerSideEncryptionByDefault:\n            SSEAlgorithm: AES256\n    PublicAccessBlockConfiguration:\n      BlockPublicAcls: true\n      BlockPublicPolicy: true\n      IgnorePublicAcls: true\n      RestrictPublicBuckets: true\n    LifecycleConfiguration:\n      Rules:\n        - Id: GlacierTransition\n          Status: Enabled\n          Prefix: audit/\n          Transitions:\n            - StorageClass: GLACIER_IR\n              TransitionInDays: !Ref AuditArchiveGlacierDays\n</code></pre>"},{"location":"infra/cloudformation/#object-structure","title":"Object Structure","text":"<p>Archived audit events are stored as gzip-compressed JSONL files:</p> <pre><code>s3://&lt;auto-generated-bucket-name&gt;/\n  audit/\n    year=2024/\n      month=01/\n        day=15/\n          audit-{request_id}-{timestamp}.jsonl.gz\n</code></pre>"},{"location":"infra/cloudformation/#lifecycle-policy","title":"Lifecycle Policy","text":"<p>Objects transition to Glacier Instant Retrieval after <code>AuditArchiveGlacierDays</code> (default: 90 days) for cost-effective long-term storage while maintaining millisecond retrieval times.</p>"},{"location":"infra/cloudformation/#lambda-aggregator","title":"Lambda Aggregator","text":"<p>The aggregator Lambda processes DynamoDB Stream events to maintain usage snapshots and archive expired audit events.</p> <p>Performance Tuning</p> <p>For guidance on memory tuning, concurrency management, and error handling configuration, see the Performance Tuning Guide.</p>"},{"location":"infra/cloudformation/#function-configuration","title":"Function Configuration","text":"<pre><code>AggregatorFunction:\n  Type: AWS::Lambda::Function\n  Properties:\n    Runtime: python3.12\n    Handler: zae_limiter_aggregator.handler.handler\n    MemorySize: 256\n    Timeout: 60\n    Environment:\n      Variables:\n        TABLE_NAME: !Ref AWS::StackName\n        SNAPSHOT_WINDOWS: !Ref SnapshotWindows\n        SNAPSHOT_TTL_DAYS: !Ref SnapshotRetentionDays\n        # When audit archival is enabled:\n        ENABLE_ARCHIVAL: \"true\"\n        ARCHIVE_BUCKET_NAME: !Ref AuditArchiveBucket\n</code></pre>"},{"location":"infra/cloudformation/#event-source-mapping","title":"Event Source Mapping","text":"<pre><code>StreamEventMapping:\n  Type: AWS::Lambda::EventSourceMapping\n  Properties:\n    EventSourceArn: !GetAtt Table.StreamArn\n    FunctionName: !Ref AggregatorFunction\n    StartingPosition: LATEST\n    BatchSize: 100\n    MaximumBatchingWindowInSeconds: 5\n</code></pre>"},{"location":"infra/cloudformation/#iam-permissions","title":"IAM Permissions","text":""},{"location":"infra/cloudformation/#lambda-execution-role","title":"Lambda Execution Role","text":"<pre><code>AggregatorRole:\n  Type: AWS::IAM::Role\n  Properties:\n    AssumeRolePolicyDocument:\n      Statement:\n        - Effect: Allow\n          Principal:\n            Service: lambda.amazonaws.com\n          Action: sts:AssumeRole\n    Policies:\n      - PolicyName: DynamoDBAccess\n        PolicyDocument:\n          Statement:\n            - Effect: Allow\n              Action:\n                - dynamodb:GetItem\n                - dynamodb:PutItem\n                - dynamodb:UpdateItem\n                - dynamodb:Query\n              Resource: !GetAtt Table.Arn\n            - Effect: Allow\n              Action:\n                - dynamodb:GetRecords\n                - dynamodb:GetShardIterator\n                - dynamodb:DescribeStream\n                - dynamodb:ListStreams\n              Resource: !Sub \"${Table.Arn}/stream/*\"\n            # When audit archival is enabled:\n            - Effect: Allow\n              Action:\n                - s3:PutObject\n              Resource: !Sub \"${AuditArchiveBucket.Arn}/*\"\n</code></pre>"},{"location":"infra/cloudformation/#application-iam-policies","title":"Application IAM Policies","text":"<p>The template creates three IAM managed policies by default for different access patterns. These policies can be attached to your own IAM roles, users, or federated identities.</p>"},{"location":"infra/cloudformation/#policy-summary","title":"Policy Summary","text":"Policy Suffix Use Case DynamoDB Permissions <code>AcquireOnlyPolicy</code> <code>-acq</code> Applications calling <code>acquire()</code> GetItem, BatchGetItem, Query, TransactWriteItems <code>FullAccessPolicy</code> <code>-full</code> Ops teams managing config All of the above + PutItem, DeleteItem, UpdateItem, BatchWriteItem, Scan, DescribeTable <code>ReadOnlyPolicy</code> <code>-read</code> Monitoring and dashboards GetItem, BatchGetItem, Query, Scan, DescribeTable"},{"location":"infra/cloudformation/#permission-matrix","title":"Permission Matrix","text":"Action ReadOnly AcquireOnly FullAccess <code>GetItem</code> Y Y Y <code>BatchGetItem</code> Y Y Y <code>Query</code> Y Y Y <code>Scan</code> Y -- Y <code>DescribeTable</code> Y -- Y <code>TransactWriteItems</code> -- Y Y <code>PutItem</code> -- -- Y <code>UpdateItem</code> -- -- Y <code>DeleteItem</code> -- -- Y <code>BatchWriteItem</code> -- -- Y"},{"location":"infra/cloudformation/#iam-roles-opt-in","title":"IAM Roles (Opt-In)","text":"<p>When <code>EnableIAMRoles</code> is <code>true</code> (or <code>--create-iam-roles</code> is passed), the template also creates IAM roles that attach these managed policies. All roles trust the same AWS account root principal:</p> <pre><code>AssumeRolePolicyDocument:\n  Version: '2012-10-17'\n  Statement:\n    - Effect: Allow\n      Principal:\n        AWS: !Sub arn:${AWS::Partition}:iam::${AWS::AccountId}:root\n      Action: sts:AssumeRole\n</code></pre>"},{"location":"infra/cloudformation/#policy-and-role-naming","title":"Policy and Role Naming","text":"<ul> <li>Policies: <code>${StackName}-{acq,full,read}</code> (e.g., <code>my-app-acq</code>)</li> <li>Roles (when enabled): <code>${StackName}-{acq,full,read}</code> (same naming)</li> <li>With custom <code>PolicyNameFormat</code> / <code>RoleName</code>: format pattern applied to all</li> </ul> <p>Policies and roles respect <code>PermissionBoundary</code> if configured.</p>"},{"location":"infra/cloudformation/#usage-example","title":"Usage Example","text":"<pre><code>import boto3\n\n# Attach AcquireOnlyPolicy to your own role, or assume a created role\nsts = boto3.client('sts')\ncredentials = sts.assume_role(\n    RoleArn='arn:aws:iam::123456789012:role/my-app-acq',\n    RoleSessionName='my-app'\n)['Credentials']\n\n# Use assumed credentials\nsession = boto3.Session(\n    aws_access_key_id=credentials['AccessKeyId'],\n    aws_secret_access_key=credentials['SecretAccessKey'],\n    aws_session_token=credentials['SessionToken']\n)\n</code></pre>"},{"location":"infra/cloudformation/#customization","title":"Customization","text":""},{"location":"infra/cloudformation/#add-dead-letter-queue","title":"Add Dead Letter Queue","text":"<pre><code>Parameters:\n  EnableDLQ:\n    Type: String\n    Default: \"false\"\n    AllowedValues: [\"true\", \"false\"]\n\nConditions:\n  CreateDLQ: !Equals [!Ref EnableDLQ, \"true\"]\n\nResources:\n  DeadLetterQueue:\n    Type: AWS::SQS::Queue\n    Condition: CreateDLQ\n    Properties:\n      QueueName: !Sub \"${AWS::StackName}-aggregator-dlq\"\n      MessageRetentionPeriod: 1209600  # 14 days\n\n  StreamEventMapping:\n    Properties:\n      DestinationConfig:\n        OnFailure:\n          Destination: !If\n            - CreateDLQ\n            - !GetAtt DeadLetterQueue.Arn\n            - !Ref AWS::NoValue\n</code></pre>"},{"location":"infra/cloudformation/#add-cloudwatch-alarms","title":"Add CloudWatch Alarms","text":"<pre><code>ReadThrottleAlarm:\n  Type: AWS::CloudWatch::Alarm\n  Properties:\n    AlarmName: !Sub \"${AWS::StackName}-read-throttle\"\n    AlarmDescription: Alert when DynamoDB read requests are throttled\n    MetricName: ReadThrottleEvents\n    Namespace: AWS/DynamoDB\n    Statistic: Sum\n    Period: 300  # 5 minutes\n    EvaluationPeriods: 2\n    Threshold: 1\n    ComparisonOperator: GreaterThanThreshold\n    Dimensions:\n      - Name: TableName\n        Value: !Ref RateLimitsTable\n    TreatMissingData: notBreaching\n    AlarmActions: !If\n      - HasSNSTopic\n      - [!Ref AlarmSNSTopicArn]\n      - !Ref AWS::NoValue\n</code></pre>"},{"location":"infra/cloudformation/#enable-encryption-with-cmk","title":"Enable Encryption with CMK","text":"<pre><code>Parameters:\n  KmsKeyArn:\n    Type: String\n    Default: \"\"\n\nConditions:\n  UseCustomKey: !Not [!Equals [!Ref KmsKeyArn, \"\"]]\n\nResources:\n  Table:\n    Properties:\n      SSESpecification:\n        SSEEnabled: true\n        SSEType: !If [UseCustomKey, \"KMS\", \"AWS_OWNED_KEY\"]\n        KMSMasterKeyId: !If [UseCustomKey, !Ref KmsKeyArn, !Ref AWS::NoValue]\n</code></pre>"},{"location":"infra/cloudformation/#deployment-examples","title":"Deployment Examples","text":""},{"location":"infra/cloudformation/#basic-deployment","title":"Basic Deployment","text":"<pre><code>aws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name zae-limiter \\\n    --capabilities CAPABILITY_NAMED_IAM\n</code></pre>"},{"location":"infra/cloudformation/#with-custom-parameters","title":"With Custom Parameters","text":"<pre><code>aws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name prod \\\n    --parameter-overrides \\\n        PITRRecoveryPeriodDays=35 \\\n        SnapshotRetentionDays=365 \\\n        LogRetentionDays=90 \\\n        EnableAlarms=true \\\n    --capabilities CAPABILITY_NAMED_IAM\n</code></pre> <p>Note: The DynamoDB table name is automatically set to match the stack name (e.g., <code>prod</code>).</p>"},{"location":"infra/cloudformation/#using-sam","title":"Using SAM","text":"<pre><code># samconfig.toml\n[default.deploy.parameters]\nstack_name = \"limiter\"\ncapabilities = \"CAPABILITY_NAMED_IAM\"\n</code></pre> <pre><code>sam deploy --guided\n</code></pre>"},{"location":"infra/cloudformation/#outputs","title":"Outputs","text":"<p>The template exports:</p> Output Description <code>TableArn</code> DynamoDB table ARN <code>StreamArn</code> DynamoDB stream ARN <code>FunctionArn</code> Lambda function ARN <code>AuditArchiveBucketName</code> S3 bucket for audit archives (when enabled) <code>AuditArchiveBucketArn</code> S3 bucket ARN (when enabled) <code>AcquireOnlyPolicyArn</code> IAM policy ARN for acquire-only access <code>FullAccessPolicyArn</code> IAM policy ARN for full access <code>ReadOnlyPolicyArn</code> IAM policy ARN for read-only access <code>AppRoleArn</code> IAM role ARN for application access (when IAM roles enabled) <code>AppRoleName</code> IAM role name for application access <code>AdminRoleArn</code> IAM role ARN for admin access <code>AdminRoleName</code> IAM role name for admin access <code>ReadOnlyRoleArn</code> IAM role ARN for read-only access <code>ReadOnlyRoleName</code> IAM role name for read-only access <p>Access outputs:</p> <pre><code>aws cloudformation describe-stacks \\\n    --stack-name zae-limiter \\\n    --query \"Stacks[0].Outputs\"\n</code></pre>"},{"location":"infra/cloudformation/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment - Deployment guide</li> <li>LocalStack - Local development</li> </ul>"},{"location":"infra/deployment/","title":"Deployment","text":"<p>This guide covers deploying zae-limiter infrastructure to AWS.</p>"},{"location":"infra/deployment/#overview","title":"Overview","text":"<p>zae-limiter uses CloudFormation to deploy:</p> <ul> <li>DynamoDB Table - Stores rate limit state, entities, and usage data</li> <li>DynamoDB Streams - Captures changes for usage aggregation</li> <li>Lambda Function - Aggregates usage into hourly/daily snapshots, proactively refills token buckets for active entities, and archives audit events</li> <li>S3 Bucket - Archives expired audit events (when audit archival is enabled)</li> <li>IAM Policies - Least-privilege managed policies (AcquireOnly/FullAccess/ReadOnly)</li> <li>CloudWatch Logs - Lambda function logs</li> </ul>"},{"location":"infra/deployment/#cli-deployment-recommended","title":"CLI Deployment (Recommended)","text":"<p>The simplest way to deploy:</p> <pre><code># Deploy with defaults\nzae-limiter deploy --name limiter --region us-east-1\n\n# Deploy with custom settings\nzae-limiter deploy \\\n    --name limiter \\\n    --region us-east-1 \\\n    --log-retention-days 90 \\\n    --pitr-recovery-days 7\n</code></pre>"},{"location":"infra/deployment/#cli-options","title":"CLI Options","text":"Option Description Default <code>--name</code> Resource identifier <code>limiter</code> <code>--region</code> AWS region boto3 default <code>--endpoint-url</code> Custom endpoint (LocalStack) None <code>--enable-aggregator/--no-aggregator</code> Deploy Lambda aggregator <code>true</code> <code>--log-retention-days</code> CloudWatch log retention <code>30</code> <code>--usage-retention-days</code> Usage snapshot retention <code>90</code> <code>--audit-retention-days</code> Audit record retention in DynamoDB <code>90</code> <code>--pitr-recovery-days</code> Point-in-time recovery (1-35 days) None (disabled) <code>--enable-audit-archival/--no-audit-archival</code> Archive expired audit events to S3 <code>true</code> <code>--audit-archive-glacier-days</code> Days before Glacier IR transition <code>90</code> <code>--enable-iam-roles/--no-iam-roles</code> Create App/Admin/ReadOnly IAM roles <code>true</code> <code>--enable-deletion-protection/--no-deletion-protection</code> Enable DynamoDB table deletion protection <code>false</code> <p>For the full list of options, see the CLI Reference.</p>"},{"location":"infra/deployment/#check-stack-status","title":"Check Stack Status","text":"CLIProgrammatic <pre><code>zae-limiter status --name limiter --region us-east-1\n</code></pre> <pre><code>from zae_limiter import Repository\n\nrepo = Repository(name=\"limiter\", region=\"us-east-1\")\n\navailable = await repo.ping()  # Returns True if DynamoDB is reachable\n\nif available:\n    print(\"Stack is ready\")\nelse:\n    print(\"DynamoDB not reachable\")\n</code></pre> <p>For comprehensive status including CloudFormation details, use the CLI command.</p>"},{"location":"infra/deployment/#discover-deployed-instances","title":"Discover Deployed Instances","text":"<p>List all zae-limiter stacks in a region:</p> CLIProgrammatic <pre><code>zae-limiter list --region us-east-1\n</code></pre> <p>Output: <pre><code>Rate Limiter Instances (us-east-1)\n===========================================================================================\n\nName                 Status                    Version      Lambda       Schema     Created\n-------------------------------------------------------------------------------------------\nprod-api             \u2713 CREATE_COMPLETE         0.2.0        0.2.0        1.0.0      2024-01-15\nstaging              \u2713 CREATE_COMPLETE         0.2.0        0.2.0        1.0.0      2024-01-10\ndev-test             \u23f3 UPDATE_IN_PROGRESS     0.1.0        0.1.0        1.0.0      2023-12-01\n\nTotal: 3 instance(s)\n\u26a0\ufe0f  1 instance(s) need attention\n</code></pre></p> <pre><code>from zae_limiter import RateLimiter, LimiterInfo\n\n# List all deployed limiters in a region\nlimiters = await RateLimiter.list_deployed(region=\"us-east-1\")\n\nfor limiter in limiters:\n    if limiter.is_healthy:\n        print(f\"\u2713 {limiter.user_name}: {limiter.version}\")\n    elif limiter.is_failed:\n        print(f\"\u2717 {limiter.user_name}: {limiter.stack_status}\")\n    elif limiter.is_in_progress:\n        print(f\"\u23f3 {limiter.user_name}: {limiter.stack_status}\")\n</code></pre> <p>The <code>LimiterInfo</code> object provides:</p> <ul> <li><code>stack_name</code> / <code>user_name</code> - Full and user-friendly names</li> <li><code>stack_status</code> - CloudFormation status</li> <li><code>version</code> / <code>lambda_version</code> / <code>schema_version</code> - Version info from tags</li> <li><code>is_healthy</code> / <code>is_in_progress</code> / <code>is_failed</code> - Status helpers</li> </ul>"},{"location":"infra/deployment/#delete-stack","title":"Delete Stack","text":"<pre><code>zae-limiter delete --name limiter --region us-east-1 --yes\n</code></pre>"},{"location":"infra/deployment/#admin-vs-application-workflow","title":"Admin vs Application Workflow","text":"<p>zae-limiter supports separation of concerns between infrastructure administrators and application developers.</p>"},{"location":"infra/deployment/#admin-workflow-infrastructure-config","title":"Admin Workflow (Infrastructure &amp; Config)","text":"<p>Admins deploy infrastructure and configure rate limits centrally:</p> <pre><code># 1. Deploy infrastructure\nzae-limiter deploy --name prod --region us-east-1\n\n# 2. Configure system-wide defaults\nzae-limiter system set-defaults -l rpm:100 -l tpm:10000 --on-unavailable block\n\n# 3. Configure resource-specific limits\nzae-limiter resource set-defaults gpt-4 -l rpm:50 -l tpm:100000\nzae-limiter resource set-defaults gpt-3.5-turbo -l rpm:200 -l tpm:500000\n\n# 4. Configure premium user tiers\nzae-limiter entity set-limits user-premium --resource gpt-4 -l rpm:500 -l tpm:500000\n</code></pre>"},{"location":"infra/deployment/#application-workflow-connect-only","title":"Application Workflow (Connect Only)","text":"<p>Application code connects to existing infrastructure without managing it:</p> <pre><code>from zae_limiter import Repository, RateLimiter\n\n# Connect only - no stack_options means no infrastructure changes\nrepo = Repository(name=\"prod\", region=\"us-east-1\")\nlimiter = RateLimiter(repository=repo)\n\n# Limits are automatically resolved from stored config\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"gpt-4\",\n    limits=None,  # Auto-resolves: Entity &gt; Resource &gt; System\n    consume={\"rpm\": 1},\n) as lease:\n    await call_api()\n</code></pre>"},{"location":"infra/deployment/#benefits","title":"Benefits","text":"Concern Admin Application Infrastructure \u2713 Deploy, update, delete stacks Connect only Rate limits \u2713 Configure at all levels Auto-resolved Credentials Full AWS access (or FullAccessPolicy) DynamoDB read/write only (or AcquireOnlyPolicy) Changes Through CLI/IaC None <p>This separation allows:</p> <ul> <li>Centralized control - Admins manage limits without code changes</li> <li>Simplified apps - No hardcoded limits, automatic resolution</li> <li>Audit trail - All config changes logged to DynamoDB</li> <li>Dynamic updates - Change limits without redeploying apps</li> </ul> <p>See Configuration Hierarchy for limit resolution details.</p>"},{"location":"infra/deployment/#stack-lifecycle-management","title":"Stack Lifecycle Management","text":""},{"location":"infra/deployment/#programmatic-cleanup","title":"Programmatic Cleanup","text":"<p>In addition to the CLI, you can manage stack lifecycle programmatically using the Repository's <code>delete_stack()</code> method:</p> <pre><code>from zae_limiter import Repository, RateLimiter, StackOptions\n\n# Create repository with infrastructure options\nrepo = Repository(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\nawait repo.ensure_infrastructure()\n\nlimiter = RateLimiter(repository=repo)\n\n# Use the limiter...\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    consume={\"requests\": 1},\n    limits=[],\n) as lease:\n    pass\n\n# Delete stack when done\nawait repo.delete_stack()\n</code></pre>"},{"location":"infra/deployment/#use-case-guidance","title":"Use-Case Guidance","text":""},{"location":"infra/deployment/#development-and-prototyping","title":"Development and Prototyping","text":"<p>For rapid iteration, declare infrastructure with cleanup:</p> <pre><code>from zae_limiter import Repository, RateLimiter, StackOptions\n\nasync def dev_session():\n    repo = Repository(\n        name=\"dev\",\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n    await repo.ensure_infrastructure()\n    limiter = RateLimiter(repository=repo)\n\n    try:\n        # Development work...\n        pass\n    finally:\n        # Clean up development stack\n        await repo.delete_stack()\n</code></pre>"},{"location":"infra/deployment/#production","title":"Production","text":"<p>For production deployments, see the Production Guide covering:</p> <ul> <li>Production checklist (PITR, alarms, SNS)</li> <li>Security best practices</li> <li>Multi-region considerations</li> <li>Cost estimation</li> </ul>"},{"location":"infra/deployment/#cloudformation-template","title":"CloudFormation Template","text":"<p>Export and customize the template:</p> <pre><code># Export template\nzae-limiter cfn-template &gt; template.yaml\n\n# Deploy with AWS CLI\naws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name limiter \\\n    --parameter-overrides \\\n        SnapshotRetentionDays=90 \\\n        EnablePITR=true \\\n    --capabilities CAPABILITY_NAMED_IAM\n\n# Deploy Lambda code separately (function name is {stack-name}-aggregator)\nzae-limiter lambda-export --output lambda.zip\naws lambda update-function-code \\\n    --function-name limiter-aggregator \\\n    --zip-file fileb://lambda.zip\n</code></pre>"},{"location":"infra/deployment/#template-parameters","title":"Template Parameters","text":"Parameter Description Default <code>SnapshotWindows</code> Aggregation windows <code>hourly,daily</code> <code>SnapshotRetentionDays</code> Usage data retention <code>90</code> <code>EnablePITR</code> Point-in-time recovery <code>false</code> <code>LogRetentionDays</code> CloudWatch log retention <code>14</code>"},{"location":"infra/deployment/#programmatic-creation","title":"Programmatic Creation","text":"<p>Create infrastructure directly from your application:</p> <pre><code>from zae_limiter import Repository, RateLimiter, StackOptions\n\nrepo = Repository(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        snapshot_windows=\"hourly,daily\",\n        usage_retention_days=90,\n    ),\n)\nawait repo.ensure_infrastructure()\nlimiter = RateLimiter(repository=repo)\n</code></pre> <p><code>StackOptions</code> declares the desired infrastructure state. CloudFormation ensures the actual infrastructure matches your declaration\u2014creating, updating, or leaving unchanged as needed.</p> <p>Deployment Options</p> <p>For organizations requiring strict infrastructure/application separation, use CLI deployment or CloudFormation template export. See the Production Guide for deployment recommendations.</p>"},{"location":"infra/deployment/#infrastructure-details","title":"Infrastructure Details","text":""},{"location":"infra/deployment/#dynamodb-table","title":"DynamoDB Table","text":"<ul> <li>Billing: Pay-per-request (on-demand)</li> <li>Encryption: AWS-managed keys (default)</li> <li>Streams: NEW_AND_OLD_IMAGES for Lambda trigger</li> </ul>"},{"location":"infra/deployment/#dynamodb-schema","title":"DynamoDB Schema","text":"Key Pattern Purpose PK <code>ENTITY#{id}</code> Partition key SK <code>#META</code>, <code>#BUCKET#...</code>, <code>#LIMIT#...</code> Sort key GSI1PK <code>PARENT#{id}</code> Parent lookups GSI2PK <code>RESOURCE#{name}</code> Resource aggregation"},{"location":"infra/deployment/#lambda-function","title":"Lambda Function","text":"<ul> <li>Runtime: Python 3.12</li> <li>Memory: 256 MB</li> <li>Timeout: 60 seconds</li> <li>Trigger: DynamoDB Streams</li> </ul>"},{"location":"infra/deployment/#iam-permissions","title":"IAM Permissions","text":"<p>The Lambda function has minimal permissions:</p> <pre><code>- dynamodb:GetItem\n- dynamodb:PutItem\n- dynamodb:UpdateItem\n- dynamodb:Query\n</code></pre> <p>When X-Ray tracing is enabled, additional permissions are granted:</p> <pre><code>- xray:PutTraceSegments\n- xray:PutTelemetryRecords\n</code></pre>"},{"location":"infra/deployment/#aws-x-ray-tracing","title":"AWS X-Ray Tracing","text":"<p>Enable X-Ray tracing to gain visibility into Lambda aggregator performance and troubleshoot issues.</p>"},{"location":"infra/deployment/#enabling-tracing","title":"Enabling Tracing","text":"CLIProgrammatic <pre><code>zae-limiter deploy --name limiter --region us-east-1 --enable-tracing\n</code></pre> <pre><code>from zae_limiter import Repository, RateLimiter, StackOptions\n\nrepo = Repository(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(enable_tracing=True),\n)\nawait repo.ensure_infrastructure()\nlimiter = RateLimiter(repository=repo)\n</code></pre>"},{"location":"infra/deployment/#key-details","title":"Key Details","text":"Aspect Value Default Disabled (opt-in) Tracing Mode Active IAM Conditional (only when enabled) <p>Why Active Mode?</p> <p>The Lambda aggregator uses Active tracing mode rather than PassThrough because DynamoDB Streams do not propagate X-Ray trace context. Active mode ensures traces are always generated for Lambda invocations regardless of upstream trace headers.</p>"},{"location":"infra/deployment/#what-you-get","title":"What You Get","text":"<p>With X-Ray tracing enabled, you can:</p> <ul> <li>Trace Lambda cold starts - Identify initialization latency</li> <li>Monitor DynamoDB operations - See query and update times</li> <li>Debug failures - Trace errors through the processing pipeline</li> <li>Analyze performance - Find bottlenecks in stream processing</li> </ul>"},{"location":"infra/deployment/#cost-considerations","title":"Cost Considerations","text":"<p>X-Ray charges based on traces recorded and retrieved. For typical usage:</p> <ul> <li>First 100,000 traces/month are free</li> <li>After free tier: $5.00 per million traces recorded</li> </ul> <p>For high-volume deployments, consider sampling strategies or enabling tracing only for troubleshooting.</p>"},{"location":"infra/deployment/#application-iam-policies","title":"Application IAM Policies","text":"<p>The stack creates three managed IAM policies by default for different access patterns. These provide least-privilege access for applications, administrators, and monitoring systems.</p>"},{"location":"infra/deployment/#policy-summary","title":"Policy Summary","text":"Policy Suffix Use Case DynamoDB Permissions <code>AcquireOnlyPolicy</code> <code>-acq</code> Applications calling <code>acquire()</code> GetItem, BatchGetItem, Query, TransactWriteItems <code>FullAccessPolicy</code> <code>-full</code> Ops teams managing config All of the above + PutItem, DeleteItem, UpdateItem, BatchWriteItem, Scan, DescribeTable <code>ReadOnlyPolicy</code> <code>-read</code> Monitoring and dashboards GetItem, BatchGetItem, Query, Scan, DescribeTable"},{"location":"infra/deployment/#enablingdisabling-iam-resources","title":"Enabling/Disabling IAM Resources","text":"CLIProgrammatic <pre><code># Deploy with managed policies (default)\nzae-limiter deploy --name limiter --region us-east-1\n\n# Deploy with managed policies AND IAM roles\nzae-limiter deploy --name limiter --region us-east-1 --create-iam-roles\n\n# Deploy without any IAM resources (for restricted environments)\nzae-limiter deploy --name limiter --region us-east-1 --no-iam\n</code></pre> <pre><code>from zae_limiter import Repository, StackOptions\n\n# With managed policies only (default)\nrepo = Repository(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\n# With managed policies AND IAM roles\nrepo = Repository(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(create_iam_roles=True),\n)\n\n# Without any IAM resources\nrepo = Repository(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(create_iam=False),\n)\n</code></pre>"},{"location":"infra/deployment/#viewing-policy-arns","title":"Viewing Policy ARNs","text":"<p>The <code>status</code> command shows IAM policy ARNs:</p> <pre><code>zae-limiter status --name limiter --region us-east-1\n</code></pre> <p>Output includes: <pre><code>IAM Policies\n  AcquireOnly:   arn:aws:iam::123456789012:policy/limiter-acq\n  FullAccess:    arn:aws:iam::123456789012:policy/limiter-full\n  ReadOnly:      arn:aws:iam::123456789012:policy/limiter-read\n</code></pre></p>"},{"location":"infra/deployment/#policy-naming","title":"Policy Naming","text":"<ul> <li>Default: <code>${StackName}-{acq,full,read}</code> (e.g., <code>limiter-acq</code>)</li> <li>With <code>--policy-name-format</code>: Custom naming pattern applied to all policies</li> </ul> <p>Policies respect <code>--permission-boundary</code> if configured.</p> <p>For detailed IAM configuration and usage examples, see CloudFormation - Application IAM Policies.</p>"},{"location":"infra/deployment/#next-steps","title":"Next Steps","text":"<ul> <li>Production - Production checklist, security, cost estimation</li> <li>CloudFormation - Template details</li> <li>Monitoring - Dashboards, alerts, Logs Insights</li> <li>LocalStack - Local development setup</li> </ul>"},{"location":"infra/production/","title":"Production Deployment","text":"<p>This guide covers production-readiness for zae-limiter deployments.</p>"},{"location":"infra/production/#production-checklist","title":"Production Checklist","text":"<p>Before deploying to production:</p> Feature CLI Flag Default Recommendation Point-in-Time Recovery <code>--pitr-recovery-days N</code> Disabled Enable (7-35 days) CloudWatch Alarms <code>--enable-alarms</code> Enabled Keep enabled SNS Notifications <code>--alarm-sns-topic ARN</code> None Configure for alerts Log Retention <code>--log-retention-days N</code> 30 90+ for compliance Audit Archival <code>--enable-audit-archival</code> Enabled Keep enabled for compliance Glacier Transition <code>--audit-archive-glacier-days N</code> 90 Adjust based on access patterns Permission Boundary <code>--permission-boundary ARN</code> None Use in restricted IAM environments X-Ray Tracing <code>--enable-tracing</code> Disabled Enable for debugging/performance analysis IAM Roles <code>--create-iam-roles</code> Disabled Create App/Admin/ReadOnly roles Skip IAM <code>--no-iam</code> Disabled Skip all IAM resources for restricted environments External Role <code>--aggregator-role-arn ARN</code> None Use existing IAM role for Lambda"},{"location":"infra/production/#example-production-deployment","title":"Example Production Deployment","text":"<pre><code>zae-limiter deploy \\\n    --name prod-limiter \\\n    --region us-east-1 \\\n    --pitr-recovery-days 7 \\\n    --log-retention-days 90 \\\n    --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts \\\n    --enable-audit-archival \\\n    --audit-archive-glacier-days 90\n</code></pre>"},{"location":"infra/production/#security-best-practices","title":"Security Best Practices","text":""},{"location":"infra/production/#encryption","title":"Encryption","text":"<ul> <li>DynamoDB uses AWS-managed keys (SSE-S3) by default</li> <li>For customer-managed keys (CMK), use CloudFormation template customization</li> </ul>"},{"location":"infra/production/#iam","title":"IAM","text":""},{"location":"infra/production/#application-access-policies","title":"Application Access Policies","text":"<p>The stack creates three IAM managed policies by default:</p> Policy Suffix Use Case When to Use AcquireOnlyPolicy <code>-acq</code> Applications calling <code>acquire()</code> Production workloads, Lambda functions, ECS tasks FullAccessPolicy <code>-full</code> Ops teams managing config CLI tools, admin scripts, CI/CD pipelines ReadOnlyPolicy <code>-read</code> Monitoring and dashboards Grafana, CloudWatch dashboards, audit tools <p>Best practices:</p> <ul> <li>Attach AcquireOnlyPolicy for applications - Provides only the permissions needed for rate limiting</li> <li>Attach FullAccessPolicy for config management - Separate from application credentials</li> <li>Attach ReadOnlyPolicy for observability - Safe access for monitoring systems</li> <li>Disable with <code>--no-iam</code> - When using existing IAM policies or cross-account access</li> <li>Create roles with <code>--create-iam-roles</code> - When you want pre-built roles that attach these policies</li> </ul>"},{"location":"infra/production/#lambda-aggregator","title":"Lambda Aggregator","text":"<p>The Lambda aggregator processes DynamoDB Stream events for usage aggregation, proactive bucket refill, and audit archival. It uses a separate execution role with least-privilege permissions:</p> <ul> <li><code>dynamodb:GetItem</code>, <code>PutItem</code>, <code>UpdateItem</code>, <code>Query</code></li> <li><code>s3:PutObject</code> (when audit archival is enabled)</li> </ul>"},{"location":"infra/production/#permission-boundaries","title":"Permission Boundaries","text":"<p>For restricted IAM environments:</p> <ul> <li>Use <code>--permission-boundary</code> to apply organizational policies to all created roles</li> <li>Use <code>--role-name-format</code> for organizational naming conventions</li> </ul> <pre><code># Enterprise deployment with permission boundary\nzae-limiter deploy \\\n    --name prod-limiter \\\n    --permission-boundary arn:aws:iam::123456789012:policy/ServiceBoundary \\\n    --role-name-format \"svc-{}\"\n</code></pre>"},{"location":"infra/production/#iam-behavior-matrix","title":"IAM Behavior Matrix","text":"<p>The following table shows what IAM resources are created based on flag combinations:</p> Flag Combination Policies App Roles Aggr Role Lambda (default) Created No Created Enabled <code>--no-iam</code> No No No Disabled <code>--no-iam --aggregator-role-arn</code> No No External Enabled <code>--aggregator-role-arn</code> Created No External Enabled <code>--create-iam-roles</code> Created Created Created Enabled <code>--no-iam --create-iam-roles</code> Error - - - <p>For PowerUserAccess or similar restricted IAM environments:</p> <pre><code># Deploy without any IAM resources (aggregator disabled)\nzae-limiter deploy --name myapp --no-iam\n\n# Deploy with external Lambda role (aggregator enabled)\nzae-limiter deploy --name myapp --no-iam \\\n    --aggregator-role-arn arn:aws:iam::123456789012:role/MyLambdaRole\n</code></pre>"},{"location":"infra/production/#namespace-scoped-access-control","title":"Namespace-Scoped Access Control","text":"<p>For multi-tenant deployments, namespace-scoped policies restrict each tenant to its own namespace's DynamoDB items using tag-based access control (TBAC).</p> <p>The stack creates three additional namespace-scoped policies:</p> Policy Suffix Use Case Tag Required NamespaceAcquirePolicy <code>-ns-acq</code> Tenant apps calling <code>acquire()</code> Yes NamespaceFullAccessPolicy <code>-ns-full</code> Tenant config management Yes NamespaceReadOnlyPolicy <code>-ns-read</code> Tenant monitoring Yes <p>These policies use <code>dynamodb:LeadingKeys</code> with the <code>zael_namespace_id</code> principal tag to restrict DynamoDB access to items whose partition key starts with the tenant's namespace ID.</p>"},{"location":"infra/production/#single-namespace-most-common","title":"Single Namespace (Most Common)","text":"<p>Attach a namespace-scoped policy and tag the principal with the namespace ID:</p> <pre><code># 1. Deploy the stack (policies are created automatically)\nzae-limiter deploy --name shared-table --region us-east-1\n\n# 2. Look up the default namespace ID\nzae-limiter namespace show default --name shared-table\n# Output:\n# Namespace:    default\n# Namespace ID: default\n# Status:       active\n# Created At:   2025-01-15T10:30:00Z\n\n# 3. Attach the namespace-scoped policy to your app role\naws iam attach-role-policy --role-name my-app-role \\\n  --policy-arn arn:aws:iam::123456789012:policy/shared-table-ns-acq\n\n# 4. Tag the role with the namespace ID\naws iam tag-role --role-name my-app-role \\\n  --tags Key=zael_namespace_id,Value=default\n</code></pre> <p>For additional tenants, register a namespace and use its ID:</p> <pre><code># Register a new tenant namespace\nzae-limiter namespace register tenant-alpha --name shared-table\n\n# Look up the opaque namespace ID\nzae-limiter namespace show tenant-alpha --name shared-table\n# Namespace ID: a7x3kq2m\n\n# Tag the tenant's role\naws iam tag-role --role-name tenant-alpha-role \\\n  --tags Key=zael_namespace_id,Value=a7x3kq2m\n</code></pre>"},{"location":"infra/production/#admin-cross-namespace-access","title":"Admin / Cross-Namespace Access","text":"<p>For admin roles that need access to all namespaces, attach a table-level policy (no tag needed):</p> <pre><code>aws iam attach-role-policy --role-name admin-role \\\n  --policy-arn arn:aws:iam::123456789012:policy/shared-table-full\n</code></pre>"},{"location":"infra/production/#selective-multi-namespace-access","title":"Selective Multi-Namespace Access","text":"<p>Option A: STS Session Policy \u2014 Assume a base role with a session policy that narrows access to specific namespaces:</p> <pre><code>import json\n\nimport boto3\n\nsts = boto3.client(\"sts\")\nns_ids = [\"a7x3kq2m\", \"b9y4lr3n\"]  # resolved namespace IDs\n\nresponse = sts.assume_role(\n    RoleArn=\"arn:aws:iam::123456789012:role/shared-table-base-role\",\n    RoleSessionName=\"multi-tenant-session\",\n    Policy=json.dumps({\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [{\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:GetItem\", \"dynamodb:BatchGetItem\",\n                \"dynamodb:Query\", \"dynamodb:UpdateItem\",\n            ],\n            \"Resource\": \"arn:aws:dynamodb:us-east-1:123456789012:table/shared-table\",\n            \"Condition\": {\n                \"ForAllValues:StringLike\": {\n                    \"dynamodb:LeadingKeys\":\n                        [f\"{ns}/*\" for ns in ns_ids] + [\"_/*\"]\n                }\n            }\n        }]\n    })\n)\n# Use response[\"Credentials\"] for scoped access\n</code></pre> <p>The session policy intersects with the base role's table-level policy, narrowing access to exactly those namespaces.</p> <p>Option B: Custom IAM Policy \u2014 Create a managed policy listing specific namespace IDs:</p> <pre><code># Resolve namespace IDs\nNSID1=$(zae-limiter namespace show tenant-alpha --name shared-table \\\n  | grep \"Namespace ID:\" | awk '{print $3}')\nNSID2=$(zae-limiter namespace show tenant-beta --name shared-table \\\n  | grep \"Namespace ID:\" | awk '{print $3}')\n\n# Create a custom policy for multiple namespaces\naws iam create-policy --policy-name my-multi-ns-policy \\\n  --policy-document \"{\n    \\\"Version\\\": \\\"2012-10-17\\\",\n    \\\"Statement\\\": [{\n      \\\"Effect\\\": \\\"Allow\\\",\n      \\\"Action\\\": [\n        \\\"dynamodb:GetItem\\\", \\\"dynamodb:BatchGetItem\\\",\n        \\\"dynamodb:Query\\\", \\\"dynamodb:UpdateItem\\\"\n      ],\n      \\\"Resource\\\": \\\"arn:aws:dynamodb:us-east-1:123456789012:table/shared-table\\\",\n      \\\"Condition\\\": {\n        \\\"ForAllValues:StringLike\\\": {\n          \\\"dynamodb:LeadingKeys\\\": [\\\"${NSID1}/*\\\", \\\"${NSID2}/*\\\", \\\"_/*\\\"]\n        }\n      }\n    }]\n  }\"\n</code></pre> <p>This policy is operator-managed (not owned by the zae-limiter CloudFormation stack).</p>"},{"location":"infra/production/#network","title":"Network","text":"<ul> <li>No VPC required; uses AWS service endpoints</li> <li>For VPC deployment, configure VPC endpoints for DynamoDB and Lambda</li> </ul>"},{"location":"infra/production/#secrets-management","title":"Secrets Management","text":"<ul> <li>No secrets stored in DynamoDB</li> <li>Use AWS Secrets Manager or Parameter Store for API keys</li> <li>Rate limit entity IDs should not contain sensitive data</li> </ul>"},{"location":"infra/production/#audit-logging","title":"Audit Logging","text":"<ul> <li>All entity and limit changes are automatically logged</li> <li>Track who made changes with optional <code>principal</code> parameter</li> <li>Events auto-expire after 90 days (configurable via <code>--audit-ttl-days</code>)</li> <li>Expired events are archived to S3 for long-term retention</li> <li>Archives transition to Glacier IR after 90 days (configurable via <code>--audit-archive-glacier-days</code>)</li> <li>For compliance requirements, see Audit Logging Guide</li> </ul>"},{"location":"infra/production/#multi-region-considerations","title":"Multi-Region Considerations","text":"<p>zae-limiter is designed for single-region deployment:</p> Scenario Approach Single region Standard deployment Multi-region (independent) Deploy separate stacks per region Global rate limiting Application-level coordination required"},{"location":"infra/production/#why-not-global-tables","title":"Why Not Global Tables?","text":"<ul> <li>Rate limit state is time-sensitive (token buckets refill continuously)</li> <li>Cross-region replication lag would cause inconsistent limits</li> <li>Each region should enforce its own limits</li> </ul>"},{"location":"infra/production/#cross-region-pattern","title":"Cross-Region Pattern","text":"<pre><code># Deploy separate stacks per region\nus_limiter = RateLimiter(name=\"prod\", region=\"us-east-1\")\neu_limiter = RateLimiter(name=\"prod\", region=\"eu-west-1\")\n\n# Application coordinates between regions if needed\n</code></pre>"},{"location":"infra/production/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":"<p>The stack deploys CloudWatch alarms by default:</p> Alarm Trigger Action Lambda Errors &gt; 1 per 5 min Check logs, verify DynamoDB access Lambda Duration &gt; 80% timeout Increase memory or timeout Iterator Age &gt; 30 seconds Check Lambda concurrency DLQ Messages &gt;= 1 Investigate failed records DynamoDB Throttles &gt; 1 per 5 min Review capacity planning <p>For dashboard templates and Logs Insights queries, see Monitoring Guide.</p>"},{"location":"infra/production/#cost-estimation","title":"Cost Estimation","text":"<p>Costs scale with request volume (us-east-1 pricing, v0.7.0+ O(1) costs):</p> Volume DynamoDB Lambda CloudWatch S3 Archive Total 10K req/day ~$0.25 ~$0.20 ~$0.10 ~$0.01 ~$0.56/month 100K req/day ~$2.50 ~$2 ~$1 ~$0.10 ~$5.60/month 1M req/day ~$22 ~$12 ~$5 ~$1 ~$40/month <p>S3 costs include: - Standard storage: First 90 days (or configured <code>--audit-archive-glacier-days</code>) - Glacier IR storage: After transition (~80% cheaper than Standard) - PUT requests: One per Lambda batch (~$0.005 per 1000 requests)</p> <p>For detailed capacity planning and optimization, see Performance Guide.</p>"},{"location":"infra/production/#next-steps","title":"Next Steps","text":"<ul> <li>Monitoring Guide - Dashboards, alerts, Logs Insights</li> <li>Audit Logging - Compliance tracking and incident investigation</li> <li>Performance Guide - Capacity planning, optimization</li> <li>Operations Guide - Troubleshooting, recovery</li> </ul>"},{"location":"migrations/namespace-keys/","title":"Namespace-Prefixed Keys Migration (v0.10.0)","text":"<p>This guide walks you through migrating an existing zae-limiter deployment from bare DynamoDB keys (<code>ENTITY#user-123</code>) to namespace-prefixed keys (<code>a7x3kq/ENTITY#user-123</code>), as introduced in v0.10.0.</p>"},{"location":"migrations/namespace-keys/#overview","title":"Overview","text":""},{"location":"migrations/namespace-keys/#what-changed","title":"What Changed","text":"<p>v0.10.0 introduces namespace-prefixed DynamoDB keys to enable multi-tenant isolation within a single table. Every partition key and GSI key is now prefixed with an opaque namespace ID:</p> <pre><code># Before (v0.9.x and earlier)\nPK = ENTITY#user-123\n\n# After (v0.10.0)\nPK = a7x3kq/ENTITY#user-123\n</code></pre> <p>A new namespace registry tracks the mapping between human-readable names (e.g., <code>default</code>, <code>tenant-alpha</code>) and opaque IDs used in keys. The reserved namespace <code>_</code> is used for system-wide records like the version record.</p>"},{"location":"migrations/namespace-keys/#why","title":"Why","text":"<ul> <li>Multi-tenant isolation: Each tenant's data lives under a distinct namespace prefix, enabling IAM-level access control via <code>dynamodb:LeadingKeys</code> conditions</li> <li>Opaque IDs: Namespace IDs are random strings, preventing tenants from guessing other tenants' key prefixes</li> <li>GSI4: A new Global Secondary Index enables efficient per-namespace item discovery</li> </ul> <p>See #364 for the full schema design.</p>"},{"location":"migrations/namespace-keys/#key-format-mapping","title":"Key Format Mapping","text":"<p>The table below shows how each record type's keys change:</p>"},{"location":"migrations/namespace-keys/#partition-keys-pk","title":"Partition Keys (PK)","text":"Record Type Old Format New Format Entity <code>ENTITY#user-123</code> <code>a7x3kq/ENTITY#user-123</code> System config <code>SYSTEM#</code> <code>a7x3kq/SYSTEM#</code> Resource config <code>RESOURCE#gpt-4</code> <code>a7x3kq/RESOURCE#gpt-4</code> Audit <code>AUDIT#user-123</code> <code>a7x3kq/AUDIT#user-123</code> Version <code>SYSTEM#</code> (SK=<code>#VERSION</code>) <code>_/SYSTEM#</code> (reserved namespace)"},{"location":"migrations/namespace-keys/#gsi-keys","title":"GSI Keys","text":"GSI Old Format New Format GSI1PK (parent lookup) <code>PARENT#parent-1</code> <code>a7x3kq/PARENT#parent-1</code> GSI2PK (resource agg.) <code>RESOURCE#gpt-4</code> <code>a7x3kq/RESOURCE#gpt-4</code> GSI3PK (entity config) <code>ENTITY_CONFIG#gpt-4</code> <code>a7x3kq/ENTITY_CONFIG#gpt-4</code> GSI4PK (new) (did not exist) <code>a7x3kq</code> (namespace ID) GSI4SK (new) (did not exist) Same as PK <p>Note</p> <p>Sort keys (SK) are unchanged -- only partition keys and GSI hash keys gain the namespace prefix.</p>"},{"location":"migrations/namespace-keys/#prerequisites","title":"Prerequisites","text":"<p>Before starting the migration:</p> <ul> <li> Minimum client version: Install <code>zae-limiter &gt;= 0.10.0</code></li> <li> Backup: Enable Point-in-Time Recovery (PITR) on your DynamoDB table</li> <li> Connectivity: Verify CLI access to your stack</li> </ul> <pre><code># Verify PITR is enabled\naws dynamodb describe-continuous-backups \\\n  --table-name my-app\n\n# Or create an on-demand backup\naws dynamodb create-backup \\\n  --table-name my-app \\\n  --backup-name \"pre-namespace-migration-$(date +%Y%m%d)\"\n\n# Verify CLI can reach the stack\nzae-limiter check --name my-app --region us-east-1\n</code></pre>"},{"location":"migrations/namespace-keys/#step-1-deploy-upgrade-the-stack","title":"Step 1: Deploy / Upgrade the Stack","text":"<p>Update the CloudFormation stack to add GSI4 and namespace-scoped IAM policies:</p> <pre><code># Upgrade an existing stack\nzae-limiter upgrade --name my-app --region us-east-1\n\n# Or redeploy (also works)\nzae-limiter deploy --name my-app --region us-east-1\n</code></pre> <p>This stack update:</p> <ol> <li>Adds GSI4 (<code>GSI4PK</code> / <code>GSI4SK</code> attribute definitions and index)</li> <li>Creates namespace-scoped IAM policies (<code>NamespaceAcquirePolicy</code>, <code>NamespaceFullAccessPolicy</code>, <code>NamespaceReadOnlyPolicy</code>)</li> <li>Registers the \"default\" namespace with a random opaque ID in the namespace registry</li> </ol> <p>GSI4 creation time and empty backfill</p> <p>DynamoDB builds the new GSI by backfilling existing items. However, existing items have no <code>GSI4PK</code> attribute, so GSI4 starts empty after backfill completes -- this is expected. The migration in Step 3 adds <code>GSI4PK</code>/<code>GSI4SK</code> to every item, which populates the index.</p> <p>On large tables (millions of items), backfill can take minutes to hours. During this time the table enters <code>UPDATING</code> state: reads and writes continue normally, but other schema changes (adding another GSI, modifying attribute definitions) are blocked until the table leaves <code>UPDATING</code>. Monitor progress via:</p> <pre><code>aws dynamodb describe-table --table-name my-app \\\n  --query 'Table.GlobalSecondaryIndexes[?IndexName==`GSI4`].IndexStatus'\n</code></pre>"},{"location":"migrations/namespace-keys/#step-2-discover-the-namespace-id","title":"Step 2: Discover the Namespace ID","text":"<p>After the stack update completes, find the opaque ID assigned to the <code>default</code> namespace:</p> CLIPython <pre><code># Show default namespace details\nzae-limiter namespace show default --name my-app\n\n# Or list all namespaces\nzae-limiter namespace list --name my-app\n</code></pre> <p>Example output: <pre><code>Namespace:    default\nNamespace ID: a7x3kq\nStatus:       active\nCreated At:   2025-06-15T10:30:00Z\n</code></pre></p> <pre><code>import asyncio\nfrom zae_limiter import Repository\n\nasync def main():\n    repo = Repository(\"my-app\", \"us-east-1\", None)\n    namespaces = await repo.list_namespaces()\n    for ns in namespaces:\n        print(f\"{ns['name']}: {ns['namespace_id']}\")\n    await repo.close()\n\nasyncio.run(main())\n</code></pre> <p>Note</p> <p>DynamoDB keys use the opaque ID (e.g., <code>a7x3kq</code>), not the human-readable name <code>\"default\"</code>. The namespace registry maps between them.</p>"},{"location":"migrations/namespace-keys/#step-3-migrate-existing-items","title":"Step 3: Migrate Existing Items","text":"<p>This is the core migration step. It rewrites every existing (unprefixed) item with the new namespace-prefixed keys.</p> <p>Aggregator Lambda deployment ordering</p> <p>The aggregator Lambda's archiver (<code>archiver.py</code>) calls <code>parse_namespace(pk)</code> without a try/except guard. If the Lambda is updated to v0.10.0 code while unprefixed items still exist, the archiver will crash on every TTL-deleted audit record.</p> <p>You must migrate data BEFORE updating the Lambda code. If you used <code>zae-limiter upgrade</code>, the Lambda code is updated automatically -- so run this migration script immediately after the upgrade completes, before any audit TTL deletions occur.</p> <p>The stream processor (<code>processor.py</code>) handles this gracefully by catching the <code>ValueError</code> and skipping pre-migration records. Only the archiver path is affected.</p>"},{"location":"migrations/namespace-keys/#migration-script","title":"Migration Script","text":"<p>Save the following as <code>migrate_namespace_keys.py</code> and run it against your table:</p> <pre><code>\"\"\"\nNamespace key migration script for zae-limiter v0.10.0.\n\nMigrates existing unprefixed DynamoDB items to namespace-prefixed keys.\nIdempotent -- safe to run multiple times.\n\nUsage:\n    python migrate_namespace_keys.py --name my-app --region us-east-1\n    python migrate_namespace_keys.py --name my-app --region us-east-1 --delete\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport asyncio\nimport logging\n\nimport aioboto3\n\nfrom zae_limiter import schema\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(message)s\")\nlogger = logging.getLogger(__name__)\n\n# GSI PK attributes that need namespace prefixing\nGSI_PK_ATTRS = (\"GSI1PK\", \"GSI2PK\", \"GSI3PK\")\n\n# Known PK prefixes (used to detect unprefixed items)\nKNOWN_PK_PREFIXES = (\n    schema.ENTITY_PREFIX,   # \"ENTITY#\"\n    schema.SYSTEM_PREFIX,   # \"SYSTEM#\"\n    schema.RESOURCE_PREFIX, # \"RESOURCE#\"\n    schema.AUDIT_PREFIX,    # \"AUDIT#\"\n)\n\n# Known GSI PK prefixes\nKNOWN_GSI_PREFIXES = (\n    schema.PARENT_PREFIX,        # \"PARENT#\"\n    schema.RESOURCE_PREFIX,      # \"RESOURCE#\"\n    schema.ENTITY_CONFIG_PREFIX, # \"ENTITY_CONFIG#\"\n)\n\n\ndef is_unprefixed(pk: str) -&gt; bool:\n    \"\"\"Check if a PK lacks a namespace prefix (no '/' before the first '#').\"\"\"\n    slash_idx = pk.find(\"/\")\n    hash_idx = pk.find(\"#\")\n    if slash_idx &lt; 0:\n        return True  # No slash at all\n    if hash_idx &gt;= 0 and slash_idx &gt; hash_idx:\n        return True  # Slash comes after hash -- not a namespace prefix\n    return False\n\n\ndef determine_namespace(\n    pk: str, sk: str, default_ns_id: str\n) -&gt; str:\n    \"\"\"Determine the target namespace ID for an item.\n\n    Version records (SYSTEM# + #VERSION) go to the reserved namespace '_'.\n    Everything else goes to the default namespace.\n    \"\"\"\n    if pk.startswith(schema.SYSTEM_PREFIX) and sk == schema.SK_VERSION:\n        return schema.RESERVED_NAMESPACE\n    return default_ns_id\n\n\ndef prefix_key(namespace_id: str, key: str) -&gt; str:\n    \"\"\"Add namespace prefix to a key.\"\"\"\n    return f\"{namespace_id}/{key}\"\n\n\ndef build_new_item(\n    item: dict, namespace_id: str\n) -&gt; dict:\n    \"\"\"Build a new item with namespace-prefixed keys and GSI4 attributes.\"\"\"\n    new_item = dict(item)\n    old_pk = item[\"PK\"][\"S\"]\n\n    # Prefix the PK\n    new_item[\"PK\"] = {\"S\": prefix_key(namespace_id, old_pk)}\n\n    # Prefix GSI PK attributes (if present)\n    for gsi_attr in GSI_PK_ATTRS:\n        if gsi_attr in item:\n            old_val = item[gsi_attr][\"S\"]\n            new_item[gsi_attr] = {\"S\": prefix_key(namespace_id, old_val)}\n\n    # Add GSI4 attributes for namespace discovery\n    new_item[\"GSI4PK\"] = {\"S\": namespace_id}\n    new_item[\"GSI4SK\"] = {\"S\": new_item[\"PK\"][\"S\"]}\n\n    return new_item\n\n\nasync def scan_unprefixed_items(\n    client, table_name: str\n) -&gt; list[dict]:\n    \"\"\"Scan all items and return those with unprefixed PKs.\"\"\"\n    items = []\n    params: dict = {\"TableName\": table_name}\n\n    while True:\n        response = await client.scan(**params)\n        for item in response.get(\"Items\", []):\n            pk = item.get(\"PK\", {}).get(\"S\", \"\")\n            if is_unprefixed(pk):\n                items.append(item)\n\n        if \"LastEvaluatedKey\" not in response:\n            break\n        params[\"ExclusiveStartKey\"] = response[\"LastEvaluatedKey\"]\n\n    return items\n\n\nasync def write_prefixed_items(\n    client,\n    table_name: str,\n    items: list[dict],\n    default_ns_id: str,\n    batch_size: int = 25,\n    throttle_seconds: float = 0.1,\n) -&gt; int:\n    \"\"\"Write namespace-prefixed items using conditional puts (idempotent).\n\n    Returns the number of items successfully written.\n    \"\"\"\n    written = 0\n\n    for i in range(0, len(items), batch_size):\n        batch = items[i : i + batch_size]\n\n        for item in batch:\n            old_pk = item[\"PK\"][\"S\"]\n            sk = item[\"SK\"][\"S\"]\n            ns_id = determine_namespace(old_pk, sk, default_ns_id)\n            new_item = build_new_item(item, ns_id)\n\n            try:\n                await client.put_item(\n                    TableName=table_name,\n                    Item=new_item,\n                    ConditionExpression=\"attribute_not_exists(PK)\",\n                )\n                written += 1\n            except client.exceptions.ConditionalCheckFailedException:\n                # Item already exists (idempotent)\n                logger.debug(\n                    \"Skipping existing item: PK=%s SK=%s\",\n                    new_item[\"PK\"][\"S\"],\n                    sk,\n                )\n\n        logger.info(\n            \"Progress: %d / %d items written\",\n            min(i + batch_size, len(items)),\n            len(items),\n        )\n        await asyncio.sleep(throttle_seconds)\n\n    return written\n\n\nasync def delete_unprefixed_items(\n    client,\n    table_name: str,\n    items: list[dict],\n    batch_size: int = 25,\n    throttle_seconds: float = 0.1,\n) -&gt; int:\n    \"\"\"Delete old unprefixed items after migration is verified.\n\n    Returns the number of items deleted.\n    \"\"\"\n    deleted = 0\n\n    for i in range(0, len(items), batch_size):\n        batch = items[i : i + batch_size]\n\n        # Use BatchWriteItem for efficient deletes\n        delete_requests = [\n            {\n                \"DeleteRequest\": {\n                    \"Key\": {\"PK\": item[\"PK\"], \"SK\": item[\"SK\"]}\n                }\n            }\n            for item in batch\n        ]\n\n        if delete_requests:\n            response = await client.batch_write_item(\n                RequestItems={table_name: delete_requests}\n            )\n            # Handle unprocessed items\n            unprocessed = (\n                response.get(\"UnprocessedItems\", {})\n                .get(table_name, [])\n            )\n            deleted += len(delete_requests) - len(unprocessed)\n\n            if unprocessed:\n                logger.warning(\n                    \"%d unprocessed deletes in batch %d\",\n                    len(unprocessed),\n                    i // batch_size,\n                )\n\n        logger.info(\n            \"Delete progress: %d / %d items\",\n            min(i + batch_size, len(items)),\n            len(items),\n        )\n        await asyncio.sleep(throttle_seconds)\n\n    return deleted\n\n\nasync def get_default_namespace_id(client, table_name: str) -&gt; str:\n    \"\"\"Look up the default namespace ID from the registry.\"\"\"\n    response = await client.get_item(\n        TableName=table_name,\n        Key={\n            \"PK\": {\"S\": f\"{schema.RESERVED_NAMESPACE}/{schema.SYSTEM_PREFIX}\"},\n            \"SK\": {\"S\": schema.sk_namespace(\"default\")},\n        },\n    )\n    item = response.get(\"Item\")\n    if not item:\n        raise RuntimeError(\n            \"Default namespace not found. \"\n            \"Run 'zae-limiter upgrade' first to register the default namespace.\"\n        )\n    return item[\"namespace_id\"][\"S\"]\n\n\nasync def migrate(\n    name: str,\n    region: str,\n    endpoint_url: str | None = None,\n    delete: bool = False,\n) -&gt; None:\n    \"\"\"Run the namespace key migration.\"\"\"\n    session = aioboto3.Session()\n    async with session.client(\n        \"dynamodb\", region_name=region, endpoint_url=endpoint_url\n    ) as client:\n        table_name = name\n\n        # 1. Discover default namespace ID\n        ns_id = await get_default_namespace_id(client, table_name)\n        logger.info(\"Default namespace ID: %s\", ns_id)\n\n        # 2. Scan for unprefixed items\n        logger.info(\"Scanning for unprefixed items...\")\n        items = await scan_unprefixed_items(client, table_name)\n        logger.info(\"Found %d unprefixed items\", len(items))\n\n        if not items:\n            logger.info(\"No unprefixed items found. Migration complete.\")\n            return\n\n        # 3. Write prefixed copies\n        logger.info(\"Writing namespace-prefixed items...\")\n        written = await write_prefixed_items(\n            client, table_name, items, ns_id\n        )\n        logger.info(\"Wrote %d new prefixed items\", written)\n\n        # 4. Optionally delete old items\n        if delete:\n            logger.info(\"Deleting old unprefixed items...\")\n            deleted = await delete_unprefixed_items(\n                client, table_name, items\n            )\n            logger.info(\"Deleted %d unprefixed items\", deleted)\n        else:\n            logger.info(\n                \"Skipping deletion (run with --delete to remove old items). \"\n                \"%d unprefixed items remain.\",\n                len(items),\n            )\n\n\ndef main() -&gt; None:\n    parser = argparse.ArgumentParser(\n        description=\"Migrate zae-limiter DynamoDB items to namespace-prefixed keys\"\n    )\n    parser.add_argument(\n        \"--name\", required=True, help=\"Stack/table name\"\n    )\n    parser.add_argument(\n        \"--region\", required=True, help=\"AWS region\"\n    )\n    parser.add_argument(\n        \"--endpoint-url\", default=None,\n        help=\"AWS endpoint URL (for LocalStack)\",\n    )\n    parser.add_argument(\n        \"--delete\", action=\"store_true\",\n        help=\"Delete old unprefixed items after writing prefixed copies\",\n    )\n    args = parser.parse_args()\n\n    asyncio.run(\n        migrate(\n            name=args.name,\n            region=args.region,\n            endpoint_url=args.endpoint_url,\n            delete=args.delete,\n        )\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"migrations/namespace-keys/#running-the-migration","title":"Running the Migration","text":"<pre><code># Install the new version\npip install \"zae-limiter&gt;=0.10.0\"\n\n# Step 1: Write prefixed copies (non-destructive)\npython migrate_namespace_keys.py --name my-app --region us-east-1\n\n# Step 2: Verify (see Step 7 below)\n\n# Step 3: Delete old unprefixed items\npython migrate_namespace_keys.py --name my-app --region us-east-1 --delete\n</code></pre> <p>Dry-run approach</p> <p>Run without <code>--delete</code> first. This writes prefixed copies alongside the originals, so you can verify the migration before removing old items. The script is idempotent -- running it again skips items that already exist.</p>"},{"location":"migrations/namespace-keys/#cost-and-time-estimation","title":"Cost and Time Estimation","text":"Table Size Scan Cost Write Cost Estimated Time 10,000 items ~1,250 RCU ~10,000 WCU &lt; 1 minute 100,000 items ~12,500 RCU ~100,000 WCU ~5 minutes 1,000,000 items ~125,000 RCU ~1,000,000 WCU ~50 minutes <p>With on-demand pricing: scan = $0.125/M RCU, writes = $0.625/M WCU. A 1M-item migration costs approximately $0.64.</p>"},{"location":"migrations/namespace-keys/#step-4-update-application-config","title":"Step 4: Update Application Config","text":"<p>Update your application code to use the namespace-aware API. For existing single-tenant deployments, the default namespace is used automatically -- no code changes are required if you're already using the latest client.</p> AsyncSyncCLI <pre><code>from zae_limiter import RateLimiter, Repository\n\n# v0.10.0 automatically uses the \"default\" namespace\nrepo = Repository(\"my-app\", \"us-east-1\", None)\nlimiter = RateLimiter(repository=repo)\n\n# Explicit namespace (optional)\nns_repo = await repo.namespace(\"default\")\nlimiter = RateLimiter(repository=ns_repo)\n</code></pre> <pre><code>from zae_limiter import SyncRateLimiter, SyncRepository\n\nrepo = SyncRepository(\"my-app\", \"us-east-1\", None)\nlimiter = SyncRateLimiter(repository=repo)\n\n# Explicit namespace (optional)\nns_repo = repo.namespace(\"default\")\nlimiter = SyncRateLimiter(repository=ns_repo)\n</code></pre> <pre><code># Most commands use --namespace / -N flag (default: \"default\")\nzae-limiter audit list user-123 --name my-app -N default\n\n# Namespace management commands\nzae-limiter namespace list --name my-app\nzae-limiter namespace show default --name my-app\n</code></pre>"},{"location":"migrations/namespace-keys/#step-5-attach-namespace-iam-policies","title":"Step 5: Attach Namespace IAM Policies","text":"<p>For deployments that use IAM access control, attach the new namespace-scoped policies and tag principals.</p>"},{"location":"migrations/namespace-keys/#get-policy-arns","title":"Get Policy ARNs","text":"<p>The stack outputs the policy ARNs:</p> <pre><code># List namespace-scoped policy outputs\naws cloudformation describe-stacks --stack-name my-app \\\n  --query 'Stacks[0].Outputs[?contains(OutputKey,`Namespace`)].{Key:OutputKey,Value:OutputValue}' \\\n  --output table\n</code></pre> Output Key Description <code>NamespaceAcquirePolicyArn</code> For tenant apps calling <code>acquire()</code> <code>NamespaceFullAccessPolicyArn</code> Full access within a namespace <code>NamespaceReadOnlyPolicyArn</code> Read-only monitoring within a namespace"},{"location":"migrations/namespace-keys/#attach-to-roles-and-tag","title":"Attach to Roles and Tag","text":"<pre><code># 1. Get the default namespace ID\nNS_ID=$(zae-limiter namespace show default --name my-app \\\n  | grep \"Namespace ID:\" | awk '{print $3}')\n\n# 2. Attach namespace-scoped policy to your app role\naws iam attach-role-policy --role-name my-app-role \\\n  --policy-arn arn:aws:iam::123456789012:policy/my-app-ns-acq\n\n# 3. Tag the role with the namespace ID\naws iam tag-role --role-name my-app-role \\\n  --tags Key=zael_namespace_id,Value=$NS_ID\n</code></pre> <p>The <code>zael_namespace_id</code> tag on the IAM principal controls which namespace's items the role can access via <code>dynamodb:LeadingKeys</code> conditions.</p> <p>For detailed TBAC setup including multi-namespace access and admin roles, see Production Guide: Namespace-Scoped Access Control.</p>"},{"location":"migrations/namespace-keys/#step-6-decommission-old-stacks-optional","title":"Step 6: Decommission Old Stacks (Optional)","text":"<p>If you're consolidating multiple single-tenant stacks into one multi-tenant table:</p> graph LR     A[Stack A&lt;br/&gt;tenant-alpha] --&gt; M[Shared Stack&lt;br/&gt;namespace: tenant-alpha]     B[Stack B&lt;br/&gt;tenant-beta] --&gt; M     C[Stack C&lt;br/&gt;tenant-gamma] --&gt; M     M --&gt; D[namespace: tenant-gamma]     M --&gt; E[namespace: tenant-beta]     M --&gt; F[namespace: tenant-alpha] <ol> <li> <p>Register namespaces for each tenant in the shared table:</p> <pre><code>zae-limiter namespace register tenant-alpha --name shared-table\nzae-limiter namespace register tenant-beta --name shared-table\n</code></pre> </li> <li> <p>Export and re-import data from each old stack into the shared table under the appropriate namespace (adapt the migration script above to read from one table and write to another).</p> </li> <li> <p>Update application config to point to the shared table with the appropriate namespace.</p> </li> <li> <p>Delete old stacks once verified:</p> <pre><code>zae-limiter delete --name old-stack-alpha --yes\n</code></pre> </li> </ol>"},{"location":"migrations/namespace-keys/#rollback-procedures","title":"Rollback Procedures","text":""},{"location":"migrations/namespace-keys/#per-step-rollback","title":"Per-Step Rollback","text":"Step Rollback Action Step 1 (stack upgrade) CloudFormation does not remove GSI4 on rollback. Use PITR to restore if needed. Step 3 (data migration) If <code>--delete</code> was not used, old items still exist -- simply revert the client to v0.9.x. If <code>--delete</code> was used, restore from PITR backup. Step 4 (app config) Revert application to previous version: <code>pip install \"zae-limiter&lt;0.10.0\"</code> Step 5 (IAM policies) Detach namespace policies, re-attach table-level policies."},{"location":"migrations/namespace-keys/#full-rollback","title":"Full Rollback","text":"<p>If the migration must be completely reversed:</p> <pre><code># 1. Revert client to pre-namespace version\npip install \"zae-limiter&lt;0.10.0\"\n\n# 2. Restore table from PITR (if unprefixed items were deleted)\naws dynamodb restore-table-to-point-in-time \\\n  --source-table-name my-app \\\n  --target-table-name my-app-restored \\\n  --restore-date-time \"2025-06-15T10:00:00Z\"\n\n# 3. Detach namespace IAM policies (if attached)\naws iam detach-role-policy --role-name my-app-role \\\n  --policy-arn arn:aws:iam::123456789012:policy/my-app-ns-acq\n</code></pre> <p>Aggregator during dual-format period</p> <p>During the window between upgrading and completing migration, the table may contain both prefixed and unprefixed items. The stream processor handles this gracefully (catches <code>ValueError</code> from <code>parse_namespace()</code> and skips pre-migration records). The archiver does not -- see the warning in Step 3.</p>"},{"location":"migrations/namespace-keys/#verification-checklist","title":"Verification Checklist","text":"<p>After completing the migration, verify everything works:</p> <ul> <li> Namespace registry: <code>zae-limiter namespace list --name my-app</code> shows the default namespace</li> <li> Compatibility check: <code>zae-limiter check --name my-app --region us-east-1</code> reports <code>COMPATIBLE</code></li> <li> Sample acquire: Run a test <code>acquire()</code> call and verify it succeeds</li> <li> Unprefixed items removed: Scan the table and confirm no items have bare (unprefixed) PKs</li> <li> GSI4 active: Verify <code>GSI4</code> status is <code>ACTIVE</code> in the DynamoDB console</li> <li> Aggregator healthy: Check CloudWatch Logs for the aggregator Lambda -- no <code>ValueError</code> exceptions</li> </ul> <pre><code># Quick smoke test\npython -c \"\nimport asyncio\nfrom zae_limiter import RateLimiter, Repository, Limit\n\nasync def test():\n    repo = Repository('my-app', 'us-east-1', None)\n    limiter = RateLimiter(repository=repo)\n    await limiter.create_entity('migration-test')\n    async with await limiter.acquire(\n        'migration-test', 'test-resource',\n        limits=[Limit.per_minute('rpm', 100)],\n    ) as lease:\n        print(f'Acquired: {lease.entity_id}')\n    await limiter.delete_entity('migration-test')\n    await repo.close()\n    print('Migration verified successfully!')\n\nasyncio.run(test())\n\"\n</code></pre>"},{"location":"operations/","title":"Operations Guide","text":"<p>This guide consolidates troubleshooting and operational procedures for zae-limiter deployments. Navigate using the interactive map below or jump directly to a topic.</p>"},{"location":"operations/#navigation","title":"Navigation","text":"flowchart LR     OPS[Operations Guide]      subgraph alerts[Alerts &amp; Issues]         LAMBDA[Lambda Aggregator]         DYNAMO[DynamoDB]         STREAMS[Stream Processing]         VERSION[Version Errors]         LIMITS[Rate Limits]     end      subgraph planned[Planned Operations]         UPGRADE[Version Upgrade]         LAMBDA_UPDATE[Lambda Update]         SCALE_LIMITS[Adjust Limits]         SCALE_DYNAMO[Scale DynamoDB]         BACKUP[Backup &amp; Restore]         ROLLBACK[Emergency Rollback]     end      OPS --&gt; alerts     OPS --&gt; planned      click LAMBDA \"lambda/\" \"Lambda troubleshooting\"     click DYNAMO \"dynamodb/\" \"DynamoDB operations\"     click STREAMS \"streams/\" \"Stream processing\"     click VERSION \"version/\" \"Version management\"     click LIMITS \"rate-limits/\" \"Rate limit issues\"     click UPGRADE \"version/#upgrade-procedure\" \"Upgrade procedure\"     click LAMBDA_UPDATE \"lambda/#lambda-redeployment\" \"Redeploy Lambda\"     click SCALE_LIMITS \"rate-limits/#adjust-limits-at-runtime\" \"Adjust limits\"     click SCALE_DYNAMO \"dynamodb/#scaling-procedures\" \"Scale capacity\"     click BACKUP \"recovery/#dynamodb-backup-and-restore\" \"Backup &amp; restore\"     click ROLLBACK \"recovery/#emergency-rollback-decision-matrix\" \"Emergency rollback\""},{"location":"operations/#alerts-issues","title":"Alerts &amp; Issues","text":"Component Common Issues Lambda Error rate, Duration/timeout, DLQ messages DynamoDB Throttling, Capacity Streams Iterator age, Processing lag Version VersionMismatchError, IncompatibleSchemaError Rate Limits Unexpected RateLimitExceeded, Limits not enforcing"},{"location":"operations/#planned-operations","title":"Planned Operations","text":"Operation Guides Upgrades Version upgrade, Lambda update Scaling Adjust rate limits, DynamoDB capacity Recovery Emergency rollback, Backup/restore, PITR"},{"location":"operations/#quick-reference","title":"Quick Reference","text":"Symptom Go To <code>RateLimitExceeded</code> unexpected Rate Limits <code>ProvisionedThroughputExceededException</code> DynamoDB DLQ messages accumulating Lambda <code>VersionMismatchError</code> Version High <code>IteratorAge</code> Streams Need to rollback Recovery"},{"location":"operations/#cli-diagnostic-commands","title":"CLI Diagnostic Commands","text":"Command Description <code>zae-limiter status --name &lt;name&gt;</code> Check stack status and resources <code>zae-limiter version --name &lt;name&gt;</code> Show version information <code>zae-limiter check --name &lt;name&gt;</code> Check client/infrastructure compatibility"},{"location":"operations/#cloudwatch-metrics-overview","title":"CloudWatch Metrics Overview","text":"Metric Namespace Threshold Guide <code>Errors</code> AWS/Lambda &gt; 1/5min Lambda <code>Duration</code> AWS/Lambda &gt; 80% timeout Lambda <code>IteratorAge</code> AWS/Lambda &gt; 30,000ms Streams <code>ReadThrottleEvents</code> AWS/DynamoDB &gt; 0 DynamoDB <code>WriteThrottleEvents</code> AWS/DynamoDB &gt; 0 DynamoDB <code>ApproximateNumberOfMessagesVisible</code> AWS/SQS &gt; 0 Lambda"},{"location":"operations/#exception-reference","title":"Exception Reference","text":"Exception Cause Guide <code>RateLimitExceeded</code> Rate limit violated Rate Limits <code>RateLimiterUnavailable</code> DynamoDB unavailable DynamoDB <code>EntityNotFoundError</code> Entity doesn't exist Rate Limits <code>VersionMismatchError</code> Client/Lambda version mismatch Version <code>IncompatibleSchemaError</code> Major version difference Version <code>StackCreationError</code> CloudFormation failed Recovery"},{"location":"operations/#related-documentation","title":"Related Documentation","text":"<ul> <li>Monitoring Guide - CloudWatch metrics, dashboards, and alerts</li> <li>Performance Tuning - Capacity planning and optimization</li> <li>Migration Guide - Schema versioning and upgrades</li> <li>Unavailability Handling - Configure behavior when DynamoDB is unavailable</li> </ul>"},{"location":"operations/dynamodb/","title":"DynamoDB Operations","text":"<p>This guide covers troubleshooting and operational procedures for DynamoDB capacity management and throttling issues.</p>"},{"location":"operations/dynamodb/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([DynamoDB Issue]) --&gt; Q1{What's the symptom?}      Q1 --&gt;|ReadThrottleEvents| A1[Check read patterns]     Q1 --&gt;|WriteThrottleEvents| A2[Check write patterns]     Q1 --&gt;|High latency| A3[Check capacity utilization]     Q1 --&gt;|Planning scale| A4[Capacity planning]      A1 --&gt; FIX1{Emergency?}     A2 --&gt; FIX1     FIX1 --&gt;|Yes| EMERGENCY[Switch to on-demand]     FIX1 --&gt;|No| PLAN[Increase provisioned capacity]      A3 --&gt; CHECK[Check CloudWatch metrics]     CHECK --&gt; FIX1      A4 --&gt; LINK([\u2192 Performance Guide])      click A1 \"#throttling\" \"Diagnose throttling\"     click A2 \"#throttling\" \"Diagnose throttling\"     click A3 \"#capacity-planning\" \"Check capacity\"     click EMERGENCY \"#emergency-on-demand\" \"Switch to on-demand\"     click PLAN \"#scaling-procedures\" \"Scale capacity\"     click CHECK \"#diagnostic-queries\" \"View metrics\"     click LINK \"../performance/\" \"Capacity planning guide\""},{"location":"operations/dynamodb/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/dynamodb/#symptoms","title":"Symptoms","text":"<ul> <li><code>ProvisionedThroughputExceededException</code> errors</li> <li>Increased latency on rate limit checks</li> <li>CloudWatch throttle alarms triggered</li> <li><code>RateLimiterUnavailable</code> with <code>OnUnavailable.BLOCK</code> mode</li> </ul>"},{"location":"operations/dynamodb/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check CloudWatch metrics:</p> <pre><code># View throttle events (last hour)\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ReadThrottleEvents \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Check capacity utilization:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedReadCapacityUnits \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Identify hot partitions with Contributor Insights:</p> <p>See Per-Partition Monitoring below for detailed setup and troubleshooting.</p>"},{"location":"operations/dynamodb/#throttling","title":"Throttling","text":""},{"location":"operations/dynamodb/#common-causes-and-solutions","title":"Common Causes and Solutions","text":"Cause Solution Provisioned capacity too low Increase RCU/WCU or switch to on-demand Hot partition Distribute entity IDs more evenly Burst traffic Enable auto-scaling or use on-demand GSI throttling Check GSI capacity separately"},{"location":"operations/dynamodb/#read-throttling","title":"Read Throttling","text":"<p>Check which operations are throttling:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ThrottledRequests \\\n  --dimensions Name=TableName,Value=&lt;name&gt; Name=Operation,Value=GetItem \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre>"},{"location":"operations/dynamodb/#write-throttling","title":"Write Throttling","text":"<p>Write throttling typically occurs during high-volume rate limiting or when the aggregator Lambda is processing many stream events.</p> <p>Check write patterns:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedWriteCapacityUnits \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Sum\n</code></pre>"},{"location":"operations/dynamodb/#capacity-planning","title":"Capacity Planning","text":"<p>For detailed capacity calculations, see the Performance Tuning Guide.</p> <p>Quick estimates (v0.7.0+, O(1) costs):</p> Operation RCU WCU <code>acquire()</code> 1 1 <code>acquire()</code> with cascade 2 4 <code>acquire()</code> retry (contention) 0 1 <code>available()</code> 1 0 Aggregator (per record) 1 2"},{"location":"operations/dynamodb/#procedures","title":"Procedures","text":""},{"location":"operations/dynamodb/#emergency-capacity-increase","title":"Emergency Capacity Increase","text":"<p>Switch to on-demand capacity (immediate relief):</p> <p>Billing Impact</p> <p>On-demand pricing is typically 5-7x more expensive than provisioned capacity at steady state, but has no throttling.</p> <pre><code>aws dynamodb update-table \\\n  --table-name &lt;name&gt; \\\n  --billing-mode PAY_PER_REQUEST\n</code></pre> <p>Increase provisioned capacity:</p> <pre><code>aws dynamodb update-table \\\n  --table-name &lt;name&gt; \\\n  --provisioned-throughput ReadCapacityUnits=1000,WriteCapacityUnits=500\n</code></pre>"},{"location":"operations/dynamodb/#scaling-procedures","title":"Scaling Procedures","text":""},{"location":"operations/dynamodb/#planned-capacity-scaling","title":"Planned Capacity Scaling","text":"<p>Step 1: Analyze current usage</p> <pre><code># Get average consumption over last 24 hours\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedReadCapacityUnits \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --start-time $(date -u -d '24 hours ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 3600 \\\n  --statistics Average\n</code></pre> <p>Step 2: Calculate required capacity</p> <p>Use the formulas from Performance Tuning:</p> <ul> <li><code>RCU = (requests_per_second \u00d7 2) + (cascade_requests \u00d7 2)</code></li> <li><code>WCU = (requests_per_second \u00d7 4) + (cascade_requests \u00d7 4)</code></li> </ul> <p>Add 20% headroom for bursts.</p> <p>Step 3: Apply changes</p> <pre><code>aws dynamodb update-table \\\n  --table-name &lt;name&gt; \\\n  --provisioned-throughput ReadCapacityUnits=&lt;new_rcu&gt;,WriteCapacityUnits=&lt;new_wcu&gt;\n</code></pre> <p>Step 4: Verify</p> <pre><code>aws dynamodb describe-table --table-name &lt;name&gt; \\\n  --query 'Table.ProvisionedThroughput'\n</code></pre>"},{"location":"operations/dynamodb/#enable-auto-scaling","title":"Enable Auto-Scaling","text":"<p>Create scaling targets:</p> <pre><code># Register read capacity target\naws application-autoscaling register-scalable-target \\\n  --service-namespace dynamodb \\\n  --resource-id \"table/&lt;name&gt;\" \\\n  --scalable-dimension \"dynamodb:table:ReadCapacityUnits\" \\\n  --min-capacity 5 \\\n  --max-capacity 1000\n\n# Register write capacity target\naws application-autoscaling register-scalable-target \\\n  --service-namespace dynamodb \\\n  --resource-id \"table/&lt;name&gt;\" \\\n  --scalable-dimension \"dynamodb:table:WriteCapacityUnits\" \\\n  --min-capacity 5 \\\n  --max-capacity 500\n</code></pre> <p>Create scaling policies:</p> <pre><code># Read capacity policy (target 70% utilization)\naws application-autoscaling put-scaling-policy \\\n  --service-namespace dynamodb \\\n  --resource-id \"table/&lt;name&gt;\" \\\n  --scalable-dimension \"dynamodb:table:ReadCapacityUnits\" \\\n  --policy-name \"&lt;name&gt;-read-scaling\" \\\n  --policy-type \"TargetTrackingScaling\" \\\n  --target-tracking-scaling-policy-configuration '{\n    \"TargetValue\": 70.0,\n    \"PredefinedMetricSpecification\": {\n      \"PredefinedMetricType\": \"DynamoDBReadCapacityUtilization\"\n    }\n  }'\n</code></pre>"},{"location":"operations/dynamodb/#switch-to-on-demand","title":"Switch to On-Demand","text":"<p>When to use on-demand:</p> <ul> <li>Unpredictable traffic patterns</li> <li>New deployments without baseline data</li> <li>Cost is less important than avoiding throttling</li> </ul> <p>Switch from provisioned to on-demand:</p> <pre><code>aws dynamodb update-table \\\n  --table-name &lt;name&gt; \\\n  --billing-mode PAY_PER_REQUEST\n</code></pre> <p>Switch back to provisioned:</p> <p>Cooldown Period</p> <p>You can only switch billing modes once per 24 hours.</p> <pre><code>aws dynamodb update-table \\\n  --table-name &lt;name&gt; \\\n  --billing-mode PROVISIONED \\\n  --provisioned-throughput ReadCapacityUnits=100,WriteCapacityUnits=50\n</code></pre>"},{"location":"operations/dynamodb/#verification","title":"Verification","text":"<p>After capacity changes, monitor for 15-30 minutes:</p> <pre><code># Watch throttle events\nwatch -n 30 \"aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ReadThrottleEvents \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --start-time \\$(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time \\$(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Sum\"\n</code></pre>"},{"location":"operations/dynamodb/#per-partition-monitoring","title":"Per-Partition Monitoring","text":""},{"location":"operations/dynamodb/#understanding-hot-partitions","title":"Understanding Hot Partitions","text":"<p>DynamoDB distributes data across multiple internal partitions. Each partition has its own throughput quota:</p> <ul> <li>Per-partition read limit: ~3,000 RCU</li> <li>Per-partition write limit: ~1,000 WCU</li> </ul> <p>If a single partition receives most traffic (e.g., a high-fanout parent entity with 1,000+ children and <code>cascade=True</code>), that partition throttles while others are idle. This is called a hot partition.</p> <p>Typical symptoms: - High latency on specific operations - CloudWatch shows <code>ReadThrottleEvents</code> or <code>WriteThrottleEvents</code> - Some entity IDs throttle but others don't - Table-level capacity looks fine but requests still throttle</p>"},{"location":"operations/dynamodb/#contributor-insights-setup","title":"Contributor Insights Setup","text":"<p>DynamoDB Contributor Insights identifies which partition keys consume the most throughput, helping you spot hot partitions.</p>"},{"location":"operations/dynamodb/#enable-contributor-insights","title":"Enable Contributor Insights","text":"<pre><code># Enable for main table\naws dynamodb update-contributor-insights \\\n  --table-name &lt;name&gt; \\\n  --contributor-insights-action ENABLE\n\n# Enable for GSI (if needed)\naws dynamodb update-contributor-insights \\\n  --table-name &lt;name&gt; \\\n  --contributor-insights-action ENABLE \\\n  --index-name GSI1\n</code></pre> <p>Cost: ~$0.10 per table per day (minimal). Monitoring is available after ~30 minutes of data collection.</p>"},{"location":"operations/dynamodb/#view-contributor-insights-data","title":"View Contributor Insights Data","text":"<pre><code># Check if enabled\naws dynamodb describe-contributor-insights \\\n  --table-name &lt;name&gt;\n\n# Get top partition keys by throughput\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConributorValue \\\n  --dimensions Name=TableName,Value=&lt;name&gt; Name=Contributor,Value=PK \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum \\\n  --max-records 10\n</code></pre> <p>Or use the AWS Console:</p> <ol> <li>Go to DynamoDB \u2192 Tables \u2192 <code>&lt;name&gt;</code> \u2192 Contributor Insights</li> <li>Review \"Top Keys\" to identify which partition keys consume most throughput</li> <li>Cross-reference with your entity IDs to find the hot entity</li> </ol>"},{"location":"operations/dynamodb/#interpreting-results","title":"Interpreting Results","text":"<p>If you see:</p> Pattern Meaning Action One entity ID consuming 70%+ of throughput Hot parent with cascade Implement write sharding Multiple entity IDs evenly distributed Normal load distribution No action needed Spike on specific entity at specific time Burst traffic on one user Monitor or rate limit GSI1 showing skewed distribution Parent lookup imbalance Review parent structure"},{"location":"operations/dynamodb/#identifying-cascade-hot-partitions","title":"Identifying Cascade Hot Partitions","text":"<p>When using <code>cascade=True</code> with high-fanout parents, check for these patterns:</p> <pre><code># Query: Which parent entities have the most children?\n# This is NOT a built-in query, but you can estimate from operation patterns:\n\n# 1. Enable Contributor Insights (as above)\n# 2. In CloudWatch, look at top PK values during peak traffic\n# 3. If top 3-5 PK values account for &gt;50% of writes, those are likely high-fanout parents\n</code></pre> <p>Example diagnosis:</p> <pre><code>Top 5 Partition Keys (by write throughput):\n1. ENTITY#project-123  \u2192 45% of writes (HIGH FANOUT - HOTSPOT!)\n2. ENTITY#project-456  \u2192 12% of writes\n3. ENTITY#project-789  \u2192 10% of writes\n4. ENTITY#api-key-999  \u2192 8% of writes\n5. ENTITY#...          \u2192 remainder\n\nAnalysis:\n- project-123 likely has 1000+ API keys with cascade=True\n- This parent partition can handle ~1,000 WCU max\n- If concurrent writes exceed this, throttling occurs\n</code></pre>"},{"location":"operations/dynamodb/#mitigations","title":"Mitigations","text":"<p>Once you've identified a hot partition:</p>"},{"location":"operations/dynamodb/#1-write-sharding-recommended-for-cascade","title":"1. Write Sharding (Recommended for Cascade)","text":"<p>Split high-fanout parent into sharded parents. See Write Sharding Guide for detailed example.</p> <pre><code># Instead of:\n#   API Key \u2192 project-123 (1000+ children, hotspot)\n#\n# Create:\n#   API Key \u2192 project-123-shard-0 through project-123-shard-N\n#   (Distribute API keys across N shards)\n\n# This spreads writes across N partitions, multiplying capacity\n</code></pre> <p>Effectiveness: 10x shards = ~10x capacity improvement (linear)</p>"},{"location":"operations/dynamodb/#2-reduce-cascade-usage","title":"2. Reduce Cascade Usage","text":"<p>If hot partition is detected and write sharding isn't feasible:</p> <pre><code># Create entities without cascade\nawait limiter.create_entity(entity_id=\"api-key\", parent_id=\"project-1\", cascade=False)\n\n# Then manually check parent limits if needed\navailable = await limiter.available(\"project-1\", \"llm-api\", [Limit.per_minute(\"rpm\", 1000)])\n</code></pre> <p>Trade-off: Parent limits no longer automatically enforced; you must check them explicitly.</p>"},{"location":"operations/dynamodb/#3-switch-to-on-demand-billing","title":"3. Switch to On-Demand Billing","text":"<pre><code>aws dynamodb update-table \\\n  --table-name &lt;name&gt; \\\n  --billing-mode PAY_PER_REQUEST\n</code></pre> <p>Cost: 5-7x more expensive, but no throttling and no partition limits.</p>"},{"location":"operations/dynamodb/#4-distributed-load-strategy","title":"4. Distributed Load Strategy","text":"<p>For enterprise deployments with many customers:</p> <ul> <li>Create one parent per customer tenant instead of one global parent</li> <li>Distribute high-fanout parents across multiple tables (region sharding)</li> <li>Use AWS Global Tables for multi-region replication</li> </ul>"},{"location":"operations/dynamodb/#monitoring-checklist","title":"Monitoring Checklist","text":"<p>Add these CloudWatch alarms to catch hot partitions early:</p> <pre><code># Alert on write throttling\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"&lt;name&gt;-write-throttle\" \\\n  --alarm-description \"Alert when write throttling occurs\" \\\n  --metric-name WriteThrottleEvents \\\n  --namespace AWS/DynamoDB \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --statistic Sum \\\n  --period 300 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Alert on read throttling\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"&lt;name&gt;-read-throttle\" \\\n  --alarm-description \"Alert when read throttling occurs\" \\\n  --metric-name ReadThrottleEvents \\\n  --namespace AWS/DynamoDB \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --statistic Sum \\\n  --period 300 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:alerts\n\n# Alert on high consumed capacity (warning before throttle)\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"&lt;name&gt;-high-capacity\" \\\n  --alarm-description \"Warning: approaching provisioned capacity\" \\\n  --metric-name ConsumedWriteCapacityUnits \\\n  --namespace AWS/DynamoDB \\\n  --dimensions Name=TableName,Value=&lt;name&gt; \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 800 \\\n  --comparison-operator GreaterThanThreshold \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789012:warnings\n</code></pre>"},{"location":"operations/dynamodb/#related","title":"Related","text":"<ul> <li>Performance Tuning - Capacity planning formulas and optimization</li> <li>Lambda Operations - Aggregator throttling due to DynamoDB</li> <li>Stream Processing - Stream processing affected by DynamoDB capacity</li> </ul>"},{"location":"operations/lambda/","title":"Lambda Aggregator Operations","text":"<p>This guide covers troubleshooting and operational procedures for the Lambda aggregator function that processes DynamoDB stream events and maintains usage snapshots.</p>"},{"location":"operations/lambda/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Lambda Issue]) --&gt; Q1{What's the symptom?}      Q1 --&gt;|Error rate alarm| CHECK1[Check CloudWatch Logs]     Q1 --&gt;|Duration alarm| CHECK2[Check processing time]     Q1 --&gt;|DLQ messages| CHECK3[Inspect DLQ]     Q1 --&gt;|Cold starts| CHECK4[Check init duration]      CHECK1 --&gt; DIAG{Error type?}     DIAG --&gt;|Permission denied| FIX1[Check IAM role]     DIAG --&gt;|Timeout| FIX2[Increase memory/timeout]     DIAG --&gt;|DynamoDB error| LINK1([\u2192 DynamoDB])     DIAG --&gt;|Code error| FIX3[Check logs, deploy fix]      CHECK2 --&gt; FIX2     CHECK3 --&gt; DLQ[DLQ Processing]     CHECK4 --&gt; FIX4[Increase memory]      click CHECK1 \"#error-rate-issues\" \"View error diagnostics\"     click FIX1 \"#error-rate-issues\" \"IAM troubleshooting\"     click FIX2 \"#high-lambda-duration\" \"Increase resources\"     click LINK1 \"dynamodb/\" \"DynamoDB operations\"     click FIX3 \"#lambda-redeployment\" \"Redeploy Lambda\"     click DLQ \"#messages-in-dead-letter-queue\" \"DLQ processing\"     click FIX4 \"#cold-start-issues\" \"Cold start fixes\""},{"location":"operations/lambda/#health-indicators","title":"Health Indicators","text":"<p>Monitor these metrics for Lambda health. See Monitoring Guide for dashboard templates.</p> Metric Healthy Warning Critical Error Rate 0% &lt; 1% &gt; 1% Duration &lt; 50% timeout &lt; 80% timeout &gt; 80% timeout Iterator Age &lt; 1s &lt; 30s &gt; 30s DLQ Depth 0 1-10 &gt; 10"},{"location":"operations/lambda/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/lambda/#symptoms","title":"Symptoms","text":"<ul> <li>Usage snapshots not updating</li> <li>Messages accumulating in Dead Letter Queue (DLQ)</li> <li>Lambda duration alarm triggered</li> <li>CloudWatch Logs showing errors</li> </ul>"},{"location":"operations/lambda/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check Lambda errors:</p> <pre><code># View recent Lambda invocations\naws logs filter-log-events \\\n  --log-group-name /aws/lambda/&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%s)000 \\\n  --filter-pattern \"ERROR\"\n</code></pre> <p>Check DLQ message count:</p> <pre><code>aws sqs get-queue-attributes \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/&lt;name&gt;-aggregator-dlq \\\n  --attribute-names ApproximateNumberOfMessagesVisible\n</code></pre> <p>Inspect DLQ messages:</p> <pre><code>aws sqs receive-message \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/&lt;name&gt;-aggregator-dlq \\\n  --max-number-of-messages 10 \\\n  --visibility-timeout 0\n</code></pre>"},{"location":"operations/lambda/#error-rate-issues","title":"Error Rate Issues","text":"<p>CloudWatch Logs Insights query for errors:</p> <pre><code>fields @timestamp, @message\n| filter @message like /ERROR/\n| sort @timestamp desc\n| limit 50\n</code></pre> <p>Common errors and solutions:</p> Error Cause Solution <code>AccessDeniedException</code> IAM role missing permissions Check role has DynamoDB and SQS permissions <code>ValidationException</code> Invalid DynamoDB operation Check for schema changes <code>ResourceNotFoundException</code> Table or stream doesn't exist Verify table name, redeploy stack <code>ProvisionedThroughputExceededException</code> DynamoDB throttling See DynamoDB Operations"},{"location":"operations/lambda/#high-lambda-duration","title":"High Lambda Duration","text":"<p>Symptoms: Duration alarm triggered, <code>processing_time_ms</code> &gt; 80% of timeout</p> <p>Diagnostic query:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Batch processing completed/\n| parse @message /processing_time_ms\":(?&lt;duration&gt;[\\d.]+)/\n| stats avg(duration) as avg_ms,\n        pct(duration, 50) as p50_ms,\n        pct(duration, 95) as p95_ms,\n        pct(duration, 99) as p99_ms\n  by bin(1h)\n| sort @timestamp desc\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Increase Lambda memory (CPU scales with memory):    <pre><code>aws lambda update-function-configuration \\\n  --function-name &lt;name&gt;-aggregator \\\n  --memory-size 512\n</code></pre></p> </li> <li> <p>Reduce batch size in event source mapping:    <pre><code>MAPPING_UUID=$(aws lambda list-event-source-mappings \\\n  --function-name &lt;name&gt;-aggregator \\\n  --query 'EventSourceMappings[0].UUID' \\\n  --output text)\n\naws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --batch-size 50\n</code></pre></p> </li> <li> <p>Check DynamoDB latency - see DynamoDB Operations</p> </li> </ol>"},{"location":"operations/lambda/#messages-in-dead-letter-queue","title":"Messages in Dead Letter Queue","text":"<p>Symptoms: DLQ alarm triggered, messages accumulating</p> <p>Investigation:</p> <ol> <li>Check Lambda logs for the error that caused the failure</li> <li>Identify if it's a transient error or persistent issue</li> <li>Fix the root cause before reprocessing</li> </ol> <p>Reprocess DLQ messages after fix:</p> <pre><code>import boto3\nimport json\n\nsqs = boto3.client('sqs')\nlambda_client = boto3.client('lambda')\n\ndlq_url = \"https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/&lt;name&gt;-aggregator-dlq\"\n\nwhile True:\n    response = sqs.receive_message(\n        QueueUrl=dlq_url,\n        MaxNumberOfMessages=10,\n        WaitTimeSeconds=5,\n    )\n\n    messages = response.get('Messages', [])\n    if not messages:\n        break\n\n    for msg in messages:\n        # Reprocess the failed event\n        body = json.loads(msg['Body'])\n\n        # Invoke Lambda directly with the failed records\n        lambda_client.invoke(\n            FunctionName='&lt;name&gt;-aggregator',\n            InvocationType='Event',\n            Payload=json.dumps(body),\n        )\n\n        # Delete from DLQ after successful reprocessing\n        sqs.delete_message(\n            QueueUrl=dlq_url,\n            ReceiptHandle=msg['ReceiptHandle'],\n        )\n\n        print(f\"Reprocessed message: {msg['MessageId']}\")\n</code></pre> <p>Purge DLQ (discard all messages):</p> <p>Data Loss</p> <p>This permanently discards failed events. Only use after confirming data is not needed.</p> <pre><code>aws sqs purge-queue \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/&lt;name&gt;-aggregator-dlq\n</code></pre>"},{"location":"operations/lambda/#cold-start-issues","title":"Cold Start Issues","text":"<p>Diagnostic query:</p> <pre><code>fields @timestamp, @message, @duration\n| filter @type = \"REPORT\"\n| filter @message like /Init Duration/\n| parse @message /Init Duration: (?&lt;init_duration&gt;[\\d.]+) ms/\n| stats count() as cold_starts,\n        avg(init_duration) as avg_init_ms\n  by bin(1h)\n</code></pre> <p>Solutions:</p> <ol> <li>Increase Lambda memory (faster initialization)</li> <li>Enable provisioned concurrency for consistent latency:    <pre><code># Publish a new version first (provisioned concurrency requires a version or alias)\nVERSION=$(aws lambda publish-version \\\n  --function-name &lt;name&gt;-aggregator \\\n  --query 'Version' --output text)\n\n# Configure provisioned concurrency on the published version\naws lambda put-provisioned-concurrency-config \\\n  --function-name &lt;name&gt;-aggregator \\\n  --qualifier $VERSION \\\n  --provisioned-concurrent-executions 2\n</code></pre></li> </ol>"},{"location":"operations/lambda/#procedures","title":"Procedures","text":""},{"location":"operations/lambda/#lambda-redeployment","title":"Lambda Redeployment","text":"<p>Update Lambda code only:</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre> <p>Full stack update:</p> <pre><code>zae-limiter deploy --name &lt;name&gt; --region &lt;region&gt;\n</code></pre>"},{"location":"operations/lambda/#memorytimeout-adjustment","title":"Memory/Timeout Adjustment","text":"<p>Via CLI (recommended):</p> <pre><code># Redeploy with new settings\nzae-limiter deploy --name &lt;name&gt; --region &lt;region&gt; \\\n  --lambda-memory 512 \\\n  --lambda-timeout 120\n</code></pre> <p>Direct Lambda update:</p> <pre><code>aws lambda update-function-configuration \\\n  --function-name &lt;name&gt;-aggregator \\\n  --memory-size 512 \\\n  --timeout 120\n</code></pre>"},{"location":"operations/lambda/#verification","title":"Verification","text":"<p>After any Lambda changes, verify health:</p> <pre><code># Check function configuration\naws lambda get-function-configuration \\\n  --function-name &lt;name&gt;-aggregator\n\n# Watch for errors in real-time\naws logs tail /aws/lambda/&lt;name&gt;-aggregator --follow\n</code></pre>"},{"location":"operations/lambda/#related","title":"Related","text":"<ul> <li>Stream Processing - Iterator age and stream lag issues</li> <li>DynamoDB Operations - Throttling and capacity issues</li> <li>Monitoring Guide - CloudWatch dashboards and alerts</li> </ul>"},{"location":"operations/load-testing/","title":"Load Testing","text":"<p>Distributed load testing for zae-limiter using Locust on AWS (Fargate Spot master + Lambda workers).</p>"},{"location":"operations/load-testing/#architecture","title":"Architecture","text":"flowchart LR     CLI[zae-limiter loadtest]     ECR[ECR Repository]     ECS[Fargate Spot]     LAMBDA[Lambda Workers]     DDB[DynamoDB]     VPCE[DynamoDB Gateway Endpoint]      CLI --&gt;|deploy| ECR     CLI --&gt;|connect| ECS     ECS --&gt;|orchestrator invokes| LAMBDA     ECS --&gt;|standalone mode| VPCE     LAMBDA --&gt; VPCE     VPCE --&gt; DDB <p>Two modes:</p> <ul> <li>Distributed (default): Fargate runs Locust master + worker orchestrator sidecar. Orchestrator proactively invokes Lambda workers that connect to the master.</li> <li>Standalone (<code>--standalone</code>): Fargate runs Locust in single-process mode. No Lambda workers. Simpler but limited by single-task CPU.</li> </ul>"},{"location":"operations/load-testing/#quick-start","title":"Quick Start","text":""},{"location":"operations/load-testing/#1-deploy-infrastructure","title":"1. Deploy Infrastructure","text":"<pre><code>zae-limiter loadtest deploy --name my-limiter --region us-east-1 \\\n  --vpc-id vpc-xxx \\\n  --subnet-ids \"subnet-aaa,subnet-bbb\" \\\n  -C examples/locust/\n</code></pre> <p>The deploy command automatically:</p> <ul> <li>Creates CloudFormation stack with ECS cluster, ECR repo, Lambda function, security groups</li> <li>Discovers route tables from subnets and creates a DynamoDB VPC Gateway endpoint (free)</li> <li>Reads IAM configuration (permission boundary, role name format) from the target stack</li> <li>Builds and pushes Docker image with zae-limiter, Locust, and your locustfiles</li> <li>Packages and uploads Lambda worker code</li> </ul>"},{"location":"operations/load-testing/#2-connect-to-master","title":"2. Connect to Master","text":"<pre><code># Distributed mode (Fargate master + Lambda workers)\nzae-limiter loadtest connect --name my-limiter --region us-east-1\n\n# Standalone mode (single process, no workers)\nzae-limiter loadtest connect --name my-limiter --region us-east-1 --standalone\n\n# Override resources at connect time\nzae-limiter loadtest connect --name my-limiter --region us-east-1 \\\n  --standalone --cpu 1024 --memory 2048 --pool-connections 200\n</code></pre> <p>Opens an SSM tunnel to <code>http://localhost:8089</code> (Locust UI).</p>"},{"location":"operations/load-testing/#3-run-test","title":"3. Run Test","text":"<pre><code># Start via curl\ncurl -X POST http://localhost:8089/swarm -d \"user_count=120&amp;spawn_rate=10\"\n\n# Monitor\ncurl -s http://localhost:8089/stats/requests | python3 -c \"\nimport json, sys\nd = json.load(sys.stdin)\np = d.get('current_response_time_percentiles', {})\nt = [s for s in d['stats'] if s['name'] == 'api'][0]\nprint(f'Users: {d[\\\"user_count\\\"]}, RPS: {t[\\\"current_rps\\\"]:.1f}')\nprint(f'p50: {p.get(\\\"response_time_percentile_0.5\\\")}ms')\nprint(f'p95: {p.get(\\\"response_time_percentile_0.95\\\")}ms')\n\"\n\n# Stop\ncurl http://localhost:8089/stop\n</code></pre>"},{"location":"operations/load-testing/#4-disconnect","title":"4. Disconnect","text":"<pre><code># Ctrl+C disconnects SSM tunnel; task keeps running\n# To stop the Fargate task on disconnect:\nzae-limiter loadtest connect --name my-limiter --region us-east-1 --destroy\n</code></pre>"},{"location":"operations/load-testing/#connect-options","title":"Connect Options","text":"Option Description Default <code>--standalone</code> Single-process mode (no Lambda workers) off <code>--force</code> Stop existing task and restart with new config off <code>--destroy</code> Stop Fargate task on disconnect off <code>--cpu</code> Task CPU units (256, 512, 1024, 2048, 4096) 1024 <code>--memory</code> Task memory in MB 2048 <code>--pool-connections</code> boto3 connection pool size 1000 <code>-f</code> Locustfile path (required) \u2014 <code>--max-workers</code> Lambda worker cap from deploy <code>--min-workers</code> Minimum workers from deploy <code>--users-per-worker</code> Auto-scaling ratio 10 <code>--startup-lead-time</code> Predictive scaling lookahead (seconds) 20"},{"location":"operations/load-testing/#calibration","title":"Calibration","text":"<p>The <code>loadtest tune</code> command uses Little's Law to binary-search for the optimal per-worker user count, then recommends distributed run configuration.</p>"},{"location":"operations/load-testing/#usage","title":"Usage","text":"<pre><code># Calibrate optimal per-worker user count\nzae-limiter loadtest tune --name my-limiter --region us-east-1 \\\n  -f locustfiles/max_rps.py --step-duration 30\n\n# Cascade calibration\nzae-limiter loadtest tune --name my-limiter --region us-east-1 \\\n  -f locustfiles/max_rps.py --user-classes MaxRpsCascadeUser --step-duration 30\n</code></pre>"},{"location":"operations/load-testing/#calibration-options","title":"Calibration Options","text":"Option Description Default <code>--max-users</code> Upper bound for binary search 40 <code>--threshold</code> Target efficiency ratio (baseline_p50 / observed_p50) 0.80 <code>--step-duration</code> Seconds per calibration step 30 <code>--baseline-duration</code> Seconds for baseline phase (1 user) 60 <code>--spawn-rate</code> User spawn rate per second 10 <code>--user-classes</code> Comma-separated User class names all"},{"location":"operations/load-testing/#how-it-works","title":"How It Works","text":"<ol> <li>Baseline: Invokes Lambda with 1 user to measure floor latency (baseline_p50)</li> <li>Upper bound check: Invokes with max_users \u2014 if efficiency &gt;= threshold, done</li> <li>Binary search: Bisects [1, max_users] measuring efficiency at each midpoint</li> <li>Report: Displays calibration table and distributed recommendations</li> </ol> <p>Efficiency = <code>baseline_p50 / observed_p50</code> \u2014 what fraction of response time is actual DynamoDB work vs. GIL queuing. Expected ~6-7 Lambda invocations for the default [1, 40] range.</p>"},{"location":"operations/load-testing/#automated-runs","title":"Automated Runs","text":"<p>The <code>loadtest run</code> command runs a self-contained, headless test and reports results \u2014 no manual Locust UI interaction needed. Supports Lambda, Fargate, and distributed runtimes.</p>"},{"location":"operations/load-testing/#usage_1","title":"Usage","text":"<pre><code># Lambda run (default) \u2014 invokes a single Lambda worker\nzae-limiter loadtest run --name my-limiter --region us-east-1 \\\n  -f locustfiles/max_rps.py --users 10 --duration 60\n\n# Fargate run \u2014 starts a Fargate task in standalone headless mode\nzae-limiter loadtest run --name my-limiter --region us-east-1 \\\n  --mode fargate \\\n  -f locustfiles/max_rps.py --users 10 --duration 60\n\n# Fargate with custom CPU/memory\nzae-limiter loadtest run --name my-limiter --region us-east-1 \\\n  --mode fargate --cpu 2048 --memory 4096 \\\n  -f locustfiles/max_rps.py --users 10 --duration 60\n</code></pre>"},{"location":"operations/load-testing/#run-options","title":"Run Options","text":"Option Description Default <code>--mode [lambda\\|fargate\\|distributed]</code> Runtime mode <code>lambda</code> <code>--users</code> Number of simulated users 20 <code>--duration</code> Test duration in seconds 60 <code>--spawn-rate</code> User spawn rate per second 10 <code>-f</code> Locustfile path \u2014 <code>--cpu</code> Fargate task CPU units (Fargate mode only) from task def <code>--memory</code> Fargate task memory in MB (Fargate mode only) from task def <code>--port</code> Local port for SSM tunnel (Fargate mode only) 8089 <code>--workers</code> Number of Lambda workers (distributed mode) 1 <code>--user-classes</code> Comma-separated User class names all"},{"location":"operations/load-testing/#how-each-mode-works","title":"How Each Mode Works","text":"<p>Lambda mode invokes the Lambda worker function synchronously with a headless Locust configuration. The Lambda runs the test and returns stats in the response payload. Simple and fast \u2014 no SSM tunnel needed.</p> <p>Fargate mode starts a Fargate task with Locust in <code>--autostart</code> mode (web UI enabled, test auto-starts). An SSM tunnel is opened in the background to poll <code>/stats/requests</code> every 5 seconds. When the test completes (<code>--run-time</code> elapses), stats are collected and the task stops automatically.</p>"},{"location":"operations/load-testing/#runtime-comparison","title":"Runtime Comparison","text":"<p>Benchmarks run on the <code>load-test</code> stack (DynamoDB on-demand, us-east-1). Three modes compared:</p> <ul> <li>Lambda standalone: <code>loadtest run --mode lambda</code> \u2014 single Lambda invocation, headless</li> <li>Distributed (1 Lambda): <code>loadtest run --mode distributed --workers 1</code> \u2014 Fargate master + 1 Lambda worker</li> <li>Fargate standalone: <code>loadtest run --mode fargate</code> \u2014 single Fargate task, no workers</li> </ul> <p>max_rps.py (zero wait between requests) \u2014 10 users, 60s:</p> Metric Lambda standalone Distributed (1 Lambda) Fargate standalone Requests 15,921 13,253 22,665 RPS 265 230 387 p50 33ms 39ms 21ms p95 41ms 53ms 35ms p99 49ms 63ms 44ms Failures 0 0 0 <p>simple.py (wait between requests) \u2014 10 users, 60s:</p> Metric Lambda standalone Distributed (1 Lambda) Fargate standalone Requests 1,068 1,047 1,047 RPS 17.8 18.5 18.8 p50 12ms 12ms 10ms p95 16ms 15ms 17ms p99 69ms 44ms 390ms Failures 0 0 0 <p>Key observations:</p> <ul> <li>Distributed matches standalone Lambda \u2014 at low load (simple.py), the numbers are essentially identical. At saturation (max_rps.py), distributed adds ~6ms p50 overhead from the master relay.</li> <li>Fargate has ~46% higher max throughput (387 vs 265 RPS) and ~36% lower p50 at saturation. Fargate sits inside the VPC closer to the DynamoDB Gateway Endpoint, with no per-invocation cold path.</li> <li>Floor latency is similar across all modes \u2014 at low load (simple.py), all runtimes hit p50=10-12ms. The DynamoDB round trip dominates, not the runtime.</li> <li>Fargate p99 can spike at task startup (cold container + SSM agent initialization). Lambda amortizes cold starts across invocations.</li> <li>Use Lambda benchmarks for quick iteration (no task startup overhead). Use Fargate benchmarks for production-representative latency numbers. Use distributed benchmarks to validate the orchestration overhead.</li> </ul>"},{"location":"operations/load-testing/#reproducing","title":"Reproducing","text":"<pre><code># Prerequisites: deployed load test stack\n# zae-limiter loadtest deploy --name &lt;target&gt; --region us-east-1 ...\n\n# 1. Login\naws sso login --profile zeroae-code/AWSPowerUserAccess\n\n# 2. Lambda standalone benchmark\nAWS_PROFILE=zeroae-code/AWSPowerUserAccess \\\n  uv run zae-limiter loadtest run \\\n  --name &lt;target&gt; --region us-east-1 \\\n  -f locustfiles/max_rps.py --users 10 --duration 60\n\n# 3. Fargate standalone benchmark\n#    (don't run simultaneously \u2014 they share the same DynamoDB table)\nAWS_PROFILE=zeroae-code/AWSPowerUserAccess \\\n  uv run zae-limiter loadtest run \\\n  --name &lt;target&gt; --region us-east-1 \\\n  --mode fargate \\\n  -f locustfiles/max_rps.py --users 10 --duration 60\n\n# 4. Distributed benchmark (1 Lambda worker)\nAWS_PROFILE=zeroae-code/AWSPowerUserAccess \\\n  uv run zae-limiter loadtest run \\\n  --name &lt;target&gt; --region us-east-1 \\\n  --mode distributed --workers 1 \\\n  -f locustfiles/max_rps.py --users 10 --duration 60\n\n# 5. Repeat steps 2-4 with simple.py for floor latency\n</code></pre>"},{"location":"operations/load-testing/#capacity-planning","title":"Capacity Planning","text":""},{"location":"operations/load-testing/#standalone-mode","title":"Standalone Mode","text":"<p>Standalone runs all Locust users in a single Fargate task. Locust uses gevent (green threads) in a single Python process, so it is bound by the GIL to one CPU core regardless of how many vCPUs the task has.</p> <p>GIL limitation: Allocating 4 vCPU to a standalone task wastes 3 cores. At 500 users on 4 vCPU, only ~1024/4096 CPU units (25%) were utilized \u2014 exactly 1 core saturated. Latency degraded to p50=1100ms despite 75% idle CPU. For throughput beyond ~300 RPS, use distributed mode with Lambda workers (each worker is a separate process with its own GIL).</p> <p>Benchmark results (1 vCPU, 2 GB, pool=1000, simple.py locustfile):</p> Users RPS CPU % Current p50 Current p95 120 210 ~37% 12ms 21ms 150 266 ~50% 14ms 26ms 180 314 ~72% 17ms 39ms 220 371 ~99% 43ms 130ms 260 369 ~100% 140ms 230ms <p>Recommended: stay at or below 180 users (~70% CPU) for stable p95 latencies under 40ms.</p> <p>Above ~220 users, CPU saturates (&gt;99%) and latency degrades rapidly. The <code>write_each()</code> optimization (UpdateItem at 3.5ms vs TransactWriteItems at 15.7ms) dramatically reduced per-request latency, but the faster writes mean each coroutine completes sooner and re-enters the event loop faster, causing CPU saturation at lower user counts.</p> <p>4 vCPU comparison (to demonstrate GIL bottleneck):</p> Users RPS CPU (used/total) Current p50 Current p95 500 292 ~1007/4096 (25%) 1100ms 1200ms <p>The 4 vCPU task achieves similar RPS to 1 vCPU but with much worse latency due to 500 green threads contending for one core.</p> <p>Recommended: use 1 vCPU for standalone mode. Extra vCPUs are wasted.</p> <p>Max throughput (1 vCPU, 2 GB, pool=1000, max_rps.py \u2014 zero wait between requests):</p> Users RPS CPU % Current p50 Current p95 10 357 ~65% 26ms 36ms 20 383 ~75% 47ms 61ms 30 386 ~65% 69ms 87ms 40 381 ~100% 95ms 130ms <p>With zero inter-request delay, the system peaks at ~385 RPS on 1 vCPU. Adding users beyond 10-20 only increases latency without improving throughput \u2014 the single Python core is fully saturated. The lowest achievable latencies are p50=26ms, p95=36ms at 10 users / 357 RPS.</p> <p>DynamoDB metrics (on-demand capacity):</p> Scenario RPS Operation Avg latency Max latency Throttling simple.py, 180 users 314 UpdateItem 3.5ms 50-100ms Zero simple.py, 180 users 314 GetItem 1.2ms 20-40ms Zero max_rps.py, 10-40 users 385 UpdateItem 3.5ms 50-100ms Zero max_rps.py, 10-40 users 385 GetItem 1.2ms 20-40ms Zero <p>Each <code>acquire()</code> performs a GetItem (read buckets) + UpdateItem (write consumption). The <code>write_each()</code> optimization uses individual UpdateItem calls instead of TransactWriteItems, reducing server-side write latency from ~15.7ms to ~3.5ms. DynamoDB on-demand handles this comfortably with no throttling.</p> <p>Latency breakdown \u2014 DynamoDB server vs Python client (max_rps.py, 10 users):</p> <p>Each <code>acquire()</code> makes 2 sequential DynamoDB round trips on the hot path (config cached, non-cascade, single limit):</p> <pre><code>acquire()\n \u251c\u2500 Round trip 1: GetItem     \u2192 read entity + composite bucket   (1.2ms server)\n \u251c\u2500 Round trip 2: UpdateItem  \u2192 write consumption (write-on-enter) (3.5ms server)\n \u2514\u2500 _commit_adjustments()     \u2192 no-op (no adjust() called)\n</code></pre> Layer Avg latency Notes Round trip 1: GetItem \u2002 DynamoDB server 1.2ms Read composite bucket \u2002 boto3 overhead ~4-5ms SigV4 signing, serialization, urllib3 \u2002 Network RTT ~1-1.5ms Fargate \u2192 VPC Gateway Endpoint \u2192 DynamoDB Round trip 2: UpdateItem \u2002 DynamoDB server 3.5ms Write consumption (ADD tokens, counter) \u2002 boto3 overhead ~4-5ms SigV4 signing, serialization, urllib3 \u2002 Network RTT ~1-1.5ms Fargate \u2192 VPC Gateway Endpoint \u2192 DynamoDB Python logic ~1-2ms Validation, cache lookup, bucket math, expression building Total (Locust p50) ~26ms End-to-end from Python <p>boto3 is the dominant overhead (~8-10ms across 2 calls). Each DynamoDB call goes through SigV4 request signing (HMAC-SHA256), canonical request construction, JSON serialization/deserialization, and urllib3 HTTP handling \u2014 all in pure Python under the GIL. The business logic itself (config cache lookup, integer bucket math in <code>try_consume()</code>, UpdateExpression building) is &lt;2ms.</p> <p>The operations are inherently sequential: must read buckets \u2192 compute deltas \u2192 write results. No parallelization opportunity.</p> <p>At higher concurrency the gap grows \u2014 at 30 users p50 jumps to 69ms while DynamoDB stays at 4.7ms. The extra ~64ms is pure GIL contention, not DynamoDB.</p> <p>Comparison with Redis/Valkey (ElastiCache):</p> Backend Read (server) Write (server) Server total boto3/client overhead Est. e2e (2 RTs) DynamoDB 1.2ms 3.5ms ~4.7ms ~10-12ms (boto3 SigV4) ~26ms ElastiCache Redis/Valkey ~0.2ms ~0.3ms ~0.5ms ~1-2ms (redis-py) ~5-8ms <p>Redis/Valkey would be ~10x faster on server-side latency and ~5x faster end-to-end because the redis-py client is much lighter than boto3 (no SigV4 signing, simpler RESP protocol vs JSON). The real advantage of Redis is at scale \u2014 lower CPU cost per operation pushes the GIL saturation point to much higher user counts. The trade-off is operational: DynamoDB requires zero provisioning (on-demand, serverless, no cluster management), while ElastiCache requires choosing instance types, managing failover, and paying per-node.</p>"},{"location":"operations/load-testing/#connection-pool-sizing","title":"Connection Pool Sizing","text":"<p>Each concurrent DynamoDB request needs a connection from the pool. If the pool is exhausted, requests queue and latency spikes:</p> <pre><code>Connection pool is full, discarding connection: dynamodb.us-east-1.amazonaws.com. Connection pool size: 200\n</code></pre> <p>A larger pool also reduces CPU overhead \u2014 with pool=200, 120 users consumed ~77% CPU; with pool=1000, 120 users consumed only ~48% CPU.</p> <p>Guidelines:</p> Users Recommended Pool &lt; 100 200 100-300 1000 300+ Use distributed mode <p>Override at connect time: <code>--pool-connections 1000</code></p>"},{"location":"operations/load-testing/#distributed-mode","title":"Distributed Mode","text":"<p>For higher throughput, use distributed mode with Lambda workers. Each worker runs ~10 users optimally (65% CPU at 1 vCPU):</p> Target Users Workers Notes 100 10 Auto-scales based on user count 500 50 Auto-scales based on user count 1000 100 Set <code>--max-workers 100</code> at deploy <p>Lambda workers have their own connection pool (50 connections each), so pool exhaustion is less of a concern.</p>"},{"location":"operations/load-testing/#monitoring","title":"Monitoring","text":""},{"location":"operations/load-testing/#locust-stats","title":"Locust Stats","text":"<pre><code># Current percentiles (not contaminated by earlier spikes)\ncurl -s http://localhost:8089/stats/requests | \\\n  python3 -c \"import json,sys; d=json.load(sys.stdin); print(d['current_response_time_percentiles'])\"\n</code></pre> <p>Use <code>current_response_time_percentiles</code> for real-time monitoring. The cumulative stats (<code>response_time_percentile_0.95</code>) include all historical data and can be misleading after load changes.</p>"},{"location":"operations/load-testing/#container-insights-cpumemory","title":"Container Insights (CPU/Memory)","text":"<pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace ECS/ContainerInsights \\\n  --metric-name CpuUtilized \\\n  --dimensions Name=ClusterName,Value=&lt;stack&gt;-load \\\n  --start-time $(date -u -v-5M +%Y-%m-%dT%H:%M:%S) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\\n  --period 60 --statistics Average \\\n  --query 'Datapoints[*].[Timestamp,Average]' --output text | sort\n</code></pre> <p>CPU is reported in CPU units (1 vCPU = 1024). Compare against the task's CPU allocation.</p>"},{"location":"operations/load-testing/#dynamodb-metrics","title":"DynamoDB Metrics","text":"<pre><code># Consumed capacity\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedWriteCapacityUnits \\\n  --dimensions Name=TableName,Value=&lt;stack-name&gt; \\\n  --start-time $(date -u -v-10M +%Y-%m-%dT%H:%M:%S) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\\n  --period 60 --statistics Sum --output table\n\n# Check for throttling (should be 0)\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ThrottledRequests \\\n  --dimensions Name=TableName,Value=&lt;stack-name&gt; \\\n  --start-time $(date -u -v-10M +%Y-%m-%dT%H:%M:%S) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\\n  --period 60 --statistics Sum --output table\n</code></pre>"},{"location":"operations/load-testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/load-testing/#task-fails-to-start","title":"Task Fails to Start","text":"<pre><code>Error: Task failed to start within 2 minutes\n</code></pre> <p>Check for stale tasks and force restart:</p> <pre><code>zae-limiter loadtest connect --name my-limiter --force\n</code></pre>"},{"location":"operations/load-testing/#port-already-in-use","title":"Port Already in Use","text":"<pre><code>Cannot perform start session: listen tcp 127.0.0.1:8089: bind: address already in use\n</code></pre> <p>Kill the stale SSM session process:</p> <pre><code>lsof -ti :8089 | xargs kill\n</code></pre>"},{"location":"operations/load-testing/#sso-session-expired","title":"SSO Session Expired","text":"<pre><code>UnauthorizedSSOTokenError: The SSO session associated with this profile has expired\n</code></pre> <p>Re-login:</p> <pre><code>aws sso login --profile &lt;your-profile&gt;\n</code></pre>"},{"location":"operations/load-testing/#high-p95-after-load-change","title":"High p95 After Load Change","text":"<p>Locust cumulative stats include all historical data. After changing user count, the cumulative p95/p99 will be inflated. Use <code>current_response_time_percentiles</code> for real-time values, or reset stats via the Locust UI.</p>"},{"location":"operations/rate-limits/","title":"Rate Limit Operations","text":"<p>This guide covers troubleshooting rate limit enforcement issues and procedures for adjusting limits at runtime.</p>"},{"location":"operations/rate-limits/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Rate Limit Issue]) --&gt; Q1{What's happening?}      Q1 --&gt;|Unexpected RateLimitExceeded| A1[Check bucket state]     Q1 --&gt;|Limits not enforcing| A2[Check entity exists]     Q1 --&gt;|Cascade not working| A3[Check parent entity]     Q1 --&gt;|Need to adjust limits| A4[Runtime adjustment]      A1 --&gt; CHECK1[Query bucket in DynamoDB]     A2 --&gt; CHECK2[Query entity metadata]     A3 --&gt; CHECK3[Verify parent_id and entity cascade setting]      CHECK1 --&gt; FIX1{Bucket state?}     FIX1 --&gt;|Depleted| WAIT[Wait for refill or reset]     FIX1 --&gt;|Has capacity| CONFIG[Check limit configuration]      CHECK2 --&gt; FIX2{Entity exists?}     FIX2 --&gt;|No| CREATE[Create entity first]     FIX2 --&gt;|Yes| LIMITS[Check stored limits config]      click A1 \"#unexpected-ratelimitexceeded\" \"Diagnose unexpected limits\"     click A2 \"#limits-not-enforcing\" \"Check entity setup\"     click A3 \"#cascade-not-working\" \"Check parent setup\"     click A4 \"#adjust-limits-at-runtime\" \"Adjust limits\"     click WAIT \"#reset-bucket-state\" \"Reset bucket\"     click CHECK1 \"#debug-bucket-state\" \"Query bucket state\""},{"location":"operations/rate-limits/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/rate-limits/#symptoms","title":"Symptoms","text":"<ul> <li>Requests succeed when they should be rate limited</li> <li><code>RateLimitExceeded</code> raised unexpectedly</li> <li>Cascade to parent entity not working</li> <li>Bucket state appears incorrect</li> </ul>"},{"location":"operations/rate-limits/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check entity and bucket state:</p> <pre><code># Query entity metadata\naws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n\n# Query bucket state for a specific limit\naws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre> <p>Verify stored limits:</p> <pre><code>aws dynamodb query --table-name &lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#LIMIT#\"}}'\n</code></pre>"},{"location":"operations/rate-limits/#unexpected-ratelimitexceeded","title":"Unexpected RateLimitExceeded","text":"<p>Possible causes:</p> Cause Diagnosis Solution Bucket depleted Check bucket <code>tokens</code> value Wait for refill or increase limit Limit too restrictive Compare limit capacity vs usage Increase capacity Cascade triggered Check <code>violations</code> array Increase parent limit Clock skew Compare server time with bucket <code>last_update</code> Sync NTP <p>Check bucket state:</p> <pre><code>aws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}' \\\n  --projection-expression \"tokens, last_update, capacity\"\n</code></pre> <p>Interpret the response:</p> <ul> <li><code>tokens</code>: Current token count (in millitokens, divide by 1000)</li> <li><code>last_update</code>: Unix timestamp of last access</li> <li><code>capacity</code>: Maximum bucket capacity (in millitokens)</li> </ul>"},{"location":"operations/rate-limits/#limits-not-enforcing","title":"Limits Not Enforcing","text":"<p>Common causes:</p> Cause Solution Entity not created Create entity before rate limiting: <code>await limiter.create_entity(...)</code> No stored limits configured Set limits via <code>set_system_defaults()</code>, <code>set_resource_defaults()</code>, or <code>set_limits()</code> Stale bucket state Bucket refills over time; tokens may have refilled Limit configuration mismatch Verify limit <code>capacity</code>, <code>burst</code>, and <code>refill_rate</code> match expectations <p>Verify entity exists:</p> <pre><code>aws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n</code></pre>"},{"location":"operations/rate-limits/#cascade-not-working","title":"Cascade Not Working","text":"<p>If cascade to parent is not enforced:</p> <p>Step 1: Verify parent entity exists:</p> <pre><code>aws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;parent_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n</code></pre> <p>Step 2: Verify child has <code>parent_id</code> set:</p> <pre><code>aws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;child_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n# Check the \"parent_id\" attribute in response\n</code></pre> <p>Step 3: Ensure entity was created with <code>cascade=True</code>:</p> <pre><code># Check the entity's cascade setting in its metadata\naws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;child_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n# Check the \"cascade\" attribute in response \u2014 should be true\n</code></pre> <p>If cascade is not enabled, recreate the entity with cascade:</p> <pre><code>await limiter.create_entity(\n    entity_id=\"child-id\",\n    parent_id=\"parent-id\",\n    cascade=True,  # Entity property \u2014 applies to all acquire() calls\n)\n</code></pre>"},{"location":"operations/rate-limits/#verification","title":"Verification","text":"<p>Test that rate limiting is working correctly:</p> <pre><code>from zae_limiter import RateLimiter, Limit, RateLimitExceeded\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\n# Consume all capacity\nfor i in range(100):\n    try:\n        async with limiter.acquire(\n            entity_id=\"test-entity\",\n            resource=\"test\",\n            limits=[Limit.per_minute(\"rpm\", 100)],\n            consume={\"rpm\": 1},\n        ):\n            pass\n    except RateLimitExceeded as e:\n        print(f\"Rate limited after {i} requests, retry_after={e.retry_after_seconds}s\")\n        break\n</code></pre>"},{"location":"operations/rate-limits/#procedures","title":"Procedures","text":""},{"location":"operations/rate-limits/#adjust-limits-at-runtime","title":"Adjust Limits at Runtime","text":""},{"location":"operations/rate-limits/#programmatic-adjustment","title":"Programmatic Adjustment","text":"<p>Update stored limits for an entity without redeployment:</p> <pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\n# Update limits for an entity\nawait limiter.set_limits(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",  # Resource these limits apply to\n    limits=[\n        Limit.per_minute(\"rpm\", 1000),      # Requests per minute\n        Limit.per_minute(\"tpm\", 100_000),   # Tokens per minute\n    ],\n)\n\nprint(\"Limits updated successfully\")\n</code></pre>"},{"location":"operations/rate-limits/#direct-dynamodb-update","title":"Direct DynamoDB Update","text":"<p>Advanced</p> <p>Direct DynamoDB updates bypass validation. Use programmatic API when possible.</p> <pre><code># Update a stored limit\naws dynamodb put-item --table-name &lt;name&gt; \\\n  --item '{\n    \"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"},\n    \"SK\": {\"S\": \"#LIMIT#&lt;resource&gt;#&lt;limit_name&gt;\"},\n    \"capacity\": {\"N\": \"1000000\"},\n    \"burst\": {\"N\": \"1000000\"},\n    \"refill_amount\": {\"N\": \"1000000\"},\n    \"refill_period\": {\"N\": \"60\"}\n  }'\n</code></pre>"},{"location":"operations/rate-limits/#reset-bucket-state","title":"Reset Bucket State","text":"<p>Reset a bucket to restore full capacity:</p> <pre><code># Delete the bucket (will be recreated on next acquire with full capacity)\naws dynamodb delete-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre>"},{"location":"operations/rate-limits/#debug-bucket-state","title":"Debug Bucket State","text":"<p>Query all buckets for an entity:</p> <pre><code>aws dynamodb query --table-name &lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#BUCKET#\"}}' \\\n  --projection-expression \"SK, tokens, capacity, last_update\"\n</code></pre> <p>Interpret bucket values:</p> <p>All token values are stored as millitokens (multiply by 1000):</p> Field Description Example <code>tokens</code> Current available tokens \u00d7 1000 <code>50000</code> = 50 tokens <code>capacity</code> Maximum bucket size \u00d7 1000 <code>100000</code> = 100 tokens <code>last_update</code> Unix timestamp <code>1705312800</code>"},{"location":"operations/rate-limits/#verification-after-changes","title":"Verification After Changes","text":"<p>After adjusting limits, verify:</p> <pre><code># Check available capacity\navailable = await limiter.available(\n    entity_id=\"&lt;entity_id&gt;\",\n    resource=\"&lt;resource&gt;\",\n    limits=[Limit.per_minute(\"&lt;limit_name&gt;\", &lt;capacity&gt;)],\n)\n\nprint(f\"Available: {available}\")\n# Output: {'&lt;limit_name&gt;': &lt;available_tokens&gt;}\n</code></pre>"},{"location":"operations/rate-limits/#dynamodb-key-patterns","title":"DynamoDB Key Patterns","text":"Pattern Key Description Entity metadata <code>PK=ENTITY#&lt;id&gt;, SK=#META</code> Entity configuration Bucket state <code>PK=ENTITY#&lt;id&gt;, SK=#BUCKET#&lt;resource&gt;#&lt;limit&gt;</code> Token bucket Stored limit <code>PK=ENTITY#&lt;id&gt;, SK=#LIMIT#&lt;resource&gt;#&lt;limit&gt;</code> Limit configuration"},{"location":"operations/rate-limits/#related","title":"Related","text":"<ul> <li>Recovery &amp; Rollback - Reset corrupted buckets</li> <li>Performance Tuning - Capacity planning for rate limits</li> <li>Hierarchical Limits - Cascade configuration</li> </ul>"},{"location":"operations/recovery/","title":"Recovery &amp; Rollback","text":"<p>This guide covers backup, restore, and rollback procedures for zae-limiter deployments.</p>"},{"location":"operations/recovery/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([What went wrong?]) --&gt; Q1{Issue type?}      Q1 --&gt;|Bad deployment| DEP{Deployment issue?}     Q1 --&gt;|Bad migration| MIG{Reversible?}     Q1 --&gt;|Data corruption| DATA{How recent?}     Q1 --&gt;|Complete failure| FAIL{Table exists?}      DEP --&gt;|CloudFormation failed| STACK_ROLL[Stack Rollback]     DEP --&gt;|Lambda broken| LAMBDA_FIX[Lambda Redeployment]     DEP --&gt;|Config wrong| STACK_UPDATE[Stack Redeployment]      MIG --&gt;|Yes| MIG_ROLL[Migration Rollback]     MIG --&gt;|No| BACKUP_RESTORE[Restore from Backup]      DATA --&gt;|&lt; 35 days| PITR[PITR Recovery]     DATA --&gt;|Older| BACKUP_RESTORE      FAIL --&gt;|Yes| STACK_UPDATE     FAIL --&gt;|No| FULL[Full Recovery]      click STACK_ROLL \"#stack-rollback\" \"CloudFormation auto-rollback\"     click LAMBDA_FIX \"#lambda-redeployment\" \"Redeploy Lambda code\"     click STACK_UPDATE \"#stack-redeployment\" \"Delete and recreate stack\"     click MIG_ROLL \"#migration-rollback\" \"Rollback reversible migration\"     click BACKUP_RESTORE \"#dynamodb-backup-and-restore\" \"Restore from on-demand backup\"     click PITR \"#point-in-time-recovery-pitr\" \"Point-in-time recovery\"     click FULL \"#full-recovery\" \"Complete recovery procedure\""},{"location":"operations/recovery/#emergency-rollback-decision-matrix","title":"Emergency Rollback Decision Matrix","text":"Situation Action Time to Recovery Data Loss Risk Lambda errors after upgrade <code>zae-limiter upgrade --lambda-only</code> with previous version ~2 min None Schema migration failed Restore from pre-migration backup ~10-30 min Changes since backup Stack update failed CloudFormation auto-rollback ~5 min None Data corruption (recent) PITR restore ~15-30 min None (point-in-time) Data corruption (old) On-demand backup restore ~15-30 min Changes since backup Complete stack failure Delete + redeploy (if deletion protection on) ~10 min None (table retained)"},{"location":"operations/recovery/#dynamodb-backup-and-restore","title":"DynamoDB Backup and Restore","text":""},{"location":"operations/recovery/#create-on-demand-backup","title":"Create On-Demand Backup","text":"<p>Before any risky operation:</p> <pre><code>aws dynamodb create-backup \\\n  --table-name &lt;name&gt; \\\n  --backup-name \"manual-backup-$(date +%Y%m%d-%H%M%S)\"\n</code></pre> <p>Verify backup created:</p> <pre><code>aws dynamodb list-backups \\\n  --table-name &lt;name&gt; \\\n  --time-range-lower-bound $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ)\n</code></pre>"},{"location":"operations/recovery/#list-available-backups","title":"List Available Backups","text":"<pre><code>aws dynamodb list-backups \\\n  --table-name &lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#restore-from-backup","title":"Restore from Backup","text":"<p>New Table Name</p> <p>Restore creates a new table. You must update your application to use the new table name or rename after restore.</p> <pre><code>aws dynamodb restore-table-from-backup \\\n  --target-table-name &lt;name&gt;-restored \\\n  --backup-arn &lt;backup-arn&gt;\n</code></pre> <p>Wait for restore to complete:</p> <pre><code>aws dynamodb describe-table --table-name &lt;name&gt;-restored \\\n  --query 'Table.TableStatus'\n</code></pre>"},{"location":"operations/recovery/#point-in-time-recovery-pitr","title":"Point-in-Time Recovery (PITR)","text":"<p>PITR allows restore to any point in the last 35 days.</p> <p>Check if PITR is enabled:</p> <pre><code>aws dynamodb describe-continuous-backups \\\n  --table-name &lt;name&gt;\n</code></pre> <p>Enable PITR (if not enabled):</p> <pre><code>aws dynamodb update-continuous-backups \\\n  --table-name &lt;name&gt; \\\n  --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true\n</code></pre> <p>Restore to specific point in time:</p> <pre><code>aws dynamodb restore-table-to-point-in-time \\\n  --source-table-name &lt;name&gt; \\\n  --target-table-name &lt;name&gt;-restored \\\n  --restore-date-time \"2024-01-15T10:00:00Z\"\n</code></pre> <p>Restore to latest restorable time:</p> <pre><code>aws dynamodb restore-table-to-point-in-time \\\n  --source-table-name &lt;name&gt; \\\n  --target-table-name &lt;name&gt;-restored \\\n  --use-latest-restorable-time\n</code></pre>"},{"location":"operations/recovery/#migration-rollback","title":"Migration Rollback","text":""},{"location":"operations/recovery/#reversible-migrations","title":"Reversible Migrations","text":"<p>For migrations that support rollback:</p> <pre><code>from zae_limiter.migrations import get_migrations\nfrom zae_limiter.repository import Repository\n\nasync def rollback_migration(name: str, region: str, target_version: str):\n    \"\"\"Rollback a reversible migration.\"\"\"\n    repo = Repository(name, region, None)\n\n    try:\n        migrations = get_migrations()\n        target = next((m for m in migrations if m.version == target_version), None)\n\n        if target and target.reversible and target.rollback:\n            await target.rollback(repo)\n            print(f\"Rolled back migration {target_version}\")\n\n            # Update version record\n            await repo.set_version_record(\n                schema_version=\"&lt;previous_version&gt;\",\n                updated_by=\"manual_rollback\",\n            )\n        else:\n            print(\"Migration is not reversible - restore from backup\")\n    finally:\n        await repo.close()\n</code></pre>"},{"location":"operations/recovery/#non-reversible-migrations","title":"Non-Reversible Migrations","text":"<p>For migrations without rollback support:</p> <ol> <li>Restore from backup taken before migration</li> <li>Update stack to match restored schema version</li> <li>Downgrade client to compatible version</li> </ol>"},{"location":"operations/recovery/#stack-operations","title":"Stack Operations","text":""},{"location":"operations/recovery/#stack-rollback","title":"Stack Rollback","text":"<p>CloudFormation automatically rolls back failed updates. If a stack is stuck:</p> <p>Check stack status:</p> <pre><code>aws cloudformation describe-stacks \\\n  --stack-name &lt;name&gt; \\\n  --query 'Stacks[0].StackStatus'\n</code></pre> <p>View rollback events:</p> <pre><code>aws cloudformation describe-stack-events \\\n  --stack-name &lt;name&gt; \\\n  --query 'StackEvents[?ResourceStatus==`UPDATE_ROLLBACK_IN_PROGRESS` || ResourceStatus==`UPDATE_ROLLBACK_COMPLETE`]'\n</code></pre> <p>Continue rollback (if stuck):</p> <pre><code>aws cloudformation continue-update-rollback \\\n  --stack-name &lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#stack-redeployment","title":"Stack Redeployment","text":"<p>Delete and recreate stack (preserves DynamoDB data with deletion protection):</p> <pre><code># Step 1: Verify deletion protection is enabled\naws dynamodb describe-table --table-name &lt;name&gt; \\\n  --query 'Table.DeletionProtectionEnabled'\n\n# Step 2: Delete stack (table retained if deletion protection enabled)\nzae-limiter delete --name &lt;name&gt; --region &lt;region&gt; --yes\n\n# Step 3: Wait for deletion\naws cloudformation wait stack-delete-complete --stack-name &lt;name&gt;\n\n# Step 4: Redeploy\nzae-limiter deploy --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Update existing stack:</p> <pre><code># Export current template\nzae-limiter cfn-template &gt; updated-template.yaml\n\n# Update via CloudFormation\naws cloudformation update-stack \\\n  --stack-name &lt;name&gt; \\\n  --template-body file://updated-template.yaml \\\n  --capabilities CAPABILITY_NAMED_IAM\n\n# Wait for update\naws cloudformation wait stack-update-complete --stack-name &lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#lambda-redeployment","title":"Lambda Redeployment","text":"<p>Redeploy Lambda with current code:</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre> <p>Redeploy with specific version:</p> <pre><code># First, install the specific version\npip install zae-limiter==&lt;version&gt;\n\n# Then upgrade Lambda\nzae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre>"},{"location":"operations/recovery/#data-reconciliation","title":"Data Reconciliation","text":""},{"location":"operations/recovery/#reset-corrupted-bucket","title":"Reset Corrupted Bucket","text":"<p>Delete a specific bucket (will be recreated on next acquire):</p> <pre><code>aws dynamodb delete-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre>"},{"location":"operations/recovery/#reset-all-buckets-for-entity","title":"Reset All Buckets for Entity","text":"<pre><code># Query all buckets\nBUCKETS=$(aws dynamodb query --table-name &lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#BUCKET#\"}}' \\\n  --projection-expression \"PK, SK\" \\\n  --output json)\n\n# Delete each bucket\necho $BUCKETS | jq -r '.Items[] | @base64' | while read item; do\n  PK=$(echo $item | base64 -d | jq -r '.PK.S')\n  SK=$(echo $item | base64 -d | jq -r '.SK.S')\n\n  aws dynamodb delete-item --table-name &lt;name&gt; \\\n    --key \"{\\\"PK\\\": {\\\"S\\\": \\\"$PK\\\"}, \\\"SK\\\": {\\\"S\\\": \\\"$SK\\\"}}\"\n\n  echo \"Deleted: $SK\"\ndone\n</code></pre>"},{"location":"operations/recovery/#verify-entity-integrity","title":"Verify Entity Integrity","text":"<pre><code>async def verify_entity(limiter, entity_id: str) -&gt; bool:\n    \"\"\"Verify entity can perform rate limiting operations.\"\"\"\n    from zae_limiter import Limit\n\n    try:\n        # Check entity exists\n        entity = await limiter.get_entity(entity_id)\n        print(f\"Entity: {entity.entity_id}, parent: {entity.parent_id}\")\n\n        # Check rate limiting works\n        available = await limiter.available(\n            entity_id=entity_id,\n            resource=\"health-check\",\n            limits=[Limit.per_minute(\"test\", 1000)],\n        )\n        print(f\"Available capacity: {available}\")\n\n        return True\n    except Exception as e:\n        print(f\"Entity verification failed: {e}\")\n        return False\n</code></pre>"},{"location":"operations/recovery/#full-recovery","title":"Full Recovery","text":"<p>Complete recovery from total failure:</p>"},{"location":"operations/recovery/#step-1-assess-situation","title":"Step 1: Assess Situation","text":"<pre><code># Check if table exists\naws dynamodb describe-table --table-name &lt;name&gt; 2&gt;/dev/null &amp;&amp; echo \"Table exists\" || echo \"Table missing\"\n\n# Check if stack exists\naws cloudformation describe-stacks --stack-name &lt;name&gt; 2&gt;/dev/null &amp;&amp; echo \"Stack exists\" || echo \"Stack missing\"\n</code></pre>"},{"location":"operations/recovery/#step-2-restore-table-if-needed","title":"Step 2: Restore Table (if needed)","text":"<pre><code># List available backups\naws dynamodb list-backups --table-name &lt;name&gt;\n\n# Restore from backup\naws dynamodb restore-table-from-backup \\\n  --target-table-name &lt;name&gt; \\\n  --backup-arn &lt;backup-arn&gt;\n\n# Wait for restore\naws dynamodb wait table-exists --table-name &lt;name&gt;\n</code></pre>"},{"location":"operations/recovery/#step-3-redeploy-stack","title":"Step 3: Redeploy Stack","text":"<pre><code>zae-limiter deploy --name &lt;name&gt; --region &lt;region&gt;\n</code></pre>"},{"location":"operations/recovery/#step-4-verify","title":"Step 4: Verify","text":"<pre><code># Check stack status\nzae-limiter status --name &lt;name&gt; --region &lt;region&gt;\n\n# Check version\nzae-limiter version --name &lt;name&gt; --region &lt;region&gt;\n\n# Check compatibility\nzae-limiter check --name &lt;name&gt; --region &lt;region&gt;\n</code></pre>"},{"location":"operations/recovery/#prevention","title":"Prevention","text":""},{"location":"operations/recovery/#enable-deletion-protection","title":"Enable Deletion Protection","text":"<pre><code>aws dynamodb update-table \\\n  --table-name &lt;name&gt; \\\n  --deletion-protection-enabled\n</code></pre>"},{"location":"operations/recovery/#enable-pitr","title":"Enable PITR","text":"<pre><code>aws dynamodb update-continuous-backups \\\n  --table-name &lt;name&gt; \\\n  --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true\n</code></pre>"},{"location":"operations/recovery/#schedule-regular-backups","title":"Schedule Regular Backups","text":"<p>Create a CloudWatch Events rule to backup daily:</p> <pre><code># Create backup Lambda or use AWS Backup service\naws backup create-backup-plan \\\n  --backup-plan '{\"BackupPlanName\": \"zae-limiter-daily\", \"Rules\": [{\"RuleName\": \"daily\", \"TargetBackupVaultName\": \"Default\", \"ScheduleExpression\": \"cron(0 5 * * ? *)\", \"Lifecycle\": {\"DeleteAfterDays\": 30}}]}'\n</code></pre>"},{"location":"operations/recovery/#related","title":"Related","text":"<ul> <li>Version Management - Version upgrade and rollback</li> <li>DynamoDB Operations - Capacity and throttling issues</li> <li>Migration Guide - Schema migration procedures</li> </ul>"},{"location":"operations/streams/","title":"Stream Processing Operations","text":"<p>This guide covers troubleshooting and operational procedures for DynamoDB Streams processing, which powers the usage aggregation feature.</p>"},{"location":"operations/streams/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Stream Issue]) --&gt; Q1{What's the symptom?}      Q1 --&gt;|High IteratorAge| A1[Check processing lag]     Q1 --&gt;|Lambda throttling| A2[Check concurrency]     Q1 --&gt;|Missing snapshots| A3[Check Lambda errors]     Q1 --&gt;|Planning optimization| A4[Tune configuration]      A1 --&gt; CHECK1{Lambda healthy?}     CHECK1 --&gt;|No| LINK1([\u2192 Lambda])     CHECK1 --&gt;|Yes| SCALE[Increase concurrency]      A2 --&gt; SCALE     A3 --&gt; LINK1     A4 --&gt; TUNE[Adjust batch size / concurrency]      click A1 \"#high-iterator-age\" \"Diagnose lag\"     click LINK1 \"lambda/\" \"Lambda troubleshooting\"     click SCALE \"#scaling-stream-processing\" \"Scale concurrency\"     click A3 \"lambda/#error-rate-issues\" \"Check Lambda errors\"     click TUNE \"#tuning-stream-processing\" \"Configuration tuning\""},{"location":"operations/streams/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/streams/#symptoms","title":"Symptoms","text":"<ul> <li><code>IteratorAge</code> metric growing</li> <li>Usage snapshots delayed</li> <li>Stream iterator age alarm triggered</li> <li>Lambda throttling</li> </ul>"},{"location":"operations/streams/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check IteratorAge metric:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name IteratorAge \\\n  --dimensions Name=FunctionName,Value=&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum\n</code></pre> <p>Check stream status:</p> <pre><code>aws dynamodb describe-table --table-name &lt;name&gt; \\\n  --query 'Table.StreamSpecification'\n</code></pre> <p>Check Lambda event source mapping:</p> <pre><code>aws lambda list-event-source-mappings \\\n  --function-name &lt;name&gt;-aggregator\n</code></pre> <p>Check Lambda concurrent executions:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name ConcurrentExecutions \\\n  --dimensions Name=FunctionName,Value=&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum\n</code></pre>"},{"location":"operations/streams/#high-iterator-age","title":"High Iterator Age","text":"<p>Common causes and solutions:</p> Cause Solution Lambda errors Fix errors (check DLQ and logs) - see Lambda Operations Lambda throttling Increase reserved concurrency Low Lambda concurrency Match concurrency to shard count DynamoDB throttling Increase table capacity - see DynamoDB Operations Large batch sizes Reduce batch size in event source mapping <p>Understanding IteratorAge:</p> <ul> <li><code>IteratorAge</code> measures the delay between when a record is written to the stream and when Lambda processes it</li> <li>Healthy: &lt; 1 second</li> <li>Warning: &lt; 30 seconds</li> <li>Critical: &gt; 30 seconds (default alarm threshold)</li> </ul>"},{"location":"operations/streams/#lambda-throttling","title":"Lambda Throttling","text":"<p>Check if Lambda is being throttled:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name Throttles \\\n  --dimensions Name=FunctionName,Value=&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Solution: Increase reserved concurrency (see procedures below).</p>"},{"location":"operations/streams/#procedures","title":"Procedures","text":""},{"location":"operations/streams/#increase-lambda-concurrency","title":"Increase Lambda Concurrency","text":"<p>Set reserved concurrency:</p> <pre><code>aws lambda put-function-concurrency \\\n  --function-name &lt;name&gt;-aggregator \\\n  --reserved-concurrent-executions 10\n</code></pre> <p>Check current concurrency:</p> <pre><code>aws lambda get-function-concurrency \\\n  --function-name &lt;name&gt;-aggregator\n</code></pre> <p>Remove concurrency limit (use account default):</p> <pre><code>aws lambda delete-function-concurrency \\\n  --function-name &lt;name&gt;-aggregator\n</code></pre>"},{"location":"operations/streams/#adjust-batch-size","title":"Adjust Batch Size","text":"<p>Get current mapping UUID:</p> <pre><code>MAPPING_UUID=$(aws lambda list-event-source-mappings \\\n  --function-name &lt;name&gt;-aggregator \\\n  --query 'EventSourceMappings[0].UUID' \\\n  --output text)\n\necho \"Mapping UUID: $MAPPING_UUID\"\n</code></pre> <p>Reduce batch size (process fewer records per invocation):</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --batch-size 50\n</code></pre> <p>Increase batch size (higher throughput, higher latency):</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --batch-size 100\n</code></pre> <p>Adjust batch window (wait for more records):</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --maximum-batching-window-in-seconds 5\n</code></pre>"},{"location":"operations/streams/#shard-scaling","title":"Shard Scaling","text":"<p>DynamoDB Streams automatically scales shards based on table throughput.</p> <p>Check shard count:</p> <pre><code>aws dynamodbstreams describe-stream \\\n  --stream-arn $(aws dynamodb describe-table --table-name &lt;name&gt; \\\n    --query 'Table.LatestStreamArn' --output text) \\\n  --query 'StreamDescription.Shards | length(@)'\n</code></pre> <p>Rule of thumb: Lambda concurrency should be &gt;= shard count for optimal processing.</p> <p>If you have 10 shards but only 5 concurrent Lambda executions, processing will lag.</p>"},{"location":"operations/streams/#enable-parallelization-factor","title":"Enable Parallelization Factor","text":"<p>Process multiple batches from the same shard concurrently:</p> <pre><code>aws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --parallelization-factor 2\n</code></pre> <p>Valid values: 1-10 (default: 1)</p> <p>Ordering</p> <p>Increasing parallelization factor may result in out-of-order processing within a shard. This is acceptable for usage aggregation but may not be suitable for all use cases.</p>"},{"location":"operations/streams/#verify-stream-health","title":"Verify Stream Health","text":"<p>Check stream is enabled:</p> <pre><code>aws dynamodb describe-table --table-name &lt;name&gt; \\\n  --query 'Table.StreamSpecification'\n</code></pre> <p>Expected output: <pre><code>{\n    \"StreamEnabled\": true,\n    \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n}\n</code></pre></p> <p>Check event source mapping is active:</p> <pre><code>aws lambda list-event-source-mappings \\\n  --function-name &lt;name&gt;-aggregator \\\n  --query 'EventSourceMappings[0].State'\n</code></pre> <p>Expected output: <code>\"Enabled\"</code></p>"},{"location":"operations/streams/#monitor-after-changes","title":"Monitor After Changes","text":"<p>After tuning, monitor for 15-30 minutes:</p> <pre><code># Watch IteratorAge\nwatch -n 30 \"aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name IteratorAge \\\n  --dimensions Name=FunctionName,Value=&lt;name&gt;-aggregator \\\n  --start-time \\$(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time \\$(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum \\\n  --query 'Datapoints | sort_by(@, &amp;Timestamp) | [-1].Maximum'\"\n</code></pre>"},{"location":"operations/streams/#tuning-guidelines","title":"Tuning Guidelines","text":"Scenario Batch Size Concurrency Parallelization Low volume (&lt; 100 req/s) 100 2 1 Medium volume (100-1000 req/s) 100 5-10 1 High volume (&gt; 1000 req/s) 50-100 10+ 2 Real-time requirements 10-50 10+ 2-5"},{"location":"operations/streams/#related","title":"Related","text":"<ul> <li>Lambda Operations - Lambda errors and duration issues</li> <li>DynamoDB Operations - Throttling affecting stream processing</li> <li>Monitoring Guide - CloudWatch dashboards for streams</li> </ul>"},{"location":"operations/version/","title":"Version Management","text":"<p>This guide covers version compatibility issues and upgrade procedures for zae-limiter.</p>"},{"location":"operations/version/#decision-tree","title":"Decision Tree","text":"flowchart TD     START([Version Issue]) --&gt; Q1{What's happening?}      Q1 --&gt;|VersionMismatchError| A1[Lambda needs update]     Q1 --&gt;|IncompatibleSchemaError| A2[Schema migration required]     Q1 --&gt;|Minimum client error| A3[Upgrade pip package]     Q1 --&gt;|Planning upgrade| A4[Follow upgrade procedure]      A1 --&gt; CMD1[\"zae-limiter upgrade --name X\"]     A2 --&gt; CMD2[Follow migrations guide]     A3 --&gt; CMD3[\"pip install --upgrade zae-limiter\"]     A4 --&gt; PROC[Pre-upgrade checklist]      CMD1 --&gt; VERIFY     CMD2 --&gt; VERIFY     CMD3 --&gt; VERIFY     VERIFY([Verify: zae-limiter check])      click A1 \"#versionmismatcherror\" \"Version mismatch details\"     click A2 \"#incompatibleschemaerror\" \"Schema error details\"     click CMD1 \"#upgrade-procedure\" \"Upgrade steps\"     click CMD2 \"../migrations/\" \"Migration guide\"     click A4 \"#upgrade-procedure\" \"Upgrade checklist\"     click VERIFY \"#verification\" \"Verify upgrade\""},{"location":"operations/version/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/version/#symptoms","title":"Symptoms","text":"<ul> <li><code>VersionMismatchError</code> exception raised</li> <li><code>IncompatibleSchemaError</code> exception raised</li> <li>CLI commands fail with version errors</li> <li>Rate limiter initialization fails</li> </ul>"},{"location":"operations/version/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check compatibility with CLI:</p> <pre><code>zae-limiter check --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>View detailed version information:</p> <pre><code>zae-limiter version --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Query version record directly:</p> <pre><code>aws dynamodb get-item --table-name &lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"SYSTEM#\"}, \"SK\": {\"S\": \"#VERSION\"}}'\n</code></pre>"},{"location":"operations/version/#versionmismatcherror","title":"VersionMismatchError","text":"<p>Cause: Client library version differs from deployed Lambda version.</p> <p>Example error: <pre><code>VersionMismatchError: Version mismatch: client=1.2.0, schema=1.0.0, lambda=1.0.0.\nLambda update available.\n</code></pre></p> <p>Solution: Upgrade Lambda to match client:</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Or programmatically:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\n# Auto-update Lambda on initialization\nlimiter = RateLimiter(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Enables auto-update\n)\n</code></pre>"},{"location":"operations/version/#incompatibleschemaerror","title":"IncompatibleSchemaError","text":"<p>Cause: Major version difference requiring schema migration.</p> <p>Example error: <pre><code>IncompatibleSchemaError: Incompatible schema: client 2.0.0 is not compatible\nwith schema 1.0.0. Migration required.\n</code></pre></p> <p>Solution: Follow the Migration Guide to upgrade the schema:</p> <ol> <li>Create a backup</li> <li>Run migration</li> <li>Update client</li> </ol> <pre><code># Create backup before migration\naws dynamodb create-backup \\\n  --table-name &lt;name&gt; \\\n  --backup-name \"pre-migration-$(date +%Y%m%d)\"\n</code></pre> <p>Then follow the migration procedures in the Migration Guide.</p>"},{"location":"operations/version/#minimum-client-version-error","title":"Minimum Client Version Error","text":"<p>Cause: Infrastructure requires a newer client version.</p> <p>Solution: Upgrade the client library:</p> <pre><code>pip install --upgrade zae-limiter\n</code></pre>"},{"location":"operations/version/#upgrade-procedure","title":"Upgrade Procedure","text":""},{"location":"operations/version/#pre-upgrade-checklist","title":"Pre-upgrade Checklist","text":"<p>Before upgrading, verify the following:</p> <ul> <li> Check current version: <code>zae-limiter version --name &lt;name&gt;</code></li> <li> Check compatibility: <code>zae-limiter check --name &lt;name&gt;</code></li> <li> Review release notes for breaking changes</li> <li> Verify PITR is enabled for rollback capability</li> <li> Schedule maintenance window (if major upgrade)</li> <li> Notify stakeholders</li> </ul>"},{"location":"operations/version/#upgrade-execution","title":"Upgrade Execution","text":"<p>Standard upgrade (Lambda + client):</p> <pre><code># Step 1: Upgrade client library\npip install --upgrade zae-limiter\n\n# Step 2: Update infrastructure\nzae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt;\n\n# Step 3: Verify\nzae-limiter check --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Lambda-only upgrade:</p> <pre><code># Update Lambda without schema changes\nzae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --lambda-only\n</code></pre> <p>Force upgrade (skip compatibility check):</p> <p>Use with caution</p> <p>Only use <code>--force</code> when you understand the implications.</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt; --force\n</code></pre>"},{"location":"operations/version/#post-upgrade-verification","title":"Post-upgrade Verification","text":"<p>After upgrading, verify the system is healthy:</p> <ol> <li> <p>Check version alignment: <pre><code>zae-limiter version --name &lt;name&gt;\n</code></pre></p> </li> <li> <p>Run smoke tests: <pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(name=\"limiter\", region=\"us-east-1\")\n\n# Test basic operation\nasync with limiter.acquire(\n    entity_id=\"test-entity\",\n    resource=\"test\",\n    limits=[Limit.per_minute(\"rpm\", 100)],\n    consume={\"rpm\": 1},\n):\n    print(\"Rate limiting working\")\n</code></pre></p> </li> <li> <p>Monitor for 15 minutes:</p> </li> <li>Check Lambda error rate in CloudWatch</li> <li>Verify usage snapshots are updating</li> <li>Watch for unexpected exceptions in application logs</li> </ol>"},{"location":"operations/version/#rollback","title":"Rollback","text":"<p>If issues occur after upgrade, see Recovery &amp; Rollback.</p>"},{"location":"operations/version/#related","title":"Related","text":"<ul> <li>Migration Guide - Schema versioning and migration procedures</li> <li>Recovery &amp; Rollback - Emergency rollback procedures</li> <li>CLI Reference - Full CLI command documentation</li> </ul>"},{"location":"plans/2026-01-30-iam-role-naming-design/","title":"IAM Role Naming Design","text":"<p>Issue: #252 - IAM role names can exceed 64-character limit when stack name + role_name_format is too long</p> <p>Date: 2026-01-30</p>"},{"location":"plans/2026-01-30-iam-role-naming-design/#problem","title":"Problem","text":"<p>When using <code>role_name_format</code> with permission boundaries, the final IAM role names can exceed the AWS 64-character limit. The current design has two bugs:</p> <ol> <li>Incorrect embedding: <code>-aggregator-role</code> is embedded in all role names, not just the Lambda role</li> <li>Insufficient validation: Stack name and format template are validated separately, not combined</li> </ol>"},{"location":"plans/2026-01-30-iam-role-naming-design/#example-of-current-bug","title":"Example of Current Bug","text":"<p>With <code>role_name_format=\"PowerUserPB-{}\"</code> and <code>stack_name=\"my-app\"</code>:</p> Role Current Name Problem Aggregator <code>PowerUserPB-my-app-aggregator-role</code> OK but verbose App <code>PowerUserPB-my-app-aggregator-role-app</code> \"aggregator\" wrong here Readonly <code>PowerUserPB-my-app-aggregator-role-readonly</code> \"aggregator\" wrong here <p>With suffix format <code>\"{}-PowerUserPB\"</code>:</p> Role Current Name Problem App <code>my-app-aggregator-role-PowerUserPB-app</code> Suffix in wrong position"},{"location":"plans/2026-01-30-iam-role-naming-design/#solution","title":"Solution","text":""},{"location":"plans/2026-01-30-iam-role-naming-design/#api-change","title":"API Change","text":"<p>Change <code>get_role_name()</code> to accept a component parameter:</p> <pre><code>def get_role_name(self, stack_name: str, component: str) -&gt; str | None:\n    \"\"\"\n    Get the final role name for a given stack name and component.\n\n    Args:\n        stack_name: Stack name\n        component: Role component (aggr, app, admin, read)\n\n    Returns:\n        Final role name, or None if role_name_format not set\n\n    Raises:\n        ValidationError: If resulting name exceeds 64 characters\n    \"\"\"\n    if self.role_name_format is None:\n        return None\n    role_name = self.role_name_format.replace(\"{}\", f\"{stack_name}-{component}\")\n    if len(role_name) &gt; 64:\n        # Calculate max allowed stack name\n        format_overhead = len(self.role_name_format) - 2  # subtract {}\n        max_stack_len = 64 - format_overhead - 1 - len(component)  # -1 for dash\n        raise ValidationError(\n            \"role_name\",\n            role_name,\n            f\"exceeds IAM 64-character limit by {len(role_name) - 64} characters. \"\n            f\"Shorten stack name to max {max_stack_len} characters with this format.\"\n        )\n    return role_name\n</code></pre>"},{"location":"plans/2026-01-30-iam-role-naming-design/#component-names","title":"Component Names","text":"Component Length Purpose CFN Resource <code>aggr</code> 4 Aggregator Lambda role <code>AggregatorRole</code> <code>app</code> 3 Application access <code>AppRole</code> <code>admin</code> 5 Admin/ops access <code>AdminRole</code> <code>read</code> 4 Read-only/monitoring <code>ReadOnlyRole</code> <p>Invariant: All component names must be \u2264 8 characters. This ensures users who choose a valid stack name today won't break on library upgrades (new stack name = new DynamoDB table = data loss).</p>"},{"location":"plans/2026-01-30-iam-role-naming-design/#default-role-names-breaking-change","title":"Default Role Names (Breaking Change)","text":"<p>Old defaults: - <code>{stack}-aggregator-role</code> - <code>{stack}-app-role</code> - <code>{stack}-admin-role</code> - <code>{stack}-readonly-role</code></p> <p>New defaults: - <code>{stack}-aggr</code> - <code>{stack}-app</code> - <code>{stack}-admin</code> - <code>{stack}-read</code></p>"},{"location":"plans/2026-01-30-iam-role-naming-design/#cloudformation-changes","title":"CloudFormation Changes","text":"<p>Replace single <code>RoleName</code> parameter with 4 parameters:</p> Parameter Used By <code>AggregatorRoleName</code> <code>AggregatorRole</code> resource <code>AppRoleName</code> <code>AppRole</code> resource <code>AdminRoleName</code> <code>AdminRole</code> resource <code>ReadOnlyRoleName</code> <code>ReadOnlyRole</code> resource"},{"location":"plans/2026-01-30-iam-role-naming-design/#validation","title":"Validation","text":"Location Check Value <code>naming.py</code> Max stack name length 55 chars <code>StackOptions.__post_init__</code> Max format template length 55 chars (64 - 1 - 8) <code>get_role_name()</code> Final role name length 64 chars with helpful error"},{"location":"plans/2026-01-30-iam-role-naming-design/#example-results","title":"Example Results","text":"<p>With <code>role_name_format=\"PowerUserPB-{}\"</code> and <code>stack_name=\"my-app\"</code>:</p> Role New Name Length Aggregator <code>PowerUserPB-my-app-aggr</code> 24 App <code>PowerUserPB-my-app-app</code> 23 Admin <code>PowerUserPB-my-app-admin</code> 25 Read <code>PowerUserPB-my-app-read</code> 24 <p>With <code>role_name_format=\"{}-PowerUserPB\"</code> and <code>stack_name=\"my-app\"</code>:</p> Role New Name Length Aggregator <code>my-app-aggr-PowerUserPB</code> 24 App <code>my-app-app-PowerUserPB</code> 23 Admin <code>my-app-admin-PowerUserPB</code> 25 Read <code>my-app-read-PowerUserPB</code> 24"},{"location":"plans/2026-01-30-iam-role-naming-design/#deliverables","title":"Deliverables","text":"<ol> <li>ADR for IAM role naming convention</li> <li>Document 8-char component limit invariant</li> <li> <p>Document naming pattern: <code>{format}.replace(\"{}\", f\"{stack}-{component}\")</code></p> </li> <li> <p>Update <code>models.py</code></p> </li> <li>Change <code>get_role_name(stack_name)</code> to <code>get_role_name(stack_name, component)</code></li> <li>Add validation with helpful error message</li> <li>Update <code>__post_init__</code> format length check to 55</li> <li>Update <code>to_parameters()</code> to generate 4 role name params</li> <li> <p>Define <code>ROLE_COMPONENTS = [\"aggr\", \"app\", \"admin\", \"read\"]</code> constant</p> </li> <li> <p>Update <code>naming.py</code></p> </li> <li> <p>Change max stack name from 48 to 55 chars</p> </li> <li> <p>Update <code>cfn_template.yaml</code></p> </li> <li>Replace <code>RoleName</code> parameter with 4 parameters</li> <li>Update each role resource to use its dedicated parameter</li> <li> <p>Update default names to drop <code>-role</code> suffix</p> </li> <li> <p>Unit tests (<code>test_models.py</code>)</p> </li> <li><code>get_role_name()</code> with prefix format for all components</li> <li><code>get_role_name()</code> with suffix format for all components</li> <li>Length validation with helpful error message</li> <li> <p>Test that all <code>ROLE_COMPONENTS</code> are \u2264 8 chars (invariant test)</p> </li> <li> <p>E2E LocalStack tests</p> </li> <li>Deploy with <code>role_name_format</code></li> <li>Verify all 4 roles follow the naming pattern</li> <li> <p>Test both prefix and suffix formats</p> </li> <li> <p>Update CLAUDE.md</p> </li> <li>Document new naming constraints</li> <li> <p>Update maximum identifier length section</p> </li> <li> <p>Release notes</p> </li> <li>Document breaking change for role naming</li> <li>Migration notes for existing deployments</li> </ol>"},{"location":"plans/2026-01-30-iam-role-naming-design/#breaking-change-notes","title":"Breaking Change Notes","text":"<p>Existing deployments using default role names will have roles renamed: - <code>{stack}-aggregator-role</code> \u2192 <code>{stack}-aggr</code> - <code>{stack}-app-role</code> \u2192 <code>{stack}-app</code> - <code>{stack}-admin-role</code> \u2192 <code>{stack}-admin</code> - <code>{stack}-readonly-role</code> \u2192 <code>{stack}-read</code></p> <p>CloudFormation will: 1. Create new roles with new names 2. Update Lambda to use new role 3. Delete old roles</p> <p>Running Lambdas may briefly fail during the update. Users should plan for a maintenance window.</p>"},{"location":"plans/2026-02-02-native-sync-implementation/","title":"Native Sync Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Generate native sync code (boto3) from async source (aioboto3) using AST transformation, eliminating the event loop wrapper.</p> <p>Architecture: Write async code as source of truth \u2192 AST transformer generates sync equivalents \u2192 Generated code committed to git \u2192 CI verifies sync code is up-to-date.</p> <p>Tech Stack: Python AST, Hatch build hooks, pre-commit, boto3, aioboto3</p>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-1-create-ast-transformer-script","title":"Task 1: Create AST Transformer Script","text":"<p>Files: - Create: <code>scripts/generate_sync.py</code></p> <p>Step 1: Create the transformation script with configuration</p> <pre><code>#!/usr/bin/env python3\n\"\"\"Generate sync versions of async modules using AST transformation.\n\nThis script transforms async code (aioboto3) to sync code (boto3) by:\n- Removing async/await keywords\n- Renaming classes (RateLimiter -&gt; SyncRateLimiter)\n- Rewriting imports (aioboto3 -&gt; boto3)\n\nGenerated files are committed to git and verified by CI.\n\"\"\"\n\nimport ast\nimport re\nimport sys\nfrom pathlib import Path\n\n# Project root\nROOT = Path(__file__).parent.parent\nSRC = ROOT / \"src\" / \"zae_limiter\"\n\n# Files to transform: (source, target)\nSOURCE_TRANSFORMS = [\n    (\"repository.py\", \"sync_repository.py\"),\n    (\"limiter.py\", \"sync_limiter.py\"),\n    (\"lease.py\", \"sync_lease.py\"),\n    (\"config_cache.py\", \"sync_config_cache.py\"),\n    (\"infra/stack_manager.py\", \"infra/sync_stack_manager.py\"),\n    (\"infra/discovery.py\", \"infra/sync_discovery.py\"),\n]\n\n# Class renames\nCLASS_RENAMES = {\n    \"RateLimiter\": \"SyncRateLimiter\",\n    \"Repository\": \"SyncRepository\",\n    \"Lease\": \"SyncLease\",\n    \"ConfigCache\": \"SyncConfigCache\",\n    \"StackManager\": \"SyncStackManager\",\n    \"InfrastructureDiscovery\": \"SyncInfrastructureDiscovery\",\n}\n\n# Import module rewrites\nIMPORT_MODULE_REWRITES = {\n    \"aioboto3\": \"boto3\",\n}\n\n# Import path rewrites (for relative imports)\nIMPORT_PATH_REWRITES = {\n    \".repository\": \".sync_repository\",\n    \".lease\": \".sync_lease\",\n    \".config_cache\": \".sync_config_cache\",\n    \".infra.stack_manager\": \".infra.sync_stack_manager\",\n    \".infra.discovery\": \".infra.sync_discovery\",\n}\n\n# Names to rewrite in from imports\nIMPORT_NAME_REWRITES = {\n    \"Repository\": \"SyncRepository\",\n    \"Lease\": \"SyncLease\",\n    \"ConfigCache\": \"SyncConfigCache\",\n    \"StackManager\": \"SyncStackManager\",\n    \"InfrastructureDiscovery\": \"SyncInfrastructureDiscovery\",\n}\n\n# Type annotation rewrites\nTYPE_REWRITES = {\n    \"AsyncIterator\": \"Iterator\",\n    \"AsyncContextManager\": \"ContextManager\",\n    \"AsyncGenerator\": \"Generator\",\n}\n\nGENERATED_HEADER = '''\"\"\"AUTO-GENERATED by scripts/generate_sync.py - DO NOT EDIT.\n\nSource: {source_file}\n\nThis module provides synchronous versions of the async classes.\nChanges should be made to the source file, then regenerated.\n\"\"\"\n\n'''\n\n\nclass AsyncToSyncTransformer(ast.NodeTransformer):\n    \"\"\"Transform async Python code to sync.\"\"\"\n\n    def __init__(self, source_file: str):\n        self.source_file = source_file\n        super().__init__()\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -&gt; ast.FunctionDef:\n        \"\"\"Convert async def to def.\"\"\"\n        # Transform the body first\n        new_body = [self.visit(stmt) for stmt in node.body]\n\n        # Handle __aenter__ -&gt; __enter__, __aexit__ -&gt; __exit__\n        new_name = node.name\n        if new_name == \"__aenter__\":\n            new_name = \"__enter__\"\n        elif new_name == \"__aexit__\":\n            new_name = \"__exit__\"\n\n        # Create sync function\n        new_node = ast.FunctionDef(\n            name=new_name,\n            args=node.args,\n            body=new_body,\n            decorator_list=[self.visit(d) for d in node.decorator_list],\n            returns=self._transform_annotation(node.returns) if node.returns else None,\n            type_comment=node.type_comment,\n        )\n        return ast.copy_location(new_node, node)\n\n    def visit_Await(self, node: ast.Await) -&gt; ast.AST:\n        \"\"\"Remove await, keep the expression.\"\"\"\n        return self.visit(node.value)\n\n    def visit_AsyncWith(self, node: ast.AsyncWith) -&gt; ast.With:\n        \"\"\"Convert async with to with.\"\"\"\n        new_node = ast.With(\n            items=[self.visit(item) for item in node.items],\n            body=[self.visit(stmt) for stmt in node.body],\n        )\n        return ast.copy_location(new_node, node)\n\n    def visit_AsyncFor(self, node: ast.AsyncFor) -&gt; ast.For:\n        \"\"\"Convert async for to for.\"\"\"\n        new_node = ast.For(\n            target=self.visit(node.target),\n            iter=self.visit(node.iter),\n            body=[self.visit(stmt) for stmt in node.body],\n            orelse=[self.visit(stmt) for stmt in node.orelse],\n        )\n        return ast.copy_location(new_node, node)\n\n    def visit_ClassDef(self, node: ast.ClassDef) -&gt; ast.ClassDef:\n        \"\"\"Rename classes according to CLASS_RENAMES.\"\"\"\n        if node.name in CLASS_RENAMES:\n            node.name = CLASS_RENAMES[node.name]\n\n        # Transform base classes (handle string annotations in bases)\n        new_bases = []\n        for base in node.bases:\n            new_bases.append(self._transform_base_class(base))\n        node.bases = new_bases\n\n        # Continue visiting children\n        self.generic_visit(node)\n        return node\n\n    def _transform_base_class(self, node: ast.AST) -&gt; ast.AST:\n        \"\"\"Transform base class references.\"\"\"\n        if isinstance(node, ast.Name) and node.id in CLASS_RENAMES:\n            node.id = CLASS_RENAMES[node.id]\n        elif isinstance(node, ast.Subscript):\n            # Handle Generic[T] style bases\n            node.value = self._transform_base_class(node.value)\n        return node\n\n    def visit_Import(self, node: ast.Import) -&gt; ast.Import:\n        \"\"\"Rewrite import statements.\"\"\"\n        for alias in node.names:\n            if alias.name in IMPORT_MODULE_REWRITES:\n                alias.name = IMPORT_MODULE_REWRITES[alias.name]\n        return node\n\n    def visit_ImportFrom(self, node: ast.ImportFrom) -&gt; ast.ImportFrom:\n        \"\"\"Rewrite from ... import statements.\"\"\"\n        # Rewrite module path\n        if node.module:\n            # Check for exact module rewrites\n            if node.module in IMPORT_MODULE_REWRITES:\n                node.module = IMPORT_MODULE_REWRITES[node.module]\n\n            # Check for relative import path rewrites\n            module_key = f\".{node.module}\" if node.level == 0 else \".\" * node.level + (node.module or \"\")\n            for old_path, new_path in IMPORT_PATH_REWRITES.items():\n                if module_key.endswith(old_path.lstrip(\".\")):\n                    # Replace the suffix\n                    prefix = module_key[:-len(old_path.lstrip(\".\"))]\n                    new_module = prefix + new_path.lstrip(\".\")\n                    node.module = new_module.lstrip(\".\")\n                    break\n\n        # Rewrite imported names\n        for alias in node.names:\n            if alias.name in IMPORT_NAME_REWRITES:\n                old_name = alias.name\n                alias.name = IMPORT_NAME_REWRITES[alias.name]\n                # Also update asname if it was the same as name\n                if alias.asname == old_name:\n                    alias.asname = alias.name\n            # Rewrite type names\n            if alias.name in TYPE_REWRITES:\n                alias.name = TYPE_REWRITES[alias.name]\n\n        return node\n\n    def visit_Name(self, node: ast.Name) -&gt; ast.Name:\n        \"\"\"Rewrite class name references.\"\"\"\n        if node.id in CLASS_RENAMES:\n            node.id = CLASS_RENAMES[node.id]\n        if node.id in TYPE_REWRITES:\n            node.id = TYPE_REWRITES[node.id]\n        return node\n\n    def visit_Attribute(self, node: ast.Attribute) -&gt; ast.Attribute:\n        \"\"\"Rewrite attribute access for renamed modules.\"\"\"\n        self.generic_visit(node)\n        return node\n\n    def visit_Constant(self, node: ast.Constant) -&gt; ast.Constant:\n        \"\"\"Rewrite string annotations.\"\"\"\n        if isinstance(node.value, str):\n            value = node.value\n            # Rewrite class names in string annotations\n            for old_name, new_name in CLASS_RENAMES.items():\n                value = re.sub(rf'\\b{old_name}\\b', new_name, value)\n            for old_name, new_name in TYPE_REWRITES.items():\n                value = re.sub(rf'\\b{old_name}\\b', new_name, value)\n            node.value = value\n        return node\n\n    def _transform_annotation(self, node: ast.AST | None) -&gt; ast.AST | None:\n        \"\"\"Transform type annotations.\"\"\"\n        if node is None:\n            return None\n        return self.visit(node)\n\n    def visit_FunctionDef(self, node: ast.FunctionDef) -&gt; ast.FunctionDef:\n        \"\"\"Transform sync function definitions (for annotations).\"\"\"\n        # Transform return annotation\n        if node.returns:\n            node.returns = self._transform_annotation(node.returns)\n\n        # Transform argument annotations\n        for arg in node.args.args:\n            if arg.annotation:\n                arg.annotation = self._transform_annotation(arg.annotation)\n\n        self.generic_visit(node)\n        return node\n\n    def visit_AnnAssign(self, node: ast.AnnAssign) -&gt; ast.AnnAssign:\n        \"\"\"Transform annotated assignments.\"\"\"\n        node.annotation = self._transform_annotation(node.annotation)\n        self.generic_visit(node)\n        return node\n\n\ndef transform_file(source_path: Path, target_path: Path) -&gt; bool:\n    \"\"\"Transform a single file from async to sync.\n\n    Returns True if file was changed, False otherwise.\n    \"\"\"\n    source_code = source_path.read_text()\n\n    # Parse AST\n    tree = ast.parse(source_code)\n\n    # Transform\n    transformer = AsyncToSyncTransformer(source_path.name)\n    new_tree = transformer.visit(tree)\n\n    # Fix missing locations\n    ast.fix_missing_locations(new_tree)\n\n    # Generate code\n    new_code = ast.unparse(new_tree)\n\n    # Add header\n    relative_source = source_path.relative_to(SRC)\n    header = GENERATED_HEADER.format(source_file=relative_source)\n    final_code = header + new_code + \"\\n\"\n\n    # Check if changed\n    if target_path.exists():\n        existing = target_path.read_text()\n        if existing == final_code:\n            return False\n\n    # Write\n    target_path.parent.mkdir(parents=True, exist_ok=True)\n    target_path.write_text(final_code)\n    return True\n\n\ndef main() -&gt; int:\n    \"\"\"Run all transformations.\"\"\"\n    changed = []\n\n    for source_name, target_name in SOURCE_TRANSFORMS:\n        source_path = SRC / source_name\n        target_path = SRC / target_name\n\n        if not source_path.exists():\n            print(f\"WARNING: Source file not found: {source_path}\")\n            continue\n\n        if transform_file(source_path, target_path):\n            changed.append(target_name)\n            print(f\"Generated: {target_name}\")\n        else:\n            print(f\"Unchanged: {target_name}\")\n\n    if changed:\n        print(f\"\\n{len(changed)} file(s) updated\")\n    else:\n        print(\"\\nAll files up to date\")\n\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n</code></pre> <p>Step 2: Make script executable</p> <p>Run: <code>chmod +x scripts/generate_sync.py</code></p> <p>Step 3: Test the script runs without error</p> <p>Run: <code>python scripts/generate_sync.py</code> Expected: Script runs (may show warnings about missing source patterns initially)</p> <p>Step 4: Commit</p> <pre><code>git add scripts/generate_sync.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udd28 build(scripts): add AST transformer for sync code generation\n\nAdd generate_sync.py that transforms async code to sync:\n- Converts async def -&gt; def, await -&gt; (removed)\n- Renames classes (RateLimiter -&gt; SyncRateLimiter)\n- Rewrites imports (aioboto3 -&gt; boto3)\n- Adds generated file header\n\nPart of native sync implementation (#refactor/native-sync).\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-2-add-pre-commit-hook-for-sync-verification","title":"Task 2: Add Pre-commit Hook for Sync Verification","text":"<p>Files: - Modify: <code>.pre-commit-config.yaml</code></p> <p>Step 1: Add the sync verification hook</p> <p>Add after the <code>check-aws-partition</code> hook in <code>.pre-commit-config.yaml</code>:</p> <pre><code>      - id: verify-sync-generated\n        name: Verify generated sync code is up-to-date\n        entry: bash -c 'python scripts/generate_sync.py &amp;&amp; git diff --exit-code src/zae_limiter/sync_*.py src/zae_limiter/infra/sync_*.py 2&gt;/dev/null || (echo \"Generated sync code is out of date. Run: python scripts/generate_sync.py\" &amp;&amp; exit 1)'\n        language: system\n        files: ^src/zae_limiter/(repository|limiter|lease|config_cache|infra/(stack_manager|discovery))\\.py$\n        pass_filenames: false\n        stages: [pre-commit]\n</code></pre> <p>Step 2: Test hook configuration is valid</p> <p>Run: <code>pre-commit run --all-files</code> Expected: All hooks pass (sync files don't exist yet, so verify hook may skip)</p> <p>Step 3: Commit</p> <pre><code>git add .pre-commit-config.yaml\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udc77 ci(pre-commit): add hook to verify generated sync code\n\nPre-commit hook runs generate_sync.py and checks for uncommitted\nchanges to sync_*.py files. Ensures generated code stays in sync\nwith async source.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-3-add-hatch-build-hook","title":"Task 3: Add Hatch Build Hook","text":"<p>Files: - Create: <code>hatch_build.py</code> - Modify: <code>pyproject.toml</code></p> <p>Step 1: Create hatch build hook</p> <pre><code>\"\"\"Hatch build hook to generate sync code before building.\"\"\"\n\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nfrom hatchling.builders.hooks.plugin.interface import BuildHookInterface\n\n\nclass SyncGeneratorHook(BuildHookInterface):\n    \"\"\"Generate sync code before building wheel/sdist.\"\"\"\n\n    PLUGIN_NAME = \"sync-generator\"\n\n    def initialize(self, version: str, build_data: dict) -&gt; None:\n        \"\"\"Run sync code generation.\"\"\"\n        root = Path(self.root)\n        script = root / \"scripts\" / \"generate_sync.py\"\n\n        if script.exists():\n            result = subprocess.run(\n                [sys.executable, str(script)],\n                cwd=root,\n                capture_output=True,\n                text=True,\n            )\n            if result.returncode != 0:\n                raise RuntimeError(f\"Sync generation failed:\\n{result.stderr}\")\n</code></pre> <p>Step 2: Update pyproject.toml with build hook and scripts</p> <p>Add after <code>[tool.hatch.build.targets.wheel]</code>:</p> <pre><code>[tool.hatch.build.hooks.custom]\npath = \"hatch_build.py\"\n\n[tool.hatch.envs.default.scripts]\ngenerate-sync = \"python scripts/generate_sync.py\"\n</code></pre> <p>Step 3: Test hatch recognizes the hook</p> <p>Run: <code>hatch run generate-sync</code> Expected: Script runs, shows \"Source file not found\" warnings (expected at this stage)</p> <p>Step 4: Commit</p> <pre><code>git add hatch_build.py pyproject.toml\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udd28 build(hatch): add build hook for sync code generation\n\n- hatch_build.py: Runs generate_sync.py before wheel/sdist build\n- pyproject.toml: Add custom build hook and generate-sync script\n\nDeveloper workflow: `hatch run generate-sync` after changing async code.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-4-remove-existing-syncratelimiter-and-synclease-wrappers","title":"Task 4: Remove Existing SyncRateLimiter and SyncLease Wrappers","text":"<p>Files: - Modify: <code>src/zae_limiter/limiter.py</code> - Modify: <code>src/zae_limiter/lease.py</code> - Modify: <code>src/zae_limiter/__init__.py</code></p> <p>Step 1: Read current limiter.py to identify SyncRateLimiter location</p> <p>The <code>SyncRateLimiter</code> class starts around line 1668. Remove the entire class (lines 1668-2239).</p> <p>Step 2: Remove SyncRateLimiter class from limiter.py</p> <p>Delete the <code>SyncRateLimiter</code> class entirely (from <code>class SyncRateLimiter:</code> to end of file).</p> <p>Step 3: Remove SyncLease class from lease.py</p> <p>Delete the <code>SyncLease</code> class (lines 346-368 approximately).</p> <p>Step 4: Temporarily comment out sync imports in init.py</p> <p>Comment out or remove: <pre><code># from .limiter import SyncRateLimiter  # Will be from sync_limiter\n# from .lease import SyncLease  # Will be from sync_lease\n</code></pre></p> <p>And in <code>__all__</code>: <pre><code># \"SyncRateLimiter\",  # Will be re-added\n# \"SyncLease\",  # Will be re-added\n</code></pre></p> <p>Step 5: Run tests to verify async code still works</p> <p>Run: <code>uv run pytest tests/unit/test_limiter.py -v -k \"not Sync\"</code> Expected: Async tests pass</p> <p>Step 6: Commit</p> <pre><code>git add src/zae_limiter/limiter.py src/zae_limiter/lease.py src/zae_limiter/__init__.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udd25 remove(limiter): delete SyncRateLimiter and SyncLease wrappers\n\nRemove the event loop wrapper implementations. These will be replaced\nby native sync code generated from async source via AST transformation.\n\nBREAKING: SyncRateLimiter and SyncLease temporarily unavailable.\nThey will be restored in the next commit as generated code.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-5-generate-initial-sync-code","title":"Task 5: Generate Initial Sync Code","text":"<p>Files: - Generate: <code>src/zae_limiter/sync_repository.py</code> - Generate: <code>src/zae_limiter/sync_limiter.py</code> - Generate: <code>src/zae_limiter/sync_lease.py</code> - Generate: <code>src/zae_limiter/sync_config_cache.py</code> - Generate: <code>src/zae_limiter/infra/sync_stack_manager.py</code> - Generate: <code>src/zae_limiter/infra/sync_discovery.py</code></p> <p>Step 1: Run the generator</p> <p>Run: <code>python scripts/generate_sync.py</code> Expected: All 6 files generated</p> <p>Step 2: Verify generated files are valid Python</p> <p>Run: <code>python -m py_compile src/zae_limiter/sync_repository.py src/zae_limiter/sync_limiter.py src/zae_limiter/sync_lease.py</code> Expected: No syntax errors</p> <p>Step 3: Run ruff to fix any style issues</p> <p>Run: <code>uv run ruff check --fix src/zae_limiter/sync_*.py src/zae_limiter/infra/sync_*.py</code> Run: <code>uv run ruff format src/zae_limiter/sync_*.py src/zae_limiter/infra/sync_*.py</code></p> <p>Step 4: Commit generated files</p> <pre><code>git add src/zae_limiter/sync_*.py src/zae_limiter/infra/sync_*.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\u2728 feat(sync): generate native sync code from async source\n\nGenerated via scripts/generate_sync.py:\n- sync_repository.py: SyncRepository with native boto3\n- sync_limiter.py: SyncRateLimiter without event loop wrapper\n- sync_lease.py: SyncLease with sync methods\n- sync_config_cache.py: SyncConfigCache\n- infra/sync_stack_manager.py: SyncStackManager\n- infra/sync_discovery.py: SyncInfrastructureDiscovery\n\nThese files are auto-generated. Edit the async source, not these files.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-6-update-package-exports","title":"Task 6: Update Package Exports","text":"<p>Files: - Modify: <code>src/zae_limiter/__init__.py</code></p> <p>Step 1: Add sync imports from generated modules</p> <p>Add the sync imports:</p> <pre><code># Sync (generated from async via scripts/generate_sync.py)\nfrom .sync_limiter import SyncRateLimiter\nfrom .sync_repository import SyncRepository\nfrom .sync_lease import SyncLease\nfrom .sync_config_cache import SyncConfigCache\n</code></pre> <p>Step 2: Update all to include sync classes</p> <p>Ensure <code>__all__</code> includes: <pre><code>\"SyncRateLimiter\",\n\"SyncRepository\",\n\"SyncLease\",\n\"SyncConfigCache\",\n</code></pre></p> <p>Step 3: Verify imports work</p> <p>Run: <code>python -c \"from zae_limiter import SyncRateLimiter, SyncRepository, SyncLease; print('OK')\"</code> Expected: \"OK\"</p> <p>Step 4: Commit</p> <pre><code>git add src/zae_limiter/__init__.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\u2728 feat(exports): export sync classes from generated modules\n\n- SyncRateLimiter from sync_limiter.py\n- SyncRepository from sync_repository.py\n- SyncLease from sync_lease.py\n- SyncConfigCache from sync_config_cache.py\n\nPublic API unchanged: `from zae_limiter import SyncRateLimiter`\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-7-fix-generated-code-issues","title":"Task 7: Fix Generated Code Issues","text":"<p>The AST transformer may produce code that needs manual fixes. This task handles common issues.</p> <p>Files: - Modify: <code>scripts/generate_sync.py</code> (if transformer needs improvement) - Modify: Generated files (if manual fixes needed)</p> <p>Step 1: Run type checker on generated code</p> <p>Run: <code>uv run mypy src/zae_limiter/sync_repository.py src/zae_limiter/sync_limiter.py --ignore-missing-imports</code> Expected: Note any type errors</p> <p>Step 2: Fix transformer if systematic issues found</p> <p>Common issues and fixes in <code>generate_sync.py</code>: - Missing import rewrites \u2192 add to <code>IMPORT_PATH_REWRITES</code> - Incorrect class references \u2192 add to <code>CLASS_RENAMES</code> - asyncio imports not removed \u2192 add removal logic</p> <p>Step 3: Regenerate and verify</p> <p>Run: <code>python scripts/generate_sync.py</code> Run: <code>uv run mypy src/zae_limiter/sync_*.py --ignore-missing-imports</code></p> <p>Step 4: Commit any transformer fixes</p> <pre><code>git add scripts/generate_sync.py src/zae_limiter/sync_*.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udc1b fix(generate-sync): fix transformer issues\n\n[Describe specific fixes made]\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-8-update-unit-test-fixtures-for-native-sync","title":"Task 8: Update Unit Test Fixtures for Native Sync","text":"<p>Files: - Modify: <code>tests/unit/conftest.py</code></p> <p>Step 1: Update sync_limiter fixture to use native SyncRepository</p> <p>Replace the existing <code>sync_limiter</code> fixture:</p> <pre><code>@pytest.fixture\ndef sync_limiter(mock_dynamodb):\n    \"\"\"Create a SyncRateLimiter with mocked DynamoDB and native sync.\"\"\"\n    from zae_limiter import SyncRateLimiter\n    from zae_limiter.sync_repository import SyncRepository\n\n    # Create native sync repository\n    repo = SyncRepository(\n        name=\"test-rate-limits\",\n        region=\"us-east-1\",\n    )\n    # Create table directly\n    repo.create_table()\n\n    # Create limiter with native sync repository\n    limiter = SyncRateLimiter(repository=repo)\n\n    with limiter:\n        yield limiter\n</code></pre> <p>Step 2: Add sync_repository fixture</p> <pre><code>@pytest.fixture\ndef sync_repository(mock_dynamodb):\n    \"\"\"Create a SyncRepository with mocked DynamoDB.\"\"\"\n    from zae_limiter.sync_repository import SyncRepository\n\n    repo = SyncRepository(\n        name=\"test-rate-limits\",\n        region=\"us-east-1\",\n    )\n    repo.create_table()\n    yield repo\n    repo.close()\n</code></pre> <p>Step 3: Run sync tests to verify fixture works</p> <p>Run: <code>uv run pytest tests/unit/test_sync_limiter.py -v -k \"test_create_entity\"</code> Expected: Test passes with native sync</p> <p>Step 4: Commit</p> <pre><code>git add tests/unit/conftest.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\u2705 test(fixtures): update sync fixtures for native implementation\n\n- sync_limiter: Uses SyncRepository directly (no event loop)\n- sync_repository: New fixture for repository-level tests\n\nFixtures no longer use async wrapper pattern.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-9-fix-sync-tests-for-native-implementation","title":"Task 9: Fix Sync Tests for Native Implementation","text":"<p>Files: - Modify: <code>tests/unit/test_sync_limiter.py</code></p> <p>Step 1: Remove references to internal async implementation</p> <p>Find and fix tests that reference <code>sync_limiter._limiter</code> or <code>sync_limiter._run</code>: - These internal attributes no longer exist in native sync - Replace with direct sync calls or remove tests that were testing wrapper behavior</p> <p>Step 2: Update monkeypatch targets</p> <p>Tests using <code>monkeypatch.setattr(sync_limiter._limiter._repository, ...)</code> need updating: - Change to <code>monkeypatch.setattr(sync_limiter._repository, ...)</code> - Mock sync methods instead of async methods</p> <p>Step 3: Run all sync tests</p> <p>Run: <code>uv run pytest tests/unit/test_sync_limiter.py -v</code> Expected: All tests pass</p> <p>Step 4: Commit</p> <pre><code>git add tests/unit/test_sync_limiter.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\u2705 test(sync): update tests for native sync implementation\n\n- Remove references to _limiter wrapper attribute\n- Update monkeypatch targets for sync repository\n- Fix mock functions to be sync instead of async\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-10-add-test-transformation-to-generator","title":"Task 10: Add Test Transformation to Generator","text":"<p>Files: - Modify: <code>scripts/generate_sync.py</code></p> <p>Step 1: Add test file transformations</p> <p>Add to <code>SOURCE_TRANSFORMS</code> in <code>generate_sync.py</code>:</p> <pre><code># Test files to transform\nTEST_ROOT = ROOT / \"tests\"\n\nTEST_TRANSFORMS = [\n    (\"unit/test_limiter.py\", \"unit/test_sync_limiter.py\"),\n    (\"unit/test_repository.py\", \"unit/test_sync_repository.py\"),\n    (\"unit/test_lease.py\", \"unit/test_sync_lease.py\"),\n    (\"integration/test_repository.py\", \"integration/test_sync_repository.py\"),\n    (\"e2e/test_localstack.py\", \"e2e/test_sync_localstack.py\"),\n]\n</code></pre> <p>Step 2: Add pytest marker removal</p> <p>Add to transformer class:</p> <pre><code>def visit_Decorator(self, node: ast.AST) -&gt; ast.AST | None:\n    \"\"\"Remove @pytest.mark.asyncio decorators.\"\"\"\n    if isinstance(node, ast.Attribute):\n        if (isinstance(node.value, ast.Attribute) and\n            isinstance(node.value.value, ast.Name) and\n            node.value.value.id == \"pytest\" and\n            node.value.attr == \"mark\" and\n            node.attr == \"asyncio\"):\n            return None  # Remove decorator\n    return node\n</code></pre> <p>Step 3: Add fixture name rewrites</p> <pre><code>FIXTURE_RENAMES = {\n    \"limiter\": \"sync_limiter\",\n    \"repository\": \"sync_repository\",\n}\n</code></pre> <p>Step 4: Test generator with test files</p> <p>Run: <code>python scripts/generate_sync.py</code> Expected: Test files generated</p> <p>Step 5: Commit</p> <pre><code>git add scripts/generate_sync.py\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\u2728 feat(generate-sync): add test file transformation\n\n- Transform async tests to sync tests\n- Remove @pytest.mark.asyncio decorators\n- Rename fixture references (limiter -&gt; sync_limiter)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-11-add-geventeventlet-compatibility-tests","title":"Task 11: Add Gevent/Eventlet Compatibility Tests","text":"<p>Files: - Create: <code>tests/unit/test_sync_compatibility.py</code></p> <p>Step 1: Create compatibility test file</p> <pre><code>\"\"\"Tests for sync implementation compatibility with Gevent/Eventlet.\n\nThese tests verify that the native sync implementation works correctly\nin environments that monkey-patch the standard library for cooperative\nconcurrency (Gevent, Eventlet).\n\"\"\"\n\nimport pytest\n\n\nclass TestGeventCompatibility:\n    \"\"\"Tests for Gevent compatibility.\"\"\"\n\n    @pytest.fixture\n    def gevent_patched(self):\n        \"\"\"Apply Gevent monkey-patching.\"\"\"\n        pytest.importorskip(\"gevent\")\n        from gevent import monkey\n\n        # Patch all (socket, ssl, etc.)\n        monkey.patch_all()\n        yield\n\n    def test_sync_limiter_with_gevent(self, gevent_patched, mock_dynamodb):\n        \"\"\"SyncRateLimiter works with Gevent monkey-patching.\"\"\"\n        from zae_limiter import Limit, SyncRateLimiter\n        from zae_limiter.sync_repository import SyncRepository\n\n        repo = SyncRepository(name=\"gevent-test\", region=\"us-east-1\")\n        repo.create_table()\n\n        limiter = SyncRateLimiter(repository=repo)\n\n        with limiter.acquire(\n            entity_id=\"test\",\n            resource=\"api\",\n            limits=[Limit.per_minute(\"rpm\", 100)],\n            consume={\"rpm\": 1},\n        ) as lease:\n            assert lease.consumed == {\"rpm\": 1}\n\n        limiter.close()\n\n    def test_concurrent_greenlets(self, gevent_patched, mock_dynamodb):\n        \"\"\"Multiple greenlets can use SyncRateLimiter concurrently.\"\"\"\n        pytest.importorskip(\"gevent\")\n        import gevent\n\n        from zae_limiter import Limit, SyncRateLimiter\n        from zae_limiter.sync_repository import SyncRepository\n\n        repo = SyncRepository(name=\"gevent-concurrent\", region=\"us-east-1\")\n        repo.create_table()\n        limiter = SyncRateLimiter(repository=repo)\n\n        results = []\n\n        def acquire_limit(entity_id: str):\n            with limiter.acquire(\n                entity_id=entity_id,\n                resource=\"api\",\n                limits=[Limit.per_minute(\"rpm\", 100)],\n                consume={\"rpm\": 1},\n            ):\n                results.append(entity_id)\n\n        # Spawn multiple greenlets\n        greenlets = [\n            gevent.spawn(acquire_limit, f\"entity-{i}\")\n            for i in range(5)\n        ]\n        gevent.joinall(greenlets)\n\n        assert len(results) == 5\n        limiter.close()\n\n\nclass TestEventletCompatibility:\n    \"\"\"Tests for Eventlet compatibility.\"\"\"\n\n    @pytest.fixture\n    def eventlet_patched(self):\n        \"\"\"Apply Eventlet monkey-patching.\"\"\"\n        pytest.importorskip(\"eventlet\")\n        import eventlet\n\n        eventlet.monkey_patch()\n        yield\n\n    def test_sync_limiter_with_eventlet(self, eventlet_patched, mock_dynamodb):\n        \"\"\"SyncRateLimiter works with Eventlet monkey-patching.\"\"\"\n        from zae_limiter import Limit, SyncRateLimiter\n        from zae_limiter.sync_repository import SyncRepository\n\n        repo = SyncRepository(name=\"eventlet-test\", region=\"us-east-1\")\n        repo.create_table()\n\n        limiter = SyncRateLimiter(repository=repo)\n\n        with limiter.acquire(\n            entity_id=\"test\",\n            resource=\"api\",\n            limits=[Limit.per_minute(\"rpm\", 100)],\n            consume={\"rpm\": 1},\n        ) as lease:\n            assert lease.consumed == {\"rpm\": 1}\n\n        limiter.close()\n</code></pre> <p>Step 2: Add optional test dependencies</p> <p>Add to <code>pyproject.toml</code> under <code>[project.optional-dependencies]</code>:</p> <pre><code>compat = [\n    \"gevent&gt;=24.0.0\",\n    \"eventlet&gt;=0.36.0\",\n]\n</code></pre> <p>Step 3: Run compatibility tests (if dependencies available)</p> <p>Run: <code>uv run pytest tests/unit/test_sync_compatibility.py -v</code> Expected: Tests skip if gevent/eventlet not installed, pass if available</p> <p>Step 4: Commit</p> <pre><code>git add tests/unit/test_sync_compatibility.py pyproject.toml\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\u2705 test(compat): add Gevent/Eventlet compatibility tests\n\nVerify native sync implementation works with:\n- Gevent monkey-patching\n- Eventlet monkey-patching\n- Concurrent greenlets\n\nTests skip if gevent/eventlet not installed.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-12-update-ci-workflow","title":"Task 12: Update CI Workflow","text":"<p>Files: - Modify: <code>.github/workflows/ci.yml</code> (or equivalent)</p> <p>Step 1: Add sync verification job</p> <p>Add a job that verifies generated code is up-to-date:</p> <pre><code>  verify-sync:\n    name: Verify Generated Sync Code\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: astral-sh/setup-uv@v4\n      - name: Generate sync code\n        run: python scripts/generate_sync.py\n      - name: Check for uncommitted changes\n        run: |\n          git diff --exit-code src/zae_limiter/sync_*.py src/zae_limiter/infra/sync_*.py || \\\n          (echo \"::error::Generated sync code is out of date. Run: python scripts/generate_sync.py\" &amp;&amp; exit 1)\n</code></pre> <p>Step 2: Add compatibility test job (optional)</p> <pre><code>  test-compat:\n    name: Compatibility Tests\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: astral-sh/setup-uv@v4\n      - name: Install with compat extras\n        run: uv sync --extra dev --extra compat\n      - name: Run compatibility tests\n        run: uv run pytest tests/unit/test_sync_compatibility.py -v\n</code></pre> <p>Step 3: Commit</p> <pre><code>git add .github/workflows/ci.yml\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udc77 ci: add sync code verification and compatibility tests\n\n- verify-sync: Ensures generated code matches async source\n- test-compat: Runs Gevent/Eventlet compatibility tests\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-13-create-adr-for-unasync-architecture","title":"Task 13: Create ADR for Unasync Architecture","text":"<p>Files: - Create: <code>docs/adr/120-native-sync-unasync.md</code></p> <p>Step 1: Create ADR</p> <pre><code># ADR-120: Native Sync Implementation via Unasync Pattern\n\n## Status\n\nAccepted\n\n## Context\n\nThe `SyncRateLimiter` class wrapped the async `RateLimiter` using\n`asyncio.run_until_complete()`. This approach failed in environments\nwith their own async runtime (Gevent, Eventlet) because:\n\n- Gevent/Eventlet use greenlet-based cooperative concurrency\n- asyncio's event loop conflicts with monkey-patched I/O\n- The wrapper blocked entire greenlet pools or failed outright\n\n## Decision\n\nAdopt the **unasync pattern** used by httpx, httpcore, and urllib3:\n\n1. Async code (aioboto3) is the **source of truth**\n2. AST transformation generates sync code (boto3) at build time\n3. Generated code is **committed to git** for documentation and debugging\n4. Pre-commit and CI verify generated code stays in sync\n\n### Transformation Rules\n\n| Async | Sync |\n|-------|------|\n| `async def` | `def` |\n| `await expr` | `expr` |\n| `async with` | `with` |\n| `aioboto3` | `boto3` |\n| `RateLimiter` | `SyncRateLimiter` |\n\n### File Mapping\n\n| Source | Generated |\n|--------|-----------|\n| repository.py | sync_repository.py |\n| limiter.py | sync_limiter.py |\n| lease.py | sync_lease.py |\n\n## Consequences\n\n### Positive\n\n- **Single source of truth**: Maintain async code only\n- **Native performance**: No event loop overhead\n- **Gevent/Eventlet compatible**: boto3 blocking I/O becomes cooperative\n- **Debuggable**: Generated code is committed, has line numbers\n\n### Negative\n\n- **Build complexity**: Requires AST transformer and verification hooks\n- **PR noise**: Generated code changes appear in diffs\n- **Two test suites**: Both async and sync tests must pass\n\n## References\n\n- Design doc: `docs/plans/2026-02-02-native-sync-unasync-design.md`\n- httpx unasync: https://github.com/encode/httpx/tree/master/scripts\n</code></pre> <p>Step 2: Commit</p> <pre><code>git add docs/adr/120-native-sync-unasync.md\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udcdd docs(adr): ADR-120 native sync via unasync pattern\n\nDocument architectural decision to generate native sync code from\nasync source using AST transformation, replacing event loop wrapper.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-14-update-claudemd","title":"Task 14: Update CLAUDE.md","text":"<p>Files: - Modify: <code>CLAUDE.md</code></p> <p>Step 1: Add sync generation section</p> <p>Add under \"Build &amp; Development\":</p> <pre><code>### Sync Code Generation\n\nNative sync code is generated from async source via AST transformation:\n\n```bash\n# Generate sync code after modifying async source\nhatch run generate-sync\n\n# Or directly\npython scripts/generate_sync.py\n</code></pre> <p>Generated files (DO NOT EDIT): - <code>sync_repository.py</code> \u2190 <code>repository.py</code> - <code>sync_limiter.py</code> \u2190 <code>limiter.py</code> - <code>sync_lease.py</code> \u2190 <code>lease.py</code> - <code>sync_config_cache.py</code> \u2190 <code>config_cache.py</code> - <code>infra/sync_stack_manager.py</code> \u2190 <code>infra/stack_manager.py</code> - <code>infra/sync_discovery.py</code> \u2190 <code>infra/discovery.py</code></p> <p>Pre-commit hook verifies generated code is up-to-date. <pre><code>**Step 2: Update Project Structure**\n\nAdd the new files to the structure section.\n\n**Step 3: Commit**\n\n```bash\ngit add CLAUDE.md\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udcdd docs(claude): document sync code generation workflow\n\nAdd section explaining:\n- How to regenerate sync code\n- Which files are generated (don't edit)\n- Pre-commit verification\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre></p>"},{"location":"plans/2026-02-02-native-sync-implementation/#task-15-run-full-test-suite","title":"Task 15: Run Full Test Suite","text":"<p>Step 1: Run all unit tests</p> <p>Run: <code>uv run pytest tests/unit/ -v</code> Expected: All tests pass</p> <p>Step 2: Run integration tests (with LocalStack)</p> <p>Run: <code>zae-limiter local up &amp;&amp; uv run pytest tests/integration/ -v</code> Expected: All tests pass</p> <p>Step 3: Run sync compatibility tests</p> <p>Run: <code>uv run pytest tests/unit/test_sync_compatibility.py -v</code> Expected: Tests pass or skip (depending on gevent/eventlet availability)</p> <p>Step 4: Verify pre-commit passes</p> <p>Run: <code>pre-commit run --all-files</code> Expected: All hooks pass</p> <p>Step 5: Final commit if any fixes needed</p> <pre><code>git add -A\ngit commit -m \"$(cat &lt;&lt;'EOF'\n\ud83d\udc1b fix: address test failures from native sync migration\n\n[Describe fixes]\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-implementation/#summary","title":"Summary","text":"<p>After completing all tasks:</p> <ol> <li>\u2705 AST transformer generates native sync code from async source</li> <li>\u2705 Pre-commit hook verifies generated code is up-to-date</li> <li>\u2705 Hatch build hook runs generation before packaging</li> <li>\u2705 SyncRateLimiter is now native boto3 (no event loop wrapper)</li> <li>\u2705 Tests pass for both async and sync implementations</li> <li>\u2705 Gevent/Eventlet compatibility verified</li> <li>\u2705 CI verifies generated code matches source</li> <li>\u2705 ADR documents the architecture decision</li> <li>\u2705 CLAUDE.md updated with generation workflow</li> </ol>"},{"location":"plans/2026-02-02-native-sync-unasync-design/","title":"Native Sync Implementation via Unasync","text":"<p>Date: 2026-02-02 Status: Approved Author: Brainstorming session</p>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#problem","title":"Problem","text":"<p>The current <code>SyncRateLimiter</code> wraps the async <code>RateLimiter</code> using <code>run_until_complete()</code>. This fails in environments with their own async runtime (Gevent, Eventlet) because:</p> <ul> <li>Gevent/Eventlet use monkey-patching for cooperative concurrency</li> <li>asyncio's event loop model fundamentally conflicts with greenlet-based concurrency</li> <li><code>run_until_complete()</code> blocks the entire greenlet pool or fails outright</li> </ul>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#solution","title":"Solution","text":"<p>Use the unasync pattern to generate native sync code from async source:</p> <ol> <li>Async code (aioboto3) is the source of truth</li> <li>At build time, AST transformation generates sync code (boto3)</li> <li>Generated sync code is committed to git</li> <li>Both versions are optimal for their runtime \u2014 no wrapper overhead</li> </ol> <p>This pattern is battle-tested by <code>httpx</code>, <code>httpcore</code>, and <code>urllib3</code>.</p>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#transformation-scope","title":"Transformation Scope","text":""},{"location":"plans/2026-02-02-native-sync-unasync-design/#source-files","title":"Source Files","text":"Source (async) Generated (sync) <code>repository.py</code> <code>sync_repository.py</code> <code>limiter.py</code> <code>sync_limiter.py</code> <code>lease.py</code> <code>sync_lease.py</code> <code>config_cache.py</code> <code>sync_config_cache.py</code> <code>infra/stack_manager.py</code> <code>infra/sync_stack_manager.py</code> <code>infra/discovery.py</code> <code>infra/sync_discovery.py</code>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#test-files","title":"Test Files","text":"Source (async) Generated (sync) <code>tests/unit/test_limiter.py</code> <code>tests/unit/test_sync_limiter.py</code> <code>tests/unit/test_repository.py</code> <code>tests/unit/test_sync_repository.py</code> <code>tests/unit/test_lease.py</code> <code>tests/unit/test_sync_lease.py</code> <code>tests/integration/test_repository.py</code> <code>tests/integration/test_sync_repository.py</code> <code>tests/e2e/test_localstack.py</code> <code>tests/e2e/test_sync_localstack.py</code>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#shared-files-not-transformed","title":"Shared Files (Not Transformed)","text":"<ul> <li><code>models.py</code> \u2014 Pure dataclasses, no I/O</li> <li><code>schema.py</code> \u2014 Key builders, pure functions</li> <li><code>bucket.py</code> \u2014 Token bucket math, pure functions</li> <li><code>exceptions.py</code> \u2014 Exception classes</li> <li><code>naming.py</code>, <code>version.py</code> \u2014 Pure utilities</li> </ul>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#deletions","title":"Deletions","text":"<ul> <li><code>SyncRateLimiter</code> class in <code>limiter.py</code> (replaced by generated)</li> <li><code>SyncLease</code> class in <code>lease.py</code> (replaced by generated)</li> </ul>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#transformation-rules","title":"Transformation Rules","text":""},{"location":"plans/2026-02-02-native-sync-unasync-design/#ast-transformations","title":"AST Transformations","text":"Async Pattern Sync Replacement <code>async def</code> <code>def</code> <code>await expr</code> <code>expr</code> <code>async with</code> <code>with</code> <code>async for</code> <code>for</code> <code>AsyncIterator</code> <code>Iterator</code> <code>AsyncContextManager</code> <code>ContextManager</code> <code>__aenter__</code> <code>__enter__</code> <code>__aexit__</code> <code>__exit__</code> <code>aioboto3</code> <code>boto3</code> <code>@pytest.mark.asyncio</code> (removed)"},{"location":"plans/2026-02-02-native-sync-unasync-design/#class-renames","title":"Class Renames","text":"Async Class Sync Class <code>RateLimiter</code> <code>SyncRateLimiter</code> <code>Repository</code> <code>SyncRepository</code> <code>Lease</code> <code>SyncLease</code> <code>ConfigCache</code> <code>SyncConfigCache</code> <code>StackManager</code> <code>SyncStackManager</code> <code>InfrastructureDiscovery</code> <code>SyncInfrastructureDiscovery</code>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#import-rewrites","title":"Import Rewrites","text":"Async Import Sync Import <code>from .repository import Repository</code> <code>from .sync_repository import SyncRepository</code> <code>from .lease import Lease</code> <code>from .sync_lease import SyncLease</code> <code>from .config_cache import ConfigCache</code> <code>from .sync_config_cache import SyncConfigCache</code> <code>import aioboto3</code> <code>import boto3</code>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#special-cases","title":"Special Cases","text":"<ul> <li><code>asyncio.wait_for(coro, timeout)</code> \u2192 inline call or boto3 timeout parameter</li> <li><code>asyncio.new_event_loop()</code> \u2192 deleted</li> <li><code>asyncio.run_until_complete()</code> \u2192 deleted</li> </ul>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#file-structure","title":"File Structure","text":"<pre><code>scripts/\n\u2514\u2500\u2500 generate_sync.py      # AST transformer script\n\nhatch_build.py            # Hatch build hook\n\nsrc/zae_limiter/\n\u251c\u2500\u2500 repository.py         # Async (source of truth)\n\u251c\u2500\u2500 sync_repository.py    # Generated, committed\n\u251c\u2500\u2500 limiter.py            # Async RateLimiter\n\u251c\u2500\u2500 sync_limiter.py       # Generated, committed\n\u251c\u2500\u2500 lease.py              # Async Lease\n\u251c\u2500\u2500 sync_lease.py         # Generated, committed\n\u251c\u2500\u2500 config_cache.py       # Async ConfigCache\n\u251c\u2500\u2500 sync_config_cache.py  # Generated, committed\n\u2514\u2500\u2500 infra/\n    \u251c\u2500\u2500 stack_manager.py\n    \u251c\u2500\u2500 sync_stack_manager.py    # Generated\n    \u251c\u2500\u2500 discovery.py\n    \u2514\u2500\u2500 sync_discovery.py        # Generated\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#build-integration","title":"Build Integration","text":""},{"location":"plans/2026-02-02-native-sync-unasync-design/#pyprojecttoml","title":"pyproject.toml","text":"<pre><code>[tool.hatch.build.hooks.custom]\npath = \"hatch_build.py\"\n\n[tool.hatch.envs.default.scripts]\ngenerate-sync = \"python scripts/generate_sync.py\"\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#developer-workflow","title":"Developer Workflow","text":"<pre><code># After modifying async code\nhatch run generate-sync\n\n# Run tests (covers both async and sync)\nhatch run test\n\n# Pre-commit hook verifies sync is up-to-date\ngit commit\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#ci-verification","title":"CI Verification","text":"<pre><code>- name: Verify generated sync code\n  run: |\n    hatch run generate-sync\n    git diff --exit-code src/zae_limiter/sync_*.py\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#generated-file-header","title":"Generated File Header","text":"<pre><code># AUTO-GENERATED by scripts/generate_sync.py\n# DO NOT EDIT - changes will be overwritten\n# Source: {source_file}\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#package-exports","title":"Package Exports","text":"<pre><code># __init__.py\n\n# Async (source)\nfrom .limiter import RateLimiter\nfrom .repository import Repository\nfrom .lease import Lease\nfrom .config_cache import ConfigCache\n\n# Sync (generated)\nfrom .sync_limiter import SyncRateLimiter\nfrom .sync_repository import SyncRepository\nfrom .sync_lease import SyncLease\nfrom .sync_config_cache import SyncConfigCache\n</code></pre> <p>User-facing usage unchanged:</p> <pre><code># Async users\nfrom zae_limiter import RateLimiter, Repository\n\n# Sync users\nfrom zae_limiter import SyncRateLimiter, SyncRepository\n</code></pre>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#implementation-order","title":"Implementation Order","text":""},{"location":"plans/2026-02-02-native-sync-unasync-design/#phase-1-transformation-infrastructure","title":"Phase 1: Transformation Infrastructure","text":"<ol> <li>Create <code>scripts/generate_sync.py</code> with AST transformer</li> <li>Add <code>hatch_build.py</code> build hook</li> <li>Update <code>pyproject.toml</code> with scripts and hook config</li> <li>Add pre-commit hook AND CI job to verify generated code is up-to-date</li> </ol>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#phase-2-source-preparation","title":"Phase 2: Source Preparation","text":"<ol> <li>Remove <code>SyncRateLimiter</code> class from <code>limiter.py</code></li> <li>Remove <code>SyncLease</code> class from <code>lease.py</code></li> <li>Ensure async code has no sync-specific workarounds</li> </ol>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#phase-3-generate-sync-code","title":"Phase 3: Generate Sync Code","text":"<ol> <li>Run <code>hatch run generate-sync</code></li> <li>Verify generated files compile and import</li> <li>Commit generated files</li> </ol>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#phase-4-update-exports","title":"Phase 4: Update Exports","text":"<ol> <li>Update <code>__init__.py</code> to import from generated modules</li> <li>Verify public API unchanged</li> </ol>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#phase-5-tests","title":"Phase 5: Tests","text":"<ol> <li>Add test files to transformation scope</li> <li>Generate sync tests</li> <li>Run full test suite (async + sync)</li> <li>Add Gevent/Eventlet compatibility tests</li> </ol>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#phase-6-documentation","title":"Phase 6: Documentation","text":"<ol> <li>API docs pick up both versions automatically</li> <li>Update CLAUDE.md with new architecture</li> <li>Add note in README about sync vs async</li> <li>Create ADR documenting the unasync architecture decision</li> </ol>"},{"location":"plans/2026-02-02-native-sync-unasync-design/#benefits","title":"Benefits","text":"<ul> <li>Single source of truth \u2014 Maintain async code only</li> <li>Native performance \u2014 No event loop overhead in sync contexts</li> <li>Gevent/Eventlet compatible \u2014 boto3 blocking I/O becomes cooperative via monkey-patching</li> <li>Correct types \u2014 Both versions have proper type hints</li> <li>Transparent \u2014 Generated code is committed, readable, debuggable</li> </ul>"}]}