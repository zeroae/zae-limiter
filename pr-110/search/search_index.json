{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"zae-limiter","text":"<p>A rate limiting library backed by DynamoDB using the token bucket algorithm.</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>zae-limiter is designed for limiting LLM API calls where:</p> <ul> <li>Multiple limits are tracked per call (requests per minute, tokens per minute)</li> <li>Token counts are unknown until after the call completes</li> <li>Hierarchical limits exist (API key \u2192 project)</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Token Bucket Algorithm - Precise rate limiting with configurable burst capacity</li> <li>Multiple Limits - Track requests per minute, tokens per minute, etc. in a single call</li> <li>Hierarchical Entities - Two-level hierarchy (project \u2192 API keys) with cascade mode</li> <li>Atomic Transactions - Multi-key updates via DynamoDB TransactWriteItems</li> <li>Rollback on Exception - Automatic rollback if your code throws</li> <li>Stored Limits - Configure per-entity limits in DynamoDB</li> <li>Usage Analytics - Lambda aggregator for hourly/daily usage snapshots</li> <li>Async + Sync APIs - First-class async support with sync wrapper</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    region=\"us-east-1\",\n)\n\nasync with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),       # 100 requests/minute\n        Limit.per_minute(\"tpm\", 10_000),    # 10k tokens/minute\n    ],\n    consume={\"rpm\": 1, \"tpm\": 500},  # estimate 500 tokens\n) as lease:\n    response = await call_llm()\n\n    # Reconcile actual token usage\n    actual_tokens = response.usage.total_tokens\n    await lease.adjust(tpm=actual_tokens - 500)\n</code></pre>"},{"location":"#why-dynamodb","title":"Why DynamoDB?","text":"<ul> <li>Serverless - No infrastructure to manage</li> <li>Global - Multi-region replication for low latency</li> <li>Scalable - Handles millions of requests per second</li> <li>Cost-effective - Pay per request, no idle costs</li> <li>Atomic - TransactWriteItems for multi-key consistency</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started - Installation and quick start guide</li> <li>User Guide - Detailed usage patterns</li> <li>API Reference - Complete API documentation</li> <li>Monitoring - Observability and alerting guide</li> <li>Troubleshooting - Diagnose and resolve operational issues</li> <li>Migrations - Schema migration strategy and versioning</li> </ul>"},{"location":"cli/","title":"CLI Reference","text":"<p>zae-limiter provides a command-line interface for managing infrastructure and deployments.</p>"},{"location":"cli/#installation","title":"Installation","text":"<p>The CLI is included with the package:</p> <pre><code>pip install zae-limiter\n</code></pre> <p>Verify installation:</p> <pre><code>zae-limiter --version\n</code></pre>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#deploy","title":"deploy","text":"<p>Deploy the CloudFormation stack with DynamoDB table and Lambda aggregator.</p> <pre><code>zae-limiter deploy [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (creates ZAEL-{name} resources) Required <code>--region</code> AWS region Required <code>--no-aggregator</code> Skip Lambda aggregator <code>false</code> <code>--log-retention-days</code> CloudWatch log retention (days) <code>14</code> <code>--pitr-recovery-days</code> Point-in-time recovery (days, 0=disabled) <code>0</code> <code>--endpoint-url</code> Custom AWS endpoint (LocalStack) None <p>Examples:</p> <pre><code># Basic deployment\nzae-limiter deploy --name limiter --region us-east-1\n\n# With custom settings\nzae-limiter deploy \\\n    --name prod \\\n    --region us-west-2 \\\n    --log-retention-days 90 \\\n    --pitr-recovery-days 7\n\n# Deploy to LocalStack\nzae-limiter deploy \\\n    --name limiter \\\n    --endpoint-url http://localhost:4566 \\\n    --region us-east-1\n\n# Without Lambda aggregator\nzae-limiter deploy \\\n    --name limiter \\\n    --region us-east-1 \\\n    --no-aggregator\n</code></pre>"},{"location":"cli/#status","title":"status","text":"<p>Check the status of a deployed CloudFormation stack.</p> <pre><code>zae-limiter status [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) Required <code>--region</code> AWS region Required <code>--endpoint-url</code> Custom AWS endpoint None <p>Example:</p> <pre><code>zae-limiter status --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>Stack: ZAEL-limiter\nStatus: CREATE_COMPLETE\nCreated: 2024-01-15 10:30:00\n\nResources:\n  - RateLimitsTable (AWS::DynamoDB::Table): CREATE_COMPLETE\n  - AggregatorFunction (AWS::Lambda::Function): CREATE_COMPLETE\n  - AggregatorRole (AWS::IAM::Role): CREATE_COMPLETE\n\nOutputs:\n  - TableName: ZAEL-limiter\n  - TableArn: arn:aws:dynamodb:us-east-1:123456789:table/ZAEL-limiter\n</code></pre>"},{"location":"cli/#delete","title":"delete","text":"<p>Delete a CloudFormation stack and all its resources.</p> <pre><code>zae-limiter delete [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) Required <code>--region</code> AWS region Required <code>--yes</code> Skip confirmation prompt <code>false</code> <code>--endpoint-url</code> Custom AWS endpoint None <p>Example:</p> <pre><code># With confirmation\nzae-limiter delete --name limiter --region us-east-1\n\n# Skip confirmation\nzae-limiter delete --name limiter --region us-east-1 --yes\n</code></pre> <p>Data Loss</p> <p>Deleting a stack removes the DynamoDB table and all its data. This action cannot be undone.</p>"},{"location":"cli/#cfn-template","title":"cfn-template","text":"<p>Export the CloudFormation template to stdout.</p> <pre><code>zae-limiter cfn-template [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--format</code> Output format (yaml, json) <code>yaml</code> <p>Examples:</p> <pre><code># Export YAML template\nzae-limiter cfn-template &gt; template.yaml\n\n# Export JSON template\nzae-limiter cfn-template --format json &gt; template.json\n\n# View template\nzae-limiter cfn-template | less\n</code></pre>"},{"location":"cli/#lambda-export","title":"lambda-export","text":"<p>Export the Lambda deployment package.</p> <pre><code>zae-limiter lambda-export [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--output</code> Output file path Required (unless <code>--info</code>) <code>--info</code> Show package info without building <code>false</code> <p>Examples:</p> <pre><code># Export Lambda package\nzae-limiter lambda-export --output lambda.zip\n\n# Show package info\nzae-limiter lambda-export --info\n</code></pre> <p>Info output:</p> <pre><code>Lambda Package Info:\n  Handler: zae_limiter.aggregator.handler.lambda_handler\n  Runtime: python3.12\n  Estimated size: ~30KB\n  Dependencies: boto3 (provided by Lambda runtime)\n</code></pre>"},{"location":"cli/#version","title":"version","text":"<p>Show the installed version.</p> <pre><code>zae-limiter version\n</code></pre> <p>Output:</p> <pre><code>zae-limiter 0.1.0\n</code></pre>"},{"location":"cli/#check","title":"check","text":"<p>Check schema compatibility with a deployed table.</p> <pre><code>zae-limiter check [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) Required <code>--region</code> AWS region Required <code>--endpoint-url</code> Custom AWS endpoint None <p>Example:</p> <pre><code>zae-limiter check --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>Schema version: 1.0.0\nLibrary version: 1.0.0\nStatus: Compatible\n</code></pre>"},{"location":"cli/#upgrade","title":"upgrade","text":"<p>Upgrade a table schema to the latest version.</p> <pre><code>zae-limiter upgrade [OPTIONS]\n</code></pre> <p>Options:</p> Option Description Default <code>--name</code> Resource identifier (ZAEL-{name}) Required <code>--region</code> AWS region Required <code>--endpoint-url</code> Custom AWS endpoint None <code>--dry-run</code> Show changes without applying <code>false</code> <p>Example:</p> <pre><code># Preview changes\nzae-limiter upgrade --name limiter --region us-east-1 --dry-run\n\n# Apply upgrade\nzae-limiter upgrade --name limiter --region us-east-1\n</code></pre>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>The CLI respects standard AWS environment variables:</p> Variable Description <code>AWS_ACCESS_KEY_ID</code> AWS access key <code>AWS_SECRET_ACCESS_KEY</code> AWS secret key <code>AWS_SESSION_TOKEN</code> AWS session token <code>AWS_DEFAULT_REGION</code> Default AWS region <code>AWS_PROFILE</code> AWS profile name <code>AWS_ENDPOINT_URL</code> Custom endpoint URL"},{"location":"cli/#exit-codes","title":"Exit Codes","text":"Code Description <code>0</code> Success <code>1</code> General error <code>2</code> Invalid arguments <code>3</code> AWS API error <code>4</code> Stack not found"},{"location":"cli/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment - Deployment guide</li> <li>LocalStack - Local development</li> <li>API Reference - Python API documentation</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you install zae-limiter and set up rate limiting in your application.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"pipuvpoetry <pre><code>pip install zae-limiter\n</code></pre> <pre><code>uv pip install zae-limiter\n</code></pre> <pre><code>poetry add zae-limiter\n</code></pre>"},{"location":"getting-started/#deploy-infrastructure","title":"Deploy Infrastructure","text":"<p>Before using zae-limiter, you need to deploy the DynamoDB table and optional Lambda aggregator.</p>"},{"location":"getting-started/#option-1-cli-recommended","title":"Option 1: CLI (Recommended)","text":"<pre><code>zae-limiter deploy --name limiter --region us-east-1\n</code></pre> <p>This creates a CloudFormation stack with:</p> <ul> <li>DynamoDB table with streams enabled</li> <li>Lambda function for usage aggregation</li> <li>Required IAM roles and permissions</li> </ul>"},{"location":"getting-started/#option-2-export-template","title":"Option 2: Export Template","text":"<pre><code># Export CloudFormation template\nzae-limiter cfn-template &gt; template.yaml\n\n# Deploy with AWS CLI\naws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name zae-limiter \\\n    --capabilities CAPABILITY_NAMED_IAM\n</code></pre>"},{"location":"getting-started/#option-3-auto-create-in-code-development","title":"Option 3: Auto-Create in Code (Development)","text":"<pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Auto-creates CloudFormation stack\n)\n</code></pre> <p>Production Use</p> <p>Auto-creation is convenient for development but not recommended for production. Use the CLI or CloudFormation for production deployments.</p>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/#async-api-recommended","title":"Async API (Recommended)","text":"<pre><code>from zae_limiter import RateLimiter, Limit, RateLimitExceeded\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter resources\n    region=\"us-east-1\",\n)\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"requests\", 100)],\n        consume={\"requests\": 1},\n    ) as lease:\n        await do_work()\nexcept RateLimitExceeded as e:\n    print(f\"Rate limited! Retry after {e.retry_after_seconds:.1f}s\")\n</code></pre>"},{"location":"getting-started/#sync-api","title":"Sync API","text":"<pre><code>from zae_limiter import SyncRateLimiter, Limit\n\nlimiter = SyncRateLimiter(name=\"limiter\")\n\nwith limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"requests\", 100)],\n    consume={\"requests\": 1},\n) as lease:\n    response = call_api()\n</code></pre>"},{"location":"getting-started/#understanding-limits","title":"Understanding Limits","text":"<p>A <code>Limit</code> defines a rate limit using the token bucket algorithm:</p> <pre><code># 100 requests per minute\nLimit.per_minute(\"rpm\", 100)\n\n# 10,000 tokens per minute with 15,000 burst capacity\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n\n# 1,000 requests per hour\nLimit.per_hour(\"rph\", 1_000)\n\n# Custom: 50 requests per 30 seconds\nLimit.custom(\"requests\", capacity=50, refill_period_seconds=30)\n</code></pre> Parameter Description <code>name</code> Unique identifier (e.g., \"rpm\", \"tpm\") <code>capacity</code> Tokens that refill per period (sustained rate) <code>burst</code> Maximum bucket size (defaults to capacity)"},{"location":"getting-started/#handling-rate-limit-errors","title":"Handling Rate Limit Errors","text":"<p>When a rate limit is exceeded, <code>RateLimitExceeded</code> is raised with full details:</p> <pre><code>from zae_limiter import RateLimitExceeded\n\ntry:\n    async with limiter.acquire(...):\n        await do_work()\nexcept RateLimitExceeded as e:\n    # Get retry delay\n    print(f\"Retry after: {e.retry_after_seconds}s\")\n\n    # For HTTP responses\n    return JSONResponse(\n        status_code=429,\n        content=e.as_dict(),\n        headers={\"Retry-After\": e.retry_after_header},\n    )\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage - More usage patterns</li> <li>Hierarchical Limits - Parent/child entities</li> <li>LLM Integration - Token estimation and reconciliation</li> <li>CLI Reference - Command-line interface</li> </ul>"},{"location":"migrations/","title":"Migrations","text":"<p>This guide covers managing schema migrations for zae-limiter infrastructure.</p>"},{"location":"migrations/#overview","title":"Overview","text":"<p>Schema migrations handle changes to the DynamoDB table structure when upgrading between major versions of zae-limiter. The migration framework provides:</p> <ul> <li>Version tracking - Infrastructure version stored in DynamoDB</li> <li>Compatibility checking - Automatic client/infrastructure compatibility validation</li> <li>Migration registry - Ordered list of migrations between versions</li> <li>Rollback support - Optional rollback functions for reversible changes</li> </ul>"},{"location":"migrations/#when-migrations-are-needed","title":"When Migrations Are Needed","text":"Change Type Migration Required? Version Bump Add optional attribute No Patch (x.x.1) Add new index (GSI) Yes Minor (x.1.0) Change key structure Yes Major (1.0.0) Remove attribute Yes Major (1.0.0) Change attribute type Yes Major (1.0.0)"},{"location":"migrations/#version-compatibility","title":"Version Compatibility","text":"<p>zae-limiter uses semantic versioning with specific compatibility rules.</p>"},{"location":"migrations/#compatibility-rules","title":"Compatibility Rules","text":"<pre><code>Client 1.x.x + Schema 1.x.x = Compatible\nClient 2.x.x + Schema 1.x.x = Incompatible (migration required)\nClient 1.2.0 + Min Client 1.3.0 = Incompatible (upgrade client)\n</code></pre> <p>Major version mismatch: Always incompatible. Schema migration required before the client can operate.</p> <p>Minor/patch version mismatch: Compatible. Client and infrastructure can operate together.</p> <p>Minimum client version: Infrastructure can require a minimum client version. Older clients are rejected.</p>"},{"location":"migrations/#checking-compatibility","title":"Checking Compatibility","text":"<p>Use the CLI to check compatibility without modifying anything:</p> <pre><code># Check current compatibility status\nzae-limiter check --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>Compatibility Check\n====================\n\nClient:      1.2.0\nSchema:      1.0.0\nLambda:      1.1.0\n\nResult: COMPATIBLE (update available)\n\nLambda update available: 1.1.0 -&gt; 1.2.0\n\nRun 'zae-limiter upgrade' to update.\n</code></pre>"},{"location":"migrations/#viewing-version-information","title":"Viewing Version Information","text":"<pre><code># Show detailed version information\nzae-limiter version --name limiter --region us-east-1\n</code></pre> <p>Output:</p> <pre><code>zae-limiter Infrastructure Version\n====================================\n\nClient Version:     1.2.0\nSchema Version:     1.0.0\n\nInfra Schema:       1.0.0\nLambda Version:     1.1.0\nMin Client Version: 0.0.0\n\nStatus: COMPATIBLE (Lambda update available)\n\n  Lambda update available: 1.1.0 -&gt; 1.2.0\n\nRun 'zae-limiter upgrade' to update Lambda.\n</code></pre>"},{"location":"migrations/#upgrading-infrastructure","title":"Upgrading Infrastructure","text":"<p>For minor updates (Lambda code, no schema changes):</p> <pre><code># Upgrade Lambda to match client version\nzae-limiter upgrade --name limiter --region us-east-1\n</code></pre> <p>For major version upgrades requiring schema migration, see Sample Migration: v2.0.0.</p>"},{"location":"migrations/#schema-modification-approaches","title":"Schema Modification Approaches","text":"<p>When modifying the DynamoDB schema, prefer solutions that preserve backward compatibility.</p>"},{"location":"migrations/#non-breaking-changes-preferred","title":"Non-Breaking Changes (Preferred)","text":"<p>These changes don't require migrations:</p> <p>Adding optional attributes: <pre><code># Old code works - attribute simply missing\nitem = {\"PK\": \"ENTITY#123\", \"SK\": \"#META\", \"name\": \"test\"}\n\n# New code adds optional attribute\nitem = {\"PK\": \"ENTITY#123\", \"SK\": \"#META\", \"name\": \"test\", \"tags\": [\"prod\"]}\n</code></pre></p> <p>Using <code>if_not_exists()</code> for new nested structures: <pre><code># Initialize nested map only if missing\nupdate_expression = \"SET #data.#metrics = if_not_exists(#data.#metrics, :empty_map)\"\n</code></pre></p> <p>Adding conditional logic for missing attributes: <pre><code># Handle missing attribute gracefully\nmetrics = item.get(\"data\", {}).get(\"metrics\", {})\nrequest_count = metrics.get(\"requests\", 0)\n</code></pre></p>"},{"location":"migrations/#breaking-changes-major-version","title":"Breaking Changes (Major Version)","text":"<p>These changes require migrations and major version bumps:</p> <ul> <li>Changing partition or sort key structure</li> <li>Removing required attributes</li> <li>Changing attribute data types</li> <li>Renaming attributes</li> <li>Restructuring nested data</li> </ul>"},{"location":"migrations/#dynamodb-specific-considerations","title":"DynamoDB-Specific Considerations","text":"<p>GSI Changes:</p> <ul> <li>Adding a GSI: Can be done without migration (CloudFormation update)</li> <li>Removing a GSI: Requires ensuring no code depends on it</li> <li>Changing GSI keys: Requires data migration</li> </ul> <p>Key Pattern Changes:</p> <pre><code># v1.0.0 pattern\nPK = f\"ENTITY#{entity_id}\"\nSK = f\"#BUCKET#{resource}#{limit_name}\"\n\n# v2.0.0 pattern (breaking change!)\nPK = f\"ENT#{entity_id}\"  # Changed prefix\nSK = f\"BKT#{resource}#{limit_name}\"  # Changed prefix\n</code></pre> <p>Key pattern changes require migrating all existing data.</p>"},{"location":"migrations/#creating-a-migration","title":"Creating a Migration","text":""},{"location":"migrations/#migration-file-structure","title":"Migration File Structure","text":"<p>Create a new file in <code>src/zae_limiter/migrations/</code>:</p> <pre><code># src/zae_limiter/migrations/v1_1_0.py\n\"\"\"\nMigration: v1.1.0 (Add metrics tracking)\n\nThis migration adds a metrics attribute to entity metadata\nfor tracking request statistics.\n\nChanges:\n- Add 'metrics' map to entity #META records\n- Initialize with empty counters\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom . import Migration, register_migration\n\nif TYPE_CHECKING:\n    from ..repository import Repository\n\n\nasync def migrate_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Add metrics attribute to all entity metadata records.\n\n    This is a forward-only migration that initializes the\n    metrics structure for existing entities.\n    \"\"\"\n    # Query all entity metadata records\n    # Update each to add metrics if missing\n    # Use conditional updates to be idempotent\n    pass\n\n\nasync def rollback_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Remove metrics attribute from entity metadata.\n\n    Note: This loses all collected metrics data.\n    \"\"\"\n    # Remove metrics attribute from all entities\n    pass\n\n\n# Register the migration\nregister_migration(\n    Migration(\n        version=\"1.1.0\",\n        description=\"Add metrics tracking to entities\",\n        reversible=True,\n        migrate=migrate_v1_1_0,\n        rollback=rollback_v1_1_0,\n    )\n)\n</code></pre>"},{"location":"migrations/#migration-protocol","title":"Migration Protocol","text":"<p>Migration functions must follow this protocol:</p> <pre><code>async def __call__(self, repository: Repository) -&gt; None:\n    \"\"\"Execute the migration.\"\"\"\n    ...\n</code></pre> <p>Key requirements:</p> <ol> <li>Async: All migrations are async functions</li> <li>Repository parameter: Receives a configured Repository instance</li> <li>Idempotent: Safe to run multiple times (use conditional updates)</li> <li>Atomic where possible: Use transactions for related changes</li> </ol>"},{"location":"migrations/#registering-migrations","title":"Registering Migrations","text":"<p>Migrations are auto-registered when imported. Ensure your migration module is imported in <code>migrations/__init__.py</code>:</p> <pre><code># src/zae_limiter/migrations/__init__.py\n\n# ... existing code ...\n\n# Import built-in migrations to register them\nfrom . import v1_0_0 as _v1_0_0  # noqa: F401, E402\nfrom . import v1_1_0 as _v1_1_0  # noqa: F401, E402  # Add new migration\n</code></pre>"},{"location":"migrations/#updating-schema-version","title":"Updating Schema Version","text":"<p>After adding a migration, update the current schema version:</p> <pre><code># src/zae_limiter/version.py\n\n# Current schema version - increment when schema changes\nCURRENT_SCHEMA_VERSION = \"1.1.0\"  # Updated from \"1.0.0\"\n</code></pre>"},{"location":"migrations/#validating-migrations","title":"Validating Migrations","text":""},{"location":"migrations/#unit-testing-with-moto","title":"Unit Testing with Moto","text":"<p>Test migrations using moto for fast, isolated tests:</p> <pre><code># tests/test_migrations.py\nimport pytest\nfrom moto import mock_aws\n\nfrom zae_limiter.migrations import get_migrations_between, apply_migrations\nfrom zae_limiter.repository import Repository\n\n\n@pytest.fixture\ndef mock_dynamodb():\n    with mock_aws():\n        # Create table and seed test data\n        yield\n\n\n@pytest.mark.asyncio\nasync def test_migration_v1_1_0(mock_dynamodb):\n    \"\"\"Test v1.1.0 migration adds metrics to entities.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create test entity without metrics\n    await repo.create_entity(entity_id=\"test-1\", name=\"Test Entity\")\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n\n    assert applied == [\"1.1.0\"]\n\n    # Verify metrics added - use raw DynamoDB query since Entity\n    # dataclass won't have the new 'metrics' field until code is updated\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#test-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert \"metrics\" in item[\"data\"][\"M\"]\n    assert item[\"data\"][\"M\"][\"metrics\"][\"M\"][\"requests\"][\"N\"] == \"0\"\n\n\n@pytest.mark.asyncio\nasync def test_migration_idempotent(mock_dynamodb):\n    \"\"\"Test migration can be safely run multiple times.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create test entity\n    await repo.create_entity(entity_id=\"test-1\", name=\"Test Entity\")\n\n    # Run migration twice\n    await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n    await apply_migrations(repo, \"1.0.0\", \"1.1.0\")  # Should not fail\n\n    # Verify single application via raw DynamoDB query\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#test-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert item[\"data\"][\"M\"][\"metrics\"][\"M\"][\"requests\"][\"N\"] == \"0\"\n</code></pre>"},{"location":"migrations/#integration-testing-with-localstack","title":"Integration Testing with LocalStack","text":"<p>Test migrations against real AWS-compatible infrastructure:</p> <pre><code># tests/test_migrations_integration.py\nimport os\nimport pytest\n\n# Skip if LocalStack not available\npytestmark = pytest.mark.skipif(\n    not os.environ.get(\"AWS_ENDPOINT_URL\"),\n    reason=\"LocalStack not available\"\n)\n\n\n@pytest.mark.integration\n@pytest.mark.asyncio\nasync def test_migration_with_localstack():\n    \"\"\"Test migration against LocalStack.\"\"\"\n    endpoint_url = os.environ[\"AWS_ENDPOINT_URL\"]\n\n    repo = Repository(\n        \"test_migrations\",\n        \"us-east-1\",\n        endpoint_url,\n    )\n\n    # Deploy infrastructure\n    # ... create table with CloudFormation ...\n\n    # Seed test data\n    # ... create entities ...\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"1.1.0\")\n\n    # Verify changes persisted\n    # ... assertions ...\n</code></pre> <p>Run integration tests:</p> <pre><code># Start LocalStack (from project root)\ndocker compose up -d\n\n# Set environment variables and run integration tests\nexport AWS_ENDPOINT_URL=http://localhost:4566\nexport AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-east-1\npytest -m integration -v\n</code></pre>"},{"location":"migrations/#production-validation-checklist","title":"Production Validation Checklist","text":"<p>Before running migrations in production:</p> <ul> <li>[ ] Backup: Enable Point-in-Time Recovery (PITR) or create on-demand backup</li> <li>[ ] Test: Run migration against production data copy</li> <li>[ ] Monitor: Set up CloudWatch alarms for errors</li> <li>[ ] Rollback plan: Document rollback procedure</li> <li>[ ] Maintenance window: Schedule during low-traffic period</li> <li>[ ] Communication: Notify stakeholders of potential downtime</li> </ul> <pre><code># Create on-demand backup before migration\naws dynamodb create-backup \\\n  --table-name ZAEL-limiter \\\n  --backup-name \"pre-migration-$(date +%Y%m%d)\"\n\n# Verify PITR is enabled\naws dynamodb describe-continuous-backups \\\n  --table-name ZAEL-limiter\n</code></pre>"},{"location":"migrations/#rollback-strategies","title":"Rollback Strategies","text":""},{"location":"migrations/#reversible-migrations","title":"Reversible Migrations","text":"<p>For migrations that can be safely undone:</p> <pre><code>register_migration(\n    Migration(\n        version=\"1.1.0\",\n        description=\"Add metrics tracking\",\n        reversible=True,  # Can be rolled back\n        migrate=migrate_v1_1_0,\n        rollback=rollback_v1_1_0,  # Rollback function\n    )\n)\n</code></pre> <p>Rollback removes or reverts the changes:</p> <pre><code>async def rollback_v1_1_0(repository: Repository) -&gt; None:\n    \"\"\"Remove metrics attribute from all entities.\"\"\"\n    # Implementation to remove metrics attribute\n    pass\n</code></pre>"},{"location":"migrations/#forward-only-migrations","title":"Forward-Only Migrations","text":"<p>Some migrations cannot be reversed:</p> <pre><code>register_migration(\n    Migration(\n        version=\"2.0.0\",\n        description=\"Restructure key patterns\",\n        reversible=False,  # Cannot be rolled back\n        migrate=migrate_v2_0_0,\n        rollback=None,  # No rollback function\n    )\n)\n</code></pre> <p>Forward-only migrations typically involve:</p> <ul> <li>Data transformation with information loss</li> <li>Key structure changes</li> <li>Removing deprecated attributes</li> </ul>"},{"location":"migrations/#emergency-rollback-procedures","title":"Emergency Rollback Procedures","text":"<p>If a migration fails or causes issues:</p> <p>1. Stop the bleeding: <pre><code># Revert to previous client version\npip install zae-limiter==1.0.0\n</code></pre></p> <p>2. Restore from backup (if needed): <pre><code># Restore from PITR\naws dynamodb restore-table-to-point-in-time \\\n  --source-table-name ZAEL-limiter \\\n  --target-table-name ZAEL-limiter-restored \\\n  --restore-date-time \"2024-01-15T10:00:00Z\"\n</code></pre></p> <p>3. Run rollback (if reversible): <pre><code>from zae_limiter.migrations import get_migrations\nfrom zae_limiter.repository import Repository\n\nasync def emergency_rollback():\n    repo = Repository(\"ZAEL-limiter\", \"us-east-1\", None)\n\n    migrations = get_migrations()\n    target_migration = next(m for m in migrations if m.version == \"1.1.0\")\n\n    if target_migration.reversible and target_migration.rollback:\n        await target_migration.rollback(repo)\n        print(\"Rollback complete\")\n    else:\n        print(\"Migration is not reversible - restore from backup\")\n</code></pre></p> <p>4. Update version record: <pre><code>await repo.set_version_record(\n    schema_version=\"1.0.0\",  # Reverted version\n    lambda_version=\"1.0.0\",\n    updated_by=\"emergency_rollback\",\n)\n</code></pre></p>"},{"location":"migrations/#sample-migration-v200","title":"Sample Migration: v2.0.0","text":"<p>This example demonstrates a complete migration scenario for a hypothetical v2.0.0 release that adds a new Global Secondary Index for querying entities by creation date.</p>"},{"location":"migrations/#scenario","title":"Scenario","text":"<p>Goal: Add ability to query entities by creation timestamp for audit purposes.</p> <p>Changes: 1. Add <code>created_at</code> attribute to entity metadata 2. Add GSI3 for querying by creation date 3. Backfill <code>created_at</code> for existing entities</p>"},{"location":"migrations/#migration-implementation","title":"Migration Implementation","text":"<pre><code># src/zae_limiter/migrations/v2_0_0.py\n\"\"\"\nMigration: v2.0.0 (Add creation timestamp tracking)\n\nThis migration adds a created_at timestamp to all entities and\ncreates a new GSI for querying entities by creation date.\n\nSchema changes:\n- Add 'created_at' attribute to entity #META records\n- Add GSI3: GSI3PK=CREATED#{YYYY-MM}, GSI3SK=ENTITY#{id}\n\nBreaking changes:\n- Requires CloudFormation stack update for GSI3\n- All queries using GSI3 require v2.0.0+ client\n\nRollback:\n- This migration is NOT reversible (GSI removal loses query capability)\n- Restore from backup if rollback needed\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom datetime import datetime, timezone\nfrom typing import TYPE_CHECKING\n\nfrom . import Migration, register_migration\n\nif TYPE_CHECKING:\n    from ..repository import Repository\n\n\nasync def migrate_v2_0_0(repository: Repository) -&gt; None:\n    \"\"\"\n    Add created_at timestamp to all existing entities.\n\n    Note: GSI3 must be added via CloudFormation update before\n    running this migration. The migration only backfills data.\n\n    Steps:\n    1. Scan all entity metadata records\n    2. Add created_at if missing (set to migration timestamp)\n    3. Add GSI3 keys for index population\n    \"\"\"\n    migration_time = datetime.now(timezone.utc).isoformat()\n    migration_month = datetime.now(timezone.utc).strftime(\"%Y-%m\")\n\n    # Get DynamoDB client\n    client = await repository._get_client()\n\n    # Scan for all entity metadata records\n    paginator = client.get_paginator('scan')\n\n    async for page in paginator.paginate(\n        TableName=repository.table_name,\n        FilterExpression=\"begins_with(SK, :meta)\",\n        ExpressionAttributeValues={\":meta\": {\"S\": \"#META\"}},\n    ):\n        items = page.get(\"Items\", [])\n\n        # Process in batches of 25 (DynamoDB limit)\n        for i in range(0, len(items), 25):\n            batch = items[i:i + 25]\n\n            # Build batch update\n            update_requests = []\n            for item in batch:\n                pk = item[\"PK\"][\"S\"]\n                sk = item[\"SK\"][\"S\"]\n\n                # Use conditional update - only if created_at missing\n                update_requests.append({\n                    \"Update\": {\n                        \"TableName\": repository.table_name,\n                        \"Key\": {\"PK\": {\"S\": pk}, \"SK\": {\"S\": sk}},\n                        \"UpdateExpression\": (\n                            \"SET #created = if_not_exists(#created, :ts), \"\n                            \"GSI3PK = if_not_exists(GSI3PK, :gsi3pk), \"\n                            \"GSI3SK = if_not_exists(GSI3SK, :gsi3sk)\"\n                        ),\n                        \"ExpressionAttributeNames\": {\n                            \"#created\": \"created_at\",\n                        },\n                        \"ExpressionAttributeValues\": {\n                            \":ts\": {\"S\": migration_time},\n                            \":gsi3pk\": {\"S\": f\"CREATED#{migration_month}\"},\n                            \":gsi3sk\": {\"S\": pk},\n                        },\n                    }\n                })\n\n            # Execute batch (transactions limited to 100 items)\n            if update_requests:\n                await client.transact_write_items(\n                    TransactItems=update_requests\n                )\n\n        # Rate limiting to avoid throttling\n        await asyncio.sleep(0.1)\n\n    # Update version record\n    await repository.set_version_record(\n        schema_version=\"2.0.0\",\n        client_min_version=\"2.0.0\",  # Require v2.0.0+ clients\n        updated_by=\"migration:v2.0.0\",\n    )\n\n\n# Register the migration\nregister_migration(\n    Migration(\n        version=\"2.0.0\",\n        description=\"Add creation timestamp tracking with GSI3\",\n        reversible=False,  # GSI changes are not easily reversible\n        migrate=migrate_v2_0_0,\n        rollback=None,\n    )\n)\n</code></pre>"},{"location":"migrations/#cloudformation-update","title":"CloudFormation Update","text":"<p>The GSI must be added before running the migration:</p> <pre><code># Addition to cfn_template.yaml\nResources:\n  RateLimitsTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      # ... existing properties ...\n      GlobalSecondaryIndexes:\n        # ... existing GSIs ...\n        - IndexName: GSI3\n          KeySchema:\n            - AttributeName: GSI3PK\n              KeyType: HASH\n            - AttributeName: GSI3SK\n              KeyType: RANGE\n          Projection:\n            ProjectionType: ALL\n      AttributeDefinitions:\n        # ... existing attributes ...\n        - AttributeName: GSI3PK\n          AttributeType: S\n        - AttributeName: GSI3SK\n          AttributeType: S\n</code></pre>"},{"location":"migrations/#running-the-migration","title":"Running the Migration","text":"<pre><code># 1. Create backup\naws dynamodb create-backup \\\n  --table-name ZAEL-limiter \\\n  --backup-name \"pre-v2-migration-$(date +%Y%m%d)\"\n\n# 2. Update CloudFormation stack (adds GSI3)\naws cloudformation update-stack \\\n  --stack-name ZAEL-limiter \\\n  --template-body file://updated-template.yaml \\\n  --capabilities CAPABILITY_NAMED_IAM\n\n# 3. Wait for GSI to be active\naws dynamodb wait table-exists --table-name ZAEL-limiter\n\n# 4. Install new client version\npip install zae-limiter==2.0.0\n\n# 5. Run migration (via upgrade command or programmatically)\npython -c \"\nimport asyncio\nfrom zae_limiter.migrations import apply_migrations\nfrom zae_limiter.repository import Repository\n\nasync def run():\n    repo = Repository('ZAEL-limiter', 'us-east-1', None)\n    applied = await apply_migrations(repo, '1.0.0', '2.0.0')\n    print(f'Applied migrations: {applied}')\n    await repo.close()\n\nasyncio.run(run())\n\"\n\n# 6. Verify migration\nzae-limiter version --name limiter --region us-east-1\n</code></pre>"},{"location":"migrations/#testing-the-migration","title":"Testing the Migration","text":"<pre><code>@pytest.mark.asyncio\nasync def test_v2_migration_adds_created_at(mock_dynamodb):\n    \"\"\"Test v2.0.0 migration adds created_at to entities.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create entities without created_at (v1 schema)\n    await repo.create_entity(entity_id=\"entity-1\", name=\"Test 1\")\n    await repo.create_entity(entity_id=\"entity-2\", name=\"Test 2\")\n\n    # Verify no created_at before migration\n    entity = await repo.get_entity(\"entity-1\")\n    assert entity.created_at is None\n\n    # Apply migration\n    applied = await apply_migrations(repo, \"1.0.0\", \"2.0.0\")\n    assert applied == [\"2.0.0\"]\n\n    # Verify created_at added - check raw DynamoDB for GSI3 keys\n    # (Entity dataclass has created_at, but GSI3PK/GSI3SK are schema-level)\n    client = await repo._get_client()\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#entity-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert \"created_at\" in item\n    assert item[\"created_at\"][\"S\"].startswith(\"20\")  # Valid ISO timestamp\n    assert \"GSI3PK\" in item  # GSI key was added\n    assert item[\"GSI3PK\"][\"S\"].startswith(\"CREATED#\")\n\n\n@pytest.mark.asyncio\nasync def test_v2_migration_idempotent(mock_dynamodb):\n    \"\"\"Test v2.0.0 migration is idempotent.\"\"\"\n    repo = Repository(\"test_table\", \"us-east-1\", None)\n\n    # Create entity with created_at already set\n    # (simulating an entity created after v2.0.0 code deployed)\n    original_time = \"2024-01-01T00:00:00Z\"\n    client = await repo._get_client()\n    await client.put_item(\n        TableName=repo.table_name,\n        Item={\n            \"PK\": {\"S\": \"ENTITY#entity-1\"},\n            \"SK\": {\"S\": \"#META\"},\n            \"data\": {\"M\": {\"name\": {\"S\": \"Test\"}}},\n            \"created_at\": {\"S\": original_time},\n            \"GSI3PK\": {\"S\": \"CREATED#2024-01\"},\n            \"GSI3SK\": {\"S\": \"ENTITY#entity-1\"},\n        },\n    )\n\n    # Apply migration - should not overwrite existing values\n    await apply_migrations(repo, \"1.0.0\", \"2.0.0\")\n\n    # Verify original created_at preserved (if_not_exists)\n    response = await client.get_item(\n        TableName=repo.table_name,\n        Key={\"PK\": {\"S\": \"ENTITY#entity-1\"}, \"SK\": {\"S\": \"#META\"}},\n    )\n    item = response[\"Item\"]\n    assert item[\"created_at\"][\"S\"] == original_time\n</code></pre>"},{"location":"migrations/#reference","title":"Reference","text":""},{"location":"migrations/#version-record-structure","title":"Version Record Structure","text":"<p>The version record is stored in DynamoDB:</p> Attribute Value Description PK <code>SYSTEM#</code> Partition key SK <code>#VERSION</code> Sort key schema_version <code>\"1.0.0\"</code> Current schema version lambda_version <code>\"1.2.0\"</code> Deployed Lambda version client_min_version <code>\"1.0.0\"</code> Minimum client version updated_at ISO timestamp Last update time updated_by <code>\"cli:1.2.0\"</code> What performed the update"},{"location":"migrations/#key-patterns-v100","title":"Key Patterns (v1.0.0)","text":"Pattern Example Description Entity metadata <code>PK=ENTITY#123, SK=#META</code> Entity configuration Bucket state <code>PK=ENTITY#123, SK=#BUCKET#gpt-4#rpm</code> Token bucket state Limit config <code>PK=ENTITY#123, SK=#LIMIT#gpt-4#rpm</code> Stored limit config Usage snapshot <code>PK=ENTITY#123, SK=#USAGE#gpt-4#2024-01-15</code> Usage data Version <code>PK=SYSTEM#, SK=#VERSION</code> Infrastructure version"},{"location":"migrations/#migration-api-reference","title":"Migration API Reference","text":"<pre><code>from zae_limiter.migrations import (\n    Migration,           # Migration dataclass\n    register_migration,  # Register a migration\n    get_migrations,      # Get all registered migrations\n    get_migrations_between,  # Get migrations between versions\n    apply_migrations,    # Apply migrations\n)\n\nfrom zae_limiter.version import (\n    CURRENT_SCHEMA_VERSION,  # Current schema version constant\n    parse_version,           # Parse version string\n    check_compatibility,     # Check client/infra compatibility\n    get_schema_version,      # Get current schema version\n    InfrastructureVersion,   # Version info dataclass\n    CompatibilityResult,     # Compatibility check result\n)\n</code></pre>"},{"location":"migrations/#cli-commands","title":"CLI Commands","text":"<pre><code># Check compatibility\nzae-limiter check --name NAME --region REGION\n\n# Show version information\nzae-limiter version --name NAME --region REGION\n\n# Upgrade infrastructure\nzae-limiter upgrade --name NAME --region REGION [--lambda-only] [--force]\n</code></pre>"},{"location":"monitoring/","title":"Monitoring and Observability","text":"<p>This guide covers monitoring and observability practices for zae-limiter deployments, including structured logging, CloudWatch metrics, alerts, and dashboard templates.</p>"},{"location":"monitoring/#overview","title":"Overview","text":"<p>Effective monitoring of a rate limiter is critical for:</p> <ul> <li>Availability - Detecting service degradation before users are impacted</li> <li>Latency - Ensuring rate limit checks don't become a bottleneck</li> <li>Throughput - Understanding capacity and scaling needs</li> <li>Errors - Identifying and resolving issues quickly</li> </ul> <p>zae-limiter provides built-in observability through:</p> Component Purpose CloudWatch Alarms Proactive alerting on anomalies Structured Logs JSON-formatted logs for analysis Dead Letter Queue Capturing failed events for investigation Usage Snapshots Aggregated consumption metrics"},{"location":"monitoring/#structured-logging","title":"Structured Logging","text":"<p>The Lambda aggregator uses structured JSON logging compatible with CloudWatch Logs Insights.</p>"},{"location":"monitoring/#log-format","title":"Log Format","text":"<p>All log entries follow this JSON structure:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.000000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter.aggregator.handler\",\n  \"message\": \"Lambda invocation completed\",\n  \"request_id\": \"abc123-def456\",\n  \"processed\": 50,\n  \"snapshots_updated\": 100,\n  \"processing_time_ms\": 45.23\n}\n</code></pre>"},{"location":"monitoring/#log-fields-reference","title":"Log Fields Reference","text":"Field Type Description <code>timestamp</code> string ISO 8601 timestamp (UTC) <code>level</code> string Log level: DEBUG, INFO, WARNING, ERROR <code>logger</code> string Logger name (module path) <code>message</code> string Human-readable message <code>request_id</code> string Lambda request ID for correlation <code>function_name</code> string Lambda function name <code>record_count</code> int DynamoDB stream records in batch <code>processed</code> int Records successfully processed <code>deltas_extracted</code> int Consumption deltas found <code>snapshots_updated</code> int Usage snapshots updated <code>error_count</code> int Processing errors <code>processing_time_ms</code> float Total execution time (ms)"},{"location":"monitoring/#log-levels","title":"Log Levels","text":"Level When Used DEBUG Detailed processing info (snapshot updates) INFO Invocation start/end, batch processing summary WARNING Recoverable errors (single record failures) ERROR Unrecoverable errors (batch failures)"},{"location":"monitoring/#example-log-entries","title":"Example Log Entries","text":"<p>Invocation Start: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.000000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter.aggregator.handler\",\n  \"message\": \"Lambda invocation started\",\n  \"request_id\": \"abc123-def456\",\n  \"function_name\": \"ZAEL-limiter-aggregator\",\n  \"record_count\": 50,\n  \"table_name\": \"ZAEL-limiter\",\n  \"snapshot_windows\": [\"hourly\", \"daily\"]\n}\n</code></pre></p> <p>Batch Complete: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.500000+00:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"zae_limiter.aggregator.processor\",\n  \"message\": \"Batch processing completed\",\n  \"processed_count\": 50,\n  \"deltas_extracted\": 45,\n  \"snapshots_updated\": 90,\n  \"error_count\": 0,\n  \"processing_time_ms\": 423.15\n}\n</code></pre></p> <p>Error with Exception: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:01.000000+00:00\",\n  \"level\": \"ERROR\",\n  \"logger\": \"zae_limiter.aggregator.processor\",\n  \"message\": \"Error processing record\",\n  \"record_index\": 12,\n  \"exception\": \"Traceback (most recent call last):\\n...\"\n}\n</code></pre></p>"},{"location":"monitoring/#cloudwatch-metrics","title":"CloudWatch Metrics","text":""},{"location":"monitoring/#lambda-metrics","title":"Lambda Metrics","text":"<p>Monitor the aggregator Lambda function:</p> Metric Namespace Description Recommended Threshold <code>Invocations</code> AWS/Lambda Total executions Baseline + 50% <code>Errors</code> AWS/Lambda Failed executions &gt; 1 per 5 min <code>Duration</code> AWS/Lambda Execution time (ms) &gt; 80% of timeout <code>Throttles</code> AWS/Lambda Throttled invocations &gt; 0 <code>IteratorAge</code> AWS/Lambda Stream processing lag (ms) &gt; 30,000 ms <code>ConcurrentExecutions</code> AWS/Lambda Parallel executions Account limit"},{"location":"monitoring/#dynamodb-metrics","title":"DynamoDB Metrics","text":"<p>Monitor table performance:</p> Metric Namespace Description Recommended Threshold <code>ConsumedReadCapacityUnits</code> AWS/DynamoDB RCU usage Provisioned capacity <code>ConsumedWriteCapacityUnits</code> AWS/DynamoDB WCU usage Provisioned capacity <code>ReadThrottleEvents</code> AWS/DynamoDB Read throttles &gt; 0 <code>WriteThrottleEvents</code> AWS/DynamoDB Write throttles &gt; 0 <code>SystemErrors</code> AWS/DynamoDB Service errors &gt; 0 <code>SuccessfulRequestLatency</code> AWS/DynamoDB Request latency (ms) p99 &gt; 100ms"},{"location":"monitoring/#sqs-metrics-dead-letter-queue","title":"SQS Metrics (Dead Letter Queue)","text":"<p>Monitor failed event processing:</p> Metric Namespace Description Recommended Threshold <code>ApproximateNumberOfMessagesVisible</code> AWS/SQS Messages in DLQ &gt; 0 <code>ApproximateAgeOfOldestMessage</code> AWS/SQS Oldest message age (s) &gt; 3600"},{"location":"monitoring/#cloudwatch-logs-insights-queries","title":"CloudWatch Logs Insights Queries","text":""},{"location":"monitoring/#batch-processing-performance","title":"Batch Processing Performance","text":"<p>Analyze processing latency over time:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Batch processing completed/\n| parse @message /processing_time_ms\":(?&lt;duration&gt;[\\d.]+)/\n| stats avg(duration) as avg_ms,\n        pct(duration, 50) as p50_ms,\n        pct(duration, 95) as p95_ms,\n        pct(duration, 99) as p99_ms\n  by bin(1h)\n| sort @timestamp desc\n</code></pre>"},{"location":"monitoring/#error-analysis","title":"Error Analysis","text":"<p>Find recent errors and warnings:</p> <pre><code>fields @timestamp, @message, @logStream\n| filter level = \"ERROR\" or level = \"WARNING\"\n| parse @message /message\":\"(?&lt;error_message&gt;[^\"]+)/\n| sort @timestamp desc\n| limit 100\n</code></pre>"},{"location":"monitoring/#invocation-summary","title":"Invocation Summary","text":"<p>Aggregate processing metrics:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Lambda invocation completed/\n| parse @message /processed\":(?&lt;processed&gt;\\d+).*snapshots_updated\":(?&lt;snapshots&gt;\\d+)/\n| stats sum(processed) as total_processed,\n        sum(snapshots) as total_snapshots,\n        count() as invocations\n  by bin(1h)\n| sort @timestamp desc\n</code></pre>"},{"location":"monitoring/#entity-usage-analysis","title":"Entity Usage Analysis","text":"<p>Find highest-usage entities:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Snapshot updated/\n| parse @message /entity_id\":\"(?&lt;entity&gt;[^\"]+)\".*resource\":\"(?&lt;resource&gt;[^\"]+)/\n| stats count() as updates by entity, resource\n| sort updates desc\n| limit 50\n</code></pre>"},{"location":"monitoring/#cold-start-detection","title":"Cold Start Detection","text":"<p>Identify Lambda cold starts:</p> <pre><code>fields @timestamp, @message, @duration\n| filter @type = \"REPORT\"\n| filter @message like /Init Duration/\n| parse @message /Init Duration: (?&lt;init_duration&gt;[\\d.]+) ms/\n| stats count() as cold_starts,\n        avg(init_duration) as avg_init_ms\n  by bin(1h)\n</code></pre>"},{"location":"monitoring/#error-rate-calculation","title":"Error Rate Calculation","text":"<p>Calculate error rate percentage:</p> <pre><code>fields @timestamp\n| filter @message like /Lambda invocation/\n| parse @message /error_count\":(?&lt;errors&gt;\\d+)/\n| stats sum(errors) as total_errors, count() as total_invocations\n| display total_errors, total_invocations,\n         (total_errors * 100.0 / total_invocations) as error_rate_pct\n</code></pre>"},{"location":"monitoring/#x-ray-tracing","title":"X-Ray Tracing","text":"<p>Future Enhancement</p> <p>X-Ray tracing integration is planned for a future release. Track progress in Issue #107.</p> <p>Planned capabilities include:</p> <ul> <li>Lambda Active Tracing - End-to-end request visibility</li> <li>DynamoDB SDK Instrumentation - Database call traces</li> <li>Custom Subsegments - Business logic timing (acquire/release operations)</li> <li>Trace Header Propagation - Cross-service correlation</li> </ul>"},{"location":"monitoring/#dashboard-templates","title":"Dashboard Templates","text":""},{"location":"monitoring/#operations-dashboard","title":"Operations Dashboard","text":"<p>Create a CloudWatch dashboard for day-to-day operations:</p> <pre><code>{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Invocations &amp; Errors\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"Invocations\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Sum\"}],\n          [\".\", \"Errors\", \".\", \".\", {\"stat\": \"Sum\", \"color\": \"#d62728\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Duration (p50/p95/p99)\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"Duration\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"p50\"}],\n          [\"...\", {\"stat\": \"p95\"}],\n          [\"...\", {\"stat\": \"p99\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Stream Iterator Age\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"IteratorAge\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Maximum\"}]\n        ],\n        \"period\": 60,\n        \"view\": \"timeSeries\",\n        \"annotations\": {\n          \"horizontal\": [{\"value\": 30000, \"label\": \"Threshold (30s)\"}]\n        }\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"DynamoDB Capacity\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ConsumedReadCapacityUnits\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\"}],\n          [\".\", \"ConsumedWriteCapacityUnits\", \".\", \".\", {\"stat\": \"Sum\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"DynamoDB Throttles\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ReadThrottleEvents\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\"}],\n          [\".\", \"WriteThrottleEvents\", \".\", \".\", {\"stat\": \"Sum\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Dead Letter Queue\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/SQS\", \"ApproximateNumberOfMessagesVisible\", \"QueueName\", \"${TableName}-aggregator-dlq\"]\n        ],\n        \"period\": 60,\n        \"view\": \"singleValue\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"monitoring/#capacity-planning-dashboard","title":"Capacity Planning Dashboard","text":"<p>Create a dashboard for capacity analysis:</p> <pre><code>{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"RCU/WCU Consumption Trend\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ConsumedReadCapacityUnits\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\", \"period\": 3600}],\n          [\".\", \"ConsumedWriteCapacityUnits\", \".\", \".\", {\"stat\": \"Sum\", \"period\": 3600}]\n        ],\n        \"view\": \"timeSeries\",\n        \"stacked\": false\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Request Latency Distribution\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"SuccessfulRequestLatency\", \"TableName\", \"${TableName}\", \"Operation\", \"GetItem\", {\"stat\": \"p50\"}],\n          [\"...\", {\"stat\": \"p95\"}],\n          [\"...\", {\"stat\": \"p99\"}]\n        ],\n        \"period\": 300,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Lambda Concurrent Executions\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/Lambda\", \"ConcurrentExecutions\", \"FunctionName\", \"${TableName}-aggregator\", {\"stat\": \"Maximum\"}]\n        ],\n        \"period\": 60,\n        \"view\": \"timeSeries\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Throttle Events (7 Day)\",\n        \"region\": \"${AWS::Region}\",\n        \"metrics\": [\n          [\"AWS/DynamoDB\", \"ReadThrottleEvents\", \"TableName\", \"${TableName}\", {\"stat\": \"Sum\", \"period\": 86400}],\n          [\".\", \"WriteThrottleEvents\", \".\", \".\", {\"stat\": \"Sum\", \"period\": 86400}]\n        ],\n        \"view\": \"bar\"\n      }\n    }\n  ]\n}\n</code></pre> <p>Dashboard Deployment</p> <p>Replace <code>${TableName}</code> with your actual table name (e.g., <code>ZAEL-limiter</code>) and <code>${AWS::Region}</code> with your region before deploying.</p>"},{"location":"monitoring/#alert-configuration","title":"Alert Configuration","text":""},{"location":"monitoring/#default-alarms","title":"Default Alarms","text":"<p>The stack deploys these alarms when <code>--enable-alarms</code> is set:</p> Alarm Metric Threshold Period Evaluation <code>{name}-aggregator-error-rate</code> Lambda Errors &gt; 1 5 min 2 periods <code>{name}-aggregator-duration</code> Lambda Duration &gt; 80% timeout 5 min 2 periods <code>{name}-stream-iterator-age</code> IteratorAge &gt; 30,000 ms 5 min 2 periods <code>{name}-aggregator-dlq-alarm</code> SQS Messages &gt;= 1 5 min 1 period <code>{name}-read-throttle</code> ReadThrottleEvents &gt; 1 5 min 2 periods <code>{name}-write-throttle</code> WriteThrottleEvents &gt; 1 5 min 2 periods"},{"location":"monitoring/#deploying-with-alarms","title":"Deploying with Alarms","text":"<pre><code># Deploy with alarms enabled (default)\nzae-limiter deploy --name limiter --region us-east-1\n\n# Deploy with SNS notifications\nzae-limiter deploy --name limiter --region us-east-1 \\\n    --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts\n\n# Customize duration threshold (70% of timeout)\nzae-limiter deploy --name limiter --region us-east-1 \\\n    --lambda-duration-threshold-pct 70\n\n# Disable alarms (not recommended for production)\nzae-limiter deploy --name limiter --region us-east-1 --no-alarms\n</code></pre>"},{"location":"monitoring/#threshold-tuning-guide","title":"Threshold Tuning Guide","text":"Alarm Default When to Increase When to Decrease Error Rate &gt;1/5min High-volume systems with rare transient errors Critical systems requiring immediate response Duration 80% timeout Batch workloads with variable processing time Latency-sensitive applications Iterator Age 30 seconds Batch-tolerant analytics workloads Real-time processing requirements DLQ Messages &gt;=1 Never (always investigate DLQ messages) N/A Throttles &gt;1/5min During planned traffic spikes Before hitting capacity limits"},{"location":"monitoring/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        enable_alarms=True,\n        alarm_sns_topic=\"arn:aws:sns:us-east-1:123456789012:alerts\",\n        lambda_duration_threshold_pct=75,  # Alert at 75% of timeout\n        log_retention_days=90,\n    ),\n)\n</code></pre>"},{"location":"monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Troubleshooting Guide - Diagnose and resolve operational issues</li> <li>Performance Tuning - Capacity planning and optimization</li> <li>Deployment Guide - Infrastructure setup</li> <li>CloudFormation Reference - Template customization</li> </ul>"},{"location":"performance/","title":"Performance Tuning Guide","text":"<p>This guide provides detailed recommendations for optimizing zae-limiter performance, covering DynamoDB capacity planning, Lambda configuration, and cost optimization strategies.</p>"},{"location":"performance/#1-dynamodb-capacity-planning","title":"1. DynamoDB Capacity Planning","text":""},{"location":"performance/#understanding-rcuwcu-costs","title":"Understanding RCU/WCU Costs","text":"<p>Each zae-limiter operation has specific DynamoDB capacity costs. Use this table for capacity planning:</p> Operation RCUs WCUs Notes <code>acquire()</code> - single limit 1 1 GetItem + TransactWrite <code>acquire()</code> - N limits N N N GetItems + TransactWrite(N items) <code>acquire(cascade=True)</code> 3 2 +GetEntity + parent bucket ops <code>acquire(use_stored_limits=True)</code> +2 0 +2 Query operations for limits <code>available()</code> 1 per limit 0 Read-only, no transaction <code>get_limits()</code> 1 0 Query operation <code>set_limits()</code> 1 N+1 Query + N PutItems <code>delete_entity()</code> 1 batched Query + BatchWrite in 25-item chunks <p>Capacity Validation</p> <p>These costs are validated by automated tests. Run <code>uv run pytest tests/benchmark/test_capacity.py -v</code> to verify.</p>"},{"location":"performance/#capacity-estimation-formula","title":"Capacity Estimation Formula","text":"<p>Use these formulas to estimate hourly capacity requirements:</p> <pre><code>Hourly RCUs = requests/hour \u00d7 limits/request \u00d7 (1 + cascade_pct \u00d7 2 + stored_limits_pct \u00d7 2)\nHourly WCUs = requests/hour \u00d7 limits/request \u00d7 (1 + cascade_pct)\n</code></pre> <p>With the Lambda aggregator enabled (2 windows: hourly, daily): <pre><code>Additional WCUs = requests/hour \u00d7 limits/request \u00d7 2\n</code></pre></p>"},{"location":"performance/#example-calculations","title":"Example Calculations","text":""},{"location":"performance/#scenario-1-simple-api-rate-limiting","title":"Scenario 1: Simple API Rate Limiting","text":"<ul> <li>10,000 requests/hour</li> <li>2 limits per request (rpm, tpm)</li> <li>No cascade, no stored limits</li> </ul> <p>Calculation: <pre><code>RCUs = 10,000 \u00d7 2 \u00d7 1.0 = 20,000 RCUs/hour\nWCUs = 10,000 \u00d7 2 \u00d7 1.0 = 20,000 WCUs/hour\n</code></pre></p>"},{"location":"performance/#scenario-2-hierarchical-llm-limiting","title":"Scenario 2: Hierarchical LLM Limiting","text":"<ul> <li>10,000 requests/hour</li> <li>2 limits per request</li> <li>50% use cascade (API key \u2192 project)</li> <li>20% use stored limits</li> </ul> <p>Calculation: <pre><code>RCUs = 10,000 \u00d7 2 \u00d7 (1 + 0.5\u00d72 + 0.2\u00d72) = 10,000 \u00d7 2 \u00d7 2.4 = 48,000 RCUs/hour\nWCUs = 10,000 \u00d7 2 \u00d7 (1 + 0.5) = 10,000 \u00d7 2 \u00d7 1.5 = 30,000 WCUs/hour\n</code></pre></p>"},{"location":"performance/#billing-mode-selection","title":"Billing Mode Selection","text":"Mode Best For Trade-offs PAY_PER_REQUEST (default) Variable traffic, new deployments Higher per-request cost, no planning needed Provisioned Steady traffic &gt;100 TPS Lower cost at scale, requires planning Provisioned + Reserved High-volume production Lowest cost, 1-year commitment <p>Migration Guidance</p> <p>Start with PAY_PER_REQUEST. Once traffic patterns stabilize (typically 2-4 weeks), analyze CloudWatch metrics to determine optimal provisioned capacity. Switch when monthly on-demand costs exceed provisioned + 20% buffer.</p>"},{"location":"performance/#2-lambda-concurrency-settings","title":"2. Lambda Concurrency Settings","text":"<p>The aggregator Lambda processes DynamoDB Stream events to maintain usage snapshots.</p>"},{"location":"performance/#default-configuration","title":"Default Configuration","text":"Setting Default Range Impact Memory 256 MB 128-3008 MB Higher = faster, more expensive Timeout 60 seconds 1-900 seconds Should be 2\u00d7 typical duration Reserved Concurrency None 1-1000 Limits parallel executions"},{"location":"performance/#memory-tuning","title":"Memory Tuning","text":"<p>Lambda CPU scales linearly with memory allocation:</p> Memory vCPUs Best For 128 MB ~0.08 Minimal workloads (testing only) 256 MB ~0.15 Most workloads (default) 512 MB ~0.30 High-throughput streams 1024 MB ~0.60 Rarely needed <p>Guidance based on batch size:</p> <ul> <li>&lt;50 records/batch: 128-256 MB sufficient</li> <li>50-100 records/batch: 256-512 MB recommended</li> <li>Peak streams: Monitor Lambda duration; increase memory if &gt;50% of timeout</li> </ul>"},{"location":"performance/#concurrency-management","title":"Concurrency Management","text":"<p>DynamoDB Streams creates one shard per 1000 WCU (or ~3000 writes/sec). Each shard invokes one Lambda instance.</p> <p>Recommendations:</p> Volume Reserved Concurrency Notes &lt;1000 writes/sec None Default scaling sufficient 1000-10000/sec 10-50 Prevents runaway scaling &gt;10000/sec Expected shards + 20% Based on table monitoring"},{"location":"performance/#error-handling","title":"Error Handling","text":"<p>Configure error handling for production reliability:</p> <pre><code># Deploy with DLQ and alarms\nzae-limiter deploy --table-name rate_limits \\\n  --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:alerts\n</code></pre> <ul> <li>Retries: Failed records retry 3 times within the same batch</li> <li>DLQ: Persistent failures go to Dead Letter Queue (if configured)</li> <li>Duration Alarm: Triggers at 80% of timeout (48s default)</li> </ul>"},{"location":"performance/#3-batch-operation-patterns","title":"3. Batch Operation Patterns","text":""},{"location":"performance/#transaction-limits","title":"Transaction Limits","text":"<p>DynamoDB enforces these limits:</p> Constraint Limit Impact TransactWriteItems 100 items max Affects multi-limit updates BatchWriteItem 25 items per request Entity deletion is chunked Optimistic locking Entire transaction fails Causes retry on contention"},{"location":"performance/#efficient-patterns","title":"Efficient Patterns","text":""},{"location":"performance/#multi-limit-acquisition","title":"Multi-Limit Acquisition","text":"<pre><code># Efficient: Single lease for multiple limits\nasync with limiter.acquire(\n    \"entity-id\",\n    \"llm-api\",\n    [rpm_limit, tpm_limit],\n    {\"rpm\": 1},  # Initial consumption (1 request)\n) as lease:\n    # 2 GetItems + 1 TransactWrite (2 items)\n    response = await call_llm()\n    lease.adjust({\"tpm\": response.usage.total_tokens})\n\n# Inefficient: Separate acquisitions\nasync with limiter.acquire(\"entity-id\", \"llm-api\", [rpm_limit], {\"rpm\": 1}):\n    async with limiter.acquire(\"entity-id\", \"llm-api\", [tpm_limit], {\"tpm\": 100}):\n        # 2 GetItems + 2 TransactWrites (doubles write cost!)\n        pass\n</code></pre>"},{"location":"performance/#cascade-optimization","title":"Cascade Optimization","text":"<pre><code># Only use cascade when hierarchical limits are actually needed\nasync with limiter.acquire(\n    \"api-key\",\n    \"llm-api\",\n    limits,\n    {\"rpm\": 1},\n    cascade=False,  # Saves 1 GetEntity + parent bucket operations\n):\n    pass\n\n# Use cascade for hierarchical enforcement\nasync with limiter.acquire(\n    \"api-key\",\n    \"llm-api\",\n    limits,\n    {\"rpm\": 1},\n    cascade=True,  # Checks and updates parent limits too\n):\n    pass\n</code></pre>"},{"location":"performance/#stored-limits-optimization","title":"Stored Limits Optimization","text":"<pre><code># Default: No stored limits lookup (saves 2 RCUs per acquire)\nlimiter = RateLimiter(\n    name=\"rate_limits\",\n    region=\"us-east-1\",\n)\n\n# Enable only when limits vary per entity\nlimiter = RateLimiter(\n    name=\"rate_limits\",\n    region=\"us-east-1\",\n    use_stored_limits=True,  # +2 Queries per acquire\n)\n</code></pre>"},{"location":"performance/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Efficient bulk limit setup\nawait limiter.set_limits(\"entity-1\", [rpm_limit, tpm_limit], resource=\"llm-api\")\nawait limiter.set_limits(\"entity-2\", [rpm_limit, tpm_limit], resource=\"llm-api\")\n# Runs 2 Queries + 2\u00d72 PutItems\n\n# Entity deletion (automatically batched in 25-item chunks)\nawait limiter.delete_entity(\"entity-id\")\n# Runs 1 Query + BatchWrite (up to 25 WCUs per chunk)\n</code></pre>"},{"location":"performance/#4-expected-latencies","title":"4. Expected Latencies","text":""},{"location":"performance/#operation-latencies","title":"Operation Latencies","text":"<p>Latencies vary by environment and depend on network conditions, DynamoDB utilization, and operation complexity.</p> Operation Moto p50 LocalStack p50 AWS p50 <code>acquire()</code> - single limit 14ms 36ms 36ms <code>acquire()</code> - two limits 30ms 52ms 43ms <code>acquire(cascade=True)</code> 28ms 57ms 51ms <code>available()</code> check 1ms 9ms 8ms <p>Environment Differences</p> <ul> <li>Moto: In-memory mock, measures code overhead only</li> <li>LocalStack: Docker-based, includes local network latency</li> <li>AWS: Production DynamoDB with real network round-trips</li> </ul>"},{"location":"performance/#latency-breakdown","title":"Latency Breakdown","text":"<p>Typical <code>acquire()</code> latency breakdown for a single limit:</p> <pre><code>acquire() latency breakdown:\n\u251c\u2500\u2500 DynamoDB GetItem (bucket)     ~5-15ms   (network + read)\n\u251c\u2500\u2500 Token bucket calculation      &lt;1ms      (in-memory math)\n\u251c\u2500\u2500 TransactWriteItems            ~10-25ms  (network + write + condition check)\n\u2514\u2500\u2500 Network overhead              variable  (region, instance type)\n</code></pre>"},{"location":"performance/#environment-selection","title":"Environment Selection","text":"Environment Use Case Latency Factor Moto Unit tests, CI/CD 1\u00d7 (baseline) LocalStack Integration tests, local dev 2-3\u00d7 AWS Production, load testing 2-4\u00d7 <p>Run benchmarks to measure your specific environment:</p> <pre><code># Moto benchmarks (fast)\nuv run pytest tests/benchmark/test_latency.py -v --benchmark-json=latency.json\n\n# LocalStack benchmarks (requires Docker)\ndocker compose up -d\nexport AWS_ENDPOINT_URL=http://localhost:4566\nuv run pytest tests/benchmark/test_localstack.py -v --benchmark-json=latency.json\n\n# AWS benchmarks (requires credentials)\nuv run pytest tests/benchmark/test_aws.py --run-aws -v\n</code></pre>"},{"location":"performance/#5-throughput-benchmarks","title":"5. Throughput Benchmarks","text":""},{"location":"performance/#maximum-throughput","title":"Maximum Throughput","text":"<p>Theoretical and practical throughput limits depend on contention patterns:</p> Scenario Expected TPS Bottleneck Sequential, single entity 50-200 Serialized operations Sequential, multiple entities 50-200 Network round-trip Concurrent, separate entities 100-500 Scales with parallelism Concurrent, single entity 20-100 Optimistic locking contention Cascade operations 30-100 Parent bucket contention"},{"location":"performance/#contention-analysis","title":"Contention Analysis","text":"<p>When multiple requests update the same bucket concurrently, DynamoDB's optimistic locking causes transaction retries:</p> <pre><code>Concurrent updates to same bucket:\n\u251c\u2500\u2500 Request A: Read bucket version=1\n\u251c\u2500\u2500 Request B: Read bucket version=1\n\u251c\u2500\u2500 Request A: Write with condition version=1 \u2192 SUCCESS, version=2\n\u251c\u2500\u2500 Request B: Write with condition version=1 \u2192 FAIL (ConditionalCheckFailed)\n\u2514\u2500\u2500 Request B: Retry with version=2 \u2192 SUCCESS\n</code></pre> <p>Each retry adds ~10-30ms latency.</p>"},{"location":"performance/#mitigation-strategies","title":"Mitigation Strategies","text":"<pre><code># Strategy 1: Larger bucket windows (reduces update frequency)\nrpm_limit = Limit.per_minute(\"rpm\", capacity=1000, window_seconds=60)\n\n# Strategy 2: Distribute load across entities\n# Instead of one shared entity, use sharded entities:\nshard = hash(request_id) % 10\nentity_id = f\"api-key-shard-{shard}\"\n\n# Strategy 3: Client-side rate limiting before acquire\n# Reduce concurrent requests to the same entity\n</code></pre>"},{"location":"performance/#running-benchmarks","title":"Running Benchmarks","text":"<p>Use the automated benchmark runner:</p> <pre><code># Run all benchmarks (moto + LocalStack)\npython scripts/run_benchmarks.py\n\n# Include AWS benchmarks\npython scripts/run_benchmarks.py --run-aws\n\n# Skip LocalStack (moto only)\npython scripts/run_benchmarks.py --skip-localstack\n\n# Custom output directory\npython scripts/run_benchmarks.py --output-dir ./results\n</code></pre> <p>Or run individual test suites:</p> <pre><code># Throughput tests\nuv run pytest tests/benchmark/test_throughput.py -v\n\n# Analyze results\npython -c \"import json; print(json.load(open('benchmark.json'))['benchmarks'])\"\n</code></pre>"},{"location":"performance/#6-cost-optimization-strategies","title":"6. Cost Optimization Strategies","text":""},{"location":"performance/#dynamodb-cost-breakdown","title":"DynamoDB Cost Breakdown","text":"<p>Costs vary by region. Using us-east-1 as reference:</p> Component On-Demand Cost Notes Write Request Units $0.625 per million Each WCU = one write Read Request Units $0.125 per million Each RCU = one read Storage $0.25 per GB/month Usually minimal Streams $0.02 per 100K reads Lambda polling Lambda $0.20 per million + duration Aggregator function"},{"location":"performance/#cost-estimation-examples","title":"Cost Estimation Examples","text":""},{"location":"performance/#low-volume-10k-requestsday","title":"Low Volume: 10K requests/day","text":"<pre><code>DynamoDB:\n  Writes: 10K \u00d7 2 limits \u00d7 30 days = 600K WCUs = $0.38\n  Reads:  10K \u00d7 2 limits \u00d7 30 days = 600K RCUs = $0.08\n  Streams: 600K events                         = $0.12\nLambda: 600K invocations                       \u2248 $0.12 + duration\nStorage: ~10 MB                                = negligible\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal: ~$0.70/month\n</code></pre>"},{"location":"performance/#medium-volume-1m-requestsday","title":"Medium Volume: 1M requests/day","text":"<pre><code>DynamoDB:\n  Writes: 1M \u00d7 2 \u00d7 30 = 60M WCUs               = $37.50\n  Reads:  1M \u00d7 2 \u00d7 30 = 60M RCUs               = $7.50\n  Streams: 60M events                          = $12.00\nLambda: 60M invocations                        \u2248 $12.00 + duration\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal (on-demand): ~$70/month\nTotal (provisioned with auto-scaling): ~$45/month\n</code></pre>"},{"location":"performance/#cost-reduction-strategies","title":"Cost Reduction Strategies","text":""},{"location":"performance/#1-disable-unused-features","title":"1. Disable Unused Features","text":"<pre><code># Skip cascade if not needed (saves 1-2 WCUs per request)\nasync with limiter.acquire(\"entity\", \"api\", limits, {\"rpm\": 1}, cascade=False):\n    pass\n\n# Disable stored limits if static (saves 2 RCUs per request)\nlimiter = RateLimiter(name=\"rate_limits\", region=\"us-east-1\")\n</code></pre>"},{"location":"performance/#2-optimize-ttl-settings","title":"2. Optimize TTL Settings","text":"<pre><code># Shorter TTL = faster cleanup = less storage\nlimiter = RateLimiter(\n    name=\"rate_limits\",\n    region=\"us-east-1\",\n    bucket_ttl_seconds=3600,  # 1 hour vs 24 hour default\n)\n</code></pre>"},{"location":"performance/#3-reduce-snapshot-granularity","title":"3. Reduce Snapshot Granularity","text":"<pre><code># Deploy without aggregator if usage tracking not needed\nzae-limiter deploy --table-name rate_limits --no-aggregator\n</code></pre>"},{"location":"performance/#4-switch-to-provisioned-at-scale","title":"4. Switch to Provisioned at Scale","text":"<ul> <li>Break-even: ~5M operations/month</li> <li>Use auto-scaling with 70% target utilization</li> <li>Consider reserved capacity for &gt;20M ops/month</li> </ul>"},{"location":"performance/#5-batch-similar-operations","title":"5. Batch Similar Operations","text":"<pre><code># Combine multiple limits into single acquire\nasync with limiter.acquire(\n    \"entity\",\n    \"api\",\n    [rpm_limit, tpm_limit, daily_limit],\n    {\"rpm\": 1},  # 1 transaction vs 3\n):\n    pass\n</code></pre>"},{"location":"performance/#cost-monitoring","title":"Cost Monitoring","text":"<p>Set up CloudWatch metrics for cost tracking:</p> <p>DynamoDB Metrics:</p> <ul> <li><code>ConsumedReadCapacityUnits</code></li> <li><code>ConsumedWriteCapacityUnits</code></li> <li><code>AccountProvisionedReadCapacityUtilization</code></li> <li><code>AccountProvisionedWriteCapacityUtilization</code></li> </ul> <p>Lambda Metrics:</p> <ul> <li><code>Invocations</code></li> <li><code>Duration</code></li> <li><code>ConcurrentExecutions</code></li> </ul> <p>Recommended Alerts:</p> <pre><code># Deploy with alarms for cost anomalies\nzae-limiter deploy --table-name rate_limits \\\n  --alarm-sns-topic arn:aws:sns:us-east-1:123456789012:billing-alerts\n\n# Set AWS Budgets alert at 80% of expected monthly cost\naws budgets create-budget \\\n  --account-id 123456789012 \\\n  --budget file://budget.json \\\n  --notifications-with-subscribers file://notifications.json\n</code></pre>"},{"location":"performance/#summary","title":"Summary","text":"Optimization Area Key Recommendations Capacity Start with on-demand, switch to provisioned at 5M+ ops/month Latency Expect 30-50ms p50 on AWS; use LocalStack for realistic testing Throughput Distribute load across entities to avoid contention Cost Disable cascade/stored_limits when not needed Monitoring Set up CloudWatch alerts for capacity and cost anomalies <p>For detailed benchmark data, run: <pre><code>python scripts/run_benchmarks.py --run-aws\n</code></pre></p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide helps operators diagnose and resolve common issues with zae-limiter deployments.</p>"},{"location":"troubleshooting/#overview","title":"Overview","text":"Issue Category Common Symptoms Rate Limit Enforcement Limits not enforced, unexpected <code>RateLimitExceeded</code> DynamoDB Throttling <code>ProvisionedThroughputExceededException</code>, slow requests Lambda Aggregator Missing usage snapshots, DLQ messages Version Compatibility <code>VersionMismatchError</code>, <code>IncompatibleSchemaError</code> Stream Processing High <code>IteratorAge</code>, delayed aggregation Recovery Data corruption, failed migrations"},{"location":"troubleshooting/#1-rate-limit-enforcement-failures","title":"1. Rate Limit Enforcement Failures","text":""},{"location":"troubleshooting/#symptoms","title":"Symptoms","text":"<ul> <li>Requests succeed when they should be rate limited</li> <li><code>RateLimitExceeded</code> raised unexpectedly</li> <li>Cascade to parent entity not working</li> <li>Bucket state appears incorrect</li> </ul>"},{"location":"troubleshooting/#diagnostic-steps","title":"Diagnostic Steps","text":"<p>Check entity and bucket state:</p> <pre><code># Query entity metadata\naws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n\n# Query bucket state for a specific limit\naws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre> <p>Verify stored limits (if using <code>use_stored_limits=True</code>):</p> <pre><code>aws dynamodb query --table-name ZAEL-&lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#LIMIT#\"}}'\n</code></pre>"},{"location":"troubleshooting/#common-causes-and-solutions","title":"Common Causes and Solutions","text":"Cause Solution Entity not created Create entity before rate limiting: <code>await limiter.create_entity(...)</code> Wrong <code>use_stored_limits</code> setting Set <code>use_stored_limits=True</code> if limits are in DynamoDB Parent entity missing (cascade) Create parent entity and set <code>parent_id</code> on child Clock skew Ensure server time is synchronized (NTP) Stale bucket state Bucket refills over time; wait or manually reset Limit configuration mismatch Verify limit <code>capacity</code>, <code>burst</code>, and <code>refill_rate</code> match expectations"},{"location":"troubleshooting/#cascade-not-working","title":"Cascade Not Working","text":"<p>If cascade to parent is not enforced:</p> <ol> <li> <p>Verify parent entity exists:    <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;parent_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n</code></pre></p> </li> <li> <p>Verify child has <code>parent_id</code> set:    <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;child_id&gt;\"}, \"SK\": {\"S\": \"#META\"}}'\n# Check the \"parent_id\" attribute in response\n</code></pre></p> </li> <li> <p>Ensure <code>cascade=True</code> in acquire call:    <pre><code>async with limiter.acquire(\n    entity_id=\"child-id\",\n    cascade=True,  # Must be True to check parent\n    ...\n):\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#verification","title":"Verification","text":"<pre><code># Test rate limiting is working\nfrom zae_limiter import RateLimiter, Limit, RateLimitExceeded\n\nlimiter = RateLimiter(name=\"&lt;name&gt;\", region=\"&lt;region&gt;\")\n\n# Consume all capacity\nfor i in range(100):\n    try:\n        async with limiter.acquire(\n            entity_id=\"test-entity\",\n            resource=\"test\",\n            limits=[Limit.per_minute(\"rpm\", 100)],\n            consume={\"rpm\": 1},\n        ):\n            pass\n    except RateLimitExceeded as e:\n        print(f\"Rate limited after {i} requests, retry_after={e.retry_after_seconds}s\")\n        break\n</code></pre>"},{"location":"troubleshooting/#2-dynamodb-throttling","title":"2. DynamoDB Throttling","text":""},{"location":"troubleshooting/#symptoms_1","title":"Symptoms","text":"<ul> <li><code>ProvisionedThroughputExceededException</code> errors</li> <li>Increased latency on rate limit checks</li> <li>CloudWatch throttle alarms triggered</li> <li><code>RateLimiterUnavailable</code> with <code>FAIL_CLOSED</code> mode</li> </ul>"},{"location":"troubleshooting/#diagnostic-steps_1","title":"Diagnostic Steps","text":"<p>Check CloudWatch metrics:</p> <pre><code># View throttle events (last hour)\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ReadThrottleEvents \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Check capacity utilization:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/DynamoDB \\\n  --metric-name ConsumedReadCapacityUnits \\\n  --dimensions Name=TableName,Value=ZAEL-&lt;name&gt; \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Sum\n</code></pre> <p>Identify hot partitions (if Contributor Insights enabled):</p> <pre><code>aws dynamodb describe-contributor-insights \\\n  --table-name ZAEL-&lt;name&gt;\n</code></pre>"},{"location":"troubleshooting/#common-causes-and-solutions_1","title":"Common Causes and Solutions","text":"Cause Solution Provisioned capacity too low Increase RCU/WCU or switch to on-demand Hot partition Distribute entity IDs more evenly Burst traffic Enable auto-scaling or use on-demand GSI throttling Check GSI capacity separately"},{"location":"troubleshooting/#emergency-mitigation","title":"Emergency Mitigation","text":"<p>Switch to on-demand capacity (immediate):</p> <pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --billing-mode PAY_PER_REQUEST\n</code></pre> <p>Increase provisioned capacity:</p> <pre><code>aws dynamodb update-table \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --provisioned-throughput ReadCapacityUnits=1000,WriteCapacityUnits=500\n</code></pre>"},{"location":"troubleshooting/#capacity-planning","title":"Capacity Planning","text":"<p>For detailed capacity calculations, see the Performance Tuning Guide.</p> <p>Quick estimates: - Each <code>acquire()</code> call: ~2 RCU, ~4 WCU (with cascade: ~4 RCU, ~8 WCU) - Each <code>available()</code> call: ~2 RCU, ~0 WCU</p>"},{"location":"troubleshooting/#3-lambda-aggregator-malfunctions","title":"3. Lambda Aggregator Malfunctions","text":""},{"location":"troubleshooting/#symptoms_2","title":"Symptoms","text":"<ul> <li>Usage snapshots not updating</li> <li>Messages accumulating in Dead Letter Queue (DLQ)</li> <li>Lambda duration alarm triggered</li> <li>CloudWatch Logs showing errors</li> </ul>"},{"location":"troubleshooting/#diagnostic-steps_2","title":"Diagnostic Steps","text":"<p>Check Lambda errors:</p> <pre><code># View recent Lambda invocations\naws logs filter-log-events \\\n  --log-group-name /aws/lambda/ZAEL-&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%s)000 \\\n  --filter-pattern \"ERROR\"\n</code></pre> <p>Check DLQ message count:</p> <pre><code>aws sqs get-queue-attributes \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/ZAEL-&lt;name&gt;-aggregator-dlq \\\n  --attribute-names ApproximateNumberOfMessagesVisible\n</code></pre> <p>Inspect DLQ messages:</p> <pre><code>aws sqs receive-message \\\n  --queue-url https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/ZAEL-&lt;name&gt;-aggregator-dlq \\\n  --max-number-of-messages 10 \\\n  --visibility-timeout 0\n</code></pre> <p>Check Lambda duration:</p> <pre><code>-- CloudWatch Logs Insights query\nfields @timestamp, @message\n| filter @message like /processing_time_ms/\n| parse @message /processing_time_ms\":(?&lt;duration&gt;[\\d.]+)/\n| filter duration &gt; 40000\n| sort @timestamp desc\n| limit 20\n</code></pre>"},{"location":"troubleshooting/#high-lambda-duration","title":"High Lambda Duration","text":"<p>Symptoms: Duration alarm triggered, <code>processing_time_ms</code> &gt; 80% of timeout</p> <p>Diagnostic query:</p> <pre><code>fields @timestamp, @message\n| filter @message like /Batch processing completed/\n| parse @message /processing_time_ms\":(?&lt;duration&gt;[\\d.]+)/\n| stats avg(duration) as avg_ms,\n        pct(duration, 50) as p50_ms,\n        pct(duration, 95) as p95_ms,\n        pct(duration, 99) as p99_ms\n  by bin(1h)\n| sort @timestamp desc\n</code></pre> <p>Solutions:</p> <ul> <li>Increase Lambda memory (CPU scales with memory)</li> <li>Reduce batch size in event source mapping</li> <li>Check DynamoDB latency metrics</li> </ul> <p>Adjust Lambda memory:</p> <pre><code>aws lambda update-function-configuration \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --memory-size 512\n</code></pre>"},{"location":"troubleshooting/#messages-in-dead-letter-queue","title":"Messages in Dead Letter Queue","text":"<p>Symptoms: DLQ alarm triggered, messages accumulating</p> <p>Solutions:</p> <ol> <li>Fix the root cause (check Lambda logs for errors)</li> <li>Reprocess DLQ messages after fix:</li> </ol> <pre><code>import boto3\nimport json\n\nsqs = boto3.client('sqs')\nlambda_client = boto3.client('lambda')\n\ndlq_url = \"https://sqs.&lt;region&gt;.amazonaws.com/&lt;account&gt;/ZAEL-&lt;name&gt;-aggregator-dlq\"\n\nwhile True:\n    response = sqs.receive_message(\n        QueueUrl=dlq_url,\n        MaxNumberOfMessages=10,\n        WaitTimeSeconds=5,\n    )\n\n    messages = response.get('Messages', [])\n    if not messages:\n        break\n\n    for msg in messages:\n        # Reprocess the failed event\n        body = json.loads(msg['Body'])\n\n        # Invoke Lambda directly with the failed records\n        lambda_client.invoke(\n            FunctionName='ZAEL-&lt;name&gt;-aggregator',\n            InvocationType='Event',\n            Payload=json.dumps(body),\n        )\n\n        # Delete from DLQ after successful reprocessing\n        sqs.delete_message(\n            QueueUrl=dlq_url,\n            ReceiptHandle=msg['ReceiptHandle'],\n        )\n</code></pre>"},{"location":"troubleshooting/#cold-start-issues","title":"Cold Start Issues","text":"<p>Diagnostic query:</p> <pre><code>fields @timestamp, @message, @duration\n| filter @type = \"REPORT\"\n| filter @message like /Init Duration/\n| parse @message /Init Duration: (?&lt;init_duration&gt;[\\d.]+) ms/\n| stats count() as cold_starts,\n        avg(init_duration) as avg_init_ms\n  by bin(1h)\n</code></pre> <p>Solutions: - Increase Lambda memory (faster initialization) - Enable provisioned concurrency for consistent latency</p>"},{"location":"troubleshooting/#4-version-compatibility-errors","title":"4. Version Compatibility Errors","text":""},{"location":"troubleshooting/#symptoms_3","title":"Symptoms","text":"<ul> <li><code>VersionMismatchError</code> exception raised</li> <li><code>IncompatibleSchemaError</code> exception raised</li> <li>CLI commands fail with version errors</li> <li>Rate limiter initialization fails</li> </ul>"},{"location":"troubleshooting/#diagnostic-steps_3","title":"Diagnostic Steps","text":"<p>Check compatibility with CLI:</p> <pre><code>zae-limiter check --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>View detailed version information:</p> <pre><code>zae-limiter version --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Query version record directly:</p> <pre><code>aws dynamodb get-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"SYSTEM#\"}, \"SK\": {\"S\": \"#VERSION\"}}'\n</code></pre>"},{"location":"troubleshooting/#versionmismatcherror","title":"VersionMismatchError","text":"<p>Cause: Client library version differs from deployed Lambda version.</p> <p>Example error: <pre><code>VersionMismatchError: Version mismatch: client=1.2.0, schema=1.0.0, lambda=1.0.0.\nLambda update available.\n</code></pre></p> <p>Solution: Upgrade Lambda to match client:</p> <pre><code>zae-limiter upgrade --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Or programmatically:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\n# Auto-update Lambda on initialization\nlimiter = RateLimiter(\n    name=\"&lt;name&gt;\",\n    region=\"&lt;region&gt;\",\n    stack_options=StackOptions(),  # Enables auto-update\n)\n</code></pre>"},{"location":"troubleshooting/#incompatibleschemaerror","title":"IncompatibleSchemaError","text":"<p>Cause: Major version difference requiring schema migration.</p> <p>Example error: <pre><code>IncompatibleSchemaError: Incompatible schema: client 2.0.0 is not compatible\nwith schema 1.0.0. Migration required.\n</code></pre></p> <p>Solution: Follow the Migration Guide to upgrade the schema:</p> <ol> <li>Create a backup</li> <li>Run migration</li> <li>Update client</li> </ol> <pre><code># Create backup before migration\naws dynamodb create-backup \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --backup-name \"pre-migration-$(date +%Y%m%d)\"\n</code></pre> <p>Then follow the migration procedures in the Migration Guide.</p>"},{"location":"troubleshooting/#minimum-client-version-error","title":"Minimum Client Version Error","text":"<p>Cause: Infrastructure requires a newer client version.</p> <p>Solution: Upgrade the client library:</p> <pre><code>pip install --upgrade zae-limiter\n</code></pre>"},{"location":"troubleshooting/#5-stream-processing-lag","title":"5. Stream Processing Lag","text":""},{"location":"troubleshooting/#symptoms_4","title":"Symptoms","text":"<ul> <li><code>IteratorAge</code> metric growing</li> <li>Usage snapshots delayed</li> <li>Stream iterator age alarm triggered</li> <li>Lambda throttling</li> </ul>"},{"location":"troubleshooting/#diagnostic-steps_4","title":"Diagnostic Steps","text":"<p>Check IteratorAge metric:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name IteratorAge \\\n  --dimensions Name=FunctionName,Value=ZAEL-&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum\n</code></pre> <p>Check stream status:</p> <pre><code>aws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n  --query 'Table.StreamSpecification'\n</code></pre> <p>Check Lambda event source mapping:</p> <pre><code>aws lambda list-event-source-mappings \\\n  --function-name ZAEL-&lt;name&gt;-aggregator\n</code></pre> <p>Check Lambda concurrent executions:</p> <pre><code>aws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name ConcurrentExecutions \\\n  --dimensions Name=FunctionName,Value=ZAEL-&lt;name&gt;-aggregator \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 60 \\\n  --statistics Maximum\n</code></pre>"},{"location":"troubleshooting/#common-causes-and-solutions_2","title":"Common Causes and Solutions","text":"Cause Solution Lambda errors Fix errors (check DLQ and logs) Lambda throttling Increase reserved concurrency Low Lambda concurrency Match concurrency to shard count DynamoDB throttling Increase table capacity Large batch sizes Reduce batch size in event source mapping"},{"location":"troubleshooting/#increase-lambda-concurrency","title":"Increase Lambda Concurrency","text":"<pre><code># Set reserved concurrency\naws lambda put-function-concurrency \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --reserved-concurrent-executions 10\n</code></pre>"},{"location":"troubleshooting/#adjust-event-source-mapping","title":"Adjust Event Source Mapping","text":"<pre><code># Get current mapping UUID\nMAPPING_UUID=$(aws lambda list-event-source-mappings \\\n  --function-name ZAEL-&lt;name&gt;-aggregator \\\n  --query 'EventSourceMappings[0].UUID' \\\n  --output text)\n\n# Reduce batch size\naws lambda update-event-source-mapping \\\n  --uuid $MAPPING_UUID \\\n  --batch-size 50\n</code></pre>"},{"location":"troubleshooting/#stream-shard-scaling","title":"Stream Shard Scaling","text":"<p>DynamoDB Streams automatically scales shards based on table throughput. If you see many shards but low Lambda concurrency:</p> <pre><code># Check shard count\naws dynamodbstreams describe-stream \\\n  --stream-arn $(aws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n    --query 'Table.LatestStreamArn' --output text) \\\n  --query 'StreamDescription.Shards | length(@)'\n</code></pre> <p>Ensure Lambda concurrency &gt;= shard count for optimal processing.</p>"},{"location":"troubleshooting/#6-recovery-procedures","title":"6. Recovery Procedures","text":""},{"location":"troubleshooting/#dynamodb-backup-and-restore","title":"DynamoDB Backup and Restore","text":"<p>Create on-demand backup:</p> <pre><code>aws dynamodb create-backup \\\n  --table-name ZAEL-&lt;name&gt; \\\n  --backup-name \"manual-backup-$(date +%Y%m%d-%H%M%S)\"\n</code></pre> <p>List available backups:</p> <pre><code>aws dynamodb list-backups \\\n  --table-name ZAEL-&lt;name&gt;\n</code></pre> <p>Restore from backup:</p> <pre><code>aws dynamodb restore-table-from-backup \\\n  --target-table-name ZAEL-&lt;name&gt;-restored \\\n  --backup-arn &lt;backup-arn&gt;\n</code></pre> <p>Restore using Point-in-Time Recovery (PITR):</p> <pre><code># Check if PITR is enabled\naws dynamodb describe-continuous-backups \\\n  --table-name ZAEL-&lt;name&gt;\n\n# Restore to specific point in time\naws dynamodb restore-table-to-point-in-time \\\n  --source-table-name ZAEL-&lt;name&gt; \\\n  --target-table-name ZAEL-&lt;name&gt;-restored \\\n  --restore-date-time \"2024-01-15T10:00:00Z\"\n</code></pre>"},{"location":"troubleshooting/#migration-rollback","title":"Migration Rollback","text":"<p>For reversible migrations, use the rollback function:</p> <pre><code>from zae_limiter.migrations import get_migrations\nfrom zae_limiter.repository import Repository\n\nasync def rollback_migration(target_version: str):\n    repo = Repository(\"ZAEL-&lt;name&gt;\", \"&lt;region&gt;\", None)\n\n    migrations = get_migrations()\n    target = next((m for m in migrations if m.version == target_version), None)\n\n    if target and target.reversible and target.rollback:\n        await target.rollback(repo)\n        print(f\"Rolled back migration {target_version}\")\n\n        # Update version record\n        await repo.set_version_record(\n            schema_version=\"&lt;previous_version&gt;\",\n            updated_by=\"manual_rollback\",\n        )\n    else:\n        print(\"Migration is not reversible - restore from backup\")\n\n    await repo.close()\n</code></pre> <p>For non-reversible migrations, restore from backup taken before migration.</p>"},{"location":"troubleshooting/#stack-redeployment","title":"Stack Redeployment","text":"<p>Delete and recreate stack (preserves DynamoDB data with deletion protection):</p> <pre><code># First, check deletion protection\naws dynamodb describe-table --table-name ZAEL-&lt;name&gt; \\\n  --query 'Table.DeletionProtectionEnabled'\n\n# Delete stack (table retained if deletion protection enabled)\nzae-limiter delete --name &lt;name&gt; --region &lt;region&gt; --yes\n\n# Redeploy\nzae-limiter deploy --name &lt;name&gt; --region &lt;region&gt;\n</code></pre> <p>Update existing stack:</p> <pre><code># Export template\nzae-limiter cfn-template &gt; updated-template.yaml\n\n# Update via CloudFormation\naws cloudformation update-stack \\\n  --stack-name ZAEL-&lt;name&gt; \\\n  --template-body file://updated-template.yaml \\\n  --capabilities CAPABILITY_NAMED_IAM\n</code></pre>"},{"location":"troubleshooting/#data-reconciliation","title":"Data Reconciliation","text":"<p>Reset a corrupted bucket:</p> <pre><code># Delete the bucket record (will be recreated on next acquire)\naws dynamodb delete-item --table-name ZAEL-&lt;name&gt; \\\n  --key '{\"PK\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \"SK\": {\"S\": \"#BUCKET#&lt;resource&gt;#&lt;limit_name&gt;\"}}'\n</code></pre> <p>Reset all buckets for an entity:</p> <pre><code># Query all buckets\naws dynamodb query --table-name ZAEL-&lt;name&gt; \\\n  --key-condition-expression \"PK = :pk AND begins_with(SK, :sk)\" \\\n  --expression-attribute-values '{\":pk\": {\"S\": \"ENTITY#&lt;entity_id&gt;\"}, \":sk\": {\"S\": \"#BUCKET#\"}}' \\\n  --projection-expression \"PK, SK\"\n\n# Delete each bucket (use batch-write-item for efficiency)\n</code></pre> <p>Verify entity integrity:</p> <pre><code>async def verify_entity(limiter, entity_id: str):\n    \"\"\"Verify entity can perform rate limiting operations.\"\"\"\n    from zae_limiter import Limit\n\n    try:\n        # Check entity exists\n        entity = await limiter.get_entity(entity_id)\n        print(f\"Entity: {entity.entity_id}, parent: {entity.parent_id}\")\n\n        # Check rate limiting works\n        available = await limiter.available(\n            entity_id=entity_id,\n            resource=\"health-check\",\n            limits=[Limit.per_minute(\"test\", 1000)],\n        )\n        print(f\"Available capacity: {available}\")\n\n        return True\n    except Exception as e:\n        print(f\"Entity verification failed: {e}\")\n        return False\n</code></pre>"},{"location":"troubleshooting/#quick-reference","title":"Quick Reference","text":""},{"location":"troubleshooting/#cli-diagnostic-commands","title":"CLI Diagnostic Commands","text":"Command Description <code>zae-limiter status --name &lt;name&gt;</code> Check stack status and resources <code>zae-limiter version --name &lt;name&gt;</code> Show version information <code>zae-limiter check --name &lt;name&gt;</code> Check client/infrastructure compatibility"},{"location":"troubleshooting/#cloudwatch-metrics","title":"CloudWatch Metrics","text":"Metric Namespace Threshold Description <code>Errors</code> AWS/Lambda &gt; 1/5min Lambda execution failures <code>Duration</code> AWS/Lambda &gt; 80% timeout Processing time <code>IteratorAge</code> AWS/Lambda &gt; 30,000ms Stream processing lag <code>ReadThrottleEvents</code> AWS/DynamoDB &gt; 0 Read throttling <code>WriteThrottleEvents</code> AWS/DynamoDB &gt; 0 Write throttling <code>ApproximateNumberOfMessagesVisible</code> AWS/SQS &gt; 0 DLQ messages"},{"location":"troubleshooting/#exception-reference","title":"Exception Reference","text":"Exception Cause Resolution <code>RateLimitExceeded</code> Rate limit violated Wait <code>retry_after_seconds</code> or increase limit <code>RateLimiterUnavailable</code> DynamoDB unavailable Check DynamoDB health, consider <code>FAIL_OPEN</code> <code>EntityNotFoundError</code> Entity doesn't exist Create entity with <code>create_entity()</code> <code>VersionMismatchError</code> Client/Lambda version mismatch Run <code>zae-limiter upgrade</code> <code>IncompatibleSchemaError</code> Major version difference Follow migration guide <code>StackCreationError</code> CloudFormation failed Check stack events for details <code>ValidationError</code> Invalid input Check entity_id, resource, limit_name format"},{"location":"troubleshooting/#dynamodb-key-patterns","title":"DynamoDB Key Patterns","text":"Pattern Key Description Entity metadata <code>PK=ENTITY#&lt;id&gt;, SK=#META</code> Entity configuration Bucket state <code>PK=ENTITY#&lt;id&gt;, SK=#BUCKET#&lt;resource&gt;#&lt;limit&gt;</code> Token bucket Stored limit <code>PK=ENTITY#&lt;id&gt;, SK=#LIMIT#&lt;resource&gt;#&lt;limit&gt;</code> Limit config Usage snapshot <code>PK=ENTITY#&lt;id&gt;, SK=#USAGE#&lt;resource&gt;#&lt;date&gt;</code> Aggregated usage Version <code>PK=SYSTEM#, SK=#VERSION</code> Infrastructure version"},{"location":"troubleshooting/#next-steps","title":"Next Steps","text":"<ul> <li>Monitoring Guide - CloudWatch metrics, dashboards, and alerts</li> <li>Performance Tuning - Capacity planning and optimization</li> <li>Migration Guide - Schema versioning and upgrades</li> <li>Failure Modes - Configure behavior when DynamoDB is unavailable</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section contains the complete API documentation for zae-limiter, auto-generated from source code docstrings.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>The main components of the API are:</p> Component Description <code>RateLimiter</code> Async rate limiter client <code>SyncRateLimiter</code> Synchronous rate limiter client <code>Limit</code> Rate limit configuration <code>RateLimitExceeded</code> Exception when limit is exceeded"},{"location":"api/#quick-reference","title":"Quick Reference","text":""},{"location":"api/#creating-a-limiter","title":"Creating a Limiter","text":"<pre><code>from zae_limiter import RateLimiter, SyncRateLimiter\n\n# Async\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n)\n\n# Sync\nlimiter = SyncRateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n)\n</code></pre>"},{"location":"api/#defining-limits","title":"Defining Limits","text":"<pre><code>from zae_limiter import Limit\n\n# Factory methods\nLimit.per_second(\"rps\", 10)\nLimit.per_minute(\"rpm\", 100)\nLimit.per_hour(\"rph\", 1000)\nLimit.per_day(\"rpd\", 10000)\n\n# With burst capacity\nLimit.per_minute(\"tpm\", 10_000, burst=15_000)\n\n# Custom period\nLimit.custom(\"requests\", capacity=50, refill_period_seconds=30)\n</code></pre>"},{"location":"api/#acquiring-limits","title":"Acquiring Limits","text":"<pre><code>from zae_limiter import RateLimiter, Limit, RateLimitExceeded\n\nlimiter = RateLimiter(name=\"limiter\")\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ) as lease:\n        # Do work\n        await lease.adjust(rpm=5)  # Adjust if needed\nexcept RateLimitExceeded as e:\n    print(f\"Retry after: {e.retry_after_seconds}s\")\n</code></pre>"},{"location":"api/#handling-exceptions","title":"Handling Exceptions","text":"<pre><code>from zae_limiter import RateLimitExceeded, RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(...):\n        pass\nexcept RateLimitExceeded as e:\n    # Rate limit exceeded\n    print(e.retry_after_seconds)\n    print(e.violations)\n    print(e.as_dict())\nexcept RateLimiterUnavailable as e:\n    # DynamoDB unavailable\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"api/#module-structure","title":"Module Structure","text":"<pre><code>zae_limiter/\n\u251c\u2500\u2500 __init__.py        # Public API exports\n\u251c\u2500\u2500 limiter.py         # RateLimiter, SyncRateLimiter\n\u251c\u2500\u2500 models.py          # Limit, Entity, LimitStatus, BucketState\n\u251c\u2500\u2500 exceptions.py      # RateLimitExceeded, RateLimiterUnavailable\n\u251c\u2500\u2500 lease.py           # Lease context manager\n\u251c\u2500\u2500 bucket.py          # Token bucket algorithm\n\u251c\u2500\u2500 schema.py          # DynamoDB key builders\n\u251c\u2500\u2500 repository.py      # DynamoDB operations\n\u2514\u2500\u2500 cli.py             # CLI commands\n</code></pre>"},{"location":"api/#public-exports","title":"Public Exports","text":"<p>The following are exported from <code>zae_limiter</code>:</p> <pre><code>from zae_limiter import (\n    # Main classes\n    RateLimiter,\n    SyncRateLimiter,\n    Lease,\n    SyncLease,\n\n    # Models\n    Limit,\n    Entity,\n    LimitStatus,\n    BucketState,\n\n    # Enums\n    FailureMode,\n\n    # Exceptions - Base\n    ZAELimiterError,\n\n    # Exceptions - Rate Limit\n    RateLimitExceeded,\n    RateLimiterUnavailable,\n\n    # Exceptions - Entity\n    EntityNotFoundError,\n    EntityExistsError,\n\n    # Exceptions - Infrastructure\n    StackCreationError,\n    StackAlreadyExistsError,\n    InfrastructureNotFoundError,\n\n    # Exceptions - Version\n    VersionMismatchError,\n    IncompatibleSchemaError,\n)\n</code></pre>"},{"location":"api/#detailed-documentation","title":"Detailed Documentation","text":"<ul> <li>RateLimiter - Main rate limiter classes</li> <li>Models - Data models and configuration</li> <li>Exceptions - Exception types and handling</li> </ul>"},{"location":"api/exceptions/","title":"Exceptions","text":"<p>Exception types raised by zae-limiter.</p>"},{"location":"api/exceptions/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>ZAELimiterError (base)\n\u251c\u2500\u2500 RateLimitError\n\u2502   \u251c\u2500\u2500 RateLimitExceeded\n\u2502   \u2514\u2500\u2500 RateLimiterUnavailable\n\u251c\u2500\u2500 EntityError\n\u2502   \u251c\u2500\u2500 EntityNotFoundError\n\u2502   \u2514\u2500\u2500 EntityExistsError\n\u251c\u2500\u2500 InfrastructureError\n\u2502   \u251c\u2500\u2500 StackCreationError\n\u2502   \u251c\u2500\u2500 StackAlreadyExistsError\n\u2502   \u2514\u2500\u2500 InfrastructureNotFoundError\n\u2514\u2500\u2500 VersionError\n    \u251c\u2500\u2500 VersionMismatchError\n    \u2514\u2500\u2500 IncompatibleSchemaError\n</code></pre>"},{"location":"api/exceptions/#base-exception","title":"Base Exception","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.ZAELimiterError","title":"ZAELimiterError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all zae-limiter errors.</p> <p>All exceptions raised by this library inherit from this class, allowing callers to catch all library-specific errors with a single except clause.</p>"},{"location":"api/exceptions/#rate-limit-exceptions","title":"Rate Limit Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded","title":"RateLimitExceeded","text":"<pre><code>RateLimitExceeded(statuses)\n</code></pre> <p>               Bases: <code>RateLimitError</code></p> <p>Raised when one or more rate limits would be exceeded.</p> <p>Provides full visibility into ALL limits that were checked, both passed and failed, to help callers understand the full picture.</p> <p>Attributes:</p> Name Type Description <code>statuses</code> <p>Status of ALL limits checked (both passed and failed)</p> <code>violations</code> <p>Only the limits that were exceeded</p> <code>passed</code> <p>Only the limits that passed</p> <code>retry_after_seconds</code> <p>Time until ALL requested capacity is available</p> <code>primary_violation</code> <p>The violation with longest retry time (bottleneck)</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded.retry_after_header","title":"retry_after_header  <code>property</code>","text":"<pre><code>retry_after_header\n</code></pre> <p>Value for HTTP Retry-After header (integer seconds).</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimitExceeded.as_dict","title":"as_dict","text":"<pre><code>as_dict()\n</code></pre> <p>Serialize for JSON API responses.</p> <p>Returns a dictionary suitable for returning in a 429 response body.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.RateLimiterUnavailable","title":"RateLimiterUnavailable","text":"<pre><code>RateLimiterUnavailable(message, cause=None, *, stack_name=None, entity_id=None, resource=None)\n</code></pre> <p>               Bases: <code>RateLimitError</code></p> <p>Raised when DynamoDB is unavailable and failure_mode=FAIL_CLOSED.</p> <p>This indicates a transient infrastructure issue, not a rate limit.</p> <p>Attributes:</p> Name Type Description <code>cause</code> <p>The underlying exception that caused the unavailability</p> <code>stack_name</code> <p>The stack/table that was being accessed</p> <code>entity_id</code> <p>The entity being rate limited (if applicable)</p> <code>resource</code> <p>The resource being rate limited (if applicable)</p>"},{"location":"api/exceptions/#entity-exceptions","title":"Entity Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.EntityNotFoundError","title":"EntityNotFoundError","text":"<pre><code>EntityNotFoundError(entity_id)\n</code></pre> <p>               Bases: <code>EntityError</code></p> <p>Raised when an entity is not found.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.EntityExistsError","title":"EntityExistsError","text":"<pre><code>EntityExistsError(entity_id)\n</code></pre> <p>               Bases: <code>EntityError</code></p> <p>Raised when trying to create an entity that already exists.</p>"},{"location":"api/exceptions/#infrastructure-exceptions","title":"Infrastructure Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.StackCreationError","title":"StackCreationError","text":"<pre><code>StackCreationError(stack_name, reason, events=None)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when CloudFormation stack creation fails.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.StackAlreadyExistsError","title":"StackAlreadyExistsError","text":"<pre><code>StackAlreadyExistsError(stack_name, reason, events=None)\n</code></pre> <p>               Bases: <code>StackCreationError</code></p> <p>Raised when stack already exists (informational).</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.InfrastructureNotFoundError","title":"InfrastructureNotFoundError","text":"<pre><code>InfrastructureNotFoundError(stack_name)\n</code></pre> <p>               Bases: <code>InfrastructureError</code></p> <p>Raised when expected infrastructure doesn't exist.</p> <p>This typically means the CloudFormation stack or DynamoDB table hasn't been deployed yet.</p>"},{"location":"api/exceptions/#version-exceptions","title":"Version Exceptions","text":""},{"location":"api/exceptions/#zae_limiter.exceptions.VersionMismatchError","title":"VersionMismatchError","text":"<pre><code>VersionMismatchError(client_version, schema_version, lambda_version, message, can_auto_update=False)\n</code></pre> <p>               Bases: <code>VersionError</code></p> <p>Raised when client and infrastructure versions are incompatible.</p> <p>This error indicates that the client library version doesn't match the deployed infrastructure and auto-update is disabled or failed.</p>"},{"location":"api/exceptions/#zae_limiter.exceptions.IncompatibleSchemaError","title":"IncompatibleSchemaError","text":"<pre><code>IncompatibleSchemaError(client_version, schema_version, message, migration_guide_url=None)\n</code></pre> <p>               Bases: <code>VersionError</code></p> <p>Raised when schema version requires manual migration.</p> <p>This indicates a major version difference that cannot be automatically reconciled.</p>"},{"location":"api/exceptions/#exception-handling-examples","title":"Exception Handling Examples","text":""},{"location":"api/exceptions/#basic-handling","title":"Basic Handling","text":"<pre><code>from zae_limiter import RateLimitExceeded, RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(\n        entity_id=\"user-123\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        await do_work()\nexcept RateLimitExceeded as e:\n    # Handle rate limit exceeded\n    print(f\"Rate limited. Retry after {e.retry_after_seconds}s\")\nexcept RateLimiterUnavailable as e:\n    # Handle service unavailable\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"api/exceptions/#http-api-response","title":"HTTP API Response","text":"<pre><code>from fastapi import HTTPException\nfrom fastapi.responses import JSONResponse\n\n@app.post(\"/api/endpoint\")\nasync def endpoint():\n    try:\n        async with limiter.acquire(...):\n            return await process_request()\n    except RateLimitExceeded as e:\n        return JSONResponse(\n            status_code=429,\n            content=e.as_dict(),\n            headers={\"Retry-After\": e.retry_after_header},\n        )\n    except RateLimiterUnavailable:\n        raise HTTPException(status_code=503, detail=\"Service temporarily unavailable\")\n</code></pre>"},{"location":"api/exceptions/#detailed-error-information","title":"Detailed Error Information","text":"<pre><code>try:\n    async with limiter.acquire(...):\n        pass\nexcept RateLimitExceeded as e:\n    # All limit statuses (both passed and failed)\n    for status in e.statuses:\n        print(f\"Limit: {status.limit_name}\")\n        print(f\"  Entity: {status.entity_id}\")\n        print(f\"  Available: {status.available}\")\n        print(f\"  Requested: {status.requested}\")\n        print(f\"  Exceeded: {status.exceeded}\")\n        print(f\"  Retry after: {status.retry_after_seconds}s\")\n\n    # Only the violations\n    print(f\"Violations: {len(e.violations)}\")\n    for v in e.violations:\n        print(f\"  - {v.limit_name}: {v.available} available\")\n\n    # Only the passed limits\n    print(f\"Passed: {len(e.passed)}\")\n\n    # Primary bottleneck (longest wait time)\n    print(f\"Bottleneck: {e.primary_violation.limit_name}\")\n    print(f\"Total retry after: {e.retry_after_seconds}s\")\n</code></pre>"},{"location":"api/exceptions/#as_dict-output","title":"as_dict() Output","text":"<p>The <code>as_dict()</code> method returns a dictionary suitable for API responses:</p> <pre><code>{\n    \"error\": \"rate_limit_exceeded\",\n    \"message\": \"Rate limit exceeded for user-123/api: [rpm]. Retry after 45.2s\",\n    \"retry_after_seconds\": 45.2,\n    \"retry_after_ms\": 45200,\n    \"limits\": [\n        {\n            \"entity_id\": \"user-123\",\n            \"resource\": \"api\",\n            \"limit_name\": \"rpm\",\n            \"capacity\": 100,\n            \"burst\": 100,\n            \"available\": -5,\n            \"requested\": 10,\n            \"exceeded\": True,\n            \"retry_after_seconds\": 45.2,\n        },\n        {\n            \"entity_id\": \"user-123\",\n            \"resource\": \"api\",\n            \"limit_name\": \"tpm\",\n            \"capacity\": 10000,\n            \"burst\": 10000,\n            \"available\": 8500,\n            \"requested\": 500,\n            \"exceeded\": False,\n            \"retry_after_seconds\": 0.0,\n        },\n    ],\n}\n</code></pre> <p>Single <code>limits</code> array</p> <p>All limits (both exceeded and passed) are returned in a single <code>limits</code> array. Use the <code>exceeded</code> field to distinguish between violations and passed limits.</p>"},{"location":"api/limiter/","title":"RateLimiter","text":"<p>The main rate limiter classes for async and sync usage.</p>"},{"location":"api/limiter/#ratelimiter-async","title":"RateLimiter (Async)","text":""},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter","title":"RateLimiter","text":"<pre><code>RateLimiter(name='limiter', region=None, endpoint_url=None, stack_options=None, failure_mode=FAIL_CLOSED, auto_update=True, strict_version=True, skip_version_check=False)\n</code></pre> <p>Async rate limiter backed by DynamoDB.</p> <p>Implements token bucket algorithm with support for: - Multiple limits per entity/resource - Two-level hierarchy (parent/child entities) - Cascade mode (consume from entity + parent) - Stored limit configs - Usage analytics</p> Example <p>limiter = RateLimiter(     name=\"my-app\",  # Creates ZAEL-my-app resources     region=\"us-east-1\",     stack_options=StackOptions(), )</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Resource identifier (e.g., 'my-app'). Will be prefixed with 'ZAEL-' automatically. Default: 'limiter' (creates 'ZAEL-limiter' resources)</p> <code>'limiter'</code> <code>region</code> <code>str | None</code> <p>AWS region</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>DynamoDB endpoint URL (for local development)</p> <code>None</code> <code>stack_options</code> <code>StackOptions | None</code> <p>Stack configuration for auto-creation (None = don't create)</p> <code>None</code> <code>failure_mode</code> <code>FailureMode</code> <p>Behavior when DynamoDB is unavailable</p> <code>FAIL_CLOSED</code> <code>auto_update</code> <code>bool</code> <p>Auto-update Lambda when version mismatch detected</p> <code>True</code> <code>strict_version</code> <code>bool</code> <p>Fail if version mismatch (when auto_update is False)</p> <code>True</code> <code>skip_version_check</code> <code>bool</code> <p>Skip all version checks (dangerous)</p> <code>False</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.name","title":"name  <code>property</code>","text":"<pre><code>name\n</code></pre> <p>The resource identifier (with ZAEL- prefix).</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.close","title":"close  <code>async</code>","text":"<pre><code>close()\n</code></pre> <p>Close the underlying connections.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.create_entity","title":"create_entity  <code>async</code>","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, metadata=None)\n</code></pre> <p>Create a new entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Unique identifier for the entity</p> required <code>name</code> <code>str | None</code> <p>Human-readable name (defaults to entity_id)</p> <code>None</code> <code>parent_id</code> <code>str | None</code> <p>Parent entity ID (None for root/project entities)</p> <code>None</code> <code>metadata</code> <code>dict[str, str] | None</code> <p>Additional metadata to store</p> <code>None</code> <p>Returns:</p> Type Description <code>Entity</code> <p>The created Entity</p> <p>Raises:</p> Type Description <code>EntityExistsError</code> <p>If entity already exists</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_entity","title":"get_entity  <code>async</code>","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_entity","title":"delete_entity  <code>async</code>","text":"<pre><code>delete_entity(entity_id)\n</code></pre> <p>Delete an entity and all its related data.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_children","title":"get_children  <code>async</code>","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all children of a parent entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.acquire","title":"acquire  <code>async</code>","text":"<pre><code>acquire(entity_id, resource, limits, consume, cascade=False, use_stored_limits=False, failure_mode=None)\n</code></pre> <p>Acquire rate limit capacity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to acquire capacity for</p> required <code>resource</code> <code>str</code> <p>Resource being accessed (e.g., \"gpt-4\")</p> required <code>limits</code> <code>list[Limit]</code> <p>Default limits to apply</p> required <code>consume</code> <code>dict[str, int]</code> <p>Amounts to consume by limit name</p> required <code>cascade</code> <code>bool</code> <p>If True, also consume from parent entity</p> <code>False</code> <code>use_stored_limits</code> <code>bool</code> <p>If True, use stored limits if available</p> <code>False</code> <code>failure_mode</code> <code>FailureMode | None</code> <p>Override default failure mode</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncIterator[Lease]</code> <p>Lease for managing additional consumption</p> <p>Raises:</p> Type Description <code>RateLimitExceeded</code> <p>If any limit would be exceeded</p> <code>RateLimiterUnavailable</code> <p>If DynamoDB unavailable and FAIL_CLOSED</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.available","title":"available  <code>async</code>","text":"<pre><code>available(entity_id, resource, limits, use_stored_limits=False)\n</code></pre> <p>Check available capacity without consuming.</p> <p>Returns minimum available across entity (and parent if cascade). Can return negative values if bucket is in debt.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>limits</code> <code>list[Limit]</code> <p>Default limits</p> required <code>use_stored_limits</code> <code>bool</code> <p>Use stored limits if available</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping limit_name -&gt; available tokens</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.time_until_available","title":"time_until_available  <code>async</code>","text":"<pre><code>time_until_available(entity_id, resource, limits, needed, use_stored_limits=False)\n</code></pre> <p>Calculate seconds until requested capacity is available.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to check</p> required <code>resource</code> <code>str</code> <p>Resource to check</p> required <code>limits</code> <code>list[Limit]</code> <p>Default limits</p> required <code>needed</code> <code>dict[str, int]</code> <p>Required amounts by limit name</p> required <code>use_stored_limits</code> <code>bool</code> <p>Use stored limits if available</p> <code>False</code> <p>Returns:</p> Type Description <code>float</code> <p>Seconds until available (0.0 if already available)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.set_limits","title":"set_limits  <code>async</code>","text":"<pre><code>set_limits(entity_id, limits, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Store limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to set limits for</p> required <code>limits</code> <code>list[Limit]</code> <p>Limits to store</p> required <code>resource</code> <code>str</code> <p>Resource these limits apply to (or default)</p> <code>DEFAULT_RESOURCE</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_limits","title":"get_limits  <code>async</code>","text":"<pre><code>get_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Get stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to get limits for</p> required <code>resource</code> <code>str</code> <p>Resource to get limits for</p> <code>DEFAULT_RESOURCE</code> <p>Returns:</p> Type Description <code>list[Limit]</code> <p>List of stored limits (empty if none)</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_limits","title":"delete_limits  <code>async</code>","text":"<pre><code>delete_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Delete stored limit configs for an entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity to delete limits for</p> required <code>resource</code> <code>str</code> <p>Resource to delete limits for</p> <code>DEFAULT_RESOURCE</code>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.get_resource_capacity","title":"get_resource_capacity  <code>async</code>","text":"<pre><code>get_resource_capacity(resource, limit_name, parents_only=False)\n</code></pre> <p>Get aggregated capacity for a resource across all entities.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>str</code> <p>Resource to query</p> required <code>limit_name</code> <code>str</code> <p>Limit name to query</p> required <code>parents_only</code> <code>bool</code> <p>If True, only include parent entities</p> <code>False</code> <p>Returns:</p> Type Description <code>ResourceCapacity</code> <p>ResourceCapacity with aggregated data</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.create_stack","title":"create_stack  <code>async</code>","text":"<pre><code>create_stack(stack_options=None)\n</code></pre> <p>Create CloudFormation stack for infrastructure.</p> <p>Parameters:</p> Name Type Description Default <code>stack_options</code> <code>StackOptions | None</code> <p>Stack configuration</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with stack_id, stack_name, and status</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If stack creation fails</p>"},{"location":"api/limiter/#zae_limiter.limiter.RateLimiter.delete_stack","title":"delete_stack  <code>async</code>","text":"<pre><code>delete_stack()\n</code></pre> <p>Delete the CloudFormation stack and all associated resources.</p> <p>This method permanently removes the CloudFormation stack, including:</p> <ul> <li>DynamoDB table and all stored data</li> <li>Lambda aggregator function (if deployed)</li> <li>IAM roles and CloudWatch log groups</li> <li>All other stack resources</li> </ul> <p>The method waits for deletion to complete before returning. If the stack doesn't exist, no error is raised.</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If deletion fails (e.g., permission denied, resources in use, or CloudFormation service error)</p> Example <p>Cleanup after integration testing::</p> <pre><code>limiter = RateLimiter(\n    name=\"test-limits\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\nasync with limiter:\n    # Run tests...\n    pass\n\n# Clean up infrastructure\nawait limiter.delete_stack()\n</code></pre> Warning <p>This operation is irreversible. All rate limit state, entity data, and usage history will be permanently deleted.</p>"},{"location":"api/limiter/#syncratelimiter","title":"SyncRateLimiter","text":""},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter","title":"SyncRateLimiter","text":"<pre><code>SyncRateLimiter(name='limiter', region=None, endpoint_url=None, stack_options=None, failure_mode=FAIL_CLOSED, auto_update=True, strict_version=True, skip_version_check=False)\n</code></pre> <p>Synchronous rate limiter backed by DynamoDB.</p> <p>Wraps RateLimiter, running async operations in an event loop.</p> Example <p>limiter = SyncRateLimiter(     name=\"my-app\",  # Creates ZAEL-my-app resources     region=\"us-east-1\",     stack_options=StackOptions(), )</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Close the underlying connections.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.create_entity","title":"create_entity","text":"<pre><code>create_entity(entity_id, name=None, parent_id=None, metadata=None)\n</code></pre> <p>Create a new entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_entity","title":"get_entity","text":"<pre><code>get_entity(entity_id)\n</code></pre> <p>Get an entity by ID.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.delete_entity","title":"delete_entity","text":"<pre><code>delete_entity(entity_id)\n</code></pre> <p>Delete an entity and all its related data.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_children","title":"get_children","text":"<pre><code>get_children(parent_id)\n</code></pre> <p>Get all children of a parent entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.acquire","title":"acquire","text":"<pre><code>acquire(entity_id, resource, limits, consume, cascade=False, use_stored_limits=False, failure_mode=None)\n</code></pre> <p>Acquire rate limit capacity (synchronous).</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.available","title":"available","text":"<pre><code>available(entity_id, resource, limits, use_stored_limits=False)\n</code></pre> <p>Check available capacity without consuming.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.time_until_available","title":"time_until_available","text":"<pre><code>time_until_available(entity_id, resource, limits, needed, use_stored_limits=False)\n</code></pre> <p>Calculate seconds until requested capacity is available.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.set_limits","title":"set_limits","text":"<pre><code>set_limits(entity_id, limits, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Store limit configs for an entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_limits","title":"get_limits","text":"<pre><code>get_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Get stored limit configs for an entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.delete_limits","title":"delete_limits","text":"<pre><code>delete_limits(entity_id, resource=DEFAULT_RESOURCE)\n</code></pre> <p>Delete stored limit configs for an entity.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.get_resource_capacity","title":"get_resource_capacity","text":"<pre><code>get_resource_capacity(resource, limit_name, parents_only=False)\n</code></pre> <p>Get aggregated capacity for a resource across all entities.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.create_stack","title":"create_stack","text":"<pre><code>create_stack(stack_options=None)\n</code></pre> <p>Create CloudFormation stack for infrastructure.</p>"},{"location":"api/limiter/#zae_limiter.limiter.SyncRateLimiter.delete_stack","title":"delete_stack","text":"<pre><code>delete_stack()\n</code></pre> <p>Delete the CloudFormation stack and all associated resources.</p> <p>Synchronous wrapper for :meth:<code>RateLimiter.delete_stack</code>. See the async version for full documentation.</p> <p>Raises:</p> Type Description <code>StackCreationError</code> <p>If deletion fails</p> Example <p>Cleanup after testing::</p> <pre><code>limiter = SyncRateLimiter(\n    name=\"test-limits\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\nwith limiter:\n    # Run tests...\n    pass\n\n# Clean up infrastructure\nlimiter.delete_stack()\n</code></pre> Warning <p>This operation is irreversible. All data will be permanently deleted.</p>"},{"location":"api/limiter/#failuremode","title":"FailureMode","text":""},{"location":"api/limiter/#zae_limiter.limiter.FailureMode","title":"FailureMode","text":"<p>               Bases: <code>Enum</code></p> <p>Behavior when DynamoDB is unavailable.</p>"},{"location":"api/models/","title":"Models","text":"<p>Data models for rate limit configuration and status.</p>"},{"location":"api/models/#limit","title":"Limit","text":""},{"location":"api/models/#zae_limiter.models.Limit","title":"Limit  <code>dataclass</code>","text":"<pre><code>Limit(name, capacity, burst, refill_amount, refill_period_seconds)\n</code></pre> <p>Token bucket rate limit configuration.</p> <p>Refill rate is stored as a fraction (refill_amount / refill_period_seconds) to avoid floating point precision issues.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier for this limit type (e.g., \"rpm\", \"tpm\")</p> <code>capacity</code> <code>int</code> <p>Max tokens that refill over the period (sustained rate)</p> <code>burst</code> <code>int</code> <p>Max tokens in bucket (&gt;= capacity, allows bursting)</p> <code>refill_amount</code> <code>int</code> <p>Numerator of refill rate</p> <code>refill_period_seconds</code> <code>int</code> <p>Denominator of refill rate</p>"},{"location":"api/models/#zae_limiter.models.Limit.refill_rate","title":"refill_rate  <code>property</code>","text":"<pre><code>refill_rate\n</code></pre> <p>Tokens per second (for display/debugging).</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_second","title":"per_second  <code>classmethod</code>","text":"<pre><code>per_second(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per second.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_minute","title":"per_minute  <code>classmethod</code>","text":"<pre><code>per_minute(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per minute.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_hour","title":"per_hour  <code>classmethod</code>","text":"<pre><code>per_hour(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per hour.</p>"},{"location":"api/models/#zae_limiter.models.Limit.per_day","title":"per_day  <code>classmethod</code>","text":"<pre><code>per_day(name, capacity, burst=None)\n</code></pre> <p>Create a limit that refills <code>capacity</code> tokens per day.</p>"},{"location":"api/models/#zae_limiter.models.Limit.custom","title":"custom  <code>classmethod</code>","text":"<pre><code>custom(name, capacity, refill_amount, refill_period_seconds, burst=None)\n</code></pre> <p>Create a custom limit with explicit refill rate.</p> Sustain 100/sec with burst of 1000 <p>Limit.custom(\"requests\", capacity=100, refill_amount=100,             refill_period_seconds=1, burst=1000)</p>"},{"location":"api/models/#zae_limiter.models.Limit.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Serialize to dictionary for storage.</p>"},{"location":"api/models/#zae_limiter.models.Limit.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> <p>Deserialize from dictionary.</p>"},{"location":"api/models/#entity","title":"Entity","text":""},{"location":"api/models/#zae_limiter.models.Entity","title":"Entity  <code>dataclass</code>","text":"<pre><code>Entity(id, name=None, parent_id=None, metadata=dict(), created_at=None)\n</code></pre> <p>An entity that can have rate limits applied.</p> <p>Entities can be parents (projects) or children (API keys). Children have a parent_id reference.</p> <p>Note: This model does not validate in post_init to support DynamoDB deserialization and avoid performance overhead. Validation is performed in Repository.create_entity() at the API boundary.</p>"},{"location":"api/models/#zae_limiter.models.Entity.is_parent","title":"is_parent  <code>property</code>","text":"<pre><code>is_parent\n</code></pre> <p>True if this entity has no parent (is a root/project).</p>"},{"location":"api/models/#zae_limiter.models.Entity.is_child","title":"is_child  <code>property</code>","text":"<pre><code>is_child\n</code></pre> <p>True if this entity has a parent.</p>"},{"location":"api/models/#limitstatus","title":"LimitStatus","text":""},{"location":"api/models/#zae_limiter.models.LimitStatus","title":"LimitStatus  <code>dataclass</code>","text":"<pre><code>LimitStatus(entity_id, resource, limit_name, limit, available, requested, exceeded, retry_after_seconds)\n</code></pre> <p>Status of a specific limit check.</p> <p>Returned in RateLimitExceeded to provide full visibility into all limits that were checked.</p> <p>Note: This is an internal model created by the limiter from validated inputs. No validation is performed here to avoid performance overhead.</p>"},{"location":"api/models/#zae_limiter.models.LimitStatus.deficit","title":"deficit  <code>property</code>","text":"<pre><code>deficit\n</code></pre> <p>How many tokens short we are (0 if not exceeded).</p>"},{"location":"api/models/#bucketstate","title":"BucketState","text":""},{"location":"api/models/#zae_limiter.models.BucketState","title":"BucketState  <code>dataclass</code>","text":"<pre><code>BucketState(entity_id, resource, limit_name, tokens_milli, last_refill_ms, capacity_milli, burst_milli, refill_amount_milli, refill_period_ms)\n</code></pre> <p>Internal state of a token bucket.</p> <p>All token values are stored in millitokens (x1000) for precision.</p> <p>Note: This is an internal model. Validation is performed in from_limit() for user-provided inputs, not in post_init to support DynamoDB deserialization and avoid performance overhead on frequent operations.</p>"},{"location":"api/models/#zae_limiter.models.BucketState.tokens","title":"tokens  <code>property</code>","text":"<pre><code>tokens\n</code></pre> <p>Current tokens (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.capacity","title":"capacity  <code>property</code>","text":"<pre><code>capacity\n</code></pre> <p>Capacity (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.burst","title":"burst  <code>property</code>","text":"<pre><code>burst\n</code></pre> <p>Burst (not millitokens).</p>"},{"location":"api/models/#zae_limiter.models.BucketState.from_limit","title":"from_limit  <code>classmethod</code>","text":"<pre><code>from_limit(entity_id, resource, limit, now_ms)\n</code></pre> <p>Create a new bucket at full capacity from a Limit.</p> <p>Note: This is an internal factory method. Validation of entity_id and resource is performed at the API boundary (RateLimiter public methods) before calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier (pre-validated by caller)</p> required <code>resource</code> <code>str</code> <p>Resource name (pre-validated by caller)</p> required <code>limit</code> <code>Limit</code> <p>Limit configuration (validated via post_init)</p> required <code>now_ms</code> <code>int</code> <p>Current time in milliseconds</p> required"},{"location":"guide/basic-usage/","title":"Basic Usage","text":"<p>This guide covers common rate limiting patterns with zae-limiter.</p>"},{"location":"guide/basic-usage/#the-acquire-context-manager","title":"The Acquire Context Manager","text":"<p>The <code>acquire()</code> method is the primary API for rate limiting:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"user-123\",      # Who is being rate limited\n    resource=\"gpt-4\",          # What resource they're accessing\n    limits=[...],              # Rate limit definitions\n    consume={\"rpm\": 1},        # How much to consume\n) as lease:\n    # Your code here\n    pass\n</code></pre> <p>Behavior:</p> <ul> <li>On entry: Checks limits and consumes tokens</li> <li>On success: Commits the consumption</li> <li>On exception: Rolls back the consumption</li> </ul>"},{"location":"guide/basic-usage/#multiple-limits","title":"Multiple Limits","text":"<p>Track multiple limits in a single call:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),       # 100 requests/minute\n        Limit.per_minute(\"tpm\", 10_000),    # 10,000 tokens/minute\n        Limit.per_hour(\"rph\", 1_000),       # 1,000 requests/hour\n    ],\n    consume={\"rpm\": 1, \"tpm\": 500, \"rph\": 1},\n) as lease:\n    response = await call_llm()\n</code></pre> <p>All limits are checked atomically. If any limit is exceeded, the request is rejected.</p> <p>Performance Tip</p> <p>Combining multiple limits into a single <code>acquire()</code> call is more efficient than separate calls. See Batch Operation Patterns for details.</p>"},{"location":"guide/basic-usage/#burst-capacity","title":"Burst Capacity","text":"<p>Allow temporary bursts above the sustained rate:</p> <pre><code># Sustain 10k tokens/minute, but allow bursts up to 15k\nlimits = [\n    Limit.per_minute(\"tpm\", 10_000, burst=15_000),\n]\n</code></pre> <p>The bucket starts full at <code>burst</code> capacity and refills at <code>capacity</code> tokens per period.</p>"},{"location":"guide/basic-usage/#adjusting-consumption","title":"Adjusting Consumption","text":"<p>Use <code>lease.adjust()</code> to modify consumption after the fact:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},  # Initial estimate\n) as lease:\n    response = await call_llm()\n\n    # Adjust based on actual usage\n    actual_tokens = response.usage.total_tokens\n    await lease.adjust(tpm=actual_tokens - 500)\n</code></pre> <p>Negative Adjustments</p> <p><code>adjust()</code> can go negative, allowing the bucket to go into debt. This is useful for post-hoc reconciliation when actual usage exceeds estimates.</p>"},{"location":"guide/basic-usage/#check-capacity-without-consuming","title":"Check Capacity Without Consuming","text":""},{"location":"guide/basic-usage/#check-available-tokens","title":"Check Available Tokens","text":"<pre><code>available = await limiter.available(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n)\nprint(f\"Available tokens: {available['tpm']}\")\n</code></pre>"},{"location":"guide/basic-usage/#check-time-until-available","title":"Check Time Until Available","text":"<pre><code>wait_seconds = await limiter.time_until_available(\n    entity_id=\"key-123\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    needed={\"tpm\": 5_000},\n)\n\nif wait_seconds &gt; 0:\n    print(f\"Need to wait {wait_seconds}s for capacity\")\n</code></pre>"},{"location":"guide/basic-usage/#stored-limits","title":"Stored Limits","text":"<p>Configure per-entity limits stored in DynamoDB:</p> <pre><code># Set custom limits for a premium user\nawait limiter.set_limits(\n    entity_id=\"user-premium\",\n    limits=[\n        Limit.per_minute(\"rpm\", 500),        # 5x normal\n        Limit.per_minute(\"tpm\", 50_000),     # 5x normal\n    ],\n)\n\n# Use stored limits (falls back to defaults if not found)\nasync with limiter.acquire(\n    entity_id=\"user-premium\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"rpm\", 100)],  # Default\n    consume={\"rpm\": 1},\n    use_stored_limits=True,  # Use stored if available\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/basic-usage/#entity-management","title":"Entity Management","text":""},{"location":"guide/basic-usage/#create-entities","title":"Create Entities","text":"<pre><code># Create a standalone entity\nawait limiter.create_entity(\n    entity_id=\"user-123\",\n    name=\"John Doe\",\n)\n\n# Create a child entity (API key under a project)\nawait limiter.create_entity(\n    entity_id=\"key-abc\",\n    parent_id=\"project-1\",\n    name=\"Production API Key\",\n)\n</code></pre>"},{"location":"guide/basic-usage/#get-entity-information","title":"Get Entity Information","text":"<pre><code>entity = await limiter.get_entity(\"user-123\")\nprint(f\"Name: {entity.name}\")\nprint(f\"Parent: {entity.parent_id}\")\n</code></pre>"},{"location":"guide/basic-usage/#error-handling","title":"Error Handling","text":""},{"location":"guide/basic-usage/#ratelimitexceeded-details","title":"RateLimitExceeded Details","text":"<pre><code>try:\n    async with limiter.acquire(...):\n        ...\nexcept RateLimitExceeded as e:\n    # All limit statuses\n    for status in e.statuses:\n        print(f\"{status.limit_name}: {status.available}/{status.limit.capacity}\")\n\n    # Only violations\n    for v in e.violations:\n        print(f\"Exceeded: {v.limit_name}\")\n\n    # Primary bottleneck\n    print(f\"Bottleneck: {e.primary_violation.limit_name}\")\n\n    # For API responses\n    return e.as_dict()\n</code></pre>"},{"location":"guide/basic-usage/#service-unavailable","title":"Service Unavailable","text":"<pre><code>from zae_limiter import RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(...):\n        ...\nexcept RateLimiterUnavailable as e:\n    # DynamoDB is unavailable\n    # Behavior depends on failure_mode setting\n    print(f\"Service unavailable: {e}\")\n</code></pre>"},{"location":"guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Hierarchical Limits - Parent/child rate limiting</li> <li>LLM Integration - Token estimation patterns</li> <li>Failure Modes - Handling service outages</li> </ul>"},{"location":"guide/failure-modes/","title":"Failure Modes","text":"<p>zae-limiter provides configurable behavior when DynamoDB is unavailable. This guide covers the failure modes and how to choose the right one for your application.</p>"},{"location":"guide/failure-modes/#available-failure-modes","title":"Available Failure Modes","text":"Mode Behavior Use Case <code>FAIL_CLOSED</code> Reject requests Security-critical, billing <code>FAIL_OPEN</code> Allow requests User experience priority"},{"location":"guide/failure-modes/#fail_closed-default","title":"FAIL_CLOSED (Default)","text":"<p>When DynamoDB is unavailable, reject all rate-limited requests:</p> <pre><code>from zae_limiter import RateLimiter, FailureMode, RateLimiterUnavailable\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    failure_mode=FailureMode.FAIL_CLOSED,  # Default\n)\n\ntry:\n    async with limiter.acquire(...):\n        await do_work()\nexcept RateLimiterUnavailable as e:\n    # DynamoDB is unavailable\n    return JSONResponse(\n        status_code=503,\n        content={\"error\": \"Service temporarily unavailable\"},\n    )\n</code></pre> <p>When to use:</p> <ul> <li>Billing/metering systems where accuracy is critical</li> <li>Security-sensitive operations</li> <li>When over-consumption has significant costs</li> <li>Compliance requirements</li> </ul>"},{"location":"guide/failure-modes/#fail_open","title":"FAIL_OPEN","text":"<p>When DynamoDB is unavailable, allow requests to proceed:</p> <pre><code>limiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    failure_mode=FailureMode.FAIL_OPEN,\n)\n\n# Requests proceed even if DynamoDB is down\nasync with limiter.acquire(...):\n    await do_work()  # Runs without rate limiting\n</code></pre> <p>When to use:</p> <ul> <li>User experience is the priority</li> <li>Brief outages are acceptable</li> <li>Rate limiting is a soft limit</li> <li>Development/staging environments</li> </ul>"},{"location":"guide/failure-modes/#per-request-override","title":"Per-Request Override","text":"<p>Override the default failure mode for specific requests:</p> <pre><code># Default to FAIL_CLOSED\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    failure_mode=FailureMode.FAIL_CLOSED,\n)\n\n# But allow this specific request to proceed\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    resource=\"api\",\n    limits=[...],\n    consume={\"requests\": 1},\n    failure_mode=FailureMode.FAIL_OPEN,  # Override for this call\n) as lease:\n    await do_work()\n</code></pre>"},{"location":"guide/failure-modes/#handling-unavailable-errors","title":"Handling Unavailable Errors","text":"<p>The <code>RateLimiterUnavailable</code> exception includes details about the failure:</p> <pre><code>from zae_limiter import RateLimiterUnavailable\n\ntry:\n    async with limiter.acquire(...):\n        await do_work()\nexcept RateLimiterUnavailable as e:\n    # Log the underlying error\n    logger.error(f\"Rate limiter unavailable: {e}\")\n\n    # Decide how to handle\n    if is_critical_operation:\n        raise HTTPException(status_code=503)\n    else:\n        # Proceed without rate limiting\n        await do_work()\n</code></pre>"},{"location":"guide/failure-modes/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>Monitor for rate limiter unavailability:</p> <pre><code>import logging\nfrom zae_limiter import RateLimiterUnavailable\n\nlogger = logging.getLogger(__name__)\n\nasync def monitored_acquire(limiter, **kwargs):\n    try:\n        async with limiter.acquire(**kwargs) as lease:\n            yield lease\n    except RateLimiterUnavailable as e:\n        # Emit metric for monitoring\n        metrics.increment(\"rate_limiter.unavailable\")\n        logger.warning(f\"Rate limiter unavailable: {e}\")\n        raise\n</code></pre>"},{"location":"guide/failure-modes/#best-practices","title":"Best Practices","text":""},{"location":"guide/failure-modes/#1-choose-based-on-risk","title":"1. Choose Based on Risk","text":"<pre><code># High-risk: billing, security\nbilling_limiter = RateLimiter(\n    name=\"billing\",  # Connects to ZAEL-billing\n    failure_mode=FailureMode.FAIL_CLOSED,\n)\n\n# Lower-risk: general API\napi_limiter = RateLimiter(\n    name=\"api\",  # Connects to ZAEL-api\n    failure_mode=FailureMode.FAIL_OPEN,\n)\n</code></pre>"},{"location":"guide/failure-modes/#2-use-circuit-breakers","title":"2. Use Circuit Breakers","text":"<p>Combine with circuit breakers to prevent cascading failures:</p> <pre><code>from circuitbreaker import circuit\n\n@circuit(failure_threshold=5, recovery_timeout=30)\nasync def rate_limited_operation(entity_id: str):\n    async with limiter.acquire(\n        entity_id=entity_id,\n        failure_mode=FailureMode.FAIL_CLOSED,\n        ...\n    ):\n        return await do_work()\n</code></pre>"},{"location":"guide/failure-modes/#3-graceful-degradation","title":"3. Graceful Degradation","text":"<p>Implement fallback behavior:</p> <pre><code>async def resilient_operation(entity_id: str):\n    try:\n        async with limiter.acquire(\n            entity_id=entity_id,\n            failure_mode=FailureMode.FAIL_CLOSED,\n            ...\n        ):\n            return await premium_operation()\n    except RateLimiterUnavailable:\n        # Fall back to degraded mode\n        logger.warning(\"Rate limiter unavailable, using fallback\")\n        return await basic_operation()\n</code></pre>"},{"location":"guide/failure-modes/#4-health-checks","title":"4. Health Checks","text":"<p>Include rate limiter health in your health checks:</p> <pre><code>async def health_check():\n    checks = {}\n\n    # Check rate limiter\n    try:\n        await limiter.available(\n            entity_id=\"health-check\",\n            resource=\"health\",\n            limits=[Limit.per_minute(\"requests\", 1)],\n        )\n        checks[\"rate_limiter\"] = \"healthy\"\n    except Exception as e:\n        checks[\"rate_limiter\"] = f\"unhealthy: {e}\"\n\n    return checks\n</code></pre>"},{"location":"guide/failure-modes/#dynamodb-resilience","title":"DynamoDB Resilience","text":"<p>DynamoDB itself is highly available, but consider:</p> <ul> <li>Region outages: Use multi-region tables for critical systems</li> <li>Throttling: Configure appropriate capacity</li> <li>Network issues: Set appropriate timeouts</li> </ul> <pre><code>limiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    region=\"us-east-1\",\n)\n</code></pre>"},{"location":"guide/failure-modes/#next-steps","title":"Next Steps","text":"<ul> <li>Troubleshooting Guide - Diagnose and resolve operational issues</li> <li>Deployment - Infrastructure setup</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/hierarchical/","title":"Hierarchical Limits","text":"<p>zae-limiter supports two-level hierarchies for rate limiting, enabling patterns like:</p> <ul> <li>Project \u2192 API Keys: Limit total project usage while also limiting individual keys</li> <li>Organization \u2192 Users: Organization-wide limits with per-user quotas</li> <li>Tenant \u2192 Services: Multi-tenant limits with service-level controls</li> </ul>"},{"location":"guide/hierarchical/#creating-a-hierarchy","title":"Creating a Hierarchy","text":"<pre><code># Create parent entity (project)\nawait limiter.create_entity(\n    entity_id=\"project-1\",\n    name=\"Production Project\",\n)\n\n# Create child entities (API keys)\nawait limiter.create_entity(\n    entity_id=\"key-abc\",\n    parent_id=\"project-1\",\n    name=\"Web Application Key\",\n)\n\nawait limiter.create_entity(\n    entity_id=\"key-xyz\",\n    parent_id=\"project-1\",\n    name=\"Mobile App Key\",\n)\n</code></pre>"},{"location":"guide/hierarchical/#cascade-mode","title":"Cascade Mode","text":"<p>Use <code>cascade=True</code> to apply rate limits to both the child and parent:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"tpm\", 10_000),  # Per-key limit\n    ],\n    consume={\"tpm\": 500},\n    cascade=True,  # Also applies to parent (project-1)\n) as lease:\n    await call_api()\n</code></pre> <p>Performance Impact</p> <p>Cascade mode adds overhead: +1 GetEntity + parent bucket operations. Only enable when hierarchical enforcement is needed. See Batch Operation Patterns for optimization strategies.</p> <p>What happens:</p> <ol> <li>Check if <code>key-abc</code> has capacity (10k tpm)</li> <li>Check if <code>project-1</code> has capacity (uses same limits)</li> <li>If both pass, consume from both atomically</li> <li>If either fails, reject with details about which limit was exceeded</li> </ol>"},{"location":"guide/hierarchical/#different-limits-per-level","title":"Different Limits Per Level","text":"<p>Set different limits for parents and children:</p> <pre><code># Set project-level limits (higher)\nawait limiter.set_limits(\n    entity_id=\"project-1\",\n    limits=[\n        Limit.per_minute(\"tpm\", 100_000),  # 100k for entire project\n    ],\n)\n\n# Set key-level limits (lower)\nawait limiter.set_limits(\n    entity_id=\"key-abc\",\n    limits=[\n        Limit.per_minute(\"tpm\", 10_000),   # 10k per key\n    ],\n)\n\n# Use stored limits with cascade\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 5_000)],  # Default\n    consume={\"tpm\": 500},\n    cascade=True,\n    use_stored_limits=True,  # Uses stored limits for both levels\n) as lease:\n    await call_api()\n</code></pre>"},{"location":"guide/hierarchical/#understanding-cascade-behavior","title":"Understanding Cascade Behavior","text":""},{"location":"guide/hierarchical/#without-cascade","title":"Without Cascade","text":"<pre><code># Only checks/consumes from key-abc\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},\n    cascade=False,  # Default\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#with-cascade","title":"With Cascade","text":"<pre><code># Checks/consumes from BOTH key-abc AND project-1\nasync with limiter.acquire(\n    entity_id=\"key-abc\",\n    resource=\"gpt-4\",\n    limits=[Limit.per_minute(\"tpm\", 10_000)],\n    consume={\"tpm\": 500},\n    cascade=True,\n) as lease:\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#error-handling-with-hierarchies","title":"Error Handling with Hierarchies","text":"<p>When using cascade mode, <code>RateLimitExceeded</code> includes statuses for all entities:</p> <pre><code>try:\n    async with limiter.acquire(\n        entity_id=\"key-abc\",\n        cascade=True,\n        ...\n    ):\n        ...\nexcept RateLimitExceeded as e:\n    for status in e.statuses:\n        print(f\"Entity: {status.entity_id}\")\n        print(f\"  Limit: {status.limit_name}\")\n        print(f\"  Available: {status.available}\")\n        print(f\"  Exceeded: {status.exceeded}\")\n</code></pre>"},{"location":"guide/hierarchical/#use-cases","title":"Use Cases","text":""},{"location":"guide/hierarchical/#multi-tenant-saas","title":"Multi-Tenant SaaS","text":"<pre><code># Tenant has 1M tokens/day\nawait limiter.set_limits(\n    entity_id=\"tenant-acme\",\n    limits=[Limit.per_day(\"tpd\", 1_000_000)],\n)\n\n# Each user gets 100k tokens/day\nawait limiter.set_limits(\n    entity_id=\"user-123\",\n    limits=[Limit.per_day(\"tpd\", 100_000)],\n)\n\n# Rate limit user, cascade to tenant\nasync with limiter.acquire(\n    entity_id=\"user-123\",\n    cascade=True,\n    use_stored_limits=True,\n    ...\n):\n    ...\n</code></pre>"},{"location":"guide/hierarchical/#api-key-management","title":"API Key Management","text":"<pre><code># Project limit: 10k RPM\nawait limiter.set_limits(\n    entity_id=\"project-prod\",\n    limits=[Limit.per_minute(\"rpm\", 10_000)],\n)\n\n# Production key: 5k RPM (half of project)\nawait limiter.set_limits(\n    entity_id=\"key-prod\",\n    limits=[Limit.per_minute(\"rpm\", 5_000)],\n)\n\n# Staging key: 1k RPM\nawait limiter.set_limits(\n    entity_id=\"key-staging\",\n    limits=[Limit.per_minute(\"rpm\", 1_000)],\n)\n</code></pre>"},{"location":"guide/hierarchical/#limitations","title":"Limitations","text":"<ul> <li>Two levels only: Parent \u2192 Child (no grandparents)</li> <li>Single parent: Each entity can have at most one parent</li> <li>Cascade is optional: Must be explicitly enabled per call</li> </ul>"},{"location":"guide/hierarchical/#next-steps","title":"Next Steps","text":"<ul> <li>LLM Integration - Token estimation patterns</li> <li>Failure Modes - Handling service outages</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"guide/llm-integration/","title":"LLM Integration","text":"<p>zae-limiter is designed for LLM API rate limiting where token counts are unknown until after the call completes. This guide covers patterns for integrating with LLM providers.</p>"},{"location":"guide/llm-integration/#the-challenge","title":"The Challenge","text":"<p>LLM APIs present unique rate limiting challenges:</p> <ol> <li>Token counts are unknown upfront - You don't know how many tokens a response will use</li> <li>Multiple limits - Providers often limit both requests and tokens</li> <li>Variable costs - Different models have different token limits</li> <li>Streaming responses - Token count only known after stream completes</li> </ol>"},{"location":"guide/llm-integration/#basic-pattern-estimate-and-reconcile","title":"Basic Pattern: Estimate and Reconcile","text":"<pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),       # Requests per minute\n        Limit.per_minute(\"tpm\", 10_000),    # Tokens per minute\n    ],\n    consume={\"rpm\": 1, \"tpm\": 500},  # Estimate 500 tokens\n) as lease:\n    response = await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    )\n\n    # Reconcile with actual usage\n    actual_tokens = response.usage.total_tokens\n    await lease.adjust(tpm=actual_tokens - 500)\n</code></pre>"},{"location":"guide/llm-integration/#estimation-strategies","title":"Estimation Strategies","text":""},{"location":"guide/llm-integration/#fixed-estimate","title":"Fixed Estimate","text":"<p>Simple but may over/under-estimate:</p> <pre><code>consume={\"tpm\": 500}  # Always estimate 500 tokens\n</code></pre>"},{"location":"guide/llm-integration/#input-based-estimate","title":"Input-Based Estimate","text":"<p>Estimate based on input length:</p> <pre><code>import tiktoken\n\ndef estimate_tokens(messages: list, model: str = \"gpt-4\") -&gt; int:\n    \"\"\"Estimate tokens for input messages.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    total = 0\n    for msg in messages:\n        total += len(encoding.encode(msg[\"content\"]))\n        total += 4  # Message overhead\n    total += 2  # Completion priming\n    return total\n\n# Use in rate limiting\ninput_tokens = estimate_tokens(messages)\nestimated_output = 500  # Rough estimate for output\ntotal_estimate = input_tokens + estimated_output\n\nasync with limiter.acquire(\n    ...\n    consume={\"tpm\": total_estimate},\n) as lease:\n    response = await call_llm()\n    actual = response.usage.total_tokens\n    await lease.adjust(tpm=actual - total_estimate)\n</code></pre>"},{"location":"guide/llm-integration/#max-tokens-estimate","title":"Max Tokens Estimate","text":"<p>Use max_tokens as upper bound:</p> <pre><code>max_tokens = 1000\n\nasync with limiter.acquire(\n    ...\n    consume={\"tpm\": input_tokens + max_tokens},\n) as lease:\n    response = await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        max_tokens=max_tokens,\n    )\n    actual = response.usage.total_tokens\n    await lease.adjust(tpm=actual - (input_tokens + max_tokens))\n</code></pre>"},{"location":"guide/llm-integration/#handling-streaming-responses","title":"Handling Streaming Responses","text":"<p>For streaming responses, token count is only available after the stream completes:</p> <pre><code>async with limiter.acquire(\n    entity_id=\"api-key-123\",\n    resource=\"gpt-4\",\n    limits=[\n        Limit.per_minute(\"rpm\", 100),\n        Limit.per_minute(\"tpm\", 10_000),\n    ],\n    consume={\"rpm\": 1, \"tpm\": estimated_tokens},\n) as lease:\n    chunks = []\n    async for chunk in await openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages,\n        stream=True,\n    ):\n        chunks.append(chunk)\n        yield chunk  # Stream to client\n\n    # Get final usage from last chunk (OpenAI includes it)\n    if chunks[-1].usage:\n        actual = chunks[-1].usage.total_tokens\n        await lease.adjust(tpm=actual - estimated_tokens)\n</code></pre>"},{"location":"guide/llm-integration/#per-model-rate-limits","title":"Per-Model Rate Limits","text":"<p>Different models have different limits. Use the <code>resource</code> parameter:</p> <pre><code>MODEL_LIMITS = {\n    \"gpt-4\": [\n        Limit.per_minute(\"rpm\", 100),\n        Limit.per_minute(\"tpm\", 10_000),\n    ],\n    \"gpt-4-turbo\": [\n        Limit.per_minute(\"rpm\", 500),\n        Limit.per_minute(\"tpm\", 150_000),\n    ],\n    \"gpt-3.5-turbo\": [\n        Limit.per_minute(\"rpm\", 3500),\n        Limit.per_minute(\"tpm\", 90_000),\n    ],\n}\n\nasync def rate_limited_completion(\n    entity_id: str,\n    model: str,\n    messages: list,\n    estimated_tokens: int,\n):\n    limits = MODEL_LIMITS.get(model, MODEL_LIMITS[\"gpt-3.5-turbo\"])\n\n    async with limiter.acquire(\n        entity_id=entity_id,\n        resource=model,  # Different bucket per model\n        limits=limits,\n        consume={\"rpm\": 1, \"tpm\": estimated_tokens},\n    ) as lease:\n        response = await openai.chat.completions.create(\n            model=model,\n            messages=messages,\n        )\n        actual = response.usage.total_tokens\n        await lease.adjust(tpm=actual - estimated_tokens)\n        return response\n</code></pre>"},{"location":"guide/llm-integration/#negative-buckets-debt","title":"Negative Buckets (Debt)","text":"<p>zae-limiter allows buckets to go negative, which is useful when actual usage exceeds estimates:</p> <pre><code># Estimate: 500 tokens\nasync with limiter.acquire(\n    consume={\"tpm\": 500},\n    ...\n) as lease:\n    response = await call_llm()\n\n    # Actual: 2000 tokens\n    # Adjustment: 2000 - 500 = 1500\n    await lease.adjust(tpm=1500)\n    # Bucket now at -1500 tokens (in debt)\n</code></pre> <p>The debt is repaid as tokens refill over time. This ensures accurate accounting while allowing requests to complete.</p>"},{"location":"guide/llm-integration/#pre-flight-capacity-check","title":"Pre-Flight Capacity Check","text":"<p>Check capacity before making expensive calls:</p> <pre><code>async def call_with_capacity_check(\n    entity_id: str,\n    model: str,\n    messages: list,\n    estimated_tokens: int,\n):\n    limits = MODEL_LIMITS[model]\n\n    # Check available capacity\n    available = await limiter.available(\n        entity_id=entity_id,\n        resource=model,\n        limits=limits,\n    )\n\n    if available[\"tpm\"] &lt; estimated_tokens:\n        # Not enough capacity - check when it will be available\n        wait_time = await limiter.time_until_available(\n            entity_id=entity_id,\n            resource=model,\n            limits=limits,\n            needed={\"tpm\": estimated_tokens},\n        )\n        raise RetryAfter(seconds=wait_time)\n\n    # Proceed with rate-limited call\n    async with limiter.acquire(...):\n        ...\n</code></pre>"},{"location":"guide/llm-integration/#integration-with-retry-libraries","title":"Integration with Retry Libraries","text":"<p>Combine with retry libraries like <code>tenacity</code>:</p> <pre><code>from tenacity import retry, retry_if_exception_type, wait_fixed\n\n@retry(\n    retry=retry_if_exception_type(RateLimitExceeded),\n    wait=wait_fixed(1),\n)\nasync def resilient_llm_call(entity_id: str, messages: list):\n    async with limiter.acquire(\n        entity_id=entity_id,\n        resource=\"gpt-4\",\n        limits=[Limit.per_minute(\"rpm\", 100)],\n        consume={\"rpm\": 1},\n    ):\n        return await openai.chat.completions.create(\n            model=\"gpt-4\",\n            messages=messages,\n        )\n</code></pre> <p>Or use the retry information from the exception:</p> <pre><code>async def smart_retry_llm_call(entity_id: str, messages: list):\n    while True:\n        try:\n            async with limiter.acquire(...):\n                return await call_llm()\n        except RateLimitExceeded as e:\n            await asyncio.sleep(e.retry_after_seconds)\n</code></pre>"},{"location":"guide/llm-integration/#next-steps","title":"Next Steps","text":"<ul> <li>Failure Modes - Handling service outages</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"infra/cloudformation/","title":"CloudFormation Template","text":"<p>This guide covers the CloudFormation template used by zae-limiter and how to customize it.</p>"},{"location":"infra/cloudformation/#template-overview","title":"Template Overview","text":"<p>The template creates:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                CloudFormation Stack                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502  \u2502  DynamoDB   \u2502\u2500\u2500\u2500\u25b6\u2502   Stream    \u2502                 \u2502\n\u2502  \u2502   Table     \u2502    \u2502             \u2502                 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                            \u2502                         \u2502\n\u2502                            \u25bc                         \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502                    \u2502   Lambda    \u2502                  \u2502\n\u2502                    \u2502 Aggregator  \u2502                  \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2502                            \u2502                         \u2502\n\u2502                            \u25bc                         \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502                    \u2502 CloudWatch  \u2502                  \u2502\n\u2502                    \u2502    Logs     \u2502                  \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"infra/cloudformation/#export-template","title":"Export Template","text":"<pre><code># Export to file\nzae-limiter cfn-template &gt; template.yaml\n\n# View template\nzae-limiter cfn-template | less\n</code></pre>"},{"location":"infra/cloudformation/#template-parameters","title":"Template Parameters","text":"<p>The DynamoDB table name is automatically derived from the CloudFormation stack name using the <code>AWS::StackName</code> pseudo-parameter. This ensures consistency between stack and resource names.</p> Parameter Type Default Description <code>SnapshotWindows</code> String <code>hourly,daily</code> Comma-separated list of snapshot windows <code>SnapshotRetentionDays</code> Number <code>90</code> Days to retain usage snapshots (1-3650) <code>LambdaMemorySize</code> Number <code>256</code> Memory for aggregator Lambda (128-3008 MB) <code>LambdaTimeout</code> Number <code>60</code> Timeout for aggregator Lambda (1-900 seconds) <code>EnableAggregator</code> String <code>true</code> Whether to deploy the aggregator Lambda <code>SchemaVersion</code> String <code>1.0.0</code> Schema version for infrastructure <code>PITRRecoveryPeriodDays</code> String (empty) PITR period (1-35 days, empty for AWS default) <code>EnableAlarms</code> String <code>true</code> Whether to deploy CloudWatch alarms <code>AlarmSNSTopicArn</code> String (empty) SNS topic ARN for alarm notifications <code>LogRetentionDays</code> Number <code>30</code> CloudWatch log retention (standard periods)"},{"location":"infra/cloudformation/#dynamodb-table","title":"DynamoDB Table","text":""},{"location":"infra/cloudformation/#schema","title":"Schema","text":"<pre><code>AttributeDefinitions:\n  - AttributeName: PK\n    AttributeType: S\n  - AttributeName: SK\n    AttributeType: S\n  - AttributeName: GSI1PK\n    AttributeType: S\n  - AttributeName: GSI1SK\n    AttributeType: S\n  - AttributeName: GSI2PK\n    AttributeType: S\n  - AttributeName: GSI2SK\n    AttributeType: S\n\nKeySchema:\n  - AttributeName: PK\n    KeyType: HASH\n  - AttributeName: SK\n    KeyType: RANGE\n</code></pre>"},{"location":"infra/cloudformation/#global-secondary-indexes","title":"Global Secondary Indexes","text":"<p>GSI1 - Parent to children lookups:</p> <pre><code>GlobalSecondaryIndexes:\n  - IndexName: GSI1\n    KeySchema:\n      - AttributeName: GSI1PK  # PARENT#{parent_id}\n        KeyType: HASH\n      - AttributeName: GSI1SK  # CHILD#{child_id}\n        KeyType: RANGE\n</code></pre> <p>GSI2 - Resource aggregation:</p> <pre><code>  - IndexName: GSI2\n    KeySchema:\n      - AttributeName: GSI2PK  # RESOURCE#{resource}\n        KeyType: HASH\n      - AttributeName: GSI2SK  # BUCKET#{entity_id}#{limit_name}\n        KeyType: RANGE\n</code></pre>"},{"location":"infra/cloudformation/#stream-configuration","title":"Stream Configuration","text":"<pre><code>StreamSpecification:\n  StreamViewType: NEW_AND_OLD_IMAGES\n</code></pre>"},{"location":"infra/cloudformation/#lambda-aggregator","title":"Lambda Aggregator","text":"<p>The aggregator Lambda processes DynamoDB Stream events to maintain usage snapshots.</p> <p>Performance Tuning</p> <p>For guidance on memory tuning, concurrency management, and error handling configuration, see the Performance Tuning Guide.</p>"},{"location":"infra/cloudformation/#function-configuration","title":"Function Configuration","text":"<pre><code>AggregatorFunction:\n  Type: AWS::Lambda::Function\n  Properties:\n    Runtime: python3.12\n    Handler: zae_limiter.aggregator.handler.lambda_handler\n    MemorySize: 256\n    Timeout: 60\n    Environment:\n      Variables:\n        TABLE_NAME: !Ref AWS::StackName\n        SNAPSHOT_WINDOWS: !Ref SnapshotWindows\n        SNAPSHOT_TTL_DAYS: !Ref SnapshotRetentionDays\n</code></pre>"},{"location":"infra/cloudformation/#event-source-mapping","title":"Event Source Mapping","text":"<pre><code>StreamEventMapping:\n  Type: AWS::Lambda::EventSourceMapping\n  Properties:\n    EventSourceArn: !GetAtt Table.StreamArn\n    FunctionName: !Ref AggregatorFunction\n    StartingPosition: LATEST\n    BatchSize: 100\n    MaximumBatchingWindowInSeconds: 5\n</code></pre>"},{"location":"infra/cloudformation/#iam-permissions","title":"IAM Permissions","text":""},{"location":"infra/cloudformation/#lambda-execution-role","title":"Lambda Execution Role","text":"<pre><code>AggregatorRole:\n  Type: AWS::IAM::Role\n  Properties:\n    AssumeRolePolicyDocument:\n      Statement:\n        - Effect: Allow\n          Principal:\n            Service: lambda.amazonaws.com\n          Action: sts:AssumeRole\n    Policies:\n      - PolicyName: DynamoDBAccess\n        PolicyDocument:\n          Statement:\n            - Effect: Allow\n              Action:\n                - dynamodb:GetItem\n                - dynamodb:PutItem\n                - dynamodb:UpdateItem\n                - dynamodb:Query\n              Resource: !GetAtt Table.Arn\n            - Effect: Allow\n              Action:\n                - dynamodb:GetRecords\n                - dynamodb:GetShardIterator\n                - dynamodb:DescribeStream\n                - dynamodb:ListStreams\n              Resource: !Sub \"${Table.Arn}/stream/*\"\n</code></pre>"},{"location":"infra/cloudformation/#customization","title":"Customization","text":""},{"location":"infra/cloudformation/#add-dead-letter-queue","title":"Add Dead Letter Queue","text":"<pre><code>Parameters:\n  EnableDLQ:\n    Type: String\n    Default: \"false\"\n    AllowedValues: [\"true\", \"false\"]\n\nConditions:\n  CreateDLQ: !Equals [!Ref EnableDLQ, \"true\"]\n\nResources:\n  DeadLetterQueue:\n    Type: AWS::SQS::Queue\n    Condition: CreateDLQ\n    Properties:\n      QueueName: !Sub \"${AWS::StackName}-aggregator-dlq\"\n      MessageRetentionPeriod: 1209600  # 14 days\n\n  StreamEventMapping:\n    Properties:\n      DestinationConfig:\n        OnFailure:\n          Destination: !If\n            - CreateDLQ\n            - !GetAtt DeadLetterQueue.Arn\n            - !Ref AWS::NoValue\n</code></pre>"},{"location":"infra/cloudformation/#add-cloudwatch-alarms","title":"Add CloudWatch Alarms","text":"<pre><code>ReadThrottleAlarm:\n  Type: AWS::CloudWatch::Alarm\n  Properties:\n    AlarmName: !Sub \"${AWS::StackName}-read-throttle\"\n    AlarmDescription: Alert when DynamoDB read requests are throttled\n    MetricName: ReadThrottleEvents\n    Namespace: AWS/DynamoDB\n    Statistic: Sum\n    Period: 300  # 5 minutes\n    EvaluationPeriods: 2\n    Threshold: 1\n    ComparisonOperator: GreaterThanThreshold\n    Dimensions:\n      - Name: TableName\n        Value: !Ref RateLimitsTable\n    TreatMissingData: notBreaching\n    AlarmActions: !If\n      - HasSNSTopic\n      - [!Ref AlarmSNSTopicArn]\n      - !Ref AWS::NoValue\n</code></pre>"},{"location":"infra/cloudformation/#enable-encryption-with-cmk","title":"Enable Encryption with CMK","text":"<pre><code>Parameters:\n  KmsKeyArn:\n    Type: String\n    Default: \"\"\n\nConditions:\n  UseCustomKey: !Not [!Equals [!Ref KmsKeyArn, \"\"]]\n\nResources:\n  Table:\n    Properties:\n      SSESpecification:\n        SSEEnabled: true\n        SSEType: !If [UseCustomKey, \"KMS\", \"AWS_OWNED_KEY\"]\n        KMSMasterKeyId: !If [UseCustomKey, !Ref KmsKeyArn, !Ref AWS::NoValue]\n</code></pre>"},{"location":"infra/cloudformation/#deployment-examples","title":"Deployment Examples","text":""},{"location":"infra/cloudformation/#basic-deployment","title":"Basic Deployment","text":"<pre><code>aws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name zae-limiter \\\n    --capabilities CAPABILITY_NAMED_IAM\n</code></pre>"},{"location":"infra/cloudformation/#with-custom-parameters","title":"With Custom Parameters","text":"<pre><code>aws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name ZAEL-prod \\\n    --parameter-overrides \\\n        PITRRecoveryPeriodDays=35 \\\n        SnapshotRetentionDays=365 \\\n        LogRetentionDays=90 \\\n        EnableAlarms=true \\\n    --capabilities CAPABILITY_NAMED_IAM\n</code></pre> <p>Note: The DynamoDB table name is automatically set to match the stack name (e.g., <code>ZAEL-prod</code>).</p>"},{"location":"infra/cloudformation/#using-sam","title":"Using SAM","text":"<pre><code># samconfig.toml\n[default.deploy.parameters]\nstack_name = \"ZAEL-limiter\"\ncapabilities = \"CAPABILITY_NAMED_IAM\"\n</code></pre> <pre><code>sam deploy --guided\n</code></pre>"},{"location":"infra/cloudformation/#outputs","title":"Outputs","text":"<p>The template exports:</p> Output Description <code>TableArn</code> DynamoDB table ARN <code>StreamArn</code> DynamoDB stream ARN <code>FunctionArn</code> Lambda function ARN <p>Access outputs:</p> <pre><code>aws cloudformation describe-stacks \\\n    --stack-name zae-limiter \\\n    --query \"Stacks[0].Outputs\"\n</code></pre>"},{"location":"infra/cloudformation/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment - Deployment guide</li> <li>LocalStack - Local development</li> </ul>"},{"location":"infra/deployment/","title":"Deployment","text":"<p>This guide covers deploying zae-limiter infrastructure to AWS.</p>"},{"location":"infra/deployment/#overview","title":"Overview","text":"<p>zae-limiter uses CloudFormation to deploy:</p> <ul> <li>DynamoDB Table - Stores rate limit state, entities, and usage data</li> <li>DynamoDB Streams - Captures changes for usage aggregation</li> <li>Lambda Function - Aggregates usage into hourly/daily snapshots</li> <li>IAM Roles - Least-privilege access for Lambda</li> <li>CloudWatch Logs - Lambda function logs</li> </ul>"},{"location":"infra/deployment/#cli-deployment-recommended","title":"CLI Deployment (Recommended)","text":"<p>The simplest way to deploy:</p> <pre><code># Deploy with defaults\nzae-limiter deploy --name limiter --region us-east-1\n\n# Deploy with custom settings\nzae-limiter deploy \\\n    --name limiter \\\n    --region us-east-1 \\\n    --log-retention-days 90 \\\n    --pitr-recovery-days 7\n</code></pre>"},{"location":"infra/deployment/#cli-options","title":"CLI Options","text":"Option Description Default <code>--name</code> Resource identifier (creates ZAEL-{name} resources) Required <code>--region</code> AWS region Required <code>--no-aggregator</code> Skip Lambda deployment <code>false</code> <code>--log-retention-days</code> CloudWatch log retention <code>14</code> <code>--pitr-recovery-days</code> Point-in-time recovery <code>0</code> (disabled) <code>--endpoint-url</code> Custom endpoint (LocalStack) None"},{"location":"infra/deployment/#check-stack-status","title":"Check Stack Status","text":"<pre><code>zae-limiter status --name limiter --region us-east-1\n</code></pre>"},{"location":"infra/deployment/#delete-stack","title":"Delete Stack","text":"<pre><code>zae-limiter delete --name limiter --region us-east-1 --yes\n</code></pre>"},{"location":"infra/deployment/#stack-lifecycle-management","title":"Stack Lifecycle Management","text":""},{"location":"infra/deployment/#programmatic-cleanup","title":"Programmatic Cleanup","text":"<p>In addition to the CLI, you can manage stack lifecycle programmatically using the <code>delete_stack()</code> method:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\n# Create stack\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n    stack_options=StackOptions(),\n)\n\n# Use the limiter...\nasync with limiter:\n    # Rate limiting operations here\n    pass\n\n# Delete stack when done\nawait limiter.delete_stack()\n</code></pre>"},{"location":"infra/deployment/#use-case-guidance","title":"Use-Case Guidance","text":""},{"location":"infra/deployment/#development-and-prototyping","title":"Development and Prototyping","text":"<p>For rapid iteration, use auto-creation with cleanup:</p> <pre><code>async def dev_session():\n    limiter = RateLimiter(\n        name=\"dev\",  # Creates ZAEL-dev resources\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    try:\n        async with limiter:\n            # Development work...\n            pass\n    finally:\n        # Clean up development stack\n        await limiter.delete_stack()\n</code></pre>"},{"location":"infra/deployment/#integration-testing","title":"Integration Testing","text":"<p>For test isolation, create/destroy stacks per test session:</p> <pre><code>import pytest\nimport uuid\nfrom zae_limiter import RateLimiter, StackOptions\n\n@pytest.fixture(scope=\"session\")\nasync def integration_limiter():\n    \"\"\"Session-scoped fixture with automatic cleanup.\"\"\"\n    limiter = RateLimiter(\n        name=f\"test-{uuid.uuid4().hex[:8]}\",  # Unique name\n        endpoint_url=\"http://localhost:4566\",\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    async with limiter:\n        yield limiter\n\n    await limiter.delete_stack()\n</code></pre>"},{"location":"infra/deployment/#production-deployments","title":"Production Deployments","text":"<p>For production, prefer CLI or CloudFormation-managed deployments:</p> <pre><code># Deploy via CLI (with review)\nzae-limiter deploy --name prod --region us-east-1\n\n# Delete via CLI (requires confirmation)\nzae-limiter delete --name prod --region us-east-1\n</code></pre> <p>Production Best Practice</p> <p>In production, avoid programmatic <code>delete_stack()</code> calls. Use:</p> <ul> <li>CloudFormation console for manual cleanup</li> <li>CLI with <code>--yes</code> flag for scripted cleanup (after review)</li> <li>Stack policies to prevent accidental deletion</li> </ul>"},{"location":"infra/deployment/#cloudformation-template","title":"CloudFormation Template","text":"<p>Export and customize the template:</p> <pre><code># Export template\nzae-limiter cfn-template &gt; template.yaml\n\n# Deploy with AWS CLI\naws cloudformation deploy \\\n    --template-file template.yaml \\\n    --stack-name ZAEL-limiter \\\n    --parameter-overrides \\\n        SnapshotRetentionDays=90 \\\n        EnablePITR=true \\\n    --capabilities CAPABILITY_NAMED_IAM\n\n# Deploy Lambda code separately\nzae-limiter lambda-export --output lambda.zip\naws lambda update-function-code \\\n    --function-name zae-limiter-aggregator \\\n    --zip-file fileb://lambda.zip\n</code></pre>"},{"location":"infra/deployment/#template-parameters","title":"Template Parameters","text":"Parameter Description Default <code>SnapshotWindows</code> Aggregation windows <code>hourly,daily</code> <code>SnapshotRetentionDays</code> Usage data retention <code>90</code> <code>EnablePITR</code> Point-in-time recovery <code>false</code> <code>LogRetentionDays</code> CloudWatch log retention <code>14</code>"},{"location":"infra/deployment/#auto-creation-in-code","title":"Auto-Creation in Code","text":"<p>For development, create infrastructure programmatically:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    region=\"us-east-1\",\n    stack_options=StackOptions(\n        snapshot_windows=\"hourly,daily\",\n        retention_days=90,\n    ),\n)\n</code></pre> <p>Production Use</p> <p>Auto-creation is convenient for development but has limitations:</p> <ul> <li>No control over IAM policies</li> <li>Limited error handling</li> <li>Not idempotent</li> </ul> <p>Use CLI or CloudFormation for production.</p>"},{"location":"infra/deployment/#infrastructure-details","title":"Infrastructure Details","text":""},{"location":"infra/deployment/#dynamodb-table","title":"DynamoDB Table","text":"<ul> <li>Billing: Pay-per-request (on-demand)</li> <li>Encryption: AWS-managed keys (default)</li> <li>Streams: NEW_AND_OLD_IMAGES for Lambda trigger</li> </ul>"},{"location":"infra/deployment/#dynamodb-schema","title":"DynamoDB Schema","text":"Key Pattern Purpose PK <code>ENTITY#{id}</code> Partition key SK <code>#META</code>, <code>#BUCKET#...</code>, <code>#LIMIT#...</code> Sort key GSI1PK <code>PARENT#{id}</code> Parent lookups GSI2PK <code>RESOURCE#{name}</code> Resource aggregation"},{"location":"infra/deployment/#lambda-function","title":"Lambda Function","text":"<ul> <li>Runtime: Python 3.12</li> <li>Memory: 256 MB</li> <li>Timeout: 60 seconds</li> <li>Trigger: DynamoDB Streams</li> </ul>"},{"location":"infra/deployment/#iam-permissions","title":"IAM Permissions","text":"<p>The Lambda function has minimal permissions:</p> <pre><code>- dynamodb:GetItem\n- dynamodb:PutItem\n- dynamodb:UpdateItem\n- dynamodb:Query\n</code></pre>"},{"location":"infra/deployment/#monitoring","title":"Monitoring","text":"<p>The stack includes comprehensive monitoring with CloudWatch alarms, structured logging, and a Dead Letter Queue for failed events.</p> <pre><code># Deploy with alarms and SNS notifications\nzae-limiter deploy \\\n    --name limiter \\\n    --enable-alarms \\\n    --alarm-sns-topic arn:aws:sns:us-east-1:123456789:alerts\n</code></pre> <p>Monitoring Guide</p> <p>For detailed monitoring setup including CloudWatch Logs Insights queries, dashboard templates, and troubleshooting guides, see the Monitoring and Observability Guide.</p>"},{"location":"infra/deployment/#cost-estimation","title":"Cost Estimation","text":"Component Cost Driver DynamoDB Read/write capacity units Lambda Invocations, duration CloudWatch Log storage, metrics <p>For a typical workload (1M requests/day):</p> <ul> <li>DynamoDB: ~$10-50/month</li> <li>Lambda: ~$1-5/month</li> <li>CloudWatch: ~$1-5/month</li> </ul> <p>Performance Tuning</p> <p>For detailed capacity planning, including RCU/WCU costs per operation and cost optimization strategies, see the Performance Tuning Guide.</p>"},{"location":"infra/deployment/#next-steps","title":"Next Steps","text":"<ul> <li>LocalStack - Local development setup</li> <li>CloudFormation - Template details</li> </ul>"},{"location":"infra/localstack/","title":"LocalStack Development","text":"<p>LocalStack provides a local AWS environment for development and testing. This guide covers setting up zae-limiter with LocalStack.</p>"},{"location":"infra/localstack/#why-localstack","title":"Why LocalStack?","text":"<ul> <li>Free - No AWS costs during development</li> <li>Fast - No network latency</li> <li>Isolated - No risk to production data</li> <li>Full stack - DynamoDB, Lambda, Streams, CloudFormation</li> </ul>"},{"location":"infra/localstack/#quick-start","title":"Quick Start","text":""},{"location":"infra/localstack/#1-start-localstack","title":"1. Start LocalStack","text":"Docker Compose (Preferred)DockerLocalStack CLI <p>The project includes a pre-configured <code>docker-compose.yml</code> at the repository root:</p> <pre><code># From the project root\ndocker compose up -d\n</code></pre> <p>This is the preferred method as it includes all required configuration for Lambda execution.</p> <pre><code>docker run -d \\\n  --name localstack \\\n  -p 4566:4566 \\\n  -e SERVICES=dynamodb,dynamodbstreams,lambda,cloudformation,logs,iam,cloudwatch,sqs \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v \"${TMPDIR:-/tmp}/localstack:/var/lib/localstack\" \\\n  localstack/localstack\n</code></pre> <p>Docker Socket Required</p> <p>The Docker socket mount (<code>-v /var/run/docker.sock:/var/run/docker.sock</code>) is required for LocalStack to spawn Lambda functions as Docker containers.</p> <pre><code>pip install localstack\nlocalstack start -d\n</code></pre>"},{"location":"infra/localstack/#2-deploy-infrastructure","title":"2. Deploy Infrastructure","text":"<pre><code>zae-limiter deploy \\\n    --name limiter \\\n    --endpoint-url http://localhost:4566 \\\n    --region us-east-1\n</code></pre>"},{"location":"infra/localstack/#3-use-in-code","title":"3. Use in Code","text":"<pre><code>from zae_limiter import RateLimiter, Limit\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    endpoint_url=\"http://localhost:4566\",\n    region=\"us-east-1\",\n)\n\nasync with limiter.acquire(\n    entity_id=\"test-user\",\n    resource=\"api\",\n    limits=[Limit.per_minute(\"requests\", 100)],\n    consume={\"requests\": 1},\n) as lease:\n    print(\"Rate limited request!\")\n</code></pre>"},{"location":"infra/localstack/#auto-creation-mode","title":"Auto-Creation Mode","text":"<p>For quick iteration, use auto-creation:</p> <pre><code>from zae_limiter import RateLimiter, StackOptions\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Creates ZAEL-limiter resources\n    endpoint_url=\"http://localhost:4566\",\n    region=\"us-east-1\",\n    stack_options=StackOptions(),  # Creates CloudFormation stack\n)\n</code></pre>"},{"location":"infra/localstack/#environment-variables","title":"Environment Variables","text":"<p>Configure via environment variables for easy switching:</p> <pre><code># .env.local\nAWS_ENDPOINT_URL=http://localhost:4566\nAWS_ACCESS_KEY_ID=test\nAWS_SECRET_ACCESS_KEY=test\nAWS_DEFAULT_REGION=us-east-1\n</code></pre> <pre><code>import os\n\nlimiter = RateLimiter(\n    name=\"limiter\",  # Connects to ZAEL-limiter\n    endpoint_url=os.getenv(\"AWS_ENDPOINT_URL\"),\n    region=os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\"),\n)\n</code></pre>"},{"location":"infra/localstack/#testing-with-localstack","title":"Testing with LocalStack","text":""},{"location":"infra/localstack/#pytest-fixture-with-cleanup","title":"pytest Fixture with Cleanup","text":"<p>For integration tests, use fixtures that properly clean up resources:</p> <pre><code>import os\nimport uuid\nimport pytest\nfrom zae_limiter import RateLimiter, StackOptions\n\n@pytest.fixture\ndef localstack_endpoint():\n    \"\"\"Get LocalStack endpoint from environment.\"\"\"\n    return os.getenv(\"AWS_ENDPOINT_URL\", \"http://localhost:4566\")\n\n@pytest.fixture(scope=\"function\")\nasync def limiter(localstack_endpoint):\n    \"\"\"\n    Create a rate limiter connected to LocalStack with automatic cleanup.\n\n    This fixture:\n    1. Creates a unique stack for test isolation\n    2. Yields the limiter for test use\n    3. Deletes the stack in teardown\n    \"\"\"\n    # Unique name prevents test interference\n    name = f\"test-{uuid.uuid4().hex[:8]}\"\n\n    limiter = RateLimiter(\n        name=name,  # Creates ZAEL-test-{uuid} resources\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    async with limiter:\n        yield limiter\n\n    # Cleanup: delete the CloudFormation stack\n    await limiter.delete_stack()\n\n@pytest.mark.integration\nasync def test_rate_limiting(limiter):\n    async with limiter.acquire(\n        entity_id=\"test-user\",\n        resource=\"api\",\n        limits=[Limit.per_minute(\"requests\", 10)],\n        consume={\"requests\": 1},\n    ):\n        pass  # Success\n</code></pre>"},{"location":"infra/localstack/#session-scoped-fixture-faster","title":"Session-Scoped Fixture (Faster)","text":"<p>For test suites where stack creation overhead is significant:</p> <pre><code>@pytest.fixture(scope=\"session\")\nasync def shared_limiter(localstack_endpoint):\n    \"\"\"\n    Session-scoped limiter for faster test execution.\n\n    Trade-off: Tests share state, less isolation.\n    \"\"\"\n    limiter = RateLimiter(\n        name=\"integration-test-shared\",  # Creates ZAEL-integration-test-shared\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    async with limiter:\n        yield limiter\n\n    await limiter.delete_stack()\n</code></pre>"},{"location":"infra/localstack/#sync-fixture-example","title":"Sync Fixture Example","text":"<pre><code>@pytest.fixture(scope=\"function\")\ndef sync_limiter(localstack_endpoint):\n    \"\"\"Synchronous rate limiter with cleanup.\"\"\"\n    from zae_limiter import SyncRateLimiter, StackOptions\n    import uuid\n\n    name = f\"test-sync-{uuid.uuid4().hex[:8]}\"\n\n    limiter = SyncRateLimiter(\n        name=name,  # Creates ZAEL-test-sync-{uuid} resources\n        endpoint_url=localstack_endpoint,\n        region=\"us-east-1\",\n        stack_options=StackOptions(enable_aggregator=False),\n    )\n\n    with limiter:\n        yield limiter\n\n    limiter.delete_stack()\n</code></pre>"},{"location":"infra/localstack/#ci-configuration","title":"CI Configuration","text":"<pre><code># .github/workflows/ci.yml\njobs:\n  integration:\n    runs-on: ubuntu-latest\n    services:\n      localstack:\n        image: localstack/localstack\n        ports:\n          - 4566:4566\n        env:\n          SERVICES: dynamodb,dynamodbstreams,lambda,cloudformation,logs,iam,cloudwatch,sqs\n        options: &gt;-\n          --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock\n    steps:\n      - uses: actions/checkout@v4\n      - run: pip install -e \".[dev]\"\n      - run: pytest -m integration\n        env:\n          AWS_ENDPOINT_URL: http://localhost:4566\n          AWS_ACCESS_KEY_ID: test\n          AWS_SECRET_ACCESS_KEY: test\n</code></pre>"},{"location":"infra/localstack/#debugging","title":"Debugging","text":""},{"location":"infra/localstack/#check-stack-status","title":"Check Stack Status","text":"<pre><code># List stacks\naws --endpoint-url=http://localhost:4566 cloudformation list-stacks\n\n# Describe stack\naws --endpoint-url=http://localhost:4566 cloudformation describe-stacks \\\n    --stack-name ZAEL-limiter\n</code></pre>"},{"location":"infra/localstack/#inspect-dynamodb","title":"Inspect DynamoDB","text":"<pre><code># List tables\naws --endpoint-url=http://localhost:4566 dynamodb list-tables\n\n# Scan table\naws --endpoint-url=http://localhost:4566 dynamodb scan \\\n    --table-name ZAEL-limiter\n</code></pre>"},{"location":"infra/localstack/#view-lambda-logs","title":"View Lambda Logs","text":"<pre><code># List functions\naws --endpoint-url=http://localhost:4566 lambda list-functions\n\n# Get logs\naws --endpoint-url=http://localhost:4566 logs tail \\\n    /aws/lambda/zae-limiter-aggregator\n</code></pre>"},{"location":"infra/localstack/#localstack-vs-dynamodb-local","title":"LocalStack vs DynamoDB Local","text":"Feature LocalStack DynamoDB Local DynamoDB Yes Yes Streams Yes Limited Lambda Yes No CloudFormation Yes No Cost Free Free Fidelity High Medium <p>Recommendation: Use LocalStack for full integration testing, DynamoDB Local for quick unit tests.</p>"},{"location":"infra/localstack/#troubleshooting","title":"Troubleshooting","text":""},{"location":"infra/localstack/#connection-refused","title":"Connection Refused","text":"<pre><code>Cannot connect to http://localhost:4566\n</code></pre> <p>Solution: Ensure LocalStack is running:</p> <pre><code>docker ps | grep localstack\n# or\ncurl http://localhost:4566/_localstack/health\n</code></pre>"},{"location":"infra/localstack/#lambda-not-executing","title":"Lambda Not Executing","text":"<p>Check Lambda logs:</p> <pre><code>docker logs localstack 2&gt;&amp;1 | grep -i lambda\n</code></pre> <p>Ensure the Lambda service is enabled:</p> <pre><code>docker run -e SERVICES=dynamodb,dynamodbstreams,lambda,...\n</code></pre>"},{"location":"infra/localstack/#slow-performance","title":"Slow Performance","text":"<p>LocalStack can be slow on first request. Consider:</p> <ul> <li>Pre-warming containers</li> <li>Using persistence for faster restarts</li> <li>Reducing DEBUG level</li> </ul>"},{"location":"infra/localstack/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment - Production deployment</li> <li>CloudFormation - Template customization</li> </ul>"}]}